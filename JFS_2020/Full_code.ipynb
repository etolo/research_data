{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Full_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM0QYuK5ylVO"
      },
      "source": [
        "# Predicting financial crisis with recurrent neural networks\n",
        "\n",
        "This file contains the program code behind the article Tölö, E., (2020). “Predicting financial crises with recurrent neural networks,” Journal of Financial Stability, Volume 49, August 2020, 100746. Available at: https://doi.org/10.1016/j.jfs.2020.100746.\n",
        "\n",
        "This code is made available for advanced users. The code is designed such that it can be mostly (but not completely) run sequentially starting from the top.\n",
        "\n",
        "First some libraries and data are imported. Then I define functions that transform the data (make it stationary, drop NaN values etc). Then more functions for the classification task, definition of models and model evaluation. After all the functions have been defined, the results are calculated by calling the function with specific input parameters - sometimes in a loop.\n",
        "\n",
        "Some of the code is probably dense and hard to follow. That is mainly because of storing all the intermediate results and statistics for the article, and running all different options in a loop.\n",
        "\n",
        "If you want to run some of the models included in the article, I recommend to extract the relevant parts of the code listed here, and build it into your own program.\n",
        " 1. Data processing (top part of the code)\n",
        " 2. Reshaping data to be suitable input to neural nets (search for reshape, there are one or two such short functions)\n",
        " 3. Inspect getModel to find out how the neural net that you are interested can be initialized.\n",
        " 4. Inspect fitModel to find out how the neural net that you are interested in can be fitted to the data.\n",
        " 5. There are also functions for calculating the AUC statistics, usefulness, etc. that you may find useful.\n",
        " 6. The cross-validation and sequential evaluation functions may also be of interest to you, albeit these parts of the code are somewhat complicated to read because of the factors mentioned earlier.\n",
        " 7. There is also functions that implement the calculation and analysis of Shapley values. Feel free to use them, but may be easier (safer) to build your own.\n",
        " \n",
        "**Cite as:**\n",
        " \n",
        "**Tölö, E., (2020). “Predicting financial crises with recurrent neural networks,” Journal of Financial Stability, Volume 49, August 2020, 100746. Available at: https://doi.org/10.1016/j.jfs.2020.100746**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgE2KrXfTMzF"
      },
      "source": [
        "#cd \"C:\\Users\\eerot\\Desktop\\NNCALC\"\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ3vl07TTVCn"
      },
      "source": [
        "#cd \"/content/gdrive/My Drive/Colab Notebooks/nnoutput\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "-0krMqWqBO1U",
        "outputId": "6dca5081-62ee-4d5c-adf6-5a4c29a3f2e5"
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "# %tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "print(tf.__version__)\n",
        "#from tf.keras.utils import to_categorical\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import calibration_curve\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import time \n",
        "\n",
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM,CuDNNLSTM, SimpleRNN, CuDNNGRU\n",
        "from keras.regularizers import l2 as l2_reg\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "#import tf.compat.v1.set_random_seed as set_random_seed\n",
        "\n",
        "from keras import backend as K \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lJTWnFFzRwGO",
        "outputId": "7d08d723-3012-49ac-86ba-6b200de6e67a"
      },
      "source": [
        "# https://stackoverflow.com/questions/2125702/how-to-suppress-console-output-in-python\n",
        "# With this, you can use context management wherever you want to suppress output:\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import sys, os\n",
        "\n",
        "@contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:  \n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout\n",
        "\n",
        "print(\"Now you see it\")\n",
        "with suppress_stdout():\n",
        "    print(\"Now you don't\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now you see it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5Qs4IZgypx_"
      },
      "source": [
        "## Import data (**you** need to modify this)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1ykqkc--FpS"
      },
      "source": [
        "# Upload the data file in Google Colab (if you run the code locally, you may skip this cell)\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "VpVEgkeu-I-N",
        "outputId": "dfee07b9-1c4d-4ce9-c235-2d385a649a9c"
      },
      "source": [
        "# Load the raw data file into dataframe\n",
        "#df = pd.read_csv('JSTdatasetR3.csv')\n",
        "#df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/nnoutput/JSTdatasetR3.csv')\n",
        "df = pd.read_csv('C:/Users/eerot/Desktop/NNCALC/JSTdatasetR3.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>country</th>\n",
              "      <th>iso</th>\n",
              "      <th>ifs</th>\n",
              "      <th>pop</th>\n",
              "      <th>rgdpmad</th>\n",
              "      <th>rgdppc</th>\n",
              "      <th>rconpc</th>\n",
              "      <th>gdp</th>\n",
              "      <th>iy</th>\n",
              "      <th>...</th>\n",
              "      <th>debtgdp</th>\n",
              "      <th>revenue</th>\n",
              "      <th>expenditure</th>\n",
              "      <th>xrusd</th>\n",
              "      <th>crisisJST</th>\n",
              "      <th>tloans</th>\n",
              "      <th>tmort</th>\n",
              "      <th>thh</th>\n",
              "      <th>tbus</th>\n",
              "      <th>hpnom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1870</td>\n",
              "      <td>Australia</td>\n",
              "      <td>AUS</td>\n",
              "      <td>193</td>\n",
              "      <td>1775.0</td>\n",
              "      <td>3273.239437</td>\n",
              "      <td>13.836157</td>\n",
              "      <td>21.449734</td>\n",
              "      <td>208.78</td>\n",
              "      <td>0.109266</td>\n",
              "      <td>...</td>\n",
              "      <td>0.172568</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.366946</td>\n",
              "      <td>0</td>\n",
              "      <td>54.792</td>\n",
              "      <td>1.680</td>\n",
              "      <td>1.680</td>\n",
              "      <td>53.112</td>\n",
              "      <td>0.492253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1871</td>\n",
              "      <td>Australia</td>\n",
              "      <td>AUS</td>\n",
              "      <td>193</td>\n",
              "      <td>1675.0</td>\n",
              "      <td>3298.507463</td>\n",
              "      <td>13.936864</td>\n",
              "      <td>19.930801</td>\n",
              "      <td>211.56</td>\n",
              "      <td>0.104579</td>\n",
              "      <td>...</td>\n",
              "      <td>0.191799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.369146</td>\n",
              "      <td>0</td>\n",
              "      <td>53.748</td>\n",
              "      <td>1.766</td>\n",
              "      <td>1.766</td>\n",
              "      <td>51.982</td>\n",
              "      <td>0.469877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1872</td>\n",
              "      <td>Australia</td>\n",
              "      <td>AUS</td>\n",
              "      <td>193</td>\n",
              "      <td>1722.0</td>\n",
              "      <td>3553.426249</td>\n",
              "      <td>15.044247</td>\n",
              "      <td>21.085006</td>\n",
              "      <td>227.40</td>\n",
              "      <td>0.130438</td>\n",
              "      <td>...</td>\n",
              "      <td>0.154920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.369239</td>\n",
              "      <td>0</td>\n",
              "      <td>55.822</td>\n",
              "      <td>1.470</td>\n",
              "      <td>1.470</td>\n",
              "      <td>54.352</td>\n",
              "      <td>0.484794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1873</td>\n",
              "      <td>Australia</td>\n",
              "      <td>AUS</td>\n",
              "      <td>193</td>\n",
              "      <td>1769.0</td>\n",
              "      <td>3823.629169</td>\n",
              "      <td>16.219443</td>\n",
              "      <td>23.254910</td>\n",
              "      <td>266.54</td>\n",
              "      <td>0.124986</td>\n",
              "      <td>...</td>\n",
              "      <td>0.142692</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.362405</td>\n",
              "      <td>0</td>\n",
              "      <td>65.380</td>\n",
              "      <td>1.364</td>\n",
              "      <td>1.364</td>\n",
              "      <td>64.016</td>\n",
              "      <td>0.469877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1874</td>\n",
              "      <td>Australia</td>\n",
              "      <td>AUS</td>\n",
              "      <td>193</td>\n",
              "      <td>1822.0</td>\n",
              "      <td>3834.796926</td>\n",
              "      <td>16.268228</td>\n",
              "      <td>23.458050</td>\n",
              "      <td>287.58</td>\n",
              "      <td>0.141960</td>\n",
              "      <td>...</td>\n",
              "      <td>0.194322</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.372223</td>\n",
              "      <td>0</td>\n",
              "      <td>71.478</td>\n",
              "      <td>1.434</td>\n",
              "      <td>1.434</td>\n",
              "      <td>70.044</td>\n",
              "      <td>0.566836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   year    country  iso  ifs     pop      rgdpmad     rgdppc     rconpc  \\\n",
              "0  1870  Australia  AUS  193  1775.0  3273.239437  13.836157  21.449734   \n",
              "1  1871  Australia  AUS  193  1675.0  3298.507463  13.936864  19.930801   \n",
              "2  1872  Australia  AUS  193  1722.0  3553.426249  15.044247  21.085006   \n",
              "3  1873  Australia  AUS  193  1769.0  3823.629169  16.219443  23.254910   \n",
              "4  1874  Australia  AUS  193  1822.0  3834.796926  16.268228  23.458050   \n",
              "\n",
              "      gdp        iy  ...   debtgdp  revenue  expenditure     xrusd  crisisJST  \\\n",
              "0  208.78  0.109266  ...  0.172568      NaN          NaN  0.366946          0   \n",
              "1  211.56  0.104579  ...  0.191799      NaN          NaN  0.369146          0   \n",
              "2  227.40  0.130438  ...  0.154920      NaN          NaN  0.369239          0   \n",
              "3  266.54  0.124986  ...  0.142692      NaN          NaN  0.362405          0   \n",
              "4  287.58  0.141960  ...  0.194322      NaN          NaN  0.372223          0   \n",
              "\n",
              "   tloans  tmort    thh    tbus     hpnom  \n",
              "0  54.792  1.680  1.680  53.112  0.492253  \n",
              "1  53.748  1.766  1.766  51.982  0.469877  \n",
              "2  55.822  1.470  1.470  54.352  0.484794  \n",
              "3  65.380  1.364  1.364  64.016  0.469877  \n",
              "4  71.478  1.434  1.434  70.044  0.566836  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysq38yw16xD3"
      },
      "source": [
        "## Function for initializing the data (includes making stationary, dropping NaN values and picking the interesting variables)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLb0DSyHtzKy"
      },
      "source": [
        "\n",
        "def init_data(df,start_year = 1970, end_year=2016, y_shift = 1, normalize = False):\n",
        "  # Define real gdp as nominal gdp / price level and real house price as nominal house price / price level\n",
        "  df2 = df\n",
        "  df2['tloansgdp'] = 100 * df2['tloans'] / df2['gdp']\n",
        "  df2['ca/gdp'] = 100 * df2['ca'] / df2['gdp']\n",
        "  df2['rgdp'] = df2['gdp'] / df2['cpi']\n",
        "  df2['rhp'] = df2['hpnom'] / df2['cpi']\n",
        "  df2['rsp'] = df2['stocks'] / df2['cpi']\n",
        "  df2['rtloans'] = df2['tloans'] / df2['cpi']\n",
        "  df2['rtmort'] = df2['tmort'] / df2['cpi']\n",
        "  df2['rthh'] = df2['thh'] / df2['cpi']\n",
        "  df2['rtbus'] = df2['tbus'] / df2['cpi']\n",
        "  # Define annual growth rates\n",
        "  df2['tloansgdp_g'] = 100 * ( df2['tloansgdp'] / df2['tloansgdp'].shift(+y_shift) - 1 )\n",
        "  df2['cpi_g'] = 100 * ( df2['cpi'] / df2['cpi'].shift(+y_shift) - 1 )\n",
        "  df2['rsp_g'] = 100 * ( df2['rsp'] / df2['rsp'].shift(+y_shift) - 1 )\n",
        "  df2['debtgdp_g'] = 100 * ( df2['debtgdp'] / df2['debtgdp'].shift(+y_shift) - 1 )\n",
        "  df2['rgdp_g'] = 100 * ( df2['rgdp'] / df2['rgdp'].shift(+y_shift) - 1 )\n",
        "  df2['rhp_g'] = 100 * ( df2['rhp'] / df2['rhp'].shift(+y_shift) - 1 )\n",
        "  df2['rtloans_g'] = 100 * ( df2['rtloans'] / df2['rtloans'].shift(+y_shift) - 1 )\n",
        "  df2['rtmort_g'] = 100 * ( df2['rtmort'] / df2['rtmort'].shift(+y_shift) - 1 )\n",
        "  df2['rthh_g'] = 100 * ( df2['rthh'] / df2['rthh'].shift(+y_shift) - 1 )\n",
        "  df2['rtbus_g'] = 100 * ( df2['rtbus'] / df2['rtbus'].shift(+y_shift) - 1 )\n",
        "  [n,k] = df2.shape\n",
        "  for i in range(2,n):\n",
        "    if df2.at[i, 'iso'] != df2.at[i-y_shift, 'iso']:\n",
        "      df2.at[i, 'tloansgdp_g'] = np.nan\n",
        "      df2.at[i, 'cpi_g'] = np.nan\n",
        "      df2.at[i, 'rsp_g'] = np.nan\n",
        "      df2.at[i, 'debtgdp_g'] = np.nan\n",
        "      df2.at[i, 'rgdp_g'] = np.nan\n",
        "      df2.at[i, 'rhp_g'] = np.nan\n",
        "      df2.at[i, 'rtloans_g'] = np.nan\n",
        "      df2.at[i, 'rtmort_g'] = np.nan\n",
        "      df2.at[i, 'rthh_g'] = np.nan\n",
        "      df2.at[i, 'rtbus_g'] = np.nan\n",
        "  # Keep only a set of variables\n",
        "  varlist = ['year','iso','cpi_g','rgdp_g','ca/gdp','debtgdp_g','tloansgdp_g','rsp_g','rhp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir','crisisJST']\n",
        "  df2=df2[varlist]\n",
        "  # And drop NaN values.\n",
        "  df2 = df2[df2['tloansgdp_g'].notna()]\n",
        "  \n",
        "  df2 = df2[df2['rgdp_g'].notna()]\n",
        "  df2 = df2[df2['ca/gdp'].notna()]\n",
        "  df2 = df2[df2['rhp_g'].notna()]\n",
        "  df2 = df2[df2['rsp_g'].notna()]\n",
        "  #df2 = df2[df2['rthh_g'].notna()]  \n",
        "  #df2 = df2[df2['cpi_g'].notna()]\n",
        "  #df2 = df2[df2['debtgdp_g'].notna()]\n",
        "  #df2 = df2[df2['rtloans_g'].notna()]\n",
        "  #df2 = df2[df2['rtmort_g'].notna()]\n",
        "  #df2 = df2[df2['rtbus_g'].notna()]\n",
        "  #df2 = df2[df2['ltrate'].notna()]\n",
        "  #df2 = df2[df2['stir'].notna()]\n",
        "  df2 = df2[df2.year >= start_year]\n",
        "  df2 = df2[df2.year <= end_year]\n",
        "  \n",
        "  for var in varlist[2:-1]:\n",
        "    mean = np.mean(df2[var])\n",
        "    std = np.std(df2[var])\n",
        "    print(var,'mean',mean,'std',std)\n",
        "    if normalize:\n",
        "      df2[var] = (df2[var]-mean)/std*10\n",
        "  \n",
        "  df2['cid'] = df2.iso.astype('category').cat.codes;\n",
        "  return df2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLLVTRPWp0v8"
      },
      "source": [
        "# Check whether a given year should be filtered out,\n",
        "# according to Schularick and Taylor's exclusion principle\n",
        "def jst_check(year,country):  \n",
        "  if(year>=1914 and year <= 1919): #Exclude WW1\n",
        "    return True\n",
        "  if(year>=1939 and year <= 1947):      #Exclude WW2\n",
        "    return True\n",
        "  if(country == 'DEU' and (year>=1920 and year <= 1925)): #Exclude post WW1 German crisis\n",
        "    return True\n",
        "  return False\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJY63OM6tapk"
      },
      "source": [
        "def add_dist2cris(df2,stfilter = False):\n",
        "  # Prehorizon = how many years in advance try to forecast the crisis, default is 1 year\n",
        "  # Postdrop = how many years starting with the crisis to exclude from the analysis, default is to drop 1 year\n",
        "  # which already ensures a decent cut before the model tries to predict crisis again (1 + number of lags for the features)\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  [n,k] = df2.shape\n",
        "  df2['disttonextcris'] = np.nan;\n",
        "  df2['disttoprevcris'] = np.nan;\n",
        "  df2['stfilt'] = 0\n",
        "  df2.head()\n",
        "  for i in range(1,n):\n",
        "    if(jst_check(df2.at[i, 'year'],df2.at[i, 'iso'])):\n",
        "       df2.at[i, 'stfilt'] = 1\n",
        "    for j in range(1,11):\n",
        "       if(i-j>=0):\n",
        "         if (df2.at[i, 'iso'] == df2.at[i-j, 'iso']) and (df2.at[i-j, 'crisisJST'] == 1):\n",
        "           df2.at[i,'disttoprevcris'] = j;\n",
        "    for j in range(0,11):   \n",
        "       if(i+j<n):\n",
        "         if (df2.at[i, 'iso'] == df2.at[i+j, 'iso']) and (df2.at[i+j, 'crisisJST'] == 1):\n",
        "           df2.at[i,'disttonextcris'] = j;\n",
        "        \n",
        "  #df2 = df2[df2['disttoprevcris'].notna()]\n",
        "  #df2 = df2[df2['disttonextcris'].notna()]\n",
        "  if(stfilter):\n",
        "    # Drop 1914-19, 1939-47 and \"Germany 1920-25\"\n",
        "    df2 = df2[df2.stfilt!=1]\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  return df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_uR5GUG68Iw"
      },
      "source": [
        "## A bit heavy function for the simple task of defining the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n7DjCub3Nq_"
      },
      "source": [
        "def add_precrisis(df2,fcast_horizon=1,postdrop=5, stfilter = False):\n",
        "  # Prehorizon = how many years in advance try to forecast the crisis, default is 1 year\n",
        "  # Postdrop = how many years starting with the crisis to exclude from the analysis, default is to drop 1 year\n",
        "  # which already ensures a decent cut before the model tries to predict crisis again (1 + number of lags for the features)\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  [n,k] = df2.shape\n",
        "  df2['precrisis'] = 0\n",
        "  df2['stfilt'] = 0\n",
        "  df2.head()\n",
        "  for i in range(1,n):\n",
        "    if(jst_check(df2.at[i, 'year'],df2.at[i, 'iso'])):\n",
        "       df2.at[i, 'stfilt'] = 1\n",
        "    for j in range(1,fcast_horizon+1):\n",
        "      if(i+j<n):\n",
        "        if (df2.at[i, 'iso'] == df2.at[i+j, 'iso']) and (df2.at[i+j, 'crisisJST'] == 1):\n",
        "          if j==fcast_horizon:\n",
        "            df2.at[i, 'precrisis'] =  1\n",
        "          if j!=fcast_horizon:\n",
        "            df2.at[i, 'precrisis'] = -1 # -1 means exclude periods between the crisis and the point of forecast\n",
        "    for j in range(0,postdrop):\n",
        "      if(i-j>=0):\n",
        "        if (df2.at[i, 'iso'] == df2.at[i-j, 'iso']) and (df2.at[i-j, 'crisisJST'] == 1):\n",
        "          df2.at[i, 'precrisis'] = -1 # means dropping years immediately following the crisis, default drops the crisis year only.\n",
        "\n",
        "  #df2 = df2[df2.precrisis!=-1]\n",
        "  \n",
        "  if(stfilter):\n",
        "    # Drop 1914-19, 1939-47 and \"Germany 1920-25\"\n",
        "    df2 = df2[df2.stfilt!=1]\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  return df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N3JMeZM63XE"
      },
      "source": [
        "def add_precrisis3(df2,fcast_horizon=1,postdrop=1, stfilter = False):\n",
        "  # Prehorizon = how many years in advance try to forecast the crisis, default is 1 year\n",
        "  # Postdrop = how many years starting with the crisis to exclude from the analysis, default is to drop 1 year\n",
        "  # which already ensures a decent cut before the model tries to predict crisis again (1 + number of lags for the features)\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  [n,k] = df2.shape\n",
        "  df2['precrisis'] = 0\n",
        "  df2['stfilt'] = 0\n",
        "  df2.head()\n",
        "  for i in range(1,n):\n",
        "    if(jst_check(df2.at[i, 'year'],df2.at[i, 'iso'])):\n",
        "       df2.at[i, 'stfilt'] = 1\n",
        "    for j in range(1,fcast_horizon+1):\n",
        "      if(i+j<n):\n",
        "        if (df2.at[i, 'iso'] == df2.at[i+j, 'iso']) and (df2.at[i+j, 'crisisJST'] == 1):\n",
        "          #if j==fcast_horizon:\n",
        "          df2.at[i, 'precrisis'] =  1\n",
        "          #if j!=fcast_horizon:\n",
        "            #df2.at[i, 'precrisis'] = -1 # -1 means exclude periods between the crisis and the point of forecast\n",
        "    for j in range(0,postdrop):\n",
        "      if(i-j>=0):\n",
        "        if (df2.at[i, 'iso'] == df2.at[i-j, 'iso']) and (df2.at[i-j, 'crisisJST'] == 1):\n",
        "          df2.at[i, 'precrisis'] = -1 # means dropping years immediately following the crisis, default drops the crisis year only.\n",
        "\n",
        "  df2 = df2[df2.precrisis!=-1]\n",
        "  \n",
        "  if(stfilter):\n",
        "    # Drop 1914-19, 1939-47 and \"Germany 1920-25\"\n",
        "    df2 = df2[df2.stfilt!=1]\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  return df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBfvcWW9uTL4"
      },
      "source": [
        "## Multiclass forecast\n",
        "Single forecast that gives the probabilities for different distances to crisis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JB0sF00uOb0"
      },
      "source": [
        "def add_precrisis2(df2,fcast_horizon=5,postdrop=1, stfilter = False):\n",
        "  # Prehorizon = how many years in advance try to forecast the crisis, default is 1 year\n",
        "  # Postdrop = how many years starting with the crisis to exclude from the analysis, default is to drop 1 year\n",
        "  # which already ensures a decent cut before the model tries to predict crisis again (1 + number of lags for the features)\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  [n,k] = df2.shape\n",
        "\n",
        "  df2['precrisis'] = 0\n",
        "  df2['stfilt'] = 0\n",
        "  df2.head()\n",
        "  for i in range(1,n):\n",
        "    if(jst_check(df2.at[i, 'year'],df2.at[i, 'iso'])):\n",
        "       df2.at[i, 'stfilt'] = 1\n",
        "    for j in range(1,fcast_horizon+1):\n",
        "      if(i+j<n):\n",
        "        if (df2.at[i, 'iso'] == df2.at[i+j, 'iso']) and (df2.at[i+j, 'crisisJST'] == 1):\n",
        "            df2.at[i, 'precrisis'] =  1\n",
        "    for j in range(0,postdrop):\n",
        "      if(i-j>=0):\n",
        "        if (df2.at[i, 'iso'] == df2.at[i-j, 'iso']) and (df2.at[i-j, 'crisisJST'] == 1):\n",
        "          df2.at[i, 'precrisis'] = -1 # means dropping years immediately following the crisis, default drops the crisis year only.\n",
        "\n",
        "  df2 = df2[df2.precrisis!=-1]\n",
        "  \n",
        "  if(stfilter):\n",
        "    # Drop 1914-19, 1939-47 and \"Germany 1920-25\"\n",
        "    df2 = df2[df2.stfilt!=1]\n",
        "  df2.reset_index(drop=True,inplace=True)\n",
        "  return df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_JPcUOkzHLQ"
      },
      "source": [
        "## Run the following code to confirm that the data processing works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3wAq1SD9y_uR",
        "outputId": "3e95f729-2c6c-4f84-bc65-420e672b251b"
      },
      "source": [
        "df2=init_data(df = df, start_year = 1970, y_shift = 1, normalize = True) # initializes the data\n",
        "df2=add_precrisis(df2,fcast_horizon=1,postdrop=5) # defines target variable\n",
        "pd.set_option('display.max_rows', 100)\n",
        "display(df2.head(100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 4.381527297045866 std 4.145862313755577\n",
            "rgdp_g mean 2.4965341343079355 std 2.9758598619611822\n",
            "ca/gdp mean 0.5210224414156656 std 4.371610578827272\n",
            "debtgdp_g mean 2.6697261889501607 std 10.501804250810867\n",
            "tloansgdp_g mean 1.809341956698375 std 5.007664719570753\n",
            "rsp_g mean 4.475527665001311 std 21.85636749066819\n",
            "rhp_g mean 2.029374535342964 std 7.241498800047153\n",
            "rtloans_g mean 4.34959199201426 std 5.964873391490648\n",
            "rtmort_g mean 5.600298140309238 std 6.838628764815888\n",
            "rthh_g mean 5.612714205861863 std 7.652298032694095\n",
            "rtbus_g mean 3.4901783095701417 std 8.281959067926582\n",
            "ltrate mean 6.923462557823677 std 3.8184266790062114\n",
            "stir mean 5.929161423517383 std 4.519009508156933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>iso</th>\n",
              "      <th>cpi_g</th>\n",
              "      <th>rgdp_g</th>\n",
              "      <th>ca/gdp</th>\n",
              "      <th>debtgdp_g</th>\n",
              "      <th>tloansgdp_g</th>\n",
              "      <th>rsp_g</th>\n",
              "      <th>rhp_g</th>\n",
              "      <th>rtloans_g</th>\n",
              "      <th>rtmort_g</th>\n",
              "      <th>rthh_g</th>\n",
              "      <th>rtbus_g</th>\n",
              "      <th>ltrate</th>\n",
              "      <th>stir</th>\n",
              "      <th>crisisJST</th>\n",
              "      <th>cid</th>\n",
              "      <th>precrisis</th>\n",
              "      <th>stfilt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1970</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-1.146981</td>\n",
              "      <td>19.960688</td>\n",
              "      <td>-5.564789</td>\n",
              "      <td>-7.398010</td>\n",
              "      <td>-9.743657</td>\n",
              "      <td>-11.108291</td>\n",
              "      <td>5.882485</td>\n",
              "      <td>1.270790</td>\n",
              "      <td>-0.631283</td>\n",
              "      <td>0.269924</td>\n",
              "      <td>1.449546</td>\n",
              "      <td>-0.724895</td>\n",
              "      <td>-1.211537</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1971</td>\n",
              "      <td>AUS</td>\n",
              "      <td>4.058287</td>\n",
              "      <td>2.155513</td>\n",
              "      <td>-5.120172</td>\n",
              "      <td>-9.783842</td>\n",
              "      <td>-3.768604</td>\n",
              "      <td>-8.879069</td>\n",
              "      <td>6.078516</td>\n",
              "      <td>-2.165845</td>\n",
              "      <td>-3.045783</td>\n",
              "      <td>-2.883962</td>\n",
              "      <td>-0.771107</td>\n",
              "      <td>-0.550303</td>\n",
              "      <td>-1.145151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1972</td>\n",
              "      <td>AUS</td>\n",
              "      <td>3.578159</td>\n",
              "      <td>5.802139</td>\n",
              "      <td>0.745518</td>\n",
              "      <td>-7.379162</td>\n",
              "      <td>-2.902038</td>\n",
              "      <td>9.142523</td>\n",
              "      <td>2.817973</td>\n",
              "      <td>0.410260</td>\n",
              "      <td>-0.682200</td>\n",
              "      <td>2.569146</td>\n",
              "      <td>-0.812115</td>\n",
              "      <td>-2.859282</td>\n",
              "      <td>-3.562716</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1973</td>\n",
              "      <td>AUS</td>\n",
              "      <td>12.263715</td>\n",
              "      <td>-1.135801</td>\n",
              "      <td>0.107051</td>\n",
              "      <td>-13.010876</td>\n",
              "      <td>23.314275</td>\n",
              "      <td>-18.014139</td>\n",
              "      <td>10.969530</td>\n",
              "      <td>19.420961</td>\n",
              "      <td>0.630922</td>\n",
              "      <td>11.992742</td>\n",
              "      <td>15.885606</td>\n",
              "      <td>0.025850</td>\n",
              "      <td>-1.585882</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1974</td>\n",
              "      <td>AUS</td>\n",
              "      <td>25.877901</td>\n",
              "      <td>9.310465</td>\n",
              "      <td>-9.213580</td>\n",
              "      <td>-14.965624</td>\n",
              "      <td>8.557917</td>\n",
              "      <td>-20.333482</td>\n",
              "      <td>4.040068</td>\n",
              "      <td>12.294467</td>\n",
              "      <td>-0.983021</td>\n",
              "      <td>0.013007</td>\n",
              "      <td>14.378099</td>\n",
              "      <td>5.534227</td>\n",
              "      <td>6.948437</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1975</td>\n",
              "      <td>AUS</td>\n",
              "      <td>25.785819</td>\n",
              "      <td>0.243081</td>\n",
              "      <td>-3.779526</td>\n",
              "      <td>-3.170679</td>\n",
              "      <td>-7.845865</td>\n",
              "      <td>10.009444</td>\n",
              "      <td>-6.301269</td>\n",
              "      <td>-6.630106</td>\n",
              "      <td>8.777480</td>\n",
              "      <td>5.237373</td>\n",
              "      <td>-9.987785</td>\n",
              "      <td>7.380537</td>\n",
              "      <td>3.498197</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1976</td>\n",
              "      <td>AUS</td>\n",
              "      <td>22.051857</td>\n",
              "      <td>1.780144</td>\n",
              "      <td>-6.104396</td>\n",
              "      <td>-4.885091</td>\n",
              "      <td>-3.267810</td>\n",
              "      <td>-8.303448</td>\n",
              "      <td>-3.507338</td>\n",
              "      <td>-1.919817</td>\n",
              "      <td>10.783086</td>\n",
              "      <td>5.472603</td>\n",
              "      <td>-5.488826</td>\n",
              "      <td>8.137830</td>\n",
              "      <td>3.501885</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1977</td>\n",
              "      <td>AUS</td>\n",
              "      <td>19.100283</td>\n",
              "      <td>0.986560</td>\n",
              "      <td>-7.624898</td>\n",
              "      <td>-6.001942</td>\n",
              "      <td>-2.680842</td>\n",
              "      <td>-4.384221</td>\n",
              "      <td>-6.578038</td>\n",
              "      <td>-1.809895</td>\n",
              "      <td>-2.027822</td>\n",
              "      <td>2.824991</td>\n",
              "      <td>-4.164645</td>\n",
              "      <td>8.650694</td>\n",
              "      <td>5.744264</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1978</td>\n",
              "      <td>AUS</td>\n",
              "      <td>8.543785</td>\n",
              "      <td>-4.419868</td>\n",
              "      <td>-9.650430</td>\n",
              "      <td>1.407891</td>\n",
              "      <td>1.014938</td>\n",
              "      <td>2.071211</td>\n",
              "      <td>-5.995614</td>\n",
              "      <td>-1.380387</td>\n",
              "      <td>1.473412</td>\n",
              "      <td>3.856219</td>\n",
              "      <td>-4.653355</td>\n",
              "      <td>5.595334</td>\n",
              "      <td>6.013498</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1979</td>\n",
              "      <td>AUS</td>\n",
              "      <td>11.357044</td>\n",
              "      <td>3.764981</td>\n",
              "      <td>-5.706581</td>\n",
              "      <td>-0.386258</td>\n",
              "      <td>1.476384</td>\n",
              "      <td>7.549847</td>\n",
              "      <td>-5.675181</td>\n",
              "      <td>3.199057</td>\n",
              "      <td>-0.647842</td>\n",
              "      <td>1.062409</td>\n",
              "      <td>3.171145</td>\n",
              "      <td>7.400179</td>\n",
              "      <td>6.522459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1980</td>\n",
              "      <td>AUS</td>\n",
              "      <td>13.857299</td>\n",
              "      <td>1.507345</td>\n",
              "      <td>-6.954997</td>\n",
              "      <td>-8.940313</td>\n",
              "      <td>-8.231696</td>\n",
              "      <td>11.485277</td>\n",
              "      <td>7.054865</td>\n",
              "      <td>-6.346192</td>\n",
              "      <td>-2.143388</td>\n",
              "      <td>1.128799</td>\n",
              "      <td>-9.557069</td>\n",
              "      <td>12.371686</td>\n",
              "      <td>10.485348</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1981</td>\n",
              "      <td>AUS</td>\n",
              "      <td>12.808498</td>\n",
              "      <td>2.354513</td>\n",
              "      <td>-11.196483</td>\n",
              "      <td>-13.265131</td>\n",
              "      <td>1.230513</td>\n",
              "      <td>-12.988408</td>\n",
              "      <td>3.711891</td>\n",
              "      <td>2.264429</td>\n",
              "      <td>-7.308271</td>\n",
              "      <td>-0.471860</td>\n",
              "      <td>3.177876</td>\n",
              "      <td>18.423480</td>\n",
              "      <td>16.201940</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1982</td>\n",
              "      <td>AUS</td>\n",
              "      <td>16.315013</td>\n",
              "      <td>4.569948</td>\n",
              "      <td>-11.030107</td>\n",
              "      <td>-10.370118</td>\n",
              "      <td>-14.943063</td>\n",
              "      <td>-14.246662</td>\n",
              "      <td>-9.475619</td>\n",
              "      <td>-10.705260</td>\n",
              "      <td>-10.107373</td>\n",
              "      <td>-5.605336</td>\n",
              "      <td>-10.454428</td>\n",
              "      <td>22.133560</td>\n",
              "      <td>19.281523</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1983</td>\n",
              "      <td>AUS</td>\n",
              "      <td>13.825913</td>\n",
              "      <td>-15.759982</td>\n",
              "      <td>-8.765853</td>\n",
              "      <td>5.701632</td>\n",
              "      <td>4.361569</td>\n",
              "      <td>18.565896</td>\n",
              "      <td>-8.856695</td>\n",
              "      <td>-4.421102</td>\n",
              "      <td>-3.099680</td>\n",
              "      <td>2.244394</td>\n",
              "      <td>-8.903899</td>\n",
              "      <td>18.237976</td>\n",
              "      <td>11.355745</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1984</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-1.040412</td>\n",
              "      <td>20.420806</td>\n",
              "      <td>-11.161047</td>\n",
              "      <td>4.849236</td>\n",
              "      <td>8.158819</td>\n",
              "      <td>-6.579494</td>\n",
              "      <td>8.962887</td>\n",
              "      <td>17.811443</td>\n",
              "      <td>9.215917</td>\n",
              "      <td>13.853307</td>\n",
              "      <td>12.200642</td>\n",
              "      <td>17.288632</td>\n",
              "      <td>11.187935</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1985</td>\n",
              "      <td>AUS</td>\n",
              "      <td>5.686431</td>\n",
              "      <td>2.234182</td>\n",
              "      <td>-12.985696</td>\n",
              "      <td>5.112397</td>\n",
              "      <td>27.741109</td>\n",
              "      <td>11.456200</td>\n",
              "      <td>0.485708</td>\n",
              "      <td>25.162879</td>\n",
              "      <td>19.416077</td>\n",
              "      <td>14.429446</td>\n",
              "      <td>22.876930</td>\n",
              "      <td>18.412568</td>\n",
              "      <td>21.002033</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1986</td>\n",
              "      <td>AUS</td>\n",
              "      <td>11.343867</td>\n",
              "      <td>-3.238049</td>\n",
              "      <td>-13.241211</td>\n",
              "      <td>3.593916</td>\n",
              "      <td>8.614093</td>\n",
              "      <td>13.755016</td>\n",
              "      <td>-5.140914</td>\n",
              "      <td>5.700366</td>\n",
              "      <td>3.735620</td>\n",
              "      <td>-5.066015</td>\n",
              "      <td>13.016941</td>\n",
              "      <td>17.004920</td>\n",
              "      <td>20.928270</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1987</td>\n",
              "      <td>AUS</td>\n",
              "      <td>9.906788</td>\n",
              "      <td>-4.251388</td>\n",
              "      <td>-9.456970</td>\n",
              "      <td>-8.030207</td>\n",
              "      <td>8.640294</td>\n",
              "      <td>-10.045232</td>\n",
              "      <td>-7.243171</td>\n",
              "      <td>5.186127</td>\n",
              "      <td>15.656999</td>\n",
              "      <td>5.415006</td>\n",
              "      <td>2.076235</td>\n",
              "      <td>16.415672</td>\n",
              "      <td>15.200614</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1988</td>\n",
              "      <td>AUS</td>\n",
              "      <td>6.874911</td>\n",
              "      <td>10.965370</td>\n",
              "      <td>-10.497578</td>\n",
              "      <td>9.347772</td>\n",
              "      <td>19.754780</td>\n",
              "      <td>0.313159</td>\n",
              "      <td>16.922138</td>\n",
              "      <td>23.111883</td>\n",
              "      <td>16.427402</td>\n",
              "      <td>7.844321</td>\n",
              "      <td>25.612176</td>\n",
              "      <td>13.567641</td>\n",
              "      <td>13.747493</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1989</td>\n",
              "      <td>AUS</td>\n",
              "      <td>7.665220</td>\n",
              "      <td>10.172263</td>\n",
              "      <td>-15.705788</td>\n",
              "      <td>-10.402393</td>\n",
              "      <td>52.116179</td>\n",
              "      <td>-0.611388</td>\n",
              "      <td>19.123944</td>\n",
              "      <td>51.338810</td>\n",
              "      <td>7.650941</td>\n",
              "      <td>42.149463</td>\n",
              "      <td>34.863072</td>\n",
              "      <td>16.983096</td>\n",
              "      <td>24.055799</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1990</td>\n",
              "      <td>AUS</td>\n",
              "      <td>6.972587</td>\n",
              "      <td>-0.257738</td>\n",
              "      <td>-12.534361</td>\n",
              "      <td>-7.528232</td>\n",
              "      <td>6.050461</td>\n",
              "      <td>-14.715158</td>\n",
              "      <td>-10.114036</td>\n",
              "      <td>5.073961</td>\n",
              "      <td>16.962974</td>\n",
              "      <td>-2.187257</td>\n",
              "      <td>8.588867</td>\n",
              "      <td>16.385119</td>\n",
              "      <td>18.193526</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1991</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-2.795142</td>\n",
              "      <td>-10.236995</td>\n",
              "      <td>-8.718710</td>\n",
              "      <td>3.355333</td>\n",
              "      <td>6.589436</td>\n",
              "      <td>9.393006</td>\n",
              "      <td>-6.272962</td>\n",
              "      <td>0.304406</td>\n",
              "      <td>3.958853</td>\n",
              "      <td>-2.123848</td>\n",
              "      <td>1.835107</td>\n",
              "      <td>9.866291</td>\n",
              "      <td>8.910519</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1992</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-8.190337</td>\n",
              "      <td>-5.162732</td>\n",
              "      <td>-8.819987</td>\n",
              "      <td>15.066346</td>\n",
              "      <td>-0.629529</td>\n",
              "      <td>-5.279067</td>\n",
              "      <td>-0.694516</td>\n",
              "      <td>-3.153418</td>\n",
              "      <td>23.224496</td>\n",
              "      <td>13.384440</td>\n",
              "      <td>-15.354148</td>\n",
              "      <td>6.014355</td>\n",
              "      <td>0.743169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1993</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-6.195118</td>\n",
              "      <td>2.046905</td>\n",
              "      <td>-8.214734</td>\n",
              "      <td>8.576640</td>\n",
              "      <td>0.879148</td>\n",
              "      <td>15.221341</td>\n",
              "      <td>-1.456920</td>\n",
              "      <td>1.803101</td>\n",
              "      <td>18.466387</td>\n",
              "      <td>10.421003</td>\n",
              "      <td>-8.653832</td>\n",
              "      <td>0.935911</td>\n",
              "      <td>-2.052429</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1994</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-5.997773</td>\n",
              "      <td>2.184083</td>\n",
              "      <td>-11.759766</td>\n",
              "      <td>1.009915</td>\n",
              "      <td>10.321091</td>\n",
              "      <td>-8.288261</td>\n",
              "      <td>-0.552033</td>\n",
              "      <td>10.049247</td>\n",
              "      <td>22.960687</td>\n",
              "      <td>14.826910</td>\n",
              "      <td>-2.228664</td>\n",
              "      <td>5.547322</td>\n",
              "      <td>-0.520014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1995</td>\n",
              "      <td>AUS</td>\n",
              "      <td>0.619063</td>\n",
              "      <td>-3.367527</td>\n",
              "      <td>-12.822786</td>\n",
              "      <td>-3.540912</td>\n",
              "      <td>7.051926</td>\n",
              "      <td>2.560637</td>\n",
              "      <td>-6.666764</td>\n",
              "      <td>4.300737</td>\n",
              "      <td>2.662935</td>\n",
              "      <td>1.149875</td>\n",
              "      <td>4.907020</td>\n",
              "      <td>5.990511</td>\n",
              "      <td>3.794297</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1996</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-4.267257</td>\n",
              "      <td>5.131673</td>\n",
              "      <td>-9.156802</td>\n",
              "      <td>-8.067670</td>\n",
              "      <td>2.287005</td>\n",
              "      <td>1.272636</td>\n",
              "      <td>-4.557304</td>\n",
              "      <td>4.606193</td>\n",
              "      <td>3.333490</td>\n",
              "      <td>3.086006</td>\n",
              "      <td>2.768051</td>\n",
              "      <td>3.367210</td>\n",
              "      <td>2.405977</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1997</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-10.025724</td>\n",
              "      <td>8.358913</td>\n",
              "      <td>-7.883441</td>\n",
              "      <td>-13.614605</td>\n",
              "      <td>5.516048</td>\n",
              "      <td>1.462694</td>\n",
              "      <td>1.167146</td>\n",
              "      <td>9.109801</td>\n",
              "      <td>4.392485</td>\n",
              "      <td>4.314917</td>\n",
              "      <td>9.202726</td>\n",
              "      <td>0.082379</td>\n",
              "      <td>-1.413851</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1998</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-8.496489</td>\n",
              "      <td>7.968009</td>\n",
              "      <td>-12.230239</td>\n",
              "      <td>-10.458927</td>\n",
              "      <td>3.923895</td>\n",
              "      <td>0.976382</td>\n",
              "      <td>9.604243</td>\n",
              "      <td>7.504147</td>\n",
              "      <td>5.437575</td>\n",
              "      <td>5.019406</td>\n",
              "      <td>5.306469</td>\n",
              "      <td>-3.746286</td>\n",
              "      <td>-2.417226</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1999</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-7.172277</td>\n",
              "      <td>4.712602</td>\n",
              "      <td>-13.645324</td>\n",
              "      <td>-7.216258</td>\n",
              "      <td>10.534472</td>\n",
              "      <td>2.755125</td>\n",
              "      <td>4.109797</td>\n",
              "      <td>11.584864</td>\n",
              "      <td>8.103151</td>\n",
              "      <td>7.659344</td>\n",
              "      <td>8.988337</td>\n",
              "      <td>-2.394050</td>\n",
              "      <td>-2.590637</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2000</td>\n",
              "      <td>AUS</td>\n",
              "      <td>0.182043</td>\n",
              "      <td>-1.729211</td>\n",
              "      <td>-10.502050</td>\n",
              "      <td>-15.311180</td>\n",
              "      <td>3.879216</td>\n",
              "      <td>-3.253801</td>\n",
              "      <td>4.476657</td>\n",
              "      <td>2.445379</td>\n",
              "      <td>9.294763</td>\n",
              "      <td>4.975960</td>\n",
              "      <td>-3.867364</td>\n",
              "      <td>-1.594618</td>\n",
              "      <td>0.103834</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>2001</td>\n",
              "      <td>AUS</td>\n",
              "      <td>0.061441</td>\n",
              "      <td>-0.899968</td>\n",
              "      <td>-6.096697</td>\n",
              "      <td>-14.138773</td>\n",
              "      <td>3.108166</td>\n",
              "      <td>-1.025303</td>\n",
              "      <td>2.361208</td>\n",
              "      <td>2.212865</td>\n",
              "      <td>4.346188</td>\n",
              "      <td>2.812352</td>\n",
              "      <td>-1.586660</td>\n",
              "      <td>-3.426014</td>\n",
              "      <td>-2.498272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>2002</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-3.214114</td>\n",
              "      <td>3.940542</td>\n",
              "      <td>-9.973966</td>\n",
              "      <td>-14.266789</td>\n",
              "      <td>12.402898</td>\n",
              "      <td>-8.788075</td>\n",
              "      <td>20.534418</td>\n",
              "      <td>12.798543</td>\n",
              "      <td>10.011695</td>\n",
              "      <td>9.735544</td>\n",
              "      <td>7.964871</td>\n",
              "      <td>-2.827093</td>\n",
              "      <td>-3.050067</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>2003</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-3.903958</td>\n",
              "      <td>3.119731</td>\n",
              "      <td>-13.933136</td>\n",
              "      <td>-14.263119</td>\n",
              "      <td>19.054800</td>\n",
              "      <td>1.055840</td>\n",
              "      <td>17.941823</td>\n",
              "      <td>18.131905</td>\n",
              "      <td>15.617686</td>\n",
              "      <td>12.583690</td>\n",
              "      <td>13.928432</td>\n",
              "      <td>-4.076776</td>\n",
              "      <td>-2.478408</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>2004</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-4.999026</td>\n",
              "      <td>8.887566</td>\n",
              "      <td>-15.500060</td>\n",
              "      <td>-11.669258</td>\n",
              "      <td>9.427225</td>\n",
              "      <td>7.094944</td>\n",
              "      <td>2.873849</td>\n",
              "      <td>12.837954</td>\n",
              "      <td>7.396158</td>\n",
              "      <td>6.333877</td>\n",
              "      <td>13.665697</td>\n",
              "      <td>-3.490150</td>\n",
              "      <td>-1.502899</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>2005</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-4.154811</td>\n",
              "      <td>5.937734</td>\n",
              "      <td>-14.736039</td>\n",
              "      <td>-10.922501</td>\n",
              "      <td>9.165307</td>\n",
              "      <td>4.610072</td>\n",
              "      <td>-4.456023</td>\n",
              "      <td>11.040926</td>\n",
              "      <td>5.128696</td>\n",
              "      <td>4.647109</td>\n",
              "      <td>12.703302</td>\n",
              "      <td>-4.146968</td>\n",
              "      <td>-1.043727</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>2006</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-1.996032</td>\n",
              "      <td>6.689591</td>\n",
              "      <td>-14.466116</td>\n",
              "      <td>-10.690783</td>\n",
              "      <td>7.276690</td>\n",
              "      <td>4.790292</td>\n",
              "      <td>2.900914</td>\n",
              "      <td>9.783338</td>\n",
              "      <td>1.922934</td>\n",
              "      <td>2.378619</td>\n",
              "      <td>13.623863</td>\n",
              "      <td>-3.497750</td>\n",
              "      <td>-0.274754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>2007</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-4.885660</td>\n",
              "      <td>13.165746</td>\n",
              "      <td>-16.506554</td>\n",
              "      <td>-5.238467</td>\n",
              "      <td>17.145339</td>\n",
              "      <td>2.180495</td>\n",
              "      <td>9.303411</td>\n",
              "      <td>22.006890</td>\n",
              "      <td>5.910306</td>\n",
              "      <td>5.903977</td>\n",
              "      <td>30.728116</td>\n",
              "      <td>-2.432787</td>\n",
              "      <td>1.014304</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>2008</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-0.080869</td>\n",
              "      <td>4.701514</td>\n",
              "      <td>-12.347903</td>\n",
              "      <td>17.767612</td>\n",
              "      <td>9.484804</td>\n",
              "      <td>-22.057095</td>\n",
              "      <td>-2.772627</td>\n",
              "      <td>10.663389</td>\n",
              "      <td>9.974786</td>\n",
              "      <td>4.573507</td>\n",
              "      <td>11.288813</td>\n",
              "      <td>-2.895220</td>\n",
              "      <td>1.643071</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>2009</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-6.299117</td>\n",
              "      <td>8.337171</td>\n",
              "      <td>-11.741719</td>\n",
              "      <td>38.146660</td>\n",
              "      <td>-1.432022</td>\n",
              "      <td>11.025587</td>\n",
              "      <td>-0.539772</td>\n",
              "      <td>2.975030</td>\n",
              "      <td>12.682789</td>\n",
              "      <td>8.782551</td>\n",
              "      <td>-6.481967</td>\n",
              "      <td>-4.933840</td>\n",
              "      <td>-5.866301</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2010</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-3.662754</td>\n",
              "      <td>-7.605248</td>\n",
              "      <td>-9.321683</td>\n",
              "      <td>18.703458</td>\n",
              "      <td>-2.615576</td>\n",
              "      <td>-4.466347</td>\n",
              "      <td>9.577509</td>\n",
              "      <td>-6.061417</td>\n",
              "      <td>2.485644</td>\n",
              "      <td>0.858030</td>\n",
              "      <td>-13.189154</td>\n",
              "      <td>-4.078698</td>\n",
              "      <td>-3.503245</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>2011</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-2.536330</td>\n",
              "      <td>9.086065</td>\n",
              "      <td>-7.967367</td>\n",
              "      <td>14.860417</td>\n",
              "      <td>-9.340273</td>\n",
              "      <td>-9.943967</td>\n",
              "      <td>-10.710863</td>\n",
              "      <td>-3.631714</td>\n",
              "      <td>-2.951844</td>\n",
              "      <td>-3.903213</td>\n",
              "      <td>-2.483033</td>\n",
              "      <td>-5.352674</td>\n",
              "      <td>-2.736115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>2012</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-6.439016</td>\n",
              "      <td>4.998284</td>\n",
              "      <td>-10.630001</td>\n",
              "      <td>11.656849</td>\n",
              "      <td>-5.660050</td>\n",
              "      <td>3.746158</td>\n",
              "      <td>-6.178669</td>\n",
              "      <td>-2.399877</td>\n",
              "      <td>-0.978929</td>\n",
              "      <td>-1.790007</td>\n",
              "      <td>-3.432286</td>\n",
              "      <td>-9.282084</td>\n",
              "      <td>-4.940230</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>2013</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-4.658928</td>\n",
              "      <td>-8.555873</td>\n",
              "      <td>-8.509501</td>\n",
              "      <td>7.865988</td>\n",
              "      <td>5.898326</td>\n",
              "      <td>3.613215</td>\n",
              "      <td>2.825502</td>\n",
              "      <td>0.606046</td>\n",
              "      <td>-1.486788</td>\n",
              "      <td>-1.872293</td>\n",
              "      <td>2.612446</td>\n",
              "      <td>-8.450590</td>\n",
              "      <td>-7.062746</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>2014</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-4.506969</td>\n",
              "      <td>-3.234043</td>\n",
              "      <td>-7.772930</td>\n",
              "      <td>7.995922</td>\n",
              "      <td>3.537093</td>\n",
              "      <td>-2.678964</td>\n",
              "      <td>6.007231</td>\n",
              "      <td>1.374826</td>\n",
              "      <td>-0.409639</td>\n",
              "      <td>-1.130144</td>\n",
              "      <td>2.919190</td>\n",
              "      <td>-8.558619</td>\n",
              "      <td>-7.588303</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2015</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-6.986550</td>\n",
              "      <td>-7.666753</td>\n",
              "      <td>-12.023080</td>\n",
              "      <td>6.654590</td>\n",
              "      <td>16.734126</td>\n",
              "      <td>-3.676192</td>\n",
              "      <td>7.459997</td>\n",
              "      <td>10.187246</td>\n",
              "      <td>0.796472</td>\n",
              "      <td>0.419744</td>\n",
              "      <td>17.764262</td>\n",
              "      <td>-11.034006</td>\n",
              "      <td>-8.453168</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>2016</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-7.488255</td>\n",
              "      <td>-4.919349</td>\n",
              "      <td>-7.230796</td>\n",
              "      <td>6.193710</td>\n",
              "      <td>4.586518</td>\n",
              "      <td>0.528555</td>\n",
              "      <td>2.955877</td>\n",
              "      <td>1.394044</td>\n",
              "      <td>0.889275</td>\n",
              "      <td>-0.141399</td>\n",
              "      <td>1.435941</td>\n",
              "      <td>-12.020451</td>\n",
              "      <td>-9.286684</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1970</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-1.146828</td>\n",
              "      <td>15.411561</td>\n",
              "      <td>5.272416</td>\n",
              "      <td>-10.102287</td>\n",
              "      <td>-3.340061</td>\n",
              "      <td>-3.868203</td>\n",
              "      <td>-9.412082</td>\n",
              "      <td>4.827669</td>\n",
              "      <td>-0.337402</td>\n",
              "      <td>-0.317753</td>\n",
              "      <td>6.112709</td>\n",
              "      <td>2.321735</td>\n",
              "      <td>4.272703</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1971</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-0.097715</td>\n",
              "      <td>8.151406</td>\n",
              "      <td>5.577327</td>\n",
              "      <td>-5.999140</td>\n",
              "      <td>-0.859738</td>\n",
              "      <td>-2.145056</td>\n",
              "      <td>-9.566890</td>\n",
              "      <td>3.385436</td>\n",
              "      <td>-0.387625</td>\n",
              "      <td>-0.362633</td>\n",
              "      <td>4.338212</td>\n",
              "      <td>1.117050</td>\n",
              "      <td>-1.856959</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1972</td>\n",
              "      <td>BEL</td>\n",
              "      <td>2.570297</td>\n",
              "      <td>11.996081</td>\n",
              "      <td>6.275131</td>\n",
              "      <td>-4.465394</td>\n",
              "      <td>-3.366274</td>\n",
              "      <td>6.460081</td>\n",
              "      <td>1.548449</td>\n",
              "      <td>3.098024</td>\n",
              "      <td>3.095787</td>\n",
              "      <td>2.750389</td>\n",
              "      <td>2.021942</td>\n",
              "      <td>0.305198</td>\n",
              "      <td>-4.578794</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1973</td>\n",
              "      <td>BEL</td>\n",
              "      <td>6.208439</td>\n",
              "      <td>12.583766</td>\n",
              "      <td>4.583677</td>\n",
              "      <td>-7.767481</td>\n",
              "      <td>-1.412094</td>\n",
              "      <td>-3.820205</td>\n",
              "      <td>6.683969</td>\n",
              "      <td>5.134559</td>\n",
              "      <td>5.012123</td>\n",
              "      <td>4.462962</td>\n",
              "      <td>3.377974</td>\n",
              "      <td>1.378938</td>\n",
              "      <td>0.510817</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1974</td>\n",
              "      <td>BEL</td>\n",
              "      <td>20.023560</td>\n",
              "      <td>5.423082</td>\n",
              "      <td>2.724760</td>\n",
              "      <td>-10.494454</td>\n",
              "      <td>-13.219663</td>\n",
              "      <td>-18.962056</td>\n",
              "      <td>0.061707</td>\n",
              "      <td>-8.797473</td>\n",
              "      <td>-5.792507</td>\n",
              "      <td>-5.192814</td>\n",
              "      <td>-7.485525</td>\n",
              "      <td>4.600160</td>\n",
              "      <td>9.472958</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1975</td>\n",
              "      <td>BEL</td>\n",
              "      <td>20.202825</td>\n",
              "      <td>-14.738080</td>\n",
              "      <td>1.280485</td>\n",
              "      <td>-0.098749</td>\n",
              "      <td>2.962465</td>\n",
              "      <td>-0.583494</td>\n",
              "      <td>0.490590</td>\n",
              "      <td>-5.043310</td>\n",
              "      <td>-7.564112</td>\n",
              "      <td>-6.776042</td>\n",
              "      <td>-1.771630</td>\n",
              "      <td>4.233517</td>\n",
              "      <td>2.347502</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1976</td>\n",
              "      <td>BEL</td>\n",
              "      <td>11.559411</td>\n",
              "      <td>5.915348</td>\n",
              "      <td>-2.234442</td>\n",
              "      <td>-1.995276</td>\n",
              "      <td>-3.172849</td>\n",
              "      <td>-10.399587</td>\n",
              "      <td>15.938259</td>\n",
              "      <td>0.229910</td>\n",
              "      <td>0.642474</td>\n",
              "      <td>0.557931</td>\n",
              "      <td>-0.173404</td>\n",
              "      <td>5.569146</td>\n",
              "      <td>8.499293</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1977</td>\n",
              "      <td>BEL</td>\n",
              "      <td>6.558893</td>\n",
              "      <td>-5.165502</td>\n",
              "      <td>-5.129124</td>\n",
              "      <td>4.276602</td>\n",
              "      <td>7.355722</td>\n",
              "      <td>-6.764182</td>\n",
              "      <td>12.463945</td>\n",
              "      <td>3.613317</td>\n",
              "      <td>4.626757</td>\n",
              "      <td>4.118567</td>\n",
              "      <td>1.584855</td>\n",
              "      <td>4.914426</td>\n",
              "      <td>2.546661</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1978</td>\n",
              "      <td>BEL</td>\n",
              "      <td>0.205957</td>\n",
              "      <td>1.060989</td>\n",
              "      <td>-3.511039</td>\n",
              "      <td>4.174329</td>\n",
              "      <td>6.740012</td>\n",
              "      <td>-0.781379</td>\n",
              "      <td>8.671841</td>\n",
              "      <td>6.358885</td>\n",
              "      <td>9.398381</td>\n",
              "      <td>8.382824</td>\n",
              "      <td>1.950179</td>\n",
              "      <td>5.254880</td>\n",
              "      <td>2.679434</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1979</td>\n",
              "      <td>BEL</td>\n",
              "      <td>0.218087</td>\n",
              "      <td>-0.986943</td>\n",
              "      <td>-8.198560</td>\n",
              "      <td>4.637248</td>\n",
              "      <td>11.367871</td>\n",
              "      <td>-2.579156</td>\n",
              "      <td>3.861518</td>\n",
              "      <td>9.254997</td>\n",
              "      <td>6.440715</td>\n",
              "      <td>5.739655</td>\n",
              "      <td>7.567761</td>\n",
              "      <td>7.245229</td>\n",
              "      <td>10.690039</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1980</td>\n",
              "      <td>BEL</td>\n",
              "      <td>5.470368</td>\n",
              "      <td>-0.696856</td>\n",
              "      <td>-10.305178</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.711836</td>\n",
              "      <td>-12.509498</td>\n",
              "      <td>-10.350693</td>\n",
              "      <td>10.564700</td>\n",
              "      <td>-2.748351</td>\n",
              "      <td>-2.472349</td>\n",
              "      <td>15.635569</td>\n",
              "      <td>13.032953</td>\n",
              "      <td>18.036781</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1981</td>\n",
              "      <td>BEL</td>\n",
              "      <td>7.838847</td>\n",
              "      <td>-17.090543</td>\n",
              "      <td>-10.520202</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.403009</td>\n",
              "      <td>-4.223396</td>\n",
              "      <td>-19.875871</td>\n",
              "      <td>-4.259748</td>\n",
              "      <td>7.821430</td>\n",
              "      <td>-12.279059</td>\n",
              "      <td>2.993157</td>\n",
              "      <td>17.066027</td>\n",
              "      <td>20.625844</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1982</td>\n",
              "      <td>BEL</td>\n",
              "      <td>10.476571</td>\n",
              "      <td>-9.975914</td>\n",
              "      <td>-7.793518</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-6.576755</td>\n",
              "      <td>1.393845</td>\n",
              "      <td>-18.450216</td>\n",
              "      <td>-10.559854</td>\n",
              "      <td>-11.141098</td>\n",
              "      <td>-10.511970</td>\n",
              "      <td>-6.174546</td>\n",
              "      <td>17.039839</td>\n",
              "      <td>18.058910</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1983</td>\n",
              "      <td>BEL</td>\n",
              "      <td>7.926468</td>\n",
              "      <td>-13.777903</td>\n",
              "      <td>-2.523149</td>\n",
              "      <td>7.602360</td>\n",
              "      <td>-9.008913</td>\n",
              "      <td>8.342921</td>\n",
              "      <td>-14.770099</td>\n",
              "      <td>-14.437623</td>\n",
              "      <td>-12.745552</td>\n",
              "      <td>-13.410403</td>\n",
              "      <td>-9.047539</td>\n",
              "      <td>13.137708</td>\n",
              "      <td>10.203206</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1984</td>\n",
              "      <td>BEL</td>\n",
              "      <td>4.735769</td>\n",
              "      <td>-3.032194</td>\n",
              "      <td>-1.345093</td>\n",
              "      <td>1.165137</td>\n",
              "      <td>-11.818881</td>\n",
              "      <td>2.878303</td>\n",
              "      <td>-9.406917</td>\n",
              "      <td>-11.618120</td>\n",
              "      <td>-13.636200</td>\n",
              "      <td>-11.094328</td>\n",
              "      <td>-7.091726</td>\n",
              "      <td>13.923372</td>\n",
              "      <td>12.150536</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1985</td>\n",
              "      <td>BEL</td>\n",
              "      <td>1.170111</td>\n",
              "      <td>-3.616816</td>\n",
              "      <td>0.629007</td>\n",
              "      <td>1.468154</td>\n",
              "      <td>-9.229766</td>\n",
              "      <td>9.103631</td>\n",
              "      <td>-6.842003</td>\n",
              "      <td>-9.693303</td>\n",
              "      <td>-11.454341</td>\n",
              "      <td>-7.493537</td>\n",
              "      <td>-6.991498</td>\n",
              "      <td>10.597395</td>\n",
              "      <td>8.078847</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1986</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-7.434930</td>\n",
              "      <td>2.794630</td>\n",
              "      <td>4.778508</td>\n",
              "      <td>1.670088</td>\n",
              "      <td>-4.873034</td>\n",
              "      <td>14.705151</td>\n",
              "      <td>2.017961</td>\n",
              "      <td>-2.805296</td>\n",
              "      <td>-2.121953</td>\n",
              "      <td>0.729192</td>\n",
              "      <td>-3.838488</td>\n",
              "      <td>4.458304</td>\n",
              "      <td>4.803793</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1987</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-6.822909</td>\n",
              "      <td>-0.193667</td>\n",
              "      <td>3.197855</td>\n",
              "      <td>0.932875</td>\n",
              "      <td>4.781943</td>\n",
              "      <td>-9.155728</td>\n",
              "      <td>3.180641</td>\n",
              "      <td>4.016546</td>\n",
              "      <td>0.147751</td>\n",
              "      <td>3.893717</td>\n",
              "      <td>2.333013</td>\n",
              "      <td>3.301632</td>\n",
              "      <td>2.568790</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1988</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-7.760959</td>\n",
              "      <td>10.978625</td>\n",
              "      <td>3.996188</td>\n",
              "      <td>-2.205194</td>\n",
              "      <td>9.126882</td>\n",
              "      <td>18.557989</td>\n",
              "      <td>5.586267</td>\n",
              "      <td>13.682624</td>\n",
              "      <td>2.423721</td>\n",
              "      <td>6.773586</td>\n",
              "      <td>12.420331</td>\n",
              "      <td>2.838964</td>\n",
              "      <td>1.750026</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1989</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-3.077278</td>\n",
              "      <td>8.973284</td>\n",
              "      <td>3.945863</td>\n",
              "      <td>-4.953908</td>\n",
              "      <td>12.137355</td>\n",
              "      <td>1.769465</td>\n",
              "      <td>9.872349</td>\n",
              "      <td>15.276292</td>\n",
              "      <td>3.392775</td>\n",
              "      <td>7.007201</td>\n",
              "      <td>14.197743</td>\n",
              "      <td>4.231335</td>\n",
              "      <td>6.087260</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1990</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-2.247403</td>\n",
              "      <td>0.018184</td>\n",
              "      <td>2.948519</td>\n",
              "      <td>0.377493</td>\n",
              "      <td>1.847123</td>\n",
              "      <td>-13.561106</td>\n",
              "      <td>6.593924</td>\n",
              "      <td>1.601181</td>\n",
              "      <td>-2.547223</td>\n",
              "      <td>-0.259471</td>\n",
              "      <td>2.099415</td>\n",
              "      <td>8.074541</td>\n",
              "      <td>8.278006</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1991</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-2.830985</td>\n",
              "      <td>-3.327654</td>\n",
              "      <td>4.092262</td>\n",
              "      <td>-1.509327</td>\n",
              "      <td>3.542818</td>\n",
              "      <td>0.915333</td>\n",
              "      <td>-0.035983</td>\n",
              "      <td>1.331331</td>\n",
              "      <td>-25.360249</td>\n",
              "      <td>-2.520842</td>\n",
              "      <td>3.218501</td>\n",
              "      <td>6.186765</td>\n",
              "      <td>7.481371</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1992</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.702682</td>\n",
              "      <td>0.060660</td>\n",
              "      <td>5.446454</td>\n",
              "      <td>-1.355880</td>\n",
              "      <td>-14.379983</td>\n",
              "      <td>-5.261639</td>\n",
              "      <td>4.657382</td>\n",
              "      <td>-12.342686</td>\n",
              "      <td>-3.032244</td>\n",
              "      <td>-10.361548</td>\n",
              "      <td>-8.421106</td>\n",
              "      <td>4.530323</td>\n",
              "      <td>7.592015</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1993</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-3.941146</td>\n",
              "      <td>-7.586812</td>\n",
              "      <td>10.529249</td>\n",
              "      <td>1.594304</td>\n",
              "      <td>-6.059715</td>\n",
              "      <td>10.691401</td>\n",
              "      <td>1.697046</td>\n",
              "      <td>-8.950522</td>\n",
              "      <td>-1.199004</td>\n",
              "      <td>-4.685950</td>\n",
              "      <td>-7.904036</td>\n",
              "      <td>0.798420</td>\n",
              "      <td>4.936565</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1994</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.822864</td>\n",
              "      <td>1.479685</td>\n",
              "      <td>10.840347</td>\n",
              "      <td>-3.977391</td>\n",
              "      <td>-7.754699</td>\n",
              "      <td>-5.881777</td>\n",
              "      <td>4.130819</td>\n",
              "      <td>-5.947461</td>\n",
              "      <td>0.035480</td>\n",
              "      <td>-3.620323</td>\n",
              "      <td>-5.022339</td>\n",
              "      <td>2.166785</td>\n",
              "      <td>-0.551363</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1995</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-7.020862</td>\n",
              "      <td>8.152746</td>\n",
              "      <td>10.970734</td>\n",
              "      <td>-6.373627</td>\n",
              "      <td>-12.005191</td>\n",
              "      <td>1.921843</td>\n",
              "      <td>2.011324</td>\n",
              "      <td>-6.431392</td>\n",
              "      <td>-4.134791</td>\n",
              "      <td>-3.068925</td>\n",
              "      <td>-6.074284</td>\n",
              "      <td>1.459687</td>\n",
              "      <td>-2.542950</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1996</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-5.595460</td>\n",
              "      <td>-9.241059</td>\n",
              "      <td>10.076327</td>\n",
              "      <td>-4.228624</td>\n",
              "      <td>2.614536</td>\n",
              "      <td>7.452869</td>\n",
              "      <td>-2.132140</td>\n",
              "      <td>-2.501912</td>\n",
              "      <td>-3.217958</td>\n",
              "      <td>-2.931026</td>\n",
              "      <td>-1.248880</td>\n",
              "      <td>-1.128639</td>\n",
              "      <td>-6.017162</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1997</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-6.943133</td>\n",
              "      <td>1.993406</td>\n",
              "      <td>11.486437</td>\n",
              "      <td>-6.072179</td>\n",
              "      <td>3.084065</td>\n",
              "      <td>11.145707</td>\n",
              "      <td>-1.509106</td>\n",
              "      <td>3.684089</td>\n",
              "      <td>-0.720881</td>\n",
              "      <td>0.315294</td>\n",
              "      <td>4.352240</td>\n",
              "      <td>-3.064428</td>\n",
              "      <td>-5.530330</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1998</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-8.380711</td>\n",
              "      <td>-5.344140</td>\n",
              "      <td>10.905194</td>\n",
              "      <td>-4.648611</td>\n",
              "      <td>-8.519555</td>\n",
              "      <td>15.130804</td>\n",
              "      <td>4.956509</td>\n",
              "      <td>-9.929179</td>\n",
              "      <td>12.729093</td>\n",
              "      <td>8.108018</td>\n",
              "      <td>-18.738701</td>\n",
              "      <td>-5.687672</td>\n",
              "      <td>-5.264785</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1999</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-7.830765</td>\n",
              "      <td>7.974821</td>\n",
              "      <td>10.422754</td>\n",
              "      <td>-7.270341</td>\n",
              "      <td>1.487049</td>\n",
              "      <td>-6.883902</td>\n",
              "      <td>6.358614</td>\n",
              "      <td>5.362254</td>\n",
              "      <td>3.463858</td>\n",
              "      <td>-4.224176</td>\n",
              "      <td>11.093114</td>\n",
              "      <td>-5.694219</td>\n",
              "      <td>-6.968698</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>2000</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.106570</td>\n",
              "      <td>1.580885</td>\n",
              "      <td>8.506733</td>\n",
              "      <td>-7.215280</td>\n",
              "      <td>-5.358242</td>\n",
              "      <td>-3.084904</td>\n",
              "      <td>-0.127355</td>\n",
              "      <td>-3.826439</td>\n",
              "      <td>-3.356254</td>\n",
              "      <td>-6.265791</td>\n",
              "      <td>-0.357894</td>\n",
              "      <td>-3.485631</td>\n",
              "      <td>-3.737902</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>2001</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.695108</td>\n",
              "      <td>-6.969268</td>\n",
              "      <td>7.019523</td>\n",
              "      <td>-3.549173</td>\n",
              "      <td>-9.476780</td>\n",
              "      <td>-4.866535</td>\n",
              "      <td>0.359911</td>\n",
              "      <td>-11.527042</td>\n",
              "      <td>-12.460935</td>\n",
              "      <td>-10.233199</td>\n",
              "      <td>-7.592150</td>\n",
              "      <td>-4.694680</td>\n",
              "      <td>-3.937061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>2002</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-6.834591</td>\n",
              "      <td>-2.281380</td>\n",
              "      <td>9.478455</td>\n",
              "      <td>-4.991220</td>\n",
              "      <td>-7.323127</td>\n",
              "      <td>-15.755551</td>\n",
              "      <td>3.053093</td>\n",
              "      <td>-7.416029</td>\n",
              "      <td>-0.559172</td>\n",
              "      <td>-3.211227</td>\n",
              "      <td>-7.759565</td>\n",
              "      <td>-5.072235</td>\n",
              "      <td>-6.017162</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2003</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-6.909364</td>\n",
              "      <td>-4.125442</td>\n",
              "      <td>7.069235</td>\n",
              "      <td>-5.880053</td>\n",
              "      <td>-8.500834</td>\n",
              "      <td>4.002652</td>\n",
              "      <td>3.339714</td>\n",
              "      <td>-9.320196</td>\n",
              "      <td>-0.598595</td>\n",
              "      <td>-2.743389</td>\n",
              "      <td>-11.046898</td>\n",
              "      <td>-7.182616</td>\n",
              "      <td>-8.207908</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>2004</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-6.089270</td>\n",
              "      <td>3.556062</td>\n",
              "      <td>6.476866</td>\n",
              "      <td>-6.665754</td>\n",
              "      <td>-1.232594</td>\n",
              "      <td>13.334773</td>\n",
              "      <td>3.134238</td>\n",
              "      <td>0.737070</td>\n",
              "      <td>2.660399</td>\n",
              "      <td>1.414810</td>\n",
              "      <td>-0.810176</td>\n",
              "      <td>-7.256818</td>\n",
              "      <td>-8.672612</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>2005</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.449080</td>\n",
              "      <td>-3.015444</td>\n",
              "      <td>3.701337</td>\n",
              "      <td>-4.330791</td>\n",
              "      <td>-2.352320</td>\n",
              "      <td>7.701702</td>\n",
              "      <td>11.886088</td>\n",
              "      <td>-3.535592</td>\n",
              "      <td>7.213387</td>\n",
              "      <td>3.976774</td>\n",
              "      <td>-9.816318</td>\n",
              "      <td>-9.153323</td>\n",
              "      <td>-8.539839</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>2006</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.953197</td>\n",
              "      <td>0.626420</td>\n",
              "      <td>3.307236</td>\n",
              "      <td>-6.401854</td>\n",
              "      <td>1.642921</td>\n",
              "      <td>6.872862</td>\n",
              "      <td>9.859452</td>\n",
              "      <td>1.736893</td>\n",
              "      <td>5.094866</td>\n",
              "      <td>3.278255</td>\n",
              "      <td>-1.747987</td>\n",
              "      <td>-8.140689</td>\n",
              "      <td>-6.703153</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>2007</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-6.188163</td>\n",
              "      <td>3.182394</td>\n",
              "      <td>3.387787</td>\n",
              "      <td>-6.562674</td>\n",
              "      <td>12.257557</td>\n",
              "      <td>2.994147</td>\n",
              "      <td>7.777520</td>\n",
              "      <td>12.263750</td>\n",
              "      <td>5.017595</td>\n",
              "      <td>2.722750</td>\n",
              "      <td>16.074880</td>\n",
              "      <td>-6.796331</td>\n",
              "      <td>-4.512408</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>2008</td>\n",
              "      <td>BEL</td>\n",
              "      <td>0.259229</td>\n",
              "      <td>-12.715615</td>\n",
              "      <td>-3.528414</td>\n",
              "      <td>3.057437</td>\n",
              "      <td>4.034164</td>\n",
              "      <td>-16.762899</td>\n",
              "      <td>-2.285774</td>\n",
              "      <td>-3.112948</td>\n",
              "      <td>-1.400422</td>\n",
              "      <td>-2.260708</td>\n",
              "      <td>-3.208057</td>\n",
              "      <td>-6.562814</td>\n",
              "      <td>-4.999240</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>2009</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-10.582906</td>\n",
              "      <td>-13.901421</td>\n",
              "      <td>-3.711220</td>\n",
              "      <td>4.878925</td>\n",
              "      <td>-3.112503</td>\n",
              "      <td>-16.553737</td>\n",
              "      <td>-4.563563</td>\n",
              "      <td>-9.628593</td>\n",
              "      <td>-0.668460</td>\n",
              "      <td>-2.669455</td>\n",
              "      <td>-13.268823</td>\n",
              "      <td>-7.913720</td>\n",
              "      <td>-11.659992</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>2010</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.938725</td>\n",
              "      <td>7.501335</td>\n",
              "      <td>2.844314</td>\n",
              "      <td>-2.161191</td>\n",
              "      <td>-11.419333</td>\n",
              "      <td>5.707666</td>\n",
              "      <td>1.112620</td>\n",
              "      <td>-6.227620</td>\n",
              "      <td>-0.516460</td>\n",
              "      <td>-1.992540</td>\n",
              "      <td>-9.189521</td>\n",
              "      <td>-9.063844</td>\n",
              "      <td>-12.168953</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>2011</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-2.480853</td>\n",
              "      <td>-6.818397</td>\n",
              "      <td>-3.645816</td>\n",
              "      <td>-0.032035</td>\n",
              "      <td>0.137116</td>\n",
              "      <td>-5.883278</td>\n",
              "      <td>-2.181490</td>\n",
              "      <td>-3.345139</td>\n",
              "      <td>-1.772659</td>\n",
              "      <td>-2.030976</td>\n",
              "      <td>-4.448162</td>\n",
              "      <td>-7.045125</td>\n",
              "      <td>-10.885486</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>2012</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-4.234408</td>\n",
              "      <td>-9.738001</td>\n",
              "      <td>-1.314028</td>\n",
              "      <td>-0.453157</td>\n",
              "      <td>-4.736291</td>\n",
              "      <td>-5.635169</td>\n",
              "      <td>-4.256526</td>\n",
              "      <td>-8.904006</td>\n",
              "      <td>-5.903967</td>\n",
              "      <td>-6.511342</td>\n",
              "      <td>-8.370734</td>\n",
              "      <td>-10.275076</td>\n",
              "      <td>-12.832815</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2013</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-7.558204</td>\n",
              "      <td>-8.386119</td>\n",
              "      <td>-1.918879</td>\n",
              "      <td>-1.999503</td>\n",
              "      <td>0.635351</td>\n",
              "      <td>5.311622</td>\n",
              "      <td>-2.907867</td>\n",
              "      <td>-3.723675</td>\n",
              "      <td>-3.692185</td>\n",
              "      <td>-4.842977</td>\n",
              "      <td>-1.209239</td>\n",
              "      <td>-11.820215</td>\n",
              "      <td>-13.009845</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>2014</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-9.386533</td>\n",
              "      <td>-3.253266</td>\n",
              "      <td>-3.182798</td>\n",
              "      <td>-4.071863</td>\n",
              "      <td>5.143681</td>\n",
              "      <td>4.898888</td>\n",
              "      <td>-4.232489</td>\n",
              "      <td>2.734280</td>\n",
              "      <td>-1.713981</td>\n",
              "      <td>-1.246681</td>\n",
              "      <td>5.585059</td>\n",
              "      <td>-13.644702</td>\n",
              "      <td>-13.009845</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>2015</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-9.072967</td>\n",
              "      <td>-1.994079</td>\n",
              "      <td>-1.518428</td>\n",
              "      <td>-2.756529</td>\n",
              "      <td>2.809796</td>\n",
              "      <td>4.955203</td>\n",
              "      <td>-1.445837</td>\n",
              "      <td>1.393387</td>\n",
              "      <td>-2.319813</td>\n",
              "      <td>-2.489572</td>\n",
              "      <td>4.822482</td>\n",
              "      <td>-15.931856</td>\n",
              "      <td>-13.607321</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>2016</td>\n",
              "      <td>BEL</td>\n",
              "      <td>-6.299117</td>\n",
              "      <td>-4.086450</td>\n",
              "      <td>-0.971220</td>\n",
              "      <td>-2.715348</td>\n",
              "      <td>0.434408</td>\n",
              "      <td>-4.800054</td>\n",
              "      <td>-1.621012</td>\n",
              "      <td>-1.703801</td>\n",
              "      <td>-4.179921</td>\n",
              "      <td>-4.594352</td>\n",
              "      <td>2.062732</td>\n",
              "      <td>-16.885565</td>\n",
              "      <td>-14.403956</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1970</td>\n",
              "      <td>CAN</td>\n",
              "      <td>-2.449273</td>\n",
              "      <td>5.310142</td>\n",
              "      <td>0.523363</td>\n",
              "      <td>1.515591</td>\n",
              "      <td>-3.861181</td>\n",
              "      <td>-8.917092</td>\n",
              "      <td>-6.482885</td>\n",
              "      <td>-0.674123</td>\n",
              "      <td>6.885076</td>\n",
              "      <td>4.473386</td>\n",
              "      <td>-4.938611</td>\n",
              "      <td>2.590170</td>\n",
              "      <td>0.136472</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1971</td>\n",
              "      <td>CAN</td>\n",
              "      <td>-3.726506</td>\n",
              "      <td>12.236010</td>\n",
              "      <td>-3.036251</td>\n",
              "      <td>-0.616553</td>\n",
              "      <td>11.934214</td>\n",
              "      <td>-0.555532</td>\n",
              "      <td>0.310668</td>\n",
              "      <td>16.851435</td>\n",
              "      <td>18.259012</td>\n",
              "      <td>16.219053</td>\n",
              "      <td>8.886311</td>\n",
              "      <td>0.062951</td>\n",
              "      <td>-5.237124</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1972</td>\n",
              "      <td>CAN</td>\n",
              "      <td>0.949145</td>\n",
              "      <td>13.715768</td>\n",
              "      <td>-5.607154</td>\n",
              "      <td>-4.519970</td>\n",
              "      <td>14.950586</td>\n",
              "      <td>3.559393</td>\n",
              "      <td>1.702866</td>\n",
              "      <td>20.346062</td>\n",
              "      <td>25.579007</td>\n",
              "      <td>19.999880</td>\n",
              "      <td>10.106493</td>\n",
              "      <td>0.807149</td>\n",
              "      <td>-5.240812</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1973</td>\n",
              "      <td>CAN</td>\n",
              "      <td>7.790939</td>\n",
              "      <td>21.944440</td>\n",
              "      <td>-4.228031</td>\n",
              "      <td>-9.864307</td>\n",
              "      <td>13.144044</td>\n",
              "      <td>-2.330954</td>\n",
              "      <td>14.986582</td>\n",
              "      <td>23.179410</td>\n",
              "      <td>27.505432</td>\n",
              "      <td>19.983446</td>\n",
              "      <td>14.014507</td>\n",
              "      <td>1.669197</td>\n",
              "      <td>-1.016067</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1974</td>\n",
              "      <td>CAN</td>\n",
              "      <td>15.637800</td>\n",
              "      <td>17.633249</td>\n",
              "      <td>-7.161444</td>\n",
              "      <td>-7.687647</td>\n",
              "      <td>1.643832</td>\n",
              "      <td>-13.314587</td>\n",
              "      <td>17.405051</td>\n",
              "      <td>10.445702</td>\n",
              "      <td>8.923121</td>\n",
              "      <td>6.597145</td>\n",
              "      <td>8.445424</td>\n",
              "      <td>5.185043</td>\n",
              "      <td>4.193408</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1975</td>\n",
              "      <td>CAN</td>\n",
              "      <td>15.513752</td>\n",
              "      <td>-2.628269</td>\n",
              "      <td>-11.350998</td>\n",
              "      <td>-1.821842</td>\n",
              "      <td>7.672377</td>\n",
              "      <td>-7.180117</td>\n",
              "      <td>-1.644854</td>\n",
              "      <td>5.219063</td>\n",
              "      <td>6.857813</td>\n",
              "      <td>5.578500</td>\n",
              "      <td>1.329501</td>\n",
              "      <td>5.529862</td>\n",
              "      <td>3.243717</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    year  iso      cpi_g     rgdp_g     ca/gdp  debtgdp_g  tloansgdp_g  \\\n",
              "0   1970  AUS  -1.146981  19.960688  -5.564789  -7.398010    -9.743657   \n",
              "1   1971  AUS   4.058287   2.155513  -5.120172  -9.783842    -3.768604   \n",
              "2   1972  AUS   3.578159   5.802139   0.745518  -7.379162    -2.902038   \n",
              "3   1973  AUS  12.263715  -1.135801   0.107051 -13.010876    23.314275   \n",
              "4   1974  AUS  25.877901   9.310465  -9.213580 -14.965624     8.557917   \n",
              "5   1975  AUS  25.785819   0.243081  -3.779526  -3.170679    -7.845865   \n",
              "6   1976  AUS  22.051857   1.780144  -6.104396  -4.885091    -3.267810   \n",
              "7   1977  AUS  19.100283   0.986560  -7.624898  -6.001942    -2.680842   \n",
              "8   1978  AUS   8.543785  -4.419868  -9.650430   1.407891     1.014938   \n",
              "9   1979  AUS  11.357044   3.764981  -5.706581  -0.386258     1.476384   \n",
              "10  1980  AUS  13.857299   1.507345  -6.954997  -8.940313    -8.231696   \n",
              "11  1981  AUS  12.808498   2.354513 -11.196483 -13.265131     1.230513   \n",
              "12  1982  AUS  16.315013   4.569948 -11.030107 -10.370118   -14.943063   \n",
              "13  1983  AUS  13.825913 -15.759982  -8.765853   5.701632     4.361569   \n",
              "14  1984  AUS  -1.040412  20.420806 -11.161047   4.849236     8.158819   \n",
              "15  1985  AUS   5.686431   2.234182 -12.985696   5.112397    27.741109   \n",
              "16  1986  AUS  11.343867  -3.238049 -13.241211   3.593916     8.614093   \n",
              "17  1987  AUS   9.906788  -4.251388  -9.456970  -8.030207     8.640294   \n",
              "18  1988  AUS   6.874911  10.965370 -10.497578   9.347772    19.754780   \n",
              "19  1989  AUS   7.665220  10.172263 -15.705788 -10.402393    52.116179   \n",
              "20  1990  AUS   6.972587  -0.257738 -12.534361  -7.528232     6.050461   \n",
              "21  1991  AUS  -2.795142 -10.236995  -8.718710   3.355333     6.589436   \n",
              "22  1992  AUS  -8.190337  -5.162732  -8.819987  15.066346    -0.629529   \n",
              "23  1993  AUS  -6.195118   2.046905  -8.214734   8.576640     0.879148   \n",
              "24  1994  AUS  -5.997773   2.184083 -11.759766   1.009915    10.321091   \n",
              "25  1995  AUS   0.619063  -3.367527 -12.822786  -3.540912     7.051926   \n",
              "26  1996  AUS  -4.267257   5.131673  -9.156802  -8.067670     2.287005   \n",
              "27  1997  AUS -10.025724   8.358913  -7.883441 -13.614605     5.516048   \n",
              "28  1998  AUS  -8.496489   7.968009 -12.230239 -10.458927     3.923895   \n",
              "29  1999  AUS  -7.172277   4.712602 -13.645324  -7.216258    10.534472   \n",
              "30  2000  AUS   0.182043  -1.729211 -10.502050 -15.311180     3.879216   \n",
              "31  2001  AUS   0.061441  -0.899968  -6.096697 -14.138773     3.108166   \n",
              "32  2002  AUS  -3.214114   3.940542  -9.973966 -14.266789    12.402898   \n",
              "33  2003  AUS  -3.903958   3.119731 -13.933136 -14.263119    19.054800   \n",
              "34  2004  AUS  -4.999026   8.887566 -15.500060 -11.669258     9.427225   \n",
              "35  2005  AUS  -4.154811   5.937734 -14.736039 -10.922501     9.165307   \n",
              "36  2006  AUS  -1.996032   6.689591 -14.466116 -10.690783     7.276690   \n",
              "37  2007  AUS  -4.885660  13.165746 -16.506554  -5.238467    17.145339   \n",
              "38  2008  AUS  -0.080869   4.701514 -12.347903  17.767612     9.484804   \n",
              "39  2009  AUS  -6.299117   8.337171 -11.741719  38.146660    -1.432022   \n",
              "40  2010  AUS  -3.662754  -7.605248  -9.321683  18.703458    -2.615576   \n",
              "41  2011  AUS  -2.536330   9.086065  -7.967367  14.860417    -9.340273   \n",
              "42  2012  AUS  -6.439016   4.998284 -10.630001  11.656849    -5.660050   \n",
              "43  2013  AUS  -4.658928  -8.555873  -8.509501   7.865988     5.898326   \n",
              "44  2014  AUS  -4.506969  -3.234043  -7.772930   7.995922     3.537093   \n",
              "45  2015  AUS  -6.986550  -7.666753 -12.023080   6.654590    16.734126   \n",
              "46  2016  AUS  -7.488255  -4.919349  -7.230796   6.193710     4.586518   \n",
              "47  1970  BEL  -1.146828  15.411561   5.272416 -10.102287    -3.340061   \n",
              "48  1971  BEL  -0.097715   8.151406   5.577327  -5.999140    -0.859738   \n",
              "49  1972  BEL   2.570297  11.996081   6.275131  -4.465394    -3.366274   \n",
              "50  1973  BEL   6.208439  12.583766   4.583677  -7.767481    -1.412094   \n",
              "51  1974  BEL  20.023560   5.423082   2.724760 -10.494454   -13.219663   \n",
              "52  1975  BEL  20.202825 -14.738080   1.280485  -0.098749     2.962465   \n",
              "53  1976  BEL  11.559411   5.915348  -2.234442  -1.995276    -3.172849   \n",
              "54  1977  BEL   6.558893  -5.165502  -5.129124   4.276602     7.355722   \n",
              "55  1978  BEL   0.205957   1.060989  -3.511039   4.174329     6.740012   \n",
              "56  1979  BEL   0.218087  -0.986943  -8.198560   4.637248    11.367871   \n",
              "57  1980  BEL   5.470368  -0.696856 -10.305178        NaN    12.711836   \n",
              "58  1981  BEL   7.838847 -17.090543 -10.520202        NaN     5.403009   \n",
              "59  1982  BEL  10.476571  -9.975914  -7.793518        NaN    -6.576755   \n",
              "60  1983  BEL   7.926468 -13.777903  -2.523149   7.602360    -9.008913   \n",
              "61  1984  BEL   4.735769  -3.032194  -1.345093   1.165137   -11.818881   \n",
              "62  1985  BEL   1.170111  -3.616816   0.629007   1.468154    -9.229766   \n",
              "63  1986  BEL  -7.434930   2.794630   4.778508   1.670088    -4.873034   \n",
              "64  1987  BEL  -6.822909  -0.193667   3.197855   0.932875     4.781943   \n",
              "65  1988  BEL  -7.760959  10.978625   3.996188  -2.205194     9.126882   \n",
              "66  1989  BEL  -3.077278   8.973284   3.945863  -4.953908    12.137355   \n",
              "67  1990  BEL  -2.247403   0.018184   2.948519   0.377493     1.847123   \n",
              "68  1991  BEL  -2.830985  -3.327654   4.092262  -1.509327     3.542818   \n",
              "69  1992  BEL  -4.702682   0.060660   5.446454  -1.355880   -14.379983   \n",
              "70  1993  BEL  -3.941146  -7.586812  10.529249   1.594304    -6.059715   \n",
              "71  1994  BEL  -4.822864   1.479685  10.840347  -3.977391    -7.754699   \n",
              "72  1995  BEL  -7.020862   8.152746  10.970734  -6.373627   -12.005191   \n",
              "73  1996  BEL  -5.595460  -9.241059  10.076327  -4.228624     2.614536   \n",
              "74  1997  BEL  -6.943133   1.993406  11.486437  -6.072179     3.084065   \n",
              "75  1998  BEL  -8.380711  -5.344140  10.905194  -4.648611    -8.519555   \n",
              "76  1999  BEL  -7.830765   7.974821  10.422754  -7.270341     1.487049   \n",
              "77  2000  BEL  -4.106570   1.580885   8.506733  -7.215280    -5.358242   \n",
              "78  2001  BEL  -4.695108  -6.969268   7.019523  -3.549173    -9.476780   \n",
              "79  2002  BEL  -6.834591  -2.281380   9.478455  -4.991220    -7.323127   \n",
              "80  2003  BEL  -6.909364  -4.125442   7.069235  -5.880053    -8.500834   \n",
              "81  2004  BEL  -6.089270   3.556062   6.476866  -6.665754    -1.232594   \n",
              "82  2005  BEL  -4.449080  -3.015444   3.701337  -4.330791    -2.352320   \n",
              "83  2006  BEL  -4.953197   0.626420   3.307236  -6.401854     1.642921   \n",
              "84  2007  BEL  -6.188163   3.182394   3.387787  -6.562674    12.257557   \n",
              "85  2008  BEL   0.259229 -12.715615  -3.528414   3.057437     4.034164   \n",
              "86  2009  BEL -10.582906 -13.901421  -3.711220   4.878925    -3.112503   \n",
              "87  2010  BEL  -4.938725   7.501335   2.844314  -2.161191   -11.419333   \n",
              "88  2011  BEL  -2.480853  -6.818397  -3.645816  -0.032035     0.137116   \n",
              "89  2012  BEL  -4.234408  -9.738001  -1.314028  -0.453157    -4.736291   \n",
              "90  2013  BEL  -7.558204  -8.386119  -1.918879  -1.999503     0.635351   \n",
              "91  2014  BEL  -9.386533  -3.253266  -3.182798  -4.071863     5.143681   \n",
              "92  2015  BEL  -9.072967  -1.994079  -1.518428  -2.756529     2.809796   \n",
              "93  2016  BEL  -6.299117  -4.086450  -0.971220  -2.715348     0.434408   \n",
              "94  1970  CAN  -2.449273   5.310142   0.523363   1.515591    -3.861181   \n",
              "95  1971  CAN  -3.726506  12.236010  -3.036251  -0.616553    11.934214   \n",
              "96  1972  CAN   0.949145  13.715768  -5.607154  -4.519970    14.950586   \n",
              "97  1973  CAN   7.790939  21.944440  -4.228031  -9.864307    13.144044   \n",
              "98  1974  CAN  15.637800  17.633249  -7.161444  -7.687647     1.643832   \n",
              "99  1975  CAN  15.513752  -2.628269 -11.350998  -1.821842     7.672377   \n",
              "\n",
              "        rsp_g      rhp_g  rtloans_g   rtmort_g     rthh_g    rtbus_g  \\\n",
              "0  -11.108291   5.882485   1.270790  -0.631283   0.269924   1.449546   \n",
              "1   -8.879069   6.078516  -2.165845  -3.045783  -2.883962  -0.771107   \n",
              "2    9.142523   2.817973   0.410260  -0.682200   2.569146  -0.812115   \n",
              "3  -18.014139  10.969530  19.420961   0.630922  11.992742  15.885606   \n",
              "4  -20.333482   4.040068  12.294467  -0.983021   0.013007  14.378099   \n",
              "5   10.009444  -6.301269  -6.630106   8.777480   5.237373  -9.987785   \n",
              "6   -8.303448  -3.507338  -1.919817  10.783086   5.472603  -5.488826   \n",
              "7   -4.384221  -6.578038  -1.809895  -2.027822   2.824991  -4.164645   \n",
              "8    2.071211  -5.995614  -1.380387   1.473412   3.856219  -4.653355   \n",
              "9    7.549847  -5.675181   3.199057  -0.647842   1.062409   3.171145   \n",
              "10  11.485277   7.054865  -6.346192  -2.143388   1.128799  -9.557069   \n",
              "11 -12.988408   3.711891   2.264429  -7.308271  -0.471860   3.177876   \n",
              "12 -14.246662  -9.475619 -10.705260 -10.107373  -5.605336 -10.454428   \n",
              "13  18.565896  -8.856695  -4.421102  -3.099680   2.244394  -8.903899   \n",
              "14  -6.579494   8.962887  17.811443   9.215917  13.853307  12.200642   \n",
              "15  11.456200   0.485708  25.162879  19.416077  14.429446  22.876930   \n",
              "16  13.755016  -5.140914   5.700366   3.735620  -5.066015  13.016941   \n",
              "17 -10.045232  -7.243171   5.186127  15.656999   5.415006   2.076235   \n",
              "18   0.313159  16.922138  23.111883  16.427402   7.844321  25.612176   \n",
              "19  -0.611388  19.123944  51.338810   7.650941  42.149463  34.863072   \n",
              "20 -14.715158 -10.114036   5.073961  16.962974  -2.187257   8.588867   \n",
              "21   9.393006  -6.272962   0.304406   3.958853  -2.123848   1.835107   \n",
              "22  -5.279067  -0.694516  -3.153418  23.224496  13.384440 -15.354148   \n",
              "23  15.221341  -1.456920   1.803101  18.466387  10.421003  -8.653832   \n",
              "24  -8.288261  -0.552033  10.049247  22.960687  14.826910  -2.228664   \n",
              "25   2.560637  -6.666764   4.300737   2.662935   1.149875   4.907020   \n",
              "26   1.272636  -4.557304   4.606193   3.333490   3.086006   2.768051   \n",
              "27   1.462694   1.167146   9.109801   4.392485   4.314917   9.202726   \n",
              "28   0.976382   9.604243   7.504147   5.437575   5.019406   5.306469   \n",
              "29   2.755125   4.109797  11.584864   8.103151   7.659344   8.988337   \n",
              "30  -3.253801   4.476657   2.445379   9.294763   4.975960  -3.867364   \n",
              "31  -1.025303   2.361208   2.212865   4.346188   2.812352  -1.586660   \n",
              "32  -8.788075  20.534418  12.798543  10.011695   9.735544   7.964871   \n",
              "33   1.055840  17.941823  18.131905  15.617686  12.583690  13.928432   \n",
              "34   7.094944   2.873849  12.837954   7.396158   6.333877  13.665697   \n",
              "35   4.610072  -4.456023  11.040926   5.128696   4.647109  12.703302   \n",
              "36   4.790292   2.900914   9.783338   1.922934   2.378619  13.623863   \n",
              "37   2.180495   9.303411  22.006890   5.910306   5.903977  30.728116   \n",
              "38 -22.057095  -2.772627  10.663389   9.974786   4.573507  11.288813   \n",
              "39  11.025587  -0.539772   2.975030  12.682789   8.782551  -6.481967   \n",
              "40  -4.466347   9.577509  -6.061417   2.485644   0.858030 -13.189154   \n",
              "41  -9.943967 -10.710863  -3.631714  -2.951844  -3.903213  -2.483033   \n",
              "42   3.746158  -6.178669  -2.399877  -0.978929  -1.790007  -3.432286   \n",
              "43   3.613215   2.825502   0.606046  -1.486788  -1.872293   2.612446   \n",
              "44  -2.678964   6.007231   1.374826  -0.409639  -1.130144   2.919190   \n",
              "45  -3.676192   7.459997  10.187246   0.796472   0.419744  17.764262   \n",
              "46   0.528555   2.955877   1.394044   0.889275  -0.141399   1.435941   \n",
              "47  -3.868203  -9.412082   4.827669  -0.337402  -0.317753   6.112709   \n",
              "48  -2.145056  -9.566890   3.385436  -0.387625  -0.362633   4.338212   \n",
              "49   6.460081   1.548449   3.098024   3.095787   2.750389   2.021942   \n",
              "50  -3.820205   6.683969   5.134559   5.012123   4.462962   3.377974   \n",
              "51 -18.962056   0.061707  -8.797473  -5.792507  -5.192814  -7.485525   \n",
              "52  -0.583494   0.490590  -5.043310  -7.564112  -6.776042  -1.771630   \n",
              "53 -10.399587  15.938259   0.229910   0.642474   0.557931  -0.173404   \n",
              "54  -6.764182  12.463945   3.613317   4.626757   4.118567   1.584855   \n",
              "55  -0.781379   8.671841   6.358885   9.398381   8.382824   1.950179   \n",
              "56  -2.579156   3.861518   9.254997   6.440715   5.739655   7.567761   \n",
              "57 -12.509498 -10.350693  10.564700  -2.748351  -2.472349  15.635569   \n",
              "58  -4.223396 -19.875871  -4.259748   7.821430 -12.279059   2.993157   \n",
              "59   1.393845 -18.450216 -10.559854 -11.141098 -10.511970  -6.174546   \n",
              "60   8.342921 -14.770099 -14.437623 -12.745552 -13.410403  -9.047539   \n",
              "61   2.878303  -9.406917 -11.618120 -13.636200 -11.094328  -7.091726   \n",
              "62   9.103631  -6.842003  -9.693303 -11.454341  -7.493537  -6.991498   \n",
              "63  14.705151   2.017961  -2.805296  -2.121953   0.729192  -3.838488   \n",
              "64  -9.155728   3.180641   4.016546   0.147751   3.893717   2.333013   \n",
              "65  18.557989   5.586267  13.682624   2.423721   6.773586  12.420331   \n",
              "66   1.769465   9.872349  15.276292   3.392775   7.007201  14.197743   \n",
              "67 -13.561106   6.593924   1.601181  -2.547223  -0.259471   2.099415   \n",
              "68   0.915333  -0.035983   1.331331 -25.360249  -2.520842   3.218501   \n",
              "69  -5.261639   4.657382 -12.342686  -3.032244 -10.361548  -8.421106   \n",
              "70  10.691401   1.697046  -8.950522  -1.199004  -4.685950  -7.904036   \n",
              "71  -5.881777   4.130819  -5.947461   0.035480  -3.620323  -5.022339   \n",
              "72   1.921843   2.011324  -6.431392  -4.134791  -3.068925  -6.074284   \n",
              "73   7.452869  -2.132140  -2.501912  -3.217958  -2.931026  -1.248880   \n",
              "74  11.145707  -1.509106   3.684089  -0.720881   0.315294   4.352240   \n",
              "75  15.130804   4.956509  -9.929179  12.729093   8.108018 -18.738701   \n",
              "76  -6.883902   6.358614   5.362254   3.463858  -4.224176  11.093114   \n",
              "77  -3.084904  -0.127355  -3.826439  -3.356254  -6.265791  -0.357894   \n",
              "78  -4.866535   0.359911 -11.527042 -12.460935 -10.233199  -7.592150   \n",
              "79 -15.755551   3.053093  -7.416029  -0.559172  -3.211227  -7.759565   \n",
              "80   4.002652   3.339714  -9.320196  -0.598595  -2.743389 -11.046898   \n",
              "81  13.334773   3.134238   0.737070   2.660399   1.414810  -0.810176   \n",
              "82   7.701702  11.886088  -3.535592   7.213387   3.976774  -9.816318   \n",
              "83   6.872862   9.859452   1.736893   5.094866   3.278255  -1.747987   \n",
              "84   2.994147   7.777520  12.263750   5.017595   2.722750  16.074880   \n",
              "85 -16.762899  -2.285774  -3.112948  -1.400422  -2.260708  -3.208057   \n",
              "86 -16.553737  -4.563563  -9.628593  -0.668460  -2.669455 -13.268823   \n",
              "87   5.707666   1.112620  -6.227620  -0.516460  -1.992540  -9.189521   \n",
              "88  -5.883278  -2.181490  -3.345139  -1.772659  -2.030976  -4.448162   \n",
              "89  -5.635169  -4.256526  -8.904006  -5.903967  -6.511342  -8.370734   \n",
              "90   5.311622  -2.907867  -3.723675  -3.692185  -4.842977  -1.209239   \n",
              "91   4.898888  -4.232489   2.734280  -1.713981  -1.246681   5.585059   \n",
              "92   4.955203  -1.445837   1.393387  -2.319813  -2.489572   4.822482   \n",
              "93  -4.800054  -1.621012  -1.703801  -4.179921  -4.594352   2.062732   \n",
              "94  -8.917092  -6.482885  -0.674123   6.885076   4.473386  -4.938611   \n",
              "95  -0.555532   0.310668  16.851435  18.259012  16.219053   8.886311   \n",
              "96   3.559393   1.702866  20.346062  25.579007  19.999880  10.106493   \n",
              "97  -2.330954  14.986582  23.179410  27.505432  19.983446  14.014507   \n",
              "98 -13.314587  17.405051  10.445702   8.923121   6.597145   8.445424   \n",
              "99  -7.180117  -1.644854   5.219063   6.857813   5.578500   1.329501   \n",
              "\n",
              "       ltrate       stir  crisisJST  cid  precrisis  stfilt  \n",
              "0   -0.724895  -1.211537          0    0          0       0  \n",
              "1   -0.550303  -1.145151          0    0          0       0  \n",
              "2   -2.859282  -3.562716          0    0          0       0  \n",
              "3    0.025850  -1.585882          0    0          0       0  \n",
              "4    5.534227   6.948437          0    0          0       0  \n",
              "5    7.380537   3.498197          0    0          0       0  \n",
              "6    8.137830   3.501885          0    0          0       0  \n",
              "7    8.650694   5.744264          0    0          0       0  \n",
              "8    5.595334   6.013498          0    0          0       0  \n",
              "9    7.400179   6.522459          0    0          0       0  \n",
              "10  12.371686  10.485348          0    0          0       0  \n",
              "11  18.423480  16.201940          0    0          0       0  \n",
              "12  22.133560  19.281523          0    0          0       0  \n",
              "13  18.237976  11.355745          0    0          0       0  \n",
              "14  17.288632  11.187935          0    0          0       0  \n",
              "15  18.412568  21.002033          0    0          0       0  \n",
              "16  17.004920  20.928270          0    0          0       0  \n",
              "17  16.415672  15.200614          0    0          0       0  \n",
              "18  13.567641  13.747493          0    0          1       0  \n",
              "19  16.983096  24.055799          1    0         -1       0  \n",
              "20  16.385119  18.193526          0    0         -1       0  \n",
              "21   9.866291   8.910519          0    0         -1       0  \n",
              "22   6.014355   0.743169          0    0         -1       0  \n",
              "23   0.935911  -2.052429          0    0         -1       0  \n",
              "24   5.547322  -0.520014          0    0          0       0  \n",
              "25   5.990511   3.794297          0    0          0       0  \n",
              "26   3.367210   2.405977          0    0          0       0  \n",
              "27   0.082379  -1.413851          0    0          0       0  \n",
              "28  -3.746286  -2.417226          0    0          0       0  \n",
              "29  -2.394050  -2.590637          0    0          0       0  \n",
              "30  -1.594618   0.103834          0    0          0       0  \n",
              "31  -3.426014  -2.498272          0    0          0       0  \n",
              "32  -2.827093  -3.050067          0    0          0       0  \n",
              "33  -4.076776  -2.478408          0    0          0       0  \n",
              "34  -3.490150  -1.502899          0    0          0       0  \n",
              "35  -4.146968  -1.043727          0    0          0       0  \n",
              "36  -3.497750  -0.274754          0    0          0       0  \n",
              "37  -2.432787   1.014304          0    0          0       0  \n",
              "38  -2.895220   1.643071          0    0          0       0  \n",
              "39  -4.933840  -5.866301          0    0          0       0  \n",
              "40  -4.078698  -3.503245          0    0          0       0  \n",
              "41  -5.352674  -2.736115          0    0          0       0  \n",
              "42  -9.282084  -4.940230          0    0          0       0  \n",
              "43  -8.450590  -7.062746          0    0          0       0  \n",
              "44  -8.558619  -7.588303          0    0          0       0  \n",
              "45 -11.034006  -8.453168          0    0          0       0  \n",
              "46 -12.020451  -9.286684          0    0          0       0  \n",
              "47   2.321735   4.272703          0    1          0       0  \n",
              "48   1.117050  -1.856959          0    1          0       0  \n",
              "49   0.305198  -4.578794          0    1          0       0  \n",
              "50   1.378938   0.510817          0    1          0       0  \n",
              "51   4.600160   9.472958          0    1          0       0  \n",
              "52   4.233517   2.347502          0    1          0       0  \n",
              "53   5.569146   8.499293          0    1          0       0  \n",
              "54   4.914426   2.546661          0    1          0       0  \n",
              "55   5.254880   2.679434          0    1          0       0  \n",
              "56   7.245229  10.690039          0    1          0       0  \n",
              "57  13.032953  18.036781          0    1          0       0  \n",
              "58  17.066027  20.625844          0    1          0       0  \n",
              "59  17.039839  18.058910          0    1          0       0  \n",
              "60  13.137708  10.203206          0    1          0       0  \n",
              "61  13.923372  12.150536          0    1          0       0  \n",
              "62  10.597395   8.078847          0    1          0       0  \n",
              "63   4.458304   4.803793          0    1          0       0  \n",
              "64   3.301632   2.568790          0    1          0       0  \n",
              "65   2.838964   1.750026          0    1          0       0  \n",
              "66   4.231335   6.087260          0    1          0       0  \n",
              "67   8.074541   8.278006          0    1          0       0  \n",
              "68   6.186765   7.481371          0    1          0       0  \n",
              "69   4.530323   7.592015          0    1          0       0  \n",
              "70   0.798420   4.936565          0    1          0       0  \n",
              "71   2.166785  -0.551363          0    1          0       0  \n",
              "72   1.459687  -2.542950          0    1          0       0  \n",
              "73  -1.128639  -6.017162          0    1          0       0  \n",
              "74  -3.064428  -5.530330          0    1          0       0  \n",
              "75  -5.687672  -5.264785          0    1          0       0  \n",
              "76  -5.694219  -6.968698          0    1          0       0  \n",
              "77  -3.485631  -3.737902          0    1          0       0  \n",
              "78  -4.694680  -3.937061          0    1          0       0  \n",
              "79  -5.072235  -6.017162          0    1          0       0  \n",
              "80  -7.182616  -8.207908          0    1          0       0  \n",
              "81  -7.256818  -8.672612          0    1          0       0  \n",
              "82  -9.153323  -8.539839          0    1          0       0  \n",
              "83  -8.140689  -6.703153          0    1          0       0  \n",
              "84  -6.796331  -4.512408          0    1          1       0  \n",
              "85  -6.562814  -4.999240          1    1         -1       0  \n",
              "86  -7.913720 -11.659992          0    1         -1       0  \n",
              "87  -9.063844 -12.168953          0    1         -1       0  \n",
              "88  -7.045125 -10.885486          0    1         -1       0  \n",
              "89 -10.275076 -12.832815          0    1         -1       0  \n",
              "90 -11.820215 -13.009845          0    1          0       0  \n",
              "91 -13.644702 -13.009845          0    1          0       0  \n",
              "92 -15.931856 -13.607321          0    1          0       0  \n",
              "93 -16.885565 -14.403956          0    1          0       0  \n",
              "94   2.590170   0.136472          0    2          0       0  \n",
              "95   0.062951  -5.237124          0    2          0       0  \n",
              "96   0.807149  -5.240812          0    2          0       0  \n",
              "97   1.669197  -1.016067          0    2          0       0  \n",
              "98   5.185043   4.193408          0    2          0       0  \n",
              "99   5.529862   3.243717          0    2          0       0  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKl-hHqyyQzY"
      },
      "source": [
        "## Next dozen or so cells define a bunch of functions that implement the prediction evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRksarjEa2ci"
      },
      "source": [
        "# Return the loss and relative usefulness given tp,tn,fn,fp and theta.\n",
        "def loss_use(tpfntnfp,theta):\n",
        "  tp=tpfntnfp[0]\n",
        "  fn=tpfntnfp[1]\n",
        "  tn=tpfntnfp[2]\n",
        "  fp=tpfntnfp[3]\n",
        "  fnr = fn/(tp+fn)\n",
        "  fpr = fp/(tn+fp)  \n",
        "  loss = theta * fnr + (1-theta) * fpr\n",
        "  ru = (np.minimum(theta,1-theta)-loss)/np.minimum(theta,1-theta)\n",
        "  return fnr,fpr,loss,ru  \n",
        "\n",
        "# Return tp,fn,fp,tn for test data given threshold t\n",
        "def tpfntnfp_fun(ypred,ytrue,t):\n",
        "  tp = np.sum(np.logical_and(ypred>=t,ytrue==1))\n",
        "  fn = np.sum(np.logical_and(ypred<t,ytrue==1))\n",
        "  fp = np.sum(np.logical_and(ypred>=t,ytrue==0))\n",
        "  tn = np.sum(np.logical_and(ypred<t,ytrue==0))\n",
        "  return [tp,fn,tn,fp]\n",
        "\n",
        "# Returns the optimal threshold for policymaker's loss function with parameter theta,\n",
        "# given a set of training data for the policymaker.\n",
        "def optimize_threshold(ypred,ytrue,theta):\n",
        "  # Suffices to consider each ypred with class 1 as thresholds\n",
        "  T = np.sort(ypred[ytrue==1])\n",
        "  t_opt = 0\n",
        "  loss_opt = 1e12\n",
        "  for t in T:\n",
        "    #  Calculate fpr, tpr, fnr, tnr using threshold t\n",
        "    # true positive = indicator correctly alerts crisis\n",
        "    tp = np.sum(np.logical_and(ypred>=t,ytrue==1))\n",
        "    fn = np.sum(np.logical_and(ypred<t,ytrue==1))\n",
        "    fp = np.sum(np.logical_and(ypred>=t,ytrue==0))\n",
        "    tn = np.sum(np.logical_and(ypred<t,ytrue==0))\n",
        "    \n",
        "    fnr = fn/(tp+fn) \n",
        "    fpr = fp/(tn+fp)\n",
        "    loss = theta * fnr + (1-theta) * fpr\n",
        "    if(loss<loss_opt):\n",
        "      loss_opt = loss\n",
        "      t_opt = t\n",
        "  return t_opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU9oj3_7sNob"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "class roc_callback(Callback):\n",
        "    def __init__(self,training_data,validation_data):\n",
        "        self.x = training_data[0]\n",
        "        self.y = training_data[1]\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if((epoch+1) % 10 == 0):\n",
        "          y_pred = self.model.predict(self.x)\n",
        "          roc = roc_auc_score(self.y, y_pred)\n",
        "          y_pred_val = self.model.predict(self.x_val)\n",
        "          roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "          #print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
        "          print('REPSTAT',epoch+1,'INAUC %.3f' % roc,'OUTAUC %.3f' % roc_val)\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IjIbPuVPJX0"
      },
      "source": [
        "class EarlyStopping2(Callback):\n",
        "    \"\"\"Stop training when a monitored quantity has stopped improving.\n",
        "    # Arguments\n",
        "        monitor: quantity to be monitored.\n",
        "        min_delta: minimum change in the monitored quantity\n",
        "            to qualify as an improvement, i.e. an absolute\n",
        "            change of less than min_delta, will count as no\n",
        "            improvement.\n",
        "        patience: number of epochs that produced the monitored\n",
        "            quantity with no improvement after which training will\n",
        "            be stopped.\n",
        "            Validation quantities may not be produced for every\n",
        "            epoch, if the validation frequency\n",
        "            (`model.fit(validation_freq=5)`) is greater than one.\n",
        "        verbose: verbosity mode.\n",
        "        mode: one of {auto, min, max}. In `min` mode,\n",
        "            training will stop when the quantity\n",
        "            monitored has stopped decreasing; in `max`\n",
        "            mode it will stop when the quantity\n",
        "            monitored has stopped increasing; in `auto`\n",
        "            mode, the direction is automatically inferred\n",
        "            from the name of the monitored quantity.\n",
        "        baseline: Baseline value for the monitored quantity to reach.\n",
        "            Training will stop if the model doesn't show improvement\n",
        "            over the baseline.\n",
        "        restore_best_weights: whether to restore model weights from\n",
        "            the epoch with the best value of the monitored quantity.\n",
        "            If False, the model weights obtained at the last step of\n",
        "            training are used.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,validation_data,\n",
        "                 monitor='val_loss',\n",
        "                 min_delta=0,\n",
        "                 patience=0,\n",
        "                 verbose=0,\n",
        "                 mode='auto',\n",
        "                 baseline=None,\n",
        "                 restore_best_weights=False, message = ' '):\n",
        "        super(EarlyStopping2, self).__init__()\n",
        "        self.x_val = validation_data[0]\n",
        "        self.y_val = validation_data[1]\n",
        "        self.x_train = training_data[0]\n",
        "        self.y_train = training_data[1]\n",
        "        self.monitor = monitor\n",
        "        self.baseline = baseline\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.min_delta = min_delta\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_weights = None\n",
        "        self.best_epoch = 0\n",
        "        self.message = message\n",
        "\n",
        "        if mode not in ['auto', 'min', 'max']:\n",
        "            warnings.warn('EarlyStopping mode %s is unknown, '\n",
        "                          'fallback to auto mode.' % mode,\n",
        "                          RuntimeWarning)\n",
        "            mode = 'auto'\n",
        "\n",
        "        if mode == 'min':\n",
        "            self.monitor_op = np.less\n",
        "        elif mode == 'max':\n",
        "            self.monitor_op = np.greater\n",
        "        else:\n",
        "            if 'acc' in self.monitor:\n",
        "                self.monitor_op = np.greater\n",
        "            else:\n",
        "                self.monitor_op = np.less\n",
        "\n",
        "        if self.monitor_op == np.greater:\n",
        "            self.min_delta *= 1\n",
        "        else:\n",
        "            self.min_delta *= -1\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # Allow instances to be re-used\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        if self.baseline is not None:\n",
        "            self.best = self.baseline\n",
        "        else:\n",
        "            self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_pred_val = self.model.predict(self.x_val)\n",
        "        y_pred_train = self.model.predict(self.x_train)\n",
        "        current = roc_auc_score(self.y_val, y_pred_val)\n",
        "        current_train = roc_auc_score(self.y_train, y_pred_train)\n",
        "        print(\"Epoch \" +str(epoch+1) + \" AUC callback, validation: \" + str(current) + \" training\" + str(current_train) + self.message)\n",
        "        if(epoch<10):\n",
        "          current = 0\n",
        "\n",
        "        if current is None:\n",
        "            return\n",
        "      \n",
        "        if(current > self.best):\n",
        "            self.best = current\n",
        "            self.best_epoch = epoch + 1\n",
        "            self.wait = 0\n",
        "            if self.restore_best_weights:\n",
        "                self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                if self.restore_best_weights:\n",
        "                    self.model.set_weights(self.best_weights)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
        "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1PpCl7-8eR9"
      },
      "source": [
        "# define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505\n",
        "def auc_roc(y_true, y_pred):\n",
        "    # any tensorflow metric\n",
        "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true,num_thresholds=1000)\n",
        "    print(\"Stats AUC:\" + str(value) + \" Shape:\" + str(y_pred.shape[0]))\n",
        "    # find all variables created for this metric\n",
        "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
        "\n",
        "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
        "    # They will be initialized for new session.\n",
        "    for v in metric_vars:\n",
        "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
        "\n",
        "    # force to update metric values\n",
        "    with tf.control_dependencies([update_op]):\n",
        "        value = tf.identity(value)\n",
        "        return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpBCylYO-PWF"
      },
      "source": [
        "# Next one, getModel is  the *most important* piece of code in this notebook\n",
        "\n",
        "## getModel constructs neural networks according to the provided input. 5 neural network types are supported\n",
        "\n",
        "1) One unit sigmoid activation (equivalent to logistic regression)\n",
        "\n",
        "2) Perceptron with M hidden layers\n",
        "\n",
        "- Constant number of units in each layer (units)\n",
        "\n",
        "- Possibility to include batch normalization or drop-out\n",
        "\n",
        "3) Simple recurrent neural network\n",
        "\n",
        "- Possibility to adjust the output dimensionality (units)\n",
        "\n",
        "- Possibily to adjust the number of timesteps used (timestep)\n",
        "\n",
        "- Possibility to include drop-out\n",
        "\n",
        "4) Long-short memory recurrent neural network\n",
        "\n",
        "- Same options as in the simple RNN.\n",
        "\n",
        "5) GRU recurrent neural network\n",
        "\n",
        "- Same options as in the simple RNN.\n",
        "\n",
        "In addition, all these neural network take in regularization parameter for L2 regularization, which is super important to limit the overfitting since there are not that many training observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSysL-etvYDC"
      },
      "source": [
        "# Returns the model and ts_mode.\n",
        "# ts_mode = 0 for models that use lagged value of features\n",
        "# ts_mode = 1 for RNN models that handle past features with timestep\n",
        "import keras\n",
        "from keras.layers import Input,Dense,Lambda\n",
        "from keras.models import Model\n",
        "def getModel(mm ,    # Choose the model\n",
        "             units , # All NN models - unit for the layers\n",
        "             Nf ,    # All NN models - number of feature types\n",
        "             reg_weight , # All NN models - for L2 reg\n",
        "             timestep ,   # All RNN models\n",
        "             algo ,    # All NN models - 'adam', 'rmsprop', 'nadam','adagrad','adamax','adadelta','sgd'\n",
        "             dropout , # All NN models - dropout weight\n",
        "             batchnormalization , # Multilayer perceptron - true/false\n",
        "             hiddenlayers ,       # Multilayer perceptron\n",
        "             nlags,              # Multilayer perceptron and logit - lags for features (max. value = timestep)\n",
        "             return_state,\n",
        "             rnn_mode,\n",
        "             learning_rate):\n",
        "  n_categories=1\n",
        "  # Each algo uses Keras default values for learning rate and other params.\n",
        "  \n",
        "  if(algo=='adam'):\n",
        "    algo = keras.optimizers.Adam(lr =learning_rate);\n",
        "  else:\n",
        "    algo = keras.optimizers.RMSprop(lr =learning_rate);\n",
        "  mod = Sequential()\n",
        "  if mm == 1:\n",
        "    # Simplest\n",
        "    if(n_categories>2):\n",
        "      mod.add(Dense(n_categories, activation='softmax', input_dim=Nf*nlags, kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "    else:\n",
        "      mod.add(Dense(1, activation='sigmoid', input_dim=Nf*nlags, kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "    ts_mode = 0\n",
        "  if mm == 2:\n",
        "    # Multilayer perceptron\n",
        "    # Allows for either dropout or batchnormalization or neither.\n",
        "    \n",
        "    mod.add(Dense(units, activation='relu', input_dim=Nf*nlags, kernel_regularizer=l2_reg(reg_weight[0]))) # Kernel regularizer added here, was missing from the dp version\n",
        "    if(dropout>0.0):\n",
        "      mod.add(Dropout(dropout))\n",
        "    elif(batchnormalization):\n",
        "      mod.add(BatchNormalization())\n",
        "    \n",
        "    for h in range(1, hiddenlayers):\n",
        "      mod.add(Dense(units, activation='relu', kernel_regularizer=l2_reg(reg_weight[0])))\n",
        "      if(dropout>0.0):\n",
        "        mod.add(Dropout(dropout))\n",
        "      elif(batchnormalization):\n",
        "        mod.add(BatchNormalization())\n",
        "    \n",
        "    if(n_categories>2):\n",
        "       mod.add(Dense(n_categories, activation='softmax',  kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "    else:\n",
        "      mod.add(Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "    ts_mode = 0\n",
        "  if mm == 3:\n",
        "    if(return_state == False):\n",
        "\n",
        "      if(hiddenlayers>1):\n",
        "        mod.add(SimpleRNN(units, input_shape=(timestep, Nf), return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "        for i in range(2,hiddenlayers):\n",
        "          mod.add(SimpleRNN(units, return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "        mod.add(SimpleRNN(units, return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "      else:\n",
        "        mod.add(SimpleRNN(units, input_shape=(timestep, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "              \n",
        "      if(n_categories>2):\n",
        "        mod.add(Dense(n_categories, activation='softmax',  kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      else:\n",
        "        mod.add(Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      \n",
        "      ts_mode = 1\n",
        "\n",
        "    else:\n",
        "      inputs = Input(shape=(timestep,Nf))\n",
        "      \n",
        "      if(rnn_mode==1):\n",
        "        ip0,ip1,ip2,ip3,ip4 = Lambda(lambda x: tf.split(x,timestep,axis=1))(inputs)\n",
        "\n",
        "        op1 = SimpleRNN(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True,dropout=dropout,recurrent_dropout=dropout)(inputs = ip0)\n",
        "        op2 = SimpleRNN(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True,dropout=dropout,recurrent_dropout=dropout)(inputs = ip1, initial_state=op1[1:])\n",
        "        op3 = SimpleRNN(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True,dropout=dropout,recurrent_dropout=dropout)(inputs = ip2, initial_state=op2[1:])\n",
        "        op4 = SimpleRNN(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True,dropout=dropout,recurrent_dropout=dropout)(inputs = ip3, initial_state=op3[1:])\n",
        "        op5 = SimpleRNN(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = False,dropout=dropout,recurrent_dropout=dropout)(inputs = ip4, initial_state=op4[1:])\n",
        "\n",
        "      elif(rnn_mode==2):\n",
        "        ip0,ip1 = Lambda(lambda x: tf.split(x,[timestep-1,1],axis=1))(inputs)\n",
        "        op1 = SimpleRNN(units, input_shape=(timestep-1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True,dropout=dropout,recurrent_dropout=dropout)(inputs = ip0)\n",
        "        op5 = SimpleRNN(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = False,dropout=dropout,recurrent_dropout=dropout)(inputs = ip1, initial_state=op1[1:])\n",
        "\n",
        "      predictions = Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3]))(op5)  #, kernel_regularizer=l2_reg(reg_weight[0])\n",
        "      mod = Model(inputs=inputs, outputs=predictions)\n",
        "     \n",
        "      ts_mode=1\n",
        "      \n",
        "\n",
        "  if mm == 4 and dropout==0.0:\n",
        "    if(return_state == False):\n",
        "      # LSTM\n",
        "      if(hiddenlayers>1):\n",
        "        mod.add(CuDNNLSTM(units, input_shape=(timestep, Nf), return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "        for i in range(2,hiddenlayers):\n",
        "          mod.add(CuDNNLSTM(units, return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "        mod.add(CuDNNLSTM(units, return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "      else:\n",
        "        mod.add(CuDNNLSTM(units, input_shape=(timestep, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "\n",
        "      if(n_categories>2):\n",
        "        mod.add(Dense(n_categories, activation='softmax',  kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      else:\n",
        "        mod.add(Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      \n",
        "      ts_mode = 1\n",
        "    else:\n",
        "      inputs = Input(shape=(timestep,Nf))\n",
        "      \n",
        "      if(rnn_mode==1):\n",
        "        ip0,ip1,ip2,ip3,ip4 = Lambda(lambda x: tf.split(x,timestep,axis=1))(inputs)\n",
        "\n",
        "        op1 = CuDNNLSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip0)\n",
        "        op2 = CuDNNLSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip1, initial_state=op1[1:])\n",
        "        op3 = CuDNNLSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip2, initial_state=op2[1:])\n",
        "        op4 = CuDNNLSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip3, initial_state=op3[1:])\n",
        "        op5 = CuDNNLSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = False)(inputs = ip4, initial_state=op4[1:])\n",
        "\n",
        "      elif(rnn_mode==2):\n",
        "        ip0,ip1 = Lambda(lambda x: tf.split(x,[timestep-1,1],axis=1))(inputs)\n",
        "        op1 = CuDNNLSTM(units, input_shape=(timestep-1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip0)\n",
        "        op5 = CuDNNLSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = False)(inputs = ip1, initial_state=op1[1:])\n",
        "\n",
        "      elif(rnn_mode==3):\n",
        "        op1 = CuDNNLSTM(units, input_shape=(timestep, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs)\n",
        "        op5 = keras.layers.concatenate([op1[0],op1[2]], axis=-1)\n",
        "\n",
        "      if(n_categories>2):\n",
        "        predictions = Dense(n_categories, activation='softmax', kernel_regularizer=l2_reg(reg_weight[3]))(op5)\n",
        "      else:\n",
        "        predictions = Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3]))(op5)\n",
        "      mod = Model(inputs=inputs, outputs=predictions)\n",
        "    \n",
        "      ts_mode=1      \n",
        "\n",
        "  if mm == 4 and dropout>0.0:\n",
        "    if(return_state == False):\n",
        "      # LSTM\n",
        "      if(hiddenlayers>1):\n",
        "        mod.add(LSTM(units, input_shape=(timestep, Nf), return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "        for i in range(2,hiddenlayers):\n",
        "          mod.add(LSTM(units, return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "        mod.add(LSTM(units, return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "      else:\n",
        "        mod.add(LSTM(units, input_shape=(timestep, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        " \n",
        "      if(n_categories>2):\n",
        "        mod.add(Dense(n_categories, activation='softmax',  kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      else:\n",
        "        mod.add(Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      \n",
        "      ts_mode = 1\n",
        "    else:\n",
        "      inputs = Input(shape=(timestep,Nf))\n",
        "      \n",
        "      if(rnn_mode==1):\n",
        "        ip0,ip1,ip2,ip3,ip4 = Lambda(lambda x: tf.split(x,timestep,axis=1))(inputs)\n",
        "\n",
        "        op1 = LSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip0)\n",
        "        op2 = LSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip1, initial_state=op1[1:])\n",
        "        op3 = LSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip2, initial_state=op2[1:])\n",
        "        op4 = LSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip3, initial_state=op3[1:])\n",
        "        op5 = LSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = False)(inputs = ip4, initial_state=op4[1:])\n",
        "\n",
        "      elif(rnn_mode==2):\n",
        "        ip0,ip1 = Lambda(lambda x: tf.split(x,[timestep-1,1],axis=1))(inputs)\n",
        "        op1 = LSTM(units, input_shape=(timestep-1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip0)\n",
        "        op5 = LSTM(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = False)(inputs = ip1, initial_state=op1[1:])\n",
        "\n",
        "      elif(rnn_mode==3):\n",
        "        op1 = LSTM(units, input_shape=(timestep, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs)\n",
        "        op5 = keras.layers.concatenate([op1[0],op1[2]], axis=-1)\n",
        "\n",
        "      if(n_categories>2):\n",
        "        predictions = Dense(n_categories, activation='softmax', kernel_regularizer=l2_reg(reg_weight[3]))(op5)\n",
        "      else:\n",
        "        predictions = Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3]))(op5)  #, kernel_regularizer=l2_reg(reg_weight[0])\n",
        "      mod = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "      ts_mode=1      \n",
        "\n",
        "  if mm == 5 and dropout==0:\n",
        "    if(return_state == False):\n",
        "      # GRU\n",
        "      if(hiddenlayers>1):\n",
        "        mod.add(CuDNNGRU(units, input_shape=(timestep, Nf), return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "        for i in range(2,hiddenlayers):\n",
        "          mod.add(CuDNNGRU(units, return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "        mod.add(CuDNNGRU(units, return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "      else:\n",
        "        mod.add(CuDNNGRU(units, input_shape=(timestep, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2])))\n",
        "\n",
        "      if(n_categories>2):\n",
        "        mod.add(Dense(n_categories, activation='softmax',  kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      else:\n",
        "        mod.add(Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3])))    \n",
        "      ts_mode = 1\n",
        "\n",
        "    else:\n",
        "      inputs = Input(shape=(timestep,Nf))\n",
        "      \n",
        "      if(rnn_mode==1):\n",
        "        ip0,ip1,ip2,ip3,ip4 = Lambda(lambda x: tf.split(x,timestep,axis=1))(inputs)\n",
        "\n",
        "        op1 = CuDNNGRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip0)\n",
        "        op2 = CuDNNGRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip1, initial_state=op1[1:])\n",
        "        op3 = CuDNNGRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip2, initial_state=op2[1:])\n",
        "        op4 = CuDNNGRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip3, initial_state=op3[1:])\n",
        "        op5 = CuDNNGRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = False)(inputs = ip4, initial_state=op4[1:])\n",
        "\n",
        "      elif(rnn_mode==2):\n",
        "        ip0,ip1 = Lambda(lambda x: tf.split(x,[timestep-1,1],axis=1))(inputs)\n",
        "        op1 = CuDNNGRU(units, input_shape=(timestep-1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = True)(inputs = ip0)\n",
        "        op5 = CuDNNGRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),return_state = False)(inputs = ip1, initial_state=op1[1:])\n",
        "\n",
        "      \n",
        "      if(n_categories>2):\n",
        "        predictions = Dense(n_categories, activation='softmax', kernel_regularizer=l2_reg(reg_weight[3]))(op5)\n",
        "      else:\n",
        "        predictions = Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3]))(op5)\n",
        "      mod = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "      ts_mode=1\n",
        "      \n",
        "\n",
        "  if mm == 5 and dropout>0:\n",
        "    if(return_state == False):\n",
        "      # GRU\n",
        "      if(hiddenlayers>1):\n",
        "        mod.add(GRU(units, input_shape=(timestep, Nf), return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "        for i in range(2,hiddenlayers):\n",
        "          mod.add(GRU(units, return_sequences = True, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "        mod.add(GRU(units, return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "      else:\n",
        "        mod.add(GRU(units, input_shape=(timestep, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout))\n",
        "      if(dropout>0.0):\n",
        "        mod.add(Dropout(dropout))\n",
        "      if(n_categories>2):\n",
        "        mod.add(Dense(n_categories, activation='softmax',  kernel_regularizer=l2_reg(reg_weight[3])))\n",
        "      else:\n",
        "        mod.add(Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3])))     \n",
        "      ts_mode = 1\n",
        "\n",
        "    else:\n",
        "      inputs = Input(shape=(timestep,Nf))\n",
        "      \n",
        "      if(rnn_mode==1):\n",
        "        ip0,ip1,ip2,ip3,ip4 = Lambda(lambda x: tf.split(x,timestep,axis=1))(inputs)\n",
        "\n",
        "        op1 = GRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip0)\n",
        "        op2 = GRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip1, initial_state=op1[1:])\n",
        "        op3 = GRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip2, initial_state=op2[1:])\n",
        "        op4 = GRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip3, initial_state=op3[1:])\n",
        "        op5 = GRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = False)(inputs = ip4, initial_state=op4[1:])\n",
        "\n",
        "      elif(rnn_mode==2):\n",
        "        ip0,ip1 = Lambda(lambda x: tf.split(x,[timestep-1,1],axis=1))(inputs)\n",
        "        op1 = GRU(units, input_shape=(timestep-1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = True)(inputs = ip0)\n",
        "        op5 = GRU(units, input_shape=(1, Nf), return_sequences = False, kernel_regularizer=l2_reg(reg_weight[0]), recurrent_regularizer=l2_reg(reg_weight[1]),activity_regularizer=l2_reg(reg_weight[2]),dropout=dropout,recurrent_dropout=dropout,return_state = False)(inputs = ip1, initial_state=op1[1:])\n",
        "\n",
        "      if(n_categories>2):\n",
        "        predictions = Dense(n_categories, activation='softmax', kernel_regularizer=l2_reg(reg_weight[3]))(op5)\n",
        "      else:\n",
        "        predictions = Dense(1, activation='sigmoid', kernel_regularizer=l2_reg(reg_weight[3]))(op5)\n",
        "      mod = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "      ts_mode=1\n",
        "      \n",
        "\n",
        "  if mm == 0:\n",
        "    # Logistic (use statsmodels library's logistic regression)\n",
        "    return 0,2\n",
        "  if mm == 6:\n",
        "    # Lasso (use sklearn lasso regression)\n",
        "    mod = linear_model.Lasso(alpha=reg_weight[0])\n",
        "    ts_mode = 3\n",
        "    return mod, ts_mode\n",
        "  if mm == 7:\n",
        "    # Regularized logistic regression    \n",
        "    mod = LogisticRegression( C = 1/reg_weight[0],penalty='l1', solver='liblinear' )\n",
        "    ts_mode = 4\n",
        "    return mod, ts_mode\n",
        "  \n",
        "  if(n_categories>2):\n",
        "    mod.compile(loss='categorical_crossentropy', optimizer=algo, metrics=['accuracy'])\n",
        "  else:\n",
        "    mod.compile(loss='binary_crossentropy', optimizer=algo, metrics=['accuracy'])\n",
        "  \n",
        "  return mod,ts_mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_kD6PpWE69O"
      },
      "source": [
        "# Fits the model\n",
        "def fitModel(XTRAIN, YTRAIN, XTEST, YTEST, mod, ts_mode, timestep, nlags, batch_size, epochs, print_data = True, validate = False, patience = 300, message = ' ', class_weight={0: 0.5, 1: 0.5},logit_reg_weight=0.1):\n",
        "        history = 0;\n",
        "        if ts_mode == 0:\n",
        "          # Reshape the data to use the lagged values of features\n",
        "          XTRAIN, XTEST = reshape_features(XTRAIN, XTEST, timestep, nlags)\n",
        "          if(validate):\n",
        "            my_callbacks = [EarlyStopping2(validation_data=(XTEST, YTEST),training_data=(XTRAIN, YTRAIN),monitor='auc_roc', patience=patience, verbose=1, mode='max',restore_best_weights=False, message = message)]\n",
        "            history = mod.fit(XTRAIN, YTRAIN, batch_size=batch_size, epochs=epochs, shuffle=True,verbose = 0, callbacks=my_callbacks, class_weight=class_weight)\n",
        "          else:\n",
        "            with suppress_stdout():\n",
        "              history = mod.fit(XTRAIN, YTRAIN, batch_size=batch_size, shuffle=True,epochs=epochs,verbose = 0, class_weight=class_weight)\n",
        "          yp = mod.predict(XTEST)\n",
        "          t_opt = optimize_threshold(mod.predict(XTRAIN),YTRAIN[:,0],0.5)  \n",
        "          y_pred = yp[:,0]\n",
        "          y_true = YTEST[:,0]\n",
        "          AUC_train=roc_auc_score( YTRAIN[:,0],mod.predict( XTRAIN ));\n",
        "          if(print_data):\n",
        "            print('Training results, Accuracy %.3f' % history.history['acc'][-1], 'AUC  %.3f' % roc_auc_score( YTRAIN[:,0],mod.predict( XTRAIN ) ) )\n",
        "        elif ts_mode == 1:\n",
        "          if(validate):\n",
        "            my_callbacks = [EarlyStopping2(validation_data=(XTEST, YTEST),training_data=(XTRAIN, YTRAIN),monitor='auc_roc', patience=patience, verbose=1, mode='max',restore_best_weights=False, message = message)] #, ModelCheckpoint(filepath=\"weights{epoch:03d}.hdf5\")]\n",
        "            history = mod.fit(XTRAIN, YTRAIN, batch_size=batch_size, epochs=epochs, shuffle=True,verbose = 0, callbacks=my_callbacks, class_weight=class_weight)\n",
        "          else:\n",
        "            with suppress_stdout():\n",
        "              history = mod.fit(XTRAIN, YTRAIN, batch_size=batch_size, shuffle=True,epochs=epochs,verbose = 0, class_weight=class_weight)\n",
        "          yp = mod.predict(XTEST)\n",
        "          t_opt = optimize_threshold(mod.predict(XTRAIN),YTRAIN[:,0],0.5)\n",
        "          y_pred = yp[:,0]\n",
        "          y_true = YTEST[:,0]\n",
        "          AUC_train=roc_auc_score( YTRAIN[:,0],mod.predict( XTRAIN ));\n",
        "          if(print_data):\n",
        "            print('Training results, Accuracy %.3f' % history.history['acc'][-1], 'AUC  %.3f' % roc_auc_score( YTRAIN[:,0],mod.predict( XTRAIN ) ) )\n",
        "        elif ts_mode == 2: # Logistic regression\n",
        "          XTRAIN, XTEST = reshape_features(XTRAIN, XTEST, timestep, nlags)\n",
        "          XTRAIN = sm.add_constant(XTRAIN)\n",
        "          XTEST = sm.add_constant(XTEST)\n",
        "          YTRAIN = YTRAIN[:,0]\n",
        "          with suppress_stdout():\n",
        "            if(logit_reg_weight>0):\n",
        "                mod = sm.Logit(YTRAIN, XTRAIN).fit_regularized(alpha=logit_reg_weight,method='l1');\n",
        "            else:\n",
        "                mod = sm.Logit(YTRAIN, XTRAIN).fit(method='bfgs'); #_regularized(alpha=0.01,method='l1');\n",
        "          y_pred = mod.predict(XTEST)\n",
        "          y_true = YTEST[:,0]\n",
        "          t_opt = optimize_threshold(mod.predict(XTRAIN),YTRAIN,0.5)\n",
        "          AccRate = np.sum((mod.predict( XTRAIN ) > .5)==YTRAIN)/len(YTRAIN) \n",
        "          AUC_train = roc_auc_score( YTRAIN,mod.predict( XTRAIN ));\n",
        "          if(print_data):\n",
        "            print('Training results, Accuracy  %.3f' % AccRate, 'AUC  %.3f' % roc_auc_score( YTRAIN,mod.predict( XTRAIN ) ) )\n",
        "        elif ts_mode == 3: # Lasso\n",
        "          XTRAIN, XTEST = reshape_features(XTRAIN, XTEST, timestep, nlags)\n",
        "          XTRAIN = sm.add_constant(XTRAIN)\n",
        "          print('Size:' + str(XTRAIN.shape))\n",
        "          XTEST = sm.add_constant(XTEST)\n",
        "          YTRAIN = YTRAIN[:,0]\n",
        "          with suppress_stdout():\n",
        "            mod.fit(X = XTRAIN, y = YTRAIN)\n",
        "          y_pred = mod.predict(XTEST)\n",
        "          y_true = YTEST[:,0]\n",
        "          t_opt = optimize_threshold(mod.predict(XTRAIN),YTRAIN,0.5)\n",
        "          AccRate = np.sum((mod.predict( XTRAIN ) > .5)==YTRAIN)/len(YTRAIN) \n",
        "          AUC_train = roc_auc_score( YTRAIN,mod.predict( XTRAIN ));\n",
        "          if(print_data):\n",
        "            print('Training results, Accuracy  %.3f' % AccRate, 'AUC  %.3f' % roc_auc_score( YTRAIN,mod.predict( XTRAIN ) ) )\n",
        "        elif ts_mode == 4: # Logit regu\n",
        "          XTRAIN, XTEST = reshape_features(XTRAIN, XTEST, timestep, nlags)\n",
        "          XTRAIN = sm.add_constant(XTRAIN)\n",
        "          print('Size:' + str(XTRAIN.shape))\n",
        "          XTEST = sm.add_constant(XTEST)\n",
        "          YTRAIN = YTRAIN[:,0]\n",
        "          with suppress_stdout():\n",
        "            mod.fit(X = XTRAIN, y = YTRAIN)\n",
        "          y_pred = mod.predict_proba(XTEST)[:,1]\n",
        "          y_true = YTEST[:,0]\n",
        "          t_opt = optimize_threshold(mod.predict_proba(XTRAIN)[:,1],YTRAIN,0.5)\n",
        "          AccRate = np.sum((mod.predict_proba( XTRAIN )[:,1] > .5)==YTRAIN)/len(YTRAIN) \n",
        "          AUC_train = roc_auc_score( YTRAIN,mod.predict_proba( XTRAIN )[:,1] ) ;\n",
        "          if(print_data):\n",
        "            print('Training results, Accuracy  %.3f' % AccRate, 'AUC  %.3f' % roc_auc_score( YTRAIN,mod.predict_proba( XTRAIN )[:,1] ) )\n",
        "        return mod, y_pred,y_true,t_opt, AUC_train; #shapley_means, phi;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-gQ30BkEVof"
      },
      "source": [
        "# Plot keras training loss and accuracy\n",
        "def plot_history(history):\n",
        "\n",
        "  # Plot training accuracy values\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training loss values\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnjGwnsPm09c"
      },
      "source": [
        "# Plot ROC curve given true classes and predictions\n",
        "def plot_auc(yt,yp):\n",
        "  fpr,tpr,thresholds = roc_curve(yt,yp)\n",
        "  xgrid = np.linspace(0,1,100) \n",
        "  plt.plot(fpr,tpr,'blue')\n",
        "  plt.plot(xgrid,xgrid,'red')\n",
        "  plt.xlabel(\"False positive rate\")\n",
        "  plt.ylabel(\"True positive rate\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2LK2TnwxB4D"
      },
      "source": [
        "# Reshapes 3D (obs, time step, features) array into 2D array (obs, time step * features),\n",
        "# i.e. the lagged values of features are taken as features in the new 2D array.\n",
        "def reshape_features(XTRAIN, XTEST, timestep, nlags):\n",
        "  XTRAIN = XTRAIN[:,(timestep-nlags):timestep,:]\n",
        "  XTEST = XTEST[:,(timestep-nlags):timestep,:]\n",
        "  n1,n2,n3 = np.shape(XTRAIN)\n",
        "  XTRAIN = np.reshape(XTRAIN,(n1,n2*n3),'F')\n",
        "  n1,n2,n3 = np.shape(XTEST)\n",
        "  XTEST = np.reshape(XTEST,(n1,n2*n3),'F')\n",
        "  return XTRAIN, XTEST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hORr6HTny5g4"
      },
      "source": [
        "# Reshapes 3D (obs, time step, features) array into 2D array (obs, time step * features),\n",
        "# i.e. the lagged values of features are taken as features in the new 2D array.\n",
        "def reshape_features_ksi(XTEST, timestep, nlags):  \n",
        "  XTEST = XTEST[:,(timestep-nlags):timestep,:]  \n",
        "  n1,n2,n3 = np.shape(XTEST)\n",
        "  XTEST = np.reshape(XTEST,(n1,n2*n3),'F')\n",
        "  return XTEST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-rFRNJ5JJmO"
      },
      "source": [
        "\n",
        "# EXPMODE = 'window', 'const'\n",
        "\n",
        "\n",
        "# Takes in training data of following shape:\n",
        "# 0 - Training observation index - dim n\n",
        "# 1 - Timestep dimension = Lagged value of features - dim timestep\n",
        "# 2 - Feature dimension - dim Nf\n",
        "\n",
        "# DATAMODE = 'rnn','time-window' (reshapes the input according to this mode)\n",
        "\n",
        "# pred_mode = 'keras', 'statsmodel'\n",
        "\n",
        "def Shapley_analysis(mod,XTEST,XBACK,Nf,ts_mode,mm,timestep,nlags,EXPMODE='window'):\n",
        "    \n",
        "    if(ts_mode==1):\n",
        "      data_mode='rnn';\n",
        "    else:\n",
        "      data_mode='time-window';\n",
        "\n",
        "    if(mm==0):\n",
        "      pred_mode='statsmodel';\n",
        "    else:\n",
        "      pred_mode='keras';\n",
        "\n",
        "    # Extract length of XTEST\n",
        "    len_xtest = XTEST.shape[0];\n",
        "    # Define XTEST where the features are replaced by their expected value in the training sample\n",
        "    XEXP = np.zeros_like(XTEST);\n",
        "    if(EXPMODE=='window'):     \n",
        "      #exp_vec = np.mean(XTRAIN,axis=0);      \n",
        "      exp_vec = np.mean(XBACK,axis=0);      \n",
        "      for feat in range(0,Nf):\n",
        "        for tt in range(0,timestep):\n",
        "          XEXP[:,tt,feat] = exp_vec[tt,feat];\n",
        "    elif(EXPMODE=='const'):\n",
        "      #exp_vec = np.mean(np.mean(XTRAIN,axis=0),axis=0);\n",
        "      exp_vec = np.mean(np.mean(XBACK,axis=0),axis=0);\n",
        "      for feat in range(0,Nf):\n",
        "        XEXP[:,:,feat] = exp_vec[feat];\n",
        "  \n",
        "    # Loop over subsets ksi\n",
        "    pred_ksi = np.zeros((len_xtest,32),dtype=np.double)\n",
        "    # Tabulate the predictions for each predictor set\n",
        "    for Si in range(0,pow(2,Nf)):\n",
        "        b = np.unpackbits(np.array([[Si]], dtype=np.uint8));\n",
        "        ksi = b[(8-Nf):8].astype(np.double);\n",
        "        XTEST_ksi = np.zeros_like(XTEST);\n",
        "        for feat in range(0,Nf):\n",
        "            XTEST_ksi[:,:,feat] = XTEST[:,:,feat]*ksi[feat]+(1-ksi[feat])*XEXP[:,:,feat];\n",
        "        if(data_mode=='time-window'):\n",
        "            XTEST_ksi = reshape_features_ksi(XTEST_ksi, timestep, nlags);\n",
        "        if(pred_mode=='keras'):\n",
        "            pred_ksi[:,Si] = mod.predict(XTEST_ksi)[:,0]; # Make sure that the RHS is a vector, not z x 2 array. Compare to fit.\n",
        "        else:\n",
        "            XTEST_ksi2 = sm.add_constant(XTEST_ksi,has_constant='add');\n",
        "            pred_ksi[:,Si] = mod.predict(XTEST_ksi2); # Make sure that the RHS is a vector, not z x 2 array. Compare to fit.\n",
        "\n",
        "    # The rest should be general\n",
        "    # Calculate Shapley values using the difference formula\n",
        "    phi = np.zeros((len_xtest,Nf),dtype=np.double);\n",
        "    for Si in range(0,pow(2,Nf)):\n",
        "        b = np.unpackbits(np.array([[Si]], dtype=np.uint8));\n",
        "        ksi = b[(8-Nf):8].astype(np.double);\n",
        "        for feat in range(0,Nf):\n",
        "            if(b[8-Nf+feat]==1):\n",
        "                # feature is included in set ksi\n",
        "                bs = np.copy(b);\n",
        "                bs[(8-Nf)+feat]=0;\n",
        "                S = np.packbits(bs, axis=0)[0]; # the index of the set S without feat\n",
        "                NS = np.sum(ksi)-1;\n",
        "                fac = np.math.factorial(NS)*np.math.factorial(Nf-NS-1)/np.math.factorial(Nf);\n",
        "                phi[:,feat] = phi[:,feat] + fac*(pred_ksi[:,Si]-pred_ksi[:,S]);\n",
        "\n",
        "    # Calculate the mean Shapley values\n",
        "    #shapley_means = np.mean(phi,axis=0);\n",
        "    return phi,np.mean(pred_ksi[:,0],axis=0);\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8qB-M_qAuq4"
      },
      "source": [
        "# Reshapes data into a three dimensional array such that:\n",
        "# DIM\n",
        "# 0 - Training observation index - dim n\n",
        "# 1 - Timestep dimension = Lagged value of features - dim timestep\n",
        "# 2 - Feature dimension - dim Nf\n",
        "def reshape_data(df2,timestep,Nf,time_start,time_end):\n",
        "  c_train = df2['iso'].values\n",
        "  year_train = df2['year'].values\n",
        "  x_train = df2[all_predictors[0:Nf]].values\n",
        "  y_train = df2['precrisis'].values\n",
        "  cid_train = df2['cid'].values\n",
        "\n",
        "  n,p = np.shape(x_train)\n",
        "  Xt = np.empty(shape=(0,timestep,Nf))\n",
        "  yt = np.empty(shape=(0,1),dtype=int)\n",
        "  ct = list([])\n",
        "  yeart = list([])\n",
        "  cid = np.empty(shape=(0,),dtype=int)\n",
        "\n",
        "  for ii in range(timestep-1,n): \n",
        "    if(c_train[ii-timestep+1]==c_train[ii] and year_train[ii-timestep+1]==year_train[ii]-timestep+1 and y_train[ii]!=-1 and year_train[ii]>=time_start and year_train[ii]<=time_end): # check that there is no break\n",
        "      Xt = np.append(Xt,np.reshape(x_train[(ii-timestep+1):(ii+1),:],(1,timestep,Nf)),axis=0) # append the lagged features\n",
        "      yt = np.append(yt,np.reshape(y_train[ii],(1,1)),axis=0) # append the target variable\n",
        "      cid = np.append(cid,np.reshape(cid_train[ii],(1,)),axis=0) # append the target variable\n",
        "      ct.append(c_train[ii]) # append the country\n",
        "      yeart.append(year_train[ii]) # append the year \n",
        "  return Xt,yt,ct,yeart,cid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfJjlNpgtapp"
      },
      "source": [
        "def reshape_data_d2c(df2,timestep,Nf,time_start,time_end):\n",
        "  c_train = df2['iso'].values\n",
        "  year_train = df2['year'].values\n",
        "  x_train = df2[all_predictors[0:Nf]].values\n",
        "  cid_train = df2['cid'].values\n",
        "  dp_train = df2['disttoprevcris'].values\n",
        "  dn_train = df2['disttonextcris'].values\n",
        "\n",
        "  n,p = np.shape(x_train)\n",
        "  Xt = np.empty(shape=(0,timestep,Nf))\n",
        "  ct = list([])\n",
        "  yeart = list([])\n",
        "  cid = np.empty(shape=(0,),dtype=int)\n",
        "  dp = list([])\n",
        "  dn = list([])\n",
        "\n",
        "  for ii in range(timestep-1,n): \n",
        "    if(c_train[ii-timestep+1]==c_train[ii] and year_train[ii-timestep+1]==year_train[ii]-timestep+1 and year_train[ii]>=time_start and year_train[ii]<=time_end): # check that there is no break\n",
        "      Xt = np.append(Xt,np.reshape(x_train[(ii-timestep+1):(ii+1),:],(1,timestep,Nf)),axis=0) # append the lagged features\n",
        "      cid = np.append(cid,np.reshape(cid_train[ii],(1,)),axis=0) # append the target variable\n",
        "      ct.append(c_train[ii]) # append the country\n",
        "      dp.append(dp_train[ii])\n",
        "      dn.append(-dn_train[ii])\n",
        "      yeart.append(year_train[ii]) # append the year \n",
        "  return Xt,ct,yeart,cid,dp,dn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoReE8iUpm07"
      },
      "source": [
        "# Sequential 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N740fbBCtapq"
      },
      "source": [
        "#from tf.keras.models import clone_model\n",
        "# Evaluate permance of a given model using country-by-country cross-validation.\n",
        "def sequential_evaluation(mm ,  # must choose model class\n",
        "                          df , # must choose input data\n",
        "                          batch_size = 16, # Define training params for NN\n",
        "                          epochs = 100,\n",
        "                          # Rest of them are input for getModel:\n",
        "                          units = 10, # All NN models - unit for the layers\n",
        "                          Nf = 5,     # All NN models - number of feature types\n",
        "                          reg_weight = [0.001,0,0,0.001], # All NN models - for L2 reg\n",
        "                          timestep = 5,     # All RNN models\n",
        "                          algo = 'adam',    # All NN models - 'adam', 'rmsprop', 'nadam','adagrad','adamax','adadelta','sgd'\n",
        "                          dropout = 0.0,    # All NN models - dropout weight\n",
        "                          batchnormalization = False, # Multilayer perceptron - true/false\n",
        "                          print_epoch_stats = False,\n",
        "                          hiddenlayers = 1,           # Multilayer perceptron\n",
        "                          nlags = 1,                 # Multilayer perceptron and logit - lags for features\n",
        "                          reps = 10, # How many times to train the neural network\n",
        "                          patience = 2,\n",
        "                          return_state = False,\n",
        "                          rnn_mode = 1,\n",
        "                          learning_rate=0.01,\n",
        "                          fhandle=0,\n",
        "                          fcast_horizon=1,\n",
        "                          sub_epochs=1,\n",
        "                          class_weight={0: 0.5, 1: 0.5},\n",
        "                          plot_reliability=False,\n",
        "                          validate=False,save_model=False,do_shapley=False,test_start_year=2003, # Define test set\n",
        "                          test_end_year=2016,train_start_year=1970, # Define test set\n",
        "                          train_end_year=2002,code=0,d2cgraph=False): # output file handle\n",
        "  \n",
        "  name = modelname(mm=mm,rnn_mode=rnn_mode,return_state=return_state,lags=nlags);\n",
        "  date_time = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S-\")\n",
        "  # First some helper variables\n",
        "  ts_mode=0;\n",
        "  if(mm>2):\n",
        "    ts_mode=1\n",
        "      \n",
        "  if(ts_mode==1):\n",
        "    data_mode='rnn';\n",
        "  else:\n",
        "    data_mode='time-window';\n",
        "  if(mm==0):\n",
        "    pred_mode='statsmodel';\n",
        "  else:\n",
        "    pred_mode='keras';\n",
        "  df_train=add_precrisis(df,fcast_horizon=fcast_horizon,postdrop=5, stfilter = True );  \n",
        "\n",
        "  wreturn_state = 0;\n",
        "  if(return_state==True):\n",
        "    wreturn_state = 1;\n",
        "  # Reshape the data and add timestep lags\n",
        "  Xt,yt,ct,yeart,cid = reshape_data(df_train,timestep,Nf,train_start_year,test_end_year);\n",
        "\n",
        "  # Set the training and test data for this year.\n",
        "  train = [i for i, val in enumerate(yeart) if(val>=train_start_year and val<=train_end_year)]\n",
        "  test = [i for i, val in enumerate(yeart) if(val>=test_start_year and val<=test_end_year)]\n",
        "      \n",
        "  # Extract the data from the full-sample.\n",
        "  XTRAIN=Xt[train,:,:]\n",
        "  YTRAIN=yt[train,:]\n",
        "  XTEST=Xt[test,:,:]\n",
        "  YTEST=yt[test,:]\n",
        "  cid=cid[test];\n",
        "  # Reset random seed\n",
        "  t_start = time.time()\n",
        "  seed(2)\n",
        "  set_random_seed(3)\n",
        "  print(\"Crises train:\"+ str(np.sum(YTRAIN)))\n",
        "  print(\"Crises test:\"+ str(np.sum(YTEST)))\n",
        "\n",
        "  summary_not_shown = True;\n",
        "\n",
        "  c=-1\n",
        "  K.clear_session()\n",
        "  models = [];\n",
        "  best_weights = [];\n",
        "  AUC_best=0;\n",
        "  ypreds = np.zeros((YTEST.shape[0],reps),dtype=float)\n",
        "  for epoch in range(0,epochs):\n",
        "      ave_AUC_train =0;\n",
        "      for r in range(0,reps):\n",
        "\n",
        "        if(epoch==0):\n",
        "          mod, ts_mode = getModel(mm, units, Nf, reg_weight, timestep , algo, dropout, batchnormalization, hiddenlayers, nlags, return_state = return_state, rnn_mode = rnn_mode,learning_rate=learning_rate);\n",
        "          models.append(mod);\n",
        "          if(mm>0):\n",
        "            best_weights.append(mod.get_weights());\n",
        "          \n",
        "        \n",
        "        # Fit model\n",
        "        if(validate):\n",
        "          models[r],ypreds[:,r],y_true,t_opt, AUC_train = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, models[r], ts_mode, timestep, nlags, batch_size, sub_epochs, print_data = False,validate=True,class_weight=class_weight,logit_reg_weight=reg_weight[0])    \n",
        "        else:\n",
        "          models[r],ypreds[:,r],y_true,t_opt, AUC_train = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, models[r], ts_mode, timestep, nlags, batch_size, sub_epochs, print_data = False,class_weight=class_weight,logit_reg_weight=reg_weight[0])    \n",
        "\n",
        "        # Calculate simple average of all training AUCs\n",
        "        ave_AUC_train = ave_AUC_train+AUC_train;\n",
        "        \n",
        "      \n",
        "      # Amend the statistics and predictions etc.      \n",
        "      y_pred = np.mean(ypreds,axis=1);\n",
        "\n",
        "      AUC = roc_auc_score(y_true,y_pred);\n",
        "      ave_AUC_train=ave_AUC_train/(reps);\n",
        "      if(AUC>AUC_best):\n",
        "        for r in range(0,reps):\n",
        "            if(mm>0):\n",
        "              best_weights[r] = models[r].get_weights();\n",
        "            AUC_best=AUC;\n",
        "            AUC_best_ave_AUC_train = ave_AUC_train;\n",
        "            best_epoch=epoch;\n",
        "\n",
        "      if(print_epoch_stats):\n",
        "        f.write( \"%d;%d;%d;%d;%d;%d;%7.6f;%7.6f;%7.6f;%7.6f;%7.6f\\n\" % (mm,fcast_horizon,rnn_mode,wreturn_state,hiddenlayers,epoch,AUC,reg_weight[0],reg_weight[1],reg_weight[2],reg_weight[3]) );\n",
        "        f.flush();\n",
        "      print(\"Stats - Epoch:\",(epoch+1)*sub_epochs,\"AUC-val %5.3f \" %(AUC),\"AUC-train %5.3f\" %(ave_AUC_train))\n",
        "        \n",
        "    # END OF EPOCH LOOP\n",
        "  \n",
        "  # POST-PROCESSING PART I:\n",
        "  # Retrieve the best weights and evaluate AUC for all forecast horizons\n",
        "  df1=add_precrisis(df,fcast_horizon=1,postdrop=5, stfilter = True );\n",
        "  df2=add_precrisis(df,fcast_horizon=2,postdrop=5, stfilter = True );\n",
        "  df3=add_precrisis(df,fcast_horizon=3,postdrop=5, stfilter = True );\n",
        "  df4=add_precrisis(df,fcast_horizon=4,postdrop=5, stfilter = True );\n",
        "  df5=add_precrisis(df,fcast_horizon=5,postdrop=5, stfilter = True );\n",
        "\n",
        "  Xt1,yt1,ct1,yeart1,_ = reshape_data(df1,timestep,Nf,train_start_year,test_end_year);\n",
        "  Xt2,yt2,ct2,yeart2,_ = reshape_data(df2,timestep,Nf,train_start_year,test_end_year);\n",
        "  Xt3,yt3,ct3,yeart3,_ = reshape_data(df3,timestep,Nf,train_start_year,test_end_year);\n",
        "  Xt4,yt4,ct4,yeart4,_ = reshape_data(df4,timestep,Nf,train_start_year,test_end_year);\n",
        "  Xt5,yt5,ct5,yeart5,_ = reshape_data(df5,timestep,Nf,train_start_year,test_end_year);\n",
        "\n",
        "  \n",
        "\n",
        "  test1 = [i for i, val in enumerate(yeart1) if(val>=test_start_year and val<=test_end_year)]\n",
        "  test2 = [i for i, val in enumerate(yeart2) if(val>=test_start_year and val<=test_end_year)]\n",
        "  test3 = [i for i, val in enumerate(yeart3) if(val>=test_start_year and val<=test_end_year)]\n",
        "  test4 = [i for i, val in enumerate(yeart4) if(val>=test_start_year and val<=test_end_year)]\n",
        "  test5 = [i for i, val in enumerate(yeart5) if(val>=test_start_year and val<=test_end_year)]\n",
        "  XTEST1=Xt1[test1,:,:]\n",
        "  y_true1=yt1[test1,0]\n",
        "  XTEST2=Xt2[test2,:,:]\n",
        "  y_true2=yt2[test2,0]\n",
        "  XTEST3=Xt3[test3,:,:]\n",
        "  y_true3=yt3[test3,0]\n",
        "  XTEST4=Xt4[test4,:,:]\n",
        "  y_true4=yt4[test4,0]\n",
        "  XTEST5=Xt5[test5,:,:]\n",
        "  y_true5=yt5[test5,0]\n",
        "\n",
        "  if(d2cgraph):\n",
        "    df_d2c=add_dist2cris(df, stfilter = True);\n",
        "    Xt_d2c,ct_d2c,yeart_d2c,cid_d2c,dp_d2c,dn_d2c = reshape_data_d2c(df_d2c,timestep,Nf,test_start_year,test_end_year);\n",
        "    XTEST_d2c=Xt_d2c[:,:,:];\n",
        "    ypreds_d2c = np.zeros((XTEST_d2c.shape[0],reps),dtype=float);\n",
        "    if(data_mode=='time-window'):\n",
        "      XTEST_d2c = reshape_features_ksi(XTEST_d2c, timestep, nlags);\n",
        "      if(pred_mode!='keras'):\n",
        "        XTEST_d2c = sm.add_constant(XTEST_d2c,has_constant='add');\n",
        "        \n",
        "  if(data_mode=='time-window'):\n",
        "      XTEST1 = reshape_features_ksi(XTEST1, timestep, nlags);\n",
        "      XTEST2 = reshape_features_ksi(XTEST2, timestep, nlags);\n",
        "      XTEST3 = reshape_features_ksi(XTEST3, timestep, nlags);\n",
        "      XTEST4 = reshape_features_ksi(XTEST4, timestep, nlags);\n",
        "      XTEST5 = reshape_features_ksi(XTEST5, timestep, nlags);\n",
        "      if(pred_mode!='keras'):\n",
        "        XTEST1 = sm.add_constant(XTEST1,has_constant='add');\n",
        "        XTEST2 = sm.add_constant(XTEST2,has_constant='add');\n",
        "        XTEST3 = sm.add_constant(XTEST3,has_constant='add');\n",
        "        XTEST4 = sm.add_constant(XTEST4,has_constant='add');\n",
        "        XTEST5 = sm.add_constant(XTEST5,has_constant='add');\n",
        "        \n",
        "  # Allocate tables for reps\n",
        "  ypreds1 = np.zeros((y_true1.shape[0],reps),dtype=float);\n",
        "  ypreds2 = np.zeros((y_true2.shape[0],reps),dtype=float);\n",
        "  ypreds3 = np.zeros((y_true3.shape[0],reps),dtype=float);\n",
        "  ypreds4 = np.zeros((y_true4.shape[0],reps),dtype=float);\n",
        "  ypreds5 = np.zeros((y_true5.shape[0],reps),dtype=float);\n",
        "  for r in range(0,reps):\n",
        "      if(mm>0):\n",
        "        models[r].set_weights(best_weights[r]);\n",
        "        if(save_model):\n",
        "          models[rc].save('seq_' + name + '_' + str(rc) + \"-\" + date_time + '.h5');\n",
        "      if(pred_mode=='keras'):\n",
        "        if(XTEST1.shape[0]>0):\n",
        "          ypreds1[:,r] = models[r].predict(XTEST1)[:,0];\n",
        "        if(XTEST2.shape[0]>0):\n",
        "          ypreds2[:,r] = models[r].predict(XTEST2)[:,0];\n",
        "        if(XTEST3.shape[0]>0):\n",
        "          ypreds3[:,r] = models[r].predict(XTEST3)[:,0];\n",
        "        if(XTEST4.shape[0]>0):\n",
        "          ypreds4[:,r] = models[r].predict(XTEST4)[:,0];\n",
        "        if(XTEST5.shape[0]>0):\n",
        "          ypreds5[:,r] = models[r].predict(XTEST5)[:,0];\n",
        "        if(d2cgraph):\n",
        "            if(XTEST_d2c.shape[0]>0):\n",
        "                ypreds_d2c[:,r] = models[r].predict(XTEST_d2c)[:,0];\n",
        "      else:            \n",
        "        if(XTEST1.shape[0]>0):\n",
        "          ypreds1[:,r] = models[r].predict(XTEST1);\n",
        "        if(XTEST2.shape[0]>0):\n",
        "          ypreds2[:,r] = models[r].predict(XTEST2);\n",
        "        if(XTEST3.shape[0]>0):\n",
        "          ypreds3[:,r] = models[r].predict(XTEST3);\n",
        "        if(XTEST4.shape[0]>0):\n",
        "          ypreds4[:,r] = models[r].predict(XTEST4);\n",
        "        if(XTEST5.shape[0]>0):\n",
        "          ypreds5[:,r] = models[r].predict(XTEST5);\n",
        "        if(d2cgraph):\n",
        "            if(XTEST_d2c.shape[0]>0):\n",
        "                ypreds_d2c[:,r] = models[r].predict(XTEST_d2c);\n",
        "   \n",
        "  y_pred1 = np.mean(ypreds1,axis=1);\n",
        "  y_pred2 = np.mean(ypreds2,axis=1);\n",
        "  y_pred3 = np.mean(ypreds3,axis=1);\n",
        "  y_pred4 = np.mean(ypreds4,axis=1);\n",
        "  y_pred5 = np.mean(ypreds5,axis=1);\n",
        "  \n",
        "  # Create the distance to crisis graph\n",
        "  if(d2cgraph):\n",
        "    y_pred_d2c = np.mean(ypreds_d2c,axis=1);\n",
        "    vari= '_';\n",
        "    for d in range(0,Nf):\n",
        "        vari = vari + all_predictors[d] + '_';\n",
        "    filename_d2c = 'C:/Users/eerot/Desktop/NNCALC/d2c_' + name + '_' + vari.replace(\"/\",\"\") + str(fcast_horizon) + '.txt';    \n",
        "    if(code!=0):\n",
        "        filename_d2c = 'C:/Users/eerot/Desktop/NNCALC/' + str(code) + '.txt';    \n",
        "    f_d2c=open(filename_d2c, \"w\")\n",
        "    #a = np.empty((20,))*np.nan;    \n",
        "\n",
        "    for d in range(-10,1):\n",
        "        d2c_sample = [i for i, val in enumerate(dn_d2c) if(val==d)] \n",
        "        x = y_pred_d2c[d2c_sample];\n",
        "        f_d2c.write(\"%3.0f;\" %(d));\n",
        "        for ix in range(0,x.shape[0]):\n",
        "            f_d2c.write(\"%10.7f;\" %(x[ix]));            \n",
        "        f_d2c.write(\"\\n\");\n",
        "    for d in range(1,11):\n",
        "        d2c_sample = [i for i, val in enumerate(dp_d2c) if(val==d)] \n",
        "        x = y_pred_d2c[d2c_sample];\n",
        "        f_d2c.write(\"%3.0f;\" %(d));\n",
        "        for ix in range(0,x.shape[0]):\n",
        "            f_d2c.write(\"%10.7f;\" %(x[ix]));            \n",
        "        f_d2c.write(\"\\n\");\n",
        "    f_d2c.close()\n",
        "    \n",
        "    \n",
        "  AUC1 = roc_auc_score(y_true1,y_pred1);\n",
        "  AUC2 = roc_auc_score(y_true2,y_pred2);\n",
        "  AUC3 = roc_auc_score(y_true3,y_pred3);\n",
        "  AUC4 = roc_auc_score(y_true4,y_pred4);\n",
        "  AUC5 = roc_auc_score(y_true5,y_pred5);\n",
        "  \n",
        "    \n",
        "  np.savetxt(date_time + name + \"-probs1.out\", np.concatenate((np.reshape(y_true1,(-1,1)),np.reshape(y_pred1,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs2.out\", np.concatenate((np.reshape(y_true2,(-1,1)),np.reshape(y_pred2,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs3.out\", np.concatenate((np.reshape(y_true3,(-1,1)),np.reshape(y_pred3,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs4.out\", np.concatenate((np.reshape(y_true4,(-1,1)),np.reshape(y_pred4,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs5.out\", np.concatenate((np.reshape(y_true5,(-1,1)),np.reshape(y_pred5,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  \n",
        "  # Pick the relevant thing for rest of the analysis\n",
        "  if(fcast_horizon==1):\n",
        "    y_true = y_true1;\n",
        "    y_pred = y_pred1;\n",
        "  elif(fcast_horizon==2):\n",
        "    y_true = y_true2;\n",
        "    y_pred = y_pred2;\n",
        "  elif(fcast_horizon==3):\n",
        "    y_true = y_true3;\n",
        "    y_pred = y_pred3;\n",
        "  elif(fcast_horizon==4):\n",
        "    y_true = y_true4;\n",
        "    y_pred = y_pred4;\n",
        "  elif(fcast_horizon==5):\n",
        "    y_true = y_true5;\n",
        "    y_pred = y_pred5;\n",
        "  \n",
        "  # Calculate usefulness statistics\n",
        "  t_opt=optimize_threshold(y_pred,y_true,0.5);\n",
        "  tpfntnfp=tpfntnfp_fun(y_pred,y_true,t_opt);\n",
        "  fnr,fpr,loss,ru=loss_use(tpfntnfp,0.5);\n",
        "  \n",
        "  \n",
        "  # Plot the calibration curve\n",
        "  if(plot_reliability):\n",
        "    bin_prob_true,bin_prob_pred = calibration_curve(y_true, y_pred, normalize=False, n_bins=10, strategy='quantile');\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(bin_prob_pred,bin_prob_true,color='black');\n",
        "    ax.plot([0,max(max(bin_prob_pred),max(bin_prob_true))],[0,max(max(bin_prob_pred),max(bin_prob_true))],color='black', linestyle='dashed');\n",
        "    ax.set(xlabel='Mean predicted value', ylabel='Fraction of positives',title=name)\n",
        "    plt.show();\n",
        "    fig.savefig(date_time + name + \"-cali.png\",dpi=300)\n",
        "  \n",
        "  print(\"Results\",(epoch+1)*sub_epochs,\"AUC-val %5.3f %5.3f %5.3f %5.3f %5.3f\" %(AUC1,AUC2,AUC3,AUC4,AUC5),\"AUC-train %5.3f\" %(AUC_best_ave_AUC_train))\n",
        "  # Statsout 14+5+5+3*Nf\n",
        "  #  validationtype, model_string,  fcasth horizon,time_start, time_stop, epochs, best_epoch, Nf, Units, weight[0], algo, \n",
        "  # learning rate, batchsize, time step,\n",
        "  # AUCs (5),  fnr,fpr,loss,ru,t_opt (5) , sh_means (Nf), params (Nf), pvals (Nf)\n",
        "  crises = np.sum(y_true);\n",
        "  crises_train = np.sum(YTRAIN);\n",
        "  obs = y_true.shape[0];\n",
        "  obs_train = YTRAIN.shape[0];\n",
        "\n",
        "  statsout = \"Sequential;\" + name + \";\" + str(fcast_horizon) + \";\" + str(train_start_year) + \";\" + str(train_end_year)  + \";\" + str(test_start_year) + \";\" + str(test_end_year);\n",
        "  statsout += \";\" + str(epochs*sub_epochs) + \";\" + str(best_epoch*sub_epochs) + \";\" + str(units) + \";\" + str(reg_weight[0]) + \";\" + algo + \";\";\n",
        "  statsout += str(learning_rate) + \";\" + str(batch_size) + \";\" + str(reps) + \";\"+ str(timestep) + \";%5.3f;%5.3f;%5.3f;%5.3f;%5.3f;%5.3f\" %(AUC1,AUC2,AUC3,AUC4,AUC5,AUC_best_ave_AUC_train);\n",
        "  statsout += \";%5.3f;%5.3f;%5.3f;%5.3f;\" %(fnr,fpr,loss,ru) + str(crises) + \";\" + str(crises_train) + \";\" + str(obs) + \";\" + str(obs_train)\n",
        "  \n",
        "  if(do_shapley):\n",
        "    # Shapley analysis    \n",
        "    phi_r = np.zeros((YTEST.shape[0],Nf,reps),dtype=float);\n",
        "    phi0_r = np.zeros((reps),dtype=float);\n",
        "    for r in range(0,reps):\n",
        "          phi_r[:,:,r],phi0_r[r]=Shapley_analysis(mod=models[r],XTEST=XTEST,XBACK=Xt,Nf=Nf,ts_mode=ts_mode,mm=mm,timestep=timestep,nlags=nlags,EXPMODE='window');\n",
        "    phi0 = np.array([np.mean(phi0_r,axis=0)]);    \n",
        "    phi = np.mean(phi_r,axis=2);    \n",
        "    shapley_means = np.mean(np.abs(phi),axis=0);\n",
        "    shapley_phi0 = phi0;\n",
        "    print(\"Shapley\",shapley_means,shapley_phi0);\n",
        "  \n",
        "    #xx = sm.add_constant(all_phi);\n",
        "    #mod = sm.Logit(all_ytest, xx).fit();\n",
        "    #mod.summary()\n",
        "    #params = mod.params;\n",
        "    #cse = np.diag(clustered_cov(mod,cid))**0.5;\n",
        "    #pval = 2*(1-norm.cdf(np.abs(params/cse)));\n",
        "          \n",
        "      \n",
        "    xx = sm.add_constant(phi);\n",
        "    mod = sm.Logit(y_true, xx).fit();\n",
        "    params = mod.params;\n",
        "    cse = np.diag(clustered_cov(mod,cid))**0.5;\n",
        "    pval = 2*(1-norm.cdf(np.abs(params/cse)));\n",
        "\n",
        "    for ff in range(0,Nf):\n",
        "      statsout += \";%10.3e\" %(shapley_means[ff]);\n",
        "    statsout += \";%10.3e\" %(shapley_phi0);\n",
        "    for ff in range(0,Nf+1):\n",
        "      statsout += \";%10.3e;%10.3e\" %(params[ff],pval[ff]);\n",
        "  \n",
        "\n",
        "# Create sample x  (1 (y true) + 1 (y pred) + Nf (phi)) array and dump it to csv\n",
        "  dataout = np.zeros((y_true.shape[0],Nf+4),dtype=float);\n",
        "  dataout[:,0] = y_true;\n",
        "  dataout[:,1] = y_pred;\n",
        "  if(do_shapley):  \n",
        "      dataout[:,2:(2+Nf)] = phi;\n",
        "      dataout[:,2+Nf] = phi0;\n",
        "  dataout[:,3+Nf] = cid;\n",
        "  filename = date_time + name + \"-probs.csv\"  \n",
        "  if(code!=0):\n",
        "        filename = 'C:/Users/eerot/Desktop/NNCALC/' + str(code) + '.csv';    \n",
        "  np.savetxt(filename, dataout, delimiter=\";\",header=\"y;p;phi1;phi2;phi3;phi4;phi5\");\n",
        "\n",
        "  return statsout;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwYzTA9AeQw-"
      },
      "source": [
        "#from tf.keras.models import clone_model\n",
        "# Evaluate permance of a given model using country-by-country cross-validation.\n",
        "def cross_validation2(mm ,  # must choose model class\n",
        "                          df , # must choose input data\n",
        "                          batch_size = 16, # Define training params for NN\n",
        "                          epochs = 100,\n",
        "                          # Rest of them are input for getModel:\n",
        "                          units = 10, # All NN models - unit for the layers\n",
        "                          Nf = 5,     # All NN models - number of feature types\n",
        "                          reg_weight = [0.001,0,0,0.001], # All NN models - for L2 reg\n",
        "                          timestep = 5,     # All RNN models\n",
        "                          algo = 'adam',    # All NN models - 'adam', 'rmsprop', 'nadam','adagrad','adamax','adadelta','sgd'\n",
        "                          dropout = 0.0,    # All NN models - dropout weight\n",
        "                          batchnormalization = False, # Multilayer perceptron - true/false\n",
        "                          print_epoch_stats = False,\n",
        "                          hiddenlayers = 1,           # Multilayer perceptron\n",
        "                          nlags = 1,                 # Multilayer perceptron and logit - lags for features\n",
        "                          reps = 1, # How many times to train the neural network\n",
        "                          patience = 2,\n",
        "                          return_state = False,\n",
        "                          rnn_mode = 1,\n",
        "                          learning_rate=0.01,\n",
        "                          fhandle=0,\n",
        "                          fcast_horizon=1,\n",
        "                          sub_epochs=1,\n",
        "                          class_weight={0: 0.5, 1: 0.5},\n",
        "                          plot_reliability=False,\n",
        "                          validate=False,\n",
        "                          time_start = 0,\n",
        "                          time_end = 0, save_model=False,do_shapley=False,d2cgraph=False,code=0): # output file handle\n",
        "  \n",
        "  name = modelname(mm=mm,rnn_mode=rnn_mode,return_state=return_state,lags=nlags);\n",
        "  # First some helper variables\n",
        "  ts_mode=0;\n",
        "  if(mm>2):\n",
        "    ts_mode=1\n",
        "      \n",
        "  if(ts_mode==1):\n",
        "    data_mode='rnn';\n",
        "  else:\n",
        "    data_mode='time-window';\n",
        "  if(mm==0):\n",
        "    pred_mode='statsmodel';\n",
        "  else:\n",
        "    pred_mode='keras';\n",
        "  df_train=add_precrisis(df,fcast_horizon=fcast_horizon,postdrop=5, stfilter = True );  \n",
        "  \n",
        "  wreturn_state = 0;\n",
        "  if(return_state==True):\n",
        "    wreturn_state = 1;\n",
        "  # Reshape the data and add timestep lags\n",
        "  Xt,yt,ct,yeart,cid = reshape_data(df_train,timestep,Nf,time_start,time_end);\n",
        "\n",
        "  # Reset random seed\n",
        "  t_start = time.time()\n",
        "  seed(2)\n",
        "  set_random_seed(3)\n",
        "  \n",
        "  summary_not_shown = True;\n",
        "\n",
        "  all_countries = df_train.iso.unique()\n",
        "  c=-1\n",
        "  K.clear_session()\n",
        "  models = [];\n",
        "  best_weights = [];\n",
        "  AUC_best=0;\n",
        "  for epoch in range(0,epochs):\n",
        "    \n",
        "    # Allocate tables to store predictions, statistics etc.\n",
        "    all_ytest = np.empty(shape =(0,));\n",
        "    all_yp = np.empty(shape =(0,));\n",
        "    \n",
        "    c = -1;\n",
        "    ave_AUC_train=0;    \n",
        "    rc=-1\n",
        "    for country in all_countries:\n",
        "      r = -1\n",
        "      c=c+1;\n",
        "          \n",
        "      # Specify the training and test data when one country is excluded\n",
        "      train = [i for i, val in enumerate(ct) if(val!=country)];\n",
        "      test = [i for i, val in enumerate(ct) if(val==country)];\n",
        "          \n",
        "      # Extract the training and test data from the full-sample.\n",
        "      XTRAIN=Xt[train,:,:];\n",
        "      YTRAIN=yt[train,:];\n",
        "      XTEST=Xt[test,:,:];\n",
        "      YTEST=yt[test,:];\n",
        "        \n",
        "        \n",
        "      # Allocate tables for reps\n",
        "      ypreds = np.zeros((YTEST.shape[0],reps),dtype=float);\n",
        "\n",
        "      for rep in range(0,reps):\n",
        "        rc=rc+1;\n",
        "        r=r+1;\n",
        "        if(epoch==0):\n",
        "          mod, ts_mode = getModel(mm, units, Nf, reg_weight, timestep , algo, dropout, batchnormalization, hiddenlayers, nlags, return_state = return_state, rnn_mode = rnn_mode,learning_rate=learning_rate);\n",
        "          models.append(mod);\n",
        "          if(mm>0):\n",
        "            best_weights.append(mod.get_weights());\n",
        "          \n",
        "        \n",
        "        # Fit model\n",
        "        if(validate):\n",
        "          models[rc],ypreds[:,r],y_true,t_opt, AUC_train = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, models[rc], ts_mode, timestep, nlags, batch_size, sub_epochs, print_data = False,validate=True,class_weight=class_weight,logit_reg_weight=reg_weight[0])    \n",
        "        else:\n",
        "          models[rc],ypreds[:,r],y_true,t_opt, AUC_train = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, models[rc], ts_mode, timestep, nlags, batch_size, sub_epochs, print_data = False,class_weight=class_weight,logit_reg_weight=reg_weight[0])\n",
        "\n",
        "        # Calculate simple average of all training AUCs\n",
        "        ave_AUC_train = ave_AUC_train+AUC_train;\n",
        "        \n",
        "      \n",
        "      # Amend the statistics and predictions etc.      \n",
        "      all_ytest = np.append(all_ytest,y_true,axis=0);\n",
        "      y_pred = np.mean(ypreds,axis=1);\n",
        "      all_yp = np.append(all_yp,y_pred,axis=0);\n",
        "\n",
        "      # END OF C LOOP\n",
        "    cmax=c;\n",
        "    AUC = roc_auc_score(all_ytest,all_yp);\n",
        "    ave_AUC_train=ave_AUC_train/(rc+1);\n",
        "    if(AUC>AUC_best):\n",
        "        rc=-1;\n",
        "        for c in range(0,cmax+1):\n",
        "          for r in range(0,reps):\n",
        "            rc=rc+1;\n",
        "            if(mm>0):\n",
        "              best_weights[rc] = models[rc].get_weights();\n",
        "            AUC_best=AUC;\n",
        "            AUC_best_ave_AUC_train = ave_AUC_train;\n",
        "            best_epoch=epoch;\n",
        "\n",
        "    \n",
        "    if(print_epoch_stats):\n",
        "      #f.write( \"%d;%d;%d;%d;%d;%d;%7.6f;%7.6f;%7.6f;%7.6f;%7.6f\\n\" % (mm,fcast_horizon,rnn_mode,wreturn_state,hiddenlayers,epoch,AUC,reg_weight[0],reg_weight[1],reg_weight[2],reg_weight[3]) );\n",
        "      #f.flush();\n",
        "      print(\"Stats - Epoch:\",(epoch+1)*sub_epochs,\"AUC-val %5.3f \" %(AUC),\"AUC-train %5.3f\" %(ave_AUC_train))\n",
        "        \n",
        "    # END OF EPOCH LOOP\n",
        "  \n",
        "  # POST-PROCESSING PART I:\n",
        "  # Retrieve the best weights and evaluate AUC for all forecast horizons\n",
        "  df1=add_precrisis(df,fcast_horizon=1,postdrop=5, stfilter = True );\n",
        "  df2=add_precrisis(df,fcast_horizon=2,postdrop=5, stfilter = True );\n",
        "  df3=add_precrisis(df,fcast_horizon=3,postdrop=5, stfilter = True );\n",
        "  df4=add_precrisis(df,fcast_horizon=4,postdrop=5, stfilter = True );\n",
        "  df5=add_precrisis(df,fcast_horizon=5,postdrop=5, stfilter = True );\n",
        "  \n",
        "\n",
        "  Xt1,yt1,ct1,_,_ = reshape_data(df1,timestep,Nf,time_start,time_end);\n",
        "  Xt2,yt2,ct2,_,_ = reshape_data(df2,timestep,Nf,time_start,time_end);\n",
        "  Xt3,yt3,ct3,_,_ = reshape_data(df3,timestep,Nf,time_start,time_end);\n",
        "  Xt4,yt4,ct4,_,_ = reshape_data(df4,timestep,Nf,time_start,time_end);\n",
        "  Xt5,yt5,ct5,_,_ = reshape_data(df5,timestep,Nf,time_start,time_end);  \n",
        "  rc=-1;\n",
        "  all_ytest1 = np.empty(shape =(0,));\n",
        "  all_yp1 = np.empty(shape =(0,));\n",
        "  all_ytest2 = np.empty(shape =(0,));\n",
        "  all_yp2 = np.empty(shape =(0,));\n",
        "  all_ytest3 = np.empty(shape =(0,));\n",
        "  all_yp3 = np.empty(shape =(0,));\n",
        "  all_ytest4 = np.empty(shape =(0,));\n",
        "  all_yp4 = np.empty(shape =(0,));\n",
        "  all_ytest5 = np.empty(shape =(0,));\n",
        "  all_yp5 = np.empty(shape =(0,));\n",
        "  \n",
        "  if(d2cgraph):\n",
        "    df_d2c=add_dist2cris(df, stfilter = True);\n",
        "    Xt_d2c,ct_d2c,yeart_d2c,cid_d2c,dp_d2c,dn_d2c = reshape_data_d2c(df_d2c,timestep,Nf,time_start,time_end);\n",
        "    all_yp_d2c = np.empty(shape =(0,));\n",
        "  \n",
        "  date_time = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S-\")\n",
        "  #for c in range(0,cmax+1):\n",
        "  for country in all_countries:\n",
        "    # and for longer forecast horizons\n",
        "    test1 = [i for i, val in enumerate(ct1) if(val==country)];\n",
        "    test2 = [i for i, val in enumerate(ct2) if(val==country)];\n",
        "    test3 = [i for i, val in enumerate(ct3) if(val==country)];\n",
        "    test4 = [i for i, val in enumerate(ct4) if(val==country)];\n",
        "    test5 = [i for i, val in enumerate(ct5) if(val==country)];\n",
        "        \n",
        "    XTEST1=Xt1[test1,:,:];\n",
        "    y_true1=yt1[test1,0];\n",
        "    XTEST2=Xt2[test2,:,:];\n",
        "    y_true2=yt2[test2,0];\n",
        "    XTEST3=Xt3[test3,:,:];\n",
        "    y_true3=yt3[test3,0];\n",
        "    XTEST4=Xt4[test4,:,:];\n",
        "    y_true4=yt4[test4,0];\n",
        "    XTEST5=Xt5[test5,:,:];\n",
        "    y_true5=yt5[test5,0];\n",
        "    if(d2cgraph):\n",
        "      test_d2c = [i for i, val in enumerate(ct_d2c) if(val==country)];\n",
        "      XTEST_d2c=Xt_d2c[test_d2c,:,:];\n",
        "        \n",
        "    if(data_mode=='time-window'):\n",
        "      XTEST1 = reshape_features_ksi(XTEST1, timestep, nlags);\n",
        "      XTEST2 = reshape_features_ksi(XTEST2, timestep, nlags);\n",
        "      XTEST3 = reshape_features_ksi(XTEST3, timestep, nlags);\n",
        "      XTEST4 = reshape_features_ksi(XTEST4, timestep, nlags);\n",
        "      XTEST5 = reshape_features_ksi(XTEST5, timestep, nlags);\n",
        "      if(d2cgraph):\n",
        "        XTEST_d2c= reshape_features_ksi(XTEST_d2c, timestep, nlags);\n",
        "      if(pred_mode!='keras'):\n",
        "        if(XTEST1.shape[0]>0):\n",
        "            XTEST1 = sm.add_constant(XTEST1,has_constant='add');\n",
        "        if(XTEST2.shape[0]>0):\n",
        "            XTEST2 = sm.add_constant(XTEST2,has_constant='add');\n",
        "        if(XTEST3.shape[0]>0):\n",
        "            XTEST3 = sm.add_constant(XTEST3,has_constant='add');\n",
        "        if(XTEST4.shape[0]>0):\n",
        "            XTEST4 = sm.add_constant(XTEST4,has_constant='add');\n",
        "        if(XTEST5.shape[0]>0):\n",
        "            XTEST5 = sm.add_constant(XTEST5,has_constant='add');\n",
        "        if(d2cgraph):\n",
        "            if(XTEST_d2c.shape[0]>0):\n",
        "                XTEST_d2c = sm.add_constant(XTEST_d2c,has_constant='add');\n",
        "        \n",
        "    # Allocate tables for reps\n",
        "    ypreds1 = np.zeros((y_true1.shape[0],reps),dtype=float);\n",
        "    ypreds2 = np.zeros((y_true2.shape[0],reps),dtype=float);\n",
        "    ypreds3 = np.zeros((y_true3.shape[0],reps),dtype=float);\n",
        "    ypreds4 = np.zeros((y_true4.shape[0],reps),dtype=float);\n",
        "    ypreds5 = np.zeros((y_true5.shape[0],reps),dtype=float);\n",
        "    if(d2cgraph):\n",
        "        ypreds_d2c = np.zeros((XTEST_d2c.shape[0],reps),dtype=float);\n",
        "    for r in range(0,reps):\n",
        "      rc=rc+1;\n",
        "      if(mm>0):\n",
        "        models[rc].set_weights(best_weights[rc]);\n",
        "        if(save_model):\n",
        "          models[rc].save(name + '_' + str(rc) + \"-\" + date_time + '.h5');\n",
        "      if(pred_mode=='keras'):\n",
        "        if(XTEST1.shape[0]>0):\n",
        "          ypreds1[:,r] = models[rc].predict(XTEST1)[:,0];\n",
        "        if(XTEST2.shape[0]>0):\n",
        "          ypreds2[:,r] = models[rc].predict(XTEST2)[:,0];\n",
        "        if(XTEST3.shape[0]>0):\n",
        "          ypreds3[:,r] = models[rc].predict(XTEST3)[:,0];\n",
        "        if(XTEST4.shape[0]>0):\n",
        "          ypreds4[:,r] = models[rc].predict(XTEST4)[:,0];\n",
        "        if(XTEST5.shape[0]>0):\n",
        "          ypreds5[:,r] = models[rc].predict(XTEST5)[:,0];\n",
        "        if(d2cgraph):\n",
        "            if(XTEST_d2c.shape[0]>0):\n",
        "                ypreds_d2c[:,r] = models[rc].predict(XTEST_d2c)[:,0];\n",
        "      else:            \n",
        "        if(XTEST1.shape[0]>0):\n",
        "          ypreds1[:,r] = models[rc].predict(XTEST1);\n",
        "        if(XTEST2.shape[0]>0):\n",
        "          ypreds2[:,r] = models[rc].predict(XTEST2);\n",
        "        if(XTEST3.shape[0]>0):\n",
        "          ypreds3[:,r] = models[rc].predict(XTEST3);\n",
        "        if(XTEST4.shape[0]>0):\n",
        "          ypreds4[:,r] = models[rc].predict(XTEST4);\n",
        "        if(XTEST5.shape[0]>0):\n",
        "          ypreds5[:,r] = models[rc].predict(XTEST5);\n",
        "        if(d2cgraph):\n",
        "            if(XTEST_d2c.shape[0]>0):\n",
        "                ypreds_d2c[:,r] = models[rc].predict(XTEST_d2c);\n",
        "    # Amend the statistics and predictions etc.      \n",
        "    all_ytest1 = np.append(all_ytest1,y_true1,axis=0);\n",
        "    all_ytest2 = np.append(all_ytest2,y_true2,axis=0);\n",
        "    all_ytest3 = np.append(all_ytest3,y_true3,axis=0);\n",
        "    all_ytest4 = np.append(all_ytest4,y_true4,axis=0);\n",
        "    all_ytest5 = np.append(all_ytest5,y_true5,axis=0);\n",
        "    \n",
        "    y_pred1 = np.mean(ypreds1,axis=1);\n",
        "    y_pred2 = np.mean(ypreds2,axis=1);\n",
        "    y_pred3 = np.mean(ypreds3,axis=1);\n",
        "    y_pred4 = np.mean(ypreds4,axis=1);\n",
        "    y_pred5 = np.mean(ypreds5,axis=1);\n",
        "    \n",
        "    all_yp1 = np.append(all_yp1,y_pred1,axis=0);\n",
        "    all_yp2 = np.append(all_yp2,y_pred2,axis=0);\n",
        "    all_yp3 = np.append(all_yp3,y_pred3,axis=0);\n",
        "    all_yp4 = np.append(all_yp4,y_pred4,axis=0);\n",
        "    all_yp5 = np.append(all_yp5,y_pred5,axis=0);\n",
        "    \n",
        "    if(d2cgraph):\n",
        "        y_pred_d2c = np.mean(ypreds_d2c,axis=1);\n",
        "        all_yp_d2c = np.append(all_yp_d2c,y_pred_d2c,axis=0);\n",
        "    \n",
        "  AUC1 = roc_auc_score(all_ytest1,all_yp1);\n",
        "  AUC2 = roc_auc_score(all_ytest2,all_yp2);\n",
        "  AUC3 = roc_auc_score(all_ytest3,all_yp3);\n",
        "  AUC4 = roc_auc_score(all_ytest4,all_yp4);\n",
        "  AUC5 = roc_auc_score(all_ytest5,all_yp5);\n",
        "    \n",
        "    \n",
        "    \n",
        "  np.savetxt(date_time + name + \"-probs1.out\", np.concatenate((np.reshape(all_ytest1,(-1,1)),np.reshape(all_yp1,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs2.out\", np.concatenate((np.reshape(all_ytest2,(-1,1)),np.reshape(all_yp2,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs3.out\", np.concatenate((np.reshape(all_ytest3,(-1,1)),np.reshape(all_yp3,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs4.out\", np.concatenate((np.reshape(all_ytest4,(-1,1)),np.reshape(all_yp4,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  np.savetxt(date_time + name + \"-probs5.out\", np.concatenate((np.reshape(all_ytest5,(-1,1)),np.reshape(all_yp5,(-1,1))),axis=1), delimiter=\";\",header=\"y;p\");\n",
        "  \n",
        "  # Create the distance to crisis graph\n",
        "  if(d2cgraph):\n",
        "    vari= '_';\n",
        "    for d in range(0,Nf):\n",
        "        vari = vari + all_predictors[d] + '_';\n",
        "    filename_d2c = 'C:/Users/eerot/Desktop/NNCALC/d2c_' + name + '_' + vari.replace(\"/\",\"\") + str(fcast_horizon) + '.txt';    \n",
        "    if(code!=0):\n",
        "        filename_d2c = 'C:/Users/eerot/Desktop/NNCALC/' + str(code) + '.txt';    \n",
        "    f_d2c=open(filename_d2c, \"w\")\n",
        "    #a = np.empty((20,))*np.nan;    \n",
        "\n",
        "    for d in range(-10,1):\n",
        "        d2c_sample = [i for i, val in enumerate(dn_d2c) if(val==d)] \n",
        "        x = all_yp_d2c[d2c_sample];\n",
        "        f_d2c.write(\"%3.0f;\" %(d));\n",
        "        for ix in range(0,x.shape[0]):\n",
        "            f_d2c.write(\"%10.7f;\" %(x[ix]));            \n",
        "        f_d2c.write(\"\\n\");\n",
        "    for d in range(1,11):\n",
        "        d2c_sample = [i for i, val in enumerate(dp_d2c) if(val==d)] \n",
        "        x = all_yp_d2c[d2c_sample];\n",
        "        f_d2c.write(\"%3.0f;\" %(d));\n",
        "        for ix in range(0,x.shape[0]):\n",
        "            f_d2c.write(\"%10.7f;\" %(x[ix]));            \n",
        "        f_d2c.write(\"\\n\");\n",
        "    f_d2c.close()\n",
        "        #np.mean(all_yp_d2c[(dn_d2c==d),0])\n",
        "  \n",
        "  # Pick the relevant thing for rest of the analysis\n",
        "  if(fcast_horizon==1):\n",
        "    all_ytest = all_ytest1;\n",
        "    all_yp = all_yp1;\n",
        "  elif(fcast_horizon==2):\n",
        "    all_ytest = all_ytest2;\n",
        "    all_yp = all_yp2;\n",
        "  elif(fcast_horizon==3):\n",
        "    all_ytest = all_ytest3;\n",
        "    all_yp = all_yp3;\n",
        "  elif(fcast_horizon==4):\n",
        "    all_ytest = all_ytest4;\n",
        "    all_yp = all_yp4;\n",
        "  elif(fcast_horizon==5):\n",
        "    all_ytest = all_ytest5;\n",
        "    all_yp = all_yp5;\n",
        "  \n",
        "  # Calculate usefulness statistics\n",
        "  t_opt=optimize_threshold(all_yp,all_ytest,0.5);\n",
        "  tpfntnfp=tpfntnfp_fun(all_yp,all_ytest,t_opt);\n",
        "  fnr,fpr,loss,ru=loss_use(tpfntnfp,0.5);\n",
        "  \n",
        "  \n",
        "  # Plot the calibration curve\n",
        "  if(plot_reliability):\n",
        "    bin_prob_true,bin_prob_pred = calibration_curve(all_ytest, all_yp, normalize=False, n_bins=10, strategy='quantile');\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(bin_prob_pred,bin_prob_true,color='black');\n",
        "    ax.plot([0,max(max(bin_prob_pred),max(bin_prob_true))],[0,max(max(bin_prob_pred),max(bin_prob_true))],color='black', linestyle='dashed');\n",
        "    ax.set(xlabel='Mean predicted value', ylabel='Fraction of positives',title=name)\n",
        "    plt.show();\n",
        "    fig.savefig(date_time + name + \"-cali.png\",dpi=300)\n",
        "  \n",
        "  print(\"Results\",(epoch+1)*sub_epochs,\"AUC-val %5.3f %5.3f %5.3f %5.3f %5.3f\" %(AUC1,AUC2,AUC3,AUC4,AUC5),\"AUC-train %5.3f\" %(AUC_best_ave_AUC_train))\n",
        "  # Statsout 14+5+5+3*Nf\n",
        "  #  validationtype, model_string,  fcasth horizon,time_start, time_stop, epochs, best_epoch, Nf, Units, weight[0], algo, \n",
        "  # learning rate, batchsize, time step,\n",
        "  # AUCs (5),  fnr,fpr,loss,ru,t_opt (5) , sh_means (Nf), params (Nf), pvals (Nf)\n",
        "  crises = np.sum(all_ytest);\n",
        "  obs = all_ytest.shape[0];\n",
        "\n",
        "  statsout = \"Cross-validation;\" + name + \";\" + str(fcast_horizon) + \";\" + str(time_start) + \";\" + str(time_end);\n",
        "  statsout += \";\" + str(epochs*sub_epochs) + \";\" + str(best_epoch*sub_epochs) + \";\" + str(units) + \";\" + str(reg_weight[0]) + \";\" + algo + \";\";\n",
        "  statsout += str(learning_rate) + \";\" + str(batch_size) + \";\" + str(reps) + \";\"+ str(timestep) + \";%5.3f;%5.3f;%5.3f;%5.3f;%5.3f;%5.3f\" %(AUC1,AUC2,AUC3,AUC4,AUC5, AUC_best_ave_AUC_train);\n",
        "  statsout += \";%5.3f;%5.3f;%5.3f;%5.3f;\" %(fnr,fpr,loss,ru) + str(crises) + \";\" + str(obs)\n",
        "  \n",
        "  if(do_shapley):\n",
        "      # Shapley analysis\n",
        "      all_phi = np.empty(shape =(0,Nf));\n",
        "      all_phi0 = np.empty(shape =(0,1));\n",
        "      c=-1;\n",
        "      rc=-1;\n",
        "      for country in all_countries:\n",
        "        c=c+1;\n",
        "        #train = [i for i, val in enumerate(ct) if(val!=country)]\n",
        "        test = [i for i, val in enumerate(ct) if(val==country)]\n",
        "    \n",
        "        # Extract the training and test data from the full-sample.\n",
        "        #XTRAIN=Xt[train,:,:]\n",
        "        #YTRAIN=yt[train,:]\n",
        "        XTEST=Xt[test,:,:]\n",
        "        YTEST=yt[test,:]\n",
        "        \n",
        "        phi_r = np.zeros((YTEST.shape[0],Nf,reps),dtype=float);\n",
        "        phi0_r = np.zeros((reps,),dtype=float);\n",
        "        for r in range(0,reps):\n",
        "          rc+=1;  \n",
        "          phi_r[:,:,r],phi0_r[r]=Shapley_analysis(mod=models[rc],XTEST=XTEST,XBACK=Xt,Nf=Nf,ts_mode=ts_mode,mm=mm,timestep=timestep,nlags=nlags,EXPMODE='window');\n",
        "        phi0 = np.array([np.mean(phi0_r,axis=0)]);    \n",
        "        phi = np.mean(phi_r,axis=2);\n",
        "        all_phi0= np.append(all_phi0,phi0*np.ones(shape=(phi.shape[0],1)),axis=0);\n",
        "        all_phi = np.append(all_phi,phi,axis=0);    \n",
        "      shapley_means = np.mean(np.abs(all_phi),axis=0);\n",
        "      shapley_phi0 = np.mean(all_phi0,axis=0);\n",
        "      print(\"Shapley\",shapley_means,shapley_phi0);         \n",
        "      \n",
        "      xx = sm.add_constant(np.append(all_phi,all_phi0,axis=1));\n",
        "      mod = sm.Logit(all_ytest, xx).fit();\n",
        "      params = mod.params;\n",
        "      cse = np.diag(clustered_cov(mod,cid))**0.5;\n",
        "      pval = 2*(1-norm.cdf(np.abs(params/cse)));\n",
        "\n",
        "      for ff in range(0,Nf):\n",
        "        statsout += \";%10.3e\" %(shapley_means[ff]);\n",
        "      statsout += \";%10.3e\" %(shapley_phi0);\n",
        "      for ff in range(0,Nf+2):\n",
        "        statsout += \";%10.3e;%10.3e\" %(params[ff],pval[ff]);\n",
        "  \n",
        "\n",
        "# Create sample x  (1 (y true) + 1 (y pred) + Nf (phi)) array and dump it to csv\n",
        "  dataout = np.zeros((all_ytest.shape[0],Nf+4),dtype=float);\n",
        "  dataout[:,0] = all_ytest;\n",
        "  dataout[:,1] = all_yp;\n",
        "  if(do_shapley):  \n",
        "      dataout[:,2:(2+Nf)] = all_phi;\n",
        "      dataout[:,2+Nf] = all_phi0[:,0];\n",
        "  dataout[:,3+Nf] = cid;\n",
        "  filename = date_time + name + \"-probs.csv\"  \n",
        "  if(code!=0):\n",
        "        filename = 'C:/Users/eerot/Desktop/NNCALC/' + str(code) + '.csv';    \n",
        "  np.savetxt(filename, dataout, delimiter=\";\",header=\"y;p;phi1;phi2;phi3;phi4;phi5\");\n",
        "    \n",
        "  \n",
        "\n",
        "  return statsout;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkedeCtAtapq"
      },
      "source": [
        "#clustered standard error computation\n",
        "#Uses the methods described in\n",
        "#A. Colin Cameron, Jonah B. Gelbach & Douglas L. Miller (2011) Robust Inference With Multiway\n",
        "#Clustering, Journal of Business & Economic Statistics, 29:2, 238-249, DOI: 10.1198/jbes.2010.07136\n",
        "\n",
        "\n",
        "from scipy.stats import norm\n",
        "import itertools\n",
        "\n",
        "def grad(f,x,tol=1e-6):\n",
        "    '''\n",
        "    compute approximate gradient vector of function f at x\n",
        "    '''\n",
        "    f0 = f(x)\n",
        "    x= np.array(x)\n",
        "    g= np.zeros(list(np.shape(x,)) + list(f0.shape))\n",
        "    for i in range(len(x)):\n",
        "        x1 = x.copy()\n",
        "        x1[i]+=tol\n",
        "        g[i] = (f(x1) - f0) / tol\n",
        "    return g\n",
        "\n",
        "def as_cluster_var(data):\n",
        "    '''\n",
        "    converts a 2d array to a 1d array of \"tuples\" treating each row as a group for clustering\n",
        "    '''\n",
        "    return data.view(data.dtype.descr * data.shape[1]).ravel()\n",
        "\n",
        "\n",
        "def _cluster_A(fit_results):\n",
        "    model = fit_results.model\n",
        "    B=fit_results.params\n",
        "    try:\n",
        "        try:\n",
        "            A = np.matrix(model.information(B))\n",
        "        except NotImplementedError:\n",
        "            A = np.matrix(grad(model.score,B)).transpose()\n",
        "            #print('WARNING: Using approximate gradient of score to compute information matrix')\n",
        "    except NotImplementedError:\n",
        "        score = lambda b: grad(model.loglike,b)\n",
        "        A = np.matrix(grad(score,B)).transpose()\n",
        "        #print('WARNING: Using approximate hessian to compute information matrix')\n",
        "    return A\n",
        "\n",
        "def _cluster_D(fit_results,cluster_var):\n",
        "    model = fit_results.model\n",
        "    B=fit_results.params\n",
        "    groups = np.unique(cluster_var)\n",
        "    score_cpts = grad(model.loglikeobs,B).transpose() #probit_score_cpts(y,X,B).transpose()\n",
        "    D = np.zeros((len(B),len(B)))\n",
        "    for g in groups:\n",
        "        h_g = score_cpts[cluster_var == g].sum(0)\n",
        "        D += np.outer(h_g,h_g) #was outer\n",
        "    #degrees of freedom correction\n",
        "    M = len(groups)\n",
        "    N = len(score_cpts)\n",
        "    K = len(B)\n",
        "    dfc = 1.0*M/(M-1) #*(N-1)/(N-K)\n",
        "\n",
        "    return dfc*np.matrix(D)\n",
        "\n",
        "def clustered_cov(fit_results,cluster_var):\n",
        "    '''\n",
        "    Computes one-way clustered standard errors from maximum likelihood object model,\n",
        "    with estimated params, clustering on cluster_var\n",
        "    returns a matrix containing the clustered variance-covariance terms\n",
        "    '''\n",
        "    A =  _cluster_A(fit_results)\n",
        "    D = _cluster_D(fit_results, cluster_var)\n",
        "    Ainv = A**(-1)\n",
        "    V = Ainv*D*Ainv.T\n",
        "    return V\n",
        "\n",
        "def multiway_clustered_cov(fit_results,cluster_vars):\n",
        "    '''\n",
        "    Computes multi-way clustered standard errors from maximum likelihood object model,\n",
        "    with estimated params, clustering on the variables in 2d array (or dataframe) cluster_vars\n",
        "    returns a matrix containing the clustered variance-covariance terms\n",
        "    '''\n",
        "    cluster_vars=np.array(cluster_vars)\n",
        "    D = 0\n",
        "    A = _cluster_A(fit_results)\n",
        "    Ainv = A**(-1)\n",
        "    for v in itertools.product([False,True],repeat=cluster_vars.shape[1]):\n",
        "        if sum(v)==0:\n",
        "            continue\n",
        "        v=np.array(v,dtype=bool)\n",
        "        cv = as_cluster_var(cluster_vars[:,v])\n",
        "        D0 = _cluster_D(fit_results,cv)\n",
        "        D = D - (-1)**sum(v) * D0\n",
        "    V = Ainv*D*Ainv.T\n",
        "    return V\n",
        "\n",
        "\n",
        "def clustered_output(fit_results,group):\n",
        "    '''\n",
        "    Format a pandas table of output with clustered standard errors\n",
        "    '''\n",
        "    #import pandas\n",
        "    cse= np.diag(clustered_cov(fit_results,group))**0.5\n",
        "    scse=pd.Series(cse)#,index=fit_results.params.index)\n",
        "    outp = pd.DataFrame([fit_results.params,fit_results.bse,scse]).transpose()\n",
        "    outp.columns = ['Coef','SE','Cl. SE']\n",
        "    return outp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy_-3xfK7J0e"
      },
      "source": [
        "# Evaluate permance of a given model using sequential framework.\n",
        "def full_sample2(mm ,  # must choose model class\n",
        "                          df2 , # must choose input data\n",
        "                          test_start_year=2003, # Define test set\n",
        "                          test_end_year=2016,\n",
        "                          batch_size = 16, # Define training params for NN\n",
        "                          epochs = 100,\n",
        "                          sub_epochs = 10,\n",
        "                          # Rest of them are input for getModel:\n",
        "                          units = 10, # All NN models - unit for the layers\n",
        "                          Nf = 5,     # All NN models - number of feature types\n",
        "                          reg_weight = [0.1,0,0,0.1], # All NN models - for L2 reg\n",
        "                          timestep = 5,     # All RNN models\n",
        "                          algo = 'adam',    # All NN models - 'adam', 'rmsprop', 'nadam','adagrad','adamax','adadelta','sgd'\n",
        "                          dropout = 0.0,    # All NN models - dropout weight\n",
        "                          batchnormalization = False, # Multilayer perceptron - true/false\n",
        "                          hiddenlayers = 1,           # Multilayer perceptron\n",
        "                          nlags = 1,                  # Multilayer perceptron and logit - lags for features\n",
        "                          print_epoch_stats = False,\n",
        "                          seeds = [1,2],\n",
        "                          reps = 1, # How many times to train the neural network\n",
        "                          patience = 2,\n",
        "                          return_state = False,\n",
        "                          rnn_mode = 1,\n",
        "                          learning_rate=0.001,class_weight={0: 0.5, 1: 0.5}):\n",
        "  # Reshape the data and add timestep lags\n",
        "  Xt,yt,ct,yeart = reshape_data(df2,timestep,Nf)\n",
        "    \n",
        "  t_start = time.time()\n",
        "  seed(seeds[0])\n",
        "  set_random_seed(seeds[1])\n",
        "   \n",
        "  # Set the training and test data for this year.\n",
        "  train = [i for i, val in enumerate(yeart) if((val>=test_start_year) and (val<=test_end_year))]\n",
        "      \n",
        "  # Extract the data from the full-sample.\n",
        "  XTRAIN=Xt[train,:,:]\n",
        "  YTRAIN=yt[train,:]\n",
        "  XTEST=Xt[train,:,:]\n",
        "  YTEST=yt[train,:]\n",
        " \n",
        "  \n",
        "  K.clear_session()\n",
        "  models = [];\n",
        "\n",
        "  for epoch in range(0,epochs):\n",
        "             \n",
        "    ypreds = np.zeros((YTEST.shape[0],reps),dtype=float)\n",
        "    ave_shapley_means = np.zeros(Nf,dtype=float);\n",
        "    ave_phi = np.zeros((YTEST.shape[0],Nf),dtype=float);\n",
        "    ave_pred0=0;\n",
        "    r = -1\n",
        "    for rep in range(0,reps):\n",
        "      if(epoch==0):\n",
        "        mod, ts_mode = getModel(mm, units, Nf, reg_weight, timestep , algo, dropout, batchnormalization, hiddenlayers, nlags, return_state = return_state, rnn_mode = rnn_mode,learning_rate=learning_rate)\n",
        "        models.append(mod)\n",
        "      r=r+1;\n",
        "      \n",
        "      # Fit model\n",
        "      models[r],y_pred,y_true,t_opt, history = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, models[r], ts_mode, timestep, nlags, batch_size, sub_epochs, print_data = True,class_weight=class_weight,logit_reg_weight=reg_weight[0])\n",
        "      ypreds[:,rep] = y_pred;\n",
        "\n",
        "      # Shapley stats:\n",
        "      shapley_means,phi,pred0=Shapley_analysis(mod=mod,XTEST=XTEST,XBACK=XTEST,Nf=Nf,ts_mode=ts_mode,mm=mm,timestep=timestep,nlags=nlags,EXPMODE='window');\n",
        "      ave_phi = (ave_phi*rep+phi)/(rep+1);\n",
        "      ave_shapley_means = (ave_shapley_means*rep+shapley_means)/(rep+1);\n",
        "      ave_pred0 = (ave_pred0*rep+pred0)/(rep+1);\n",
        "    \n",
        "    # END OF REP LOOP  \n",
        "    \n",
        "    # Calculate statistics for this epoch    \n",
        "    if(epoch>10):\n",
        "      y_pred = (y_pred*(epoch-10)+np.mean(ypreds,axis=1))/(epoch-9);\n",
        "    else:\n",
        "      y_pred = np.mean(ypreds,axis=1)      \n",
        "    tpfntnfp = tpfntnfp_fun(y_pred,y_true,t_opt)  \n",
        "    fnr,fpr,loss,ru = loss_use(tpfntnfp,0.5)\n",
        "    pred_class_blr = (y_pred > .5)\n",
        "    AccRate = np.sum(pred_class_blr==y_true)/len(y_true) \n",
        "    AUC = roc_auc_score(y_true,y_pred)\n",
        "    \n",
        "    print(\"Stats - \",\"Epoch:\",(epoch+1)*sub_epochs,\"AUC:\",AUC)\n",
        "    # Plot the calibration curve for this epoch\n",
        "    bin_prob_true,bin_prob_pred = calibration_curve(y_true, y_pred, normalize=False, n_bins=10, strategy='quantile');\n",
        "    plt.scatter(bin_prob_pred,bin_prob_true);\n",
        "    plt.plot([0,max(max(bin_prob_pred),max(bin_prob_true))],[0,max(max(bin_prob_pred),max(bin_prob_true))]);\n",
        "    plt.show();\n",
        "\n",
        "  # END OF EPOCH LOOP\n",
        "  \n",
        "  return AccRate,AUC,ru,fnr,fpr,loss,t_opt,y_true,y_pred,history,ave_phi,ave_shapley_means,ave_pred0,bin_prob_true,bin_prob_pred;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt_YfYw9tapq"
      },
      "source": [
        "def modelname(mm=0,rnn_mode=1,return_state=False,lags=1):\n",
        "    if(mm==0):\n",
        "        return \"Logit(\" + str(lags) + \")\";\n",
        "    if(mm==1):\n",
        "        return \"Logit LASSO(\" + str(lags) + \")\";\n",
        "    if(mm==2):\n",
        "        return \"MLP(\" + str(lags) + \")\";\n",
        "    if(mm>2):\n",
        "        if(mm==3):\n",
        "          name = \"RNN\";\n",
        "        if(mm==4):\n",
        "          name = \"LSTM\";\n",
        "        if(mm==5):\n",
        "          name = \"GRU\";\n",
        "        if(return_state):\n",
        "          if(rnn_mode==1):\n",
        "            name = name + \"_nps\";\n",
        "          if(rnn_mode==2):\n",
        "            name = name + \"_pps\";\n",
        "          if(rnn_mode==3):\n",
        "            name = name + \"-RS\";\n",
        "        return name;\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAU4FAdIQvQ"
      },
      "source": [
        "# Cross-validation code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoGiCkhikJTN"
      },
      "source": [
        "\n",
        "#from tf.keras.models import clone_model\n",
        "# Evaluate permance of a given model using country-by-country cross-validation.\n",
        "def kfold_cross_validation2(mm ,  # must choose model class\n",
        "                          df2 , # must choose input data\n",
        "                          batch_size = 16, # Define training params for NN\n",
        "                          epochs = 100,\n",
        "                          # Rest of them are input for getModel:\n",
        "                          units = 10, # All NN models - unit for the layers\n",
        "                          Nf = 5,     # All NN models - number of feature types\n",
        "                          reg_weight = 0.1, # All NN models - for L2 reg\n",
        "                          timestep = 5,     # All RNN models\n",
        "                          algo = 'adam',    # All NN models - 'adam', 'rmsprop', 'nadam','adagrad','adamax','adadelta','sgd'\n",
        "                          dropout = 0.0,    # All NN models - dropout weight\n",
        "                          batchnormalization = False, # Multilayer perceptron - true/false\n",
        "                          print_epoch_stats = False,\n",
        "                          hiddenlayers = 1,           # Multilayer perceptron\n",
        "                          nlags = 1,                 # Multilayer perceptron and logit - lags for features\n",
        "                          reps = 1, # How many times to train the neural network\n",
        "                          patience = 2,\n",
        "                          return_state = False,\n",
        "                          rnn_mode = 1,\n",
        "                          learning_rate=0.001,\n",
        "                          fhandle=0,\n",
        "                          fcast_horizon=666,sub_epochs=10,class_weight={0: 0.5, 1: 0.5},plot_reliability=False,validate=False,folds_k=2,lr_tol=0): # output file handle\n",
        "  wreturn_state = 0;\n",
        "  if(return_state==True):\n",
        "    wreturn_state = 1;\n",
        "  # Reshape the data and add timestep lags\n",
        "  Xt,yt,ct,yeart = reshape_data(df2,timestep,Nf)\n",
        "\n",
        "  # Reset random seed\n",
        "  t_start = time.time()\n",
        "  seed(2)\n",
        "  set_random_seed(3)\n",
        "  \n",
        "  summary_not_shown = True;\n",
        "\n",
        "  # Generate the random folds\n",
        "  precrisis_obs = [i for i, val in enumerate(yt) if(val==1)];\n",
        "  normal_obs = [i for i, val in enumerate(yt) if(val==0)];\n",
        "\n",
        "  np.random.shuffle(precrisis_obs);\n",
        "  np.random.shuffle(normal_obs);\n",
        "\n",
        "  f1=np.array_split(precrisis_obs, folds_k);\n",
        "  f2=np.array_split(normal_obs, folds_k);\n",
        "  testfolds=[];\n",
        "  for kk in range(0,folds_k):\n",
        "    this_f = np.concatenate((f1[kk],f2[kk]),axis=0);\n",
        "    np.random.shuffle(this_f);\n",
        "    testfolds.append(this_f.astype(np.int16));\n",
        "\n",
        "  trainfolds=[];\n",
        "  for kk in range(0,folds_k):\n",
        "    this_f = [];\n",
        "    for kk2 in range(0,folds_k):\n",
        "      if(kk2!=kk):\n",
        "        this_f = np.concatenate((this_f,testfolds[kk2]),axis=0);\n",
        "    trainfolds.append(this_f.astype(np.int16));\n",
        "  \n",
        "  # Start training loop\n",
        "  K.clear_session()\n",
        "  models = [];\n",
        "  for epoch in range(0,epochs):\n",
        "    \n",
        " \n",
        "      \n",
        "    # Allocate tables to store predictions, statistics etc.\n",
        "    all_ytest = np.empty(shape =(0,))\n",
        "    all_yp = np.empty(shape =(0,))\n",
        "    \n",
        "    ave_AUC_train=0;\n",
        "    for kk in range(0,folds_k):\n",
        "      #print(kk)\n",
        "      if(epoch==0):\n",
        "        mod, ts_mode = getModel(mm, units, Nf, reg_weight, timestep , algo, dropout, batchnormalization, hiddenlayers, nlags, return_state = return_state, rnn_mode = rnn_mode,learning_rate=learning_rate)\n",
        "        models.append(mod)\n",
        "      \n",
        "      # Specify the training and test data when one country is excluded\n",
        "\n",
        "      train = trainfolds[kk];\n",
        "      test = testfolds[kk];\n",
        "    \n",
        "      # Extract the training and test data from the full-sample.\n",
        "      XTRAIN=Xt[train,:,:]\n",
        "      YTRAIN=yt[train,:]\n",
        "      XTEST=Xt[test,:,:]\n",
        "      YTEST=yt[test,:]\n",
        "\n",
        "      # Fit model\n",
        "      if(validate):\n",
        "        models[kk],y_pred,y_true,t_opt, AUC_train = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, models[kk], ts_mode, timestep, nlags, batch_size, sub_epochs, print_data = False,validate=True,class_weight=class_weight)    \n",
        "      else:\n",
        "        models[kk],y_pred,y_true,t_opt, AUC_train = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, models[kk], ts_mode, timestep, nlags, batch_size, sub_epochs, print_data = False,class_weight=class_weight)    \n",
        "      \n",
        "      ave_AUC_train = ave_AUC_train+AUC_train;\n",
        "      # Amend the statistics and predictions etc.\n",
        "      all_ytest = np.append(all_ytest,y_true,axis=0)\n",
        "      all_yp = np.append(all_yp,y_pred,axis=0)\n",
        "      # END OF C LOOP\n",
        "    \n",
        "    ave_AUC_train=ave_AUC_train/folds_k;    \n",
        "    AUC = roc_auc_score(all_ytest,all_yp);\n",
        "    if((epoch+1)*sub_epochs>100 and AUC+lr_tol<AUC2):\n",
        "      learning_rate=learning_rate*0.5;\n",
        "      print('new_learning_rate:',learning_rate);\n",
        "      if(algo=='adam'):\n",
        "        algo = keras.optimizers.Adam(lr =learning_rate);\n",
        "      else:\n",
        "        algo = keras.optimizers.RMSprop(lr =learning_rate);\n",
        "      for kk in range(0,folds_k):\n",
        "          models[kk].compile(loss='binary_crossentropy', optimizer=algo, metrics=['accuracy'])\n",
        "    AUC2=AUC;\n",
        "    if(print_epoch_stats):\n",
        "      f.write( \"%d;%d;%d;%d;%d;%d;%7.6f;%7.6f;%7.6f;%7.6f;%7.6f\\n\" % (mm,fcast_horizon,rnn_mode,wreturn_state,hiddenlayers,epoch,AUC,reg_weight[0],reg_weight[1],reg_weight[2],reg_weight[3]) );\n",
        "      f.flush();\n",
        "    print(\"Stats - Epoch:\",(epoch+1)*sub_epochs,\"AUC-val\",AUC,\"AUC-train\",ave_AUC_train)\n",
        "    \n",
        "    # Plot the calibration curve\n",
        "    if(plot_reliability):\n",
        "      bin_prob_true,bin_prob_pred = calibration_curve(all_ytest, all_yp, normalize=False, n_bins=10, strategy='quantile');\n",
        "      plt.scatter(bin_prob_pred,bin_prob_true);\n",
        "      plt.plot([0,max(max(bin_prob_pred),max(bin_prob_true))],[0,max(max(bin_prob_pred),max(bin_prob_true))]);\n",
        "      plt.set_xlabel('Mean predicted value');\n",
        "      plt.set_ylabel('Fraction of positives');\n",
        "      plt.show();\n",
        "    # END OF EPOCH LOOP\n",
        "  \n",
        "  return bin_prob_pred,bin_prob_true;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4nhhiYaEj1c"
      },
      "source": [
        "# Evaluate permance of a given model using sequential framework.\n",
        "def in_sample_test(mm ,  # must choose model class\n",
        "                          df2 , # must choose input data\n",
        "                          test_start_year=1970, # Define test set\n",
        "                          test_end_year=2016,\n",
        "                          batch_size = 16, # Define training params for NN\n",
        "                          epochs = 100,\n",
        "                          # Rest of them are input for getModel:\n",
        "                          units = 10, # All NN models - unit for the layers\n",
        "                          Nf = 5,     # All NN models - number of feature types\n",
        "                          reg_weight = 0.1, # All NN models - for L2 reg\n",
        "                          timestep = 5,     # All RNN models\n",
        "                          algo = 'adam',    # All NN models - 'adam', 'rmsprop', 'nadam','adagrad','adamax','adadelta','sgd'\n",
        "                          dropout = 0.0,    # All NN models - dropout weight\n",
        "                          batchnormalization = False, # Multilayer perceptron - true/false\n",
        "                          hiddenlayers = 1,           # Multilayer perceptron\n",
        "                          nlags = 1,                  # Multilayer perceptron and logit - lags for features\n",
        "                          print_epoch_stats = False,\n",
        "                          seeds = [1,2],\n",
        "                          patience = 500,\n",
        "                          return_state = False,\n",
        "                          rnn_mode = 1,\n",
        "                          learning_rate=0.001):\n",
        "  # Reshape the data and add timestep lags\n",
        "  Xt,yt,ct,yeart = reshape_data(df2,timestep,Nf)\n",
        "    \n",
        "  t_start = time.time()\n",
        "  seed(seeds[0])\n",
        "  set_random_seed(seeds[1])\n",
        "     \n",
        "  # Set the data period.\n",
        "  train = [i for i, val in enumerate(yeart) if((val>=test_start_year) and (val<=test_end_year))]\n",
        "        \n",
        "  # Extract the data from the dataset.\n",
        "  XTRAIN=Xt[train,:,:]\n",
        "  YTRAIN=yt[train,:]\n",
        "  XTEST=Xt[train,:,:]\n",
        "  YTEST=yt[train,:]\n",
        " \n",
        "  # Get model\n",
        "  K.clear_session()\n",
        "  mod, ts_mode = getModel(mm, units, Nf, reg_weight, timestep , algo, dropout, batchnormalization, hiddenlayers, nlags, return_state = return_state, rnn_mode = rnn_mode,learning_rate=learning_rate)\n",
        "  if ts_mode < 2:\n",
        "    print(mod.summary())\n",
        "    \n",
        "  # Fit model\n",
        "  if(print_epoch_stats):\n",
        "    mod, y_pred,y_true,t_opt, history = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, mod, ts_mode, timestep, nlags, batch_size, epochs, print_data = True, validate = True, patience = patience)\n",
        "  else:\n",
        "    mod, y_pred,y_true,t_opt, history = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, mod, ts_mode, timestep, nlags, batch_size, epochs, print_data = True)\n",
        "  \n",
        "  # Collect predictions and store statistics  \n",
        "  tpfntnfp = tpfntnfp_fun(y_pred,y_true,t_opt)  \n",
        "  fnr,fpr,loss,ru = loss_use(tpfntnfp,0.5)\n",
        "  pred_class_blr = (y_pred > .5)\n",
        "  AccRate = np.sum(pred_class_blr==y_true)/len(y_true) \n",
        "  AUC = roc_auc_score(y_true,y_pred)\n",
        "\n",
        "  return AccRate,AUC,ru,fnr,fpr,loss,t_opt,y_true,y_pred, mod\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZObENo6tSsj5"
      },
      "source": [
        "def full_sample_logit(df2 , # must choose input data\n",
        "                          start_year=2003, # Define test set\n",
        "                          end_year=2016,\n",
        "                          timestep = 5,\n",
        "                          Nf = 4,\n",
        "                          nlags = 1):\n",
        "\n",
        "  # Reshape the data and add timestep lags\n",
        "  Xt,yt,ct,yeart = reshape_data(df2,timestep,Nf)\n",
        "         \n",
        "  # Set the data period\n",
        "  train = [i for i, val in enumerate(yeart) if(val>=start_year and val<=end_year)]\n",
        "      \n",
        "  # Extract the data from the full-sample.\n",
        "  XTRAIN=Xt[train,:,:]\n",
        "  YTRAIN=yt[train,:]\n",
        "  XTEST=XTRAIN\n",
        "  YTEST=YTRAIN\n",
        " \n",
        "  # Fit model\n",
        "  y_pred,y_true,t_opt = fitModel(XTRAIN, YTRAIN, XTEST, YTEST, 0, 2, timestep, nlags, 0, 0, print_data = True)\n",
        "  \n",
        "  # Collect predictions and store statistics  \n",
        "  tpfntnfp = tpfntnfp_fun(y_pred,y_true,t_opt)  \n",
        "  fnr,fpr,loss,ru = loss_use(tpfntnfp,0.5)\n",
        "  pred_class_blr = (y_pred > .5)\n",
        "  AccRate = np.sum(pred_class_blr==y_true)/len(y_true) \n",
        "  AUC = roc_auc_score(y_true,y_pred)\n",
        "  return AccRate,AUC,ru,fnr,fpr,loss,t_opt,y_true,y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmH92NLdyOe_"
      },
      "source": [
        "def reliability_diagram(y_pred,y_true,nbins):\n",
        "  y_min\n",
        "  tp = np.sum(np.logical_and(ypred>=t,ytrue==1))\n",
        "  fn = np.sum(np.logical_and(ypred<t,ytrue==1))\n",
        "  fp = np.sum(np.logical_and(ypred>=t,ytrue==0))\n",
        "  tn = np.sum(np.logical_and(ypred<t,ytrue==0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93bedFEr2hvw"
      },
      "source": [
        "reg_weight=[0.01,0,0,0]   # 0.6537717601547389\n",
        "reg_weight=[0.1,0,0,0]    # 0.6537717601547389\n",
        "reg_weight=[0.1,0,0,0.1]  # 0.7297115465478093\n",
        "dropout=0\n",
        "\n",
        "reps=1;\n",
        "all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];\n",
        "df3=init_data(df = df, start_year = 1870, y_shift = 1, normalize = False);\n",
        "\n",
        "AUCs = []      \n",
        "for fcast_horizon in [3]:\n",
        "  df2=add_precrisis(df3,fcast_horizon=fcast_horizon,postdrop=1, stfilter = True ); \n",
        "  AccRate,AUC,ru,fnr,fpr,loss,t_opt,y_true,y_pred, mod = in_sample_test(mm=2,df2=df2,reg_weight=reg_weight,print_epoch_stats = True,epochs=250,nlags=5)\n",
        "\n",
        "a,b = calibration_curve(y_true, y_pred, normalize=False, n_bins=10, strategy='uniform')\n",
        "plt.scatter(b,a)\n",
        "plt.plot([0,1],[0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7LR3Sub3BpR"
      },
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "a,b = calibration_curve(y_true, y_pred, normalize=False, n_bins=2, strategy='quantile')\n",
        "plt.scatter(b,a)\n",
        "plt.plot([0,max(max(b),max(a))],[0,max(max(b),max(a))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k68lM6754Z1G"
      },
      "source": [
        "# Cross-validation with one-year forecast horizon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aTfk7FpJBvLm",
        "scrolled": true,
        "outputId": "1defdd7d-c85c-4aa6-8d36-fca366fd6853"
      },
      "source": [
        "    # Cross validation\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/cross_fc1_reps50_1870_2016.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=5;\n",
        "    epochs = 100;\n",
        "    for dates in [[1870,2016]]: #[[1870,1939],[1946,2016],[1970,2016]]: #\n",
        "        end_year=dates[1];\n",
        "        start_year=dates[0];\n",
        "            \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = start_year, end_year = end_year,y_shift = 1, normalize = False);\n",
        "\n",
        "        t = time.time();\n",
        "        \n",
        "        f.write(cross_validation2(reps=1,mm=0,epochs=1,nlags=1,reg_weight=[0],df=df3,fcast_horizon=1,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=1,mm=0,epochs=1,nlags=5,reg_weight=[0],df=df3,fcast_horizon=1,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=2,nlags=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=2,nlags=5,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=3,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=4,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=5,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=3,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=3,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=4,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=4,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=4,return_state=True,rnn_mode=3,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=5,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=5,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));       \n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Results 1 AUC-val 0.598 0.524 0.480 0.412 0.539 AUC-train 0.663\n",
            "Shapley [0.00911933 0.00264962 0.0029304  0.00641264 0.00377177] [0.03326142]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.154159\n",
            "         Iterations 9\n",
            "2.410553216934204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.662 0.589 0.526 0.452 0.457 AUC-train 0.782\n",
            "Shapley [0.013319   0.0090798  0.00813132 0.01367208 0.01043193] [0.02361189]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.146926\n",
            "         Iterations 9\n",
            "5.231010675430298\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Results 100 AUC-val 0.597 0.558 0.574 0.538 0.515 AUC-train 0.727\n",
            "Shapley [0.01214453 0.00557688 0.0023743  0.00888054 0.00750414] [0.04001913]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.151098\n",
            "         Iterations 8\n",
            "4958.6844301223755\n",
            "Results 100 AUC-val 0.698 0.573 0.435 0.381 0.465 AUC-train 0.841\n",
            "Shapley [0.01331209 0.00655501 0.00206758 0.02541722 0.00639389] [0.05046689]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.144617\n",
            "         Iterations 8\n",
            "9909.995478868484\n",
            "Results 100 AUC-val 0.736 0.671 0.627 0.528 0.473 AUC-train 0.879\n",
            "Shapley [0.02067782 0.01736156 0.00726122 0.02253012 0.00886142] [0.02841206]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.142944\n",
            "         Iterations 8\n",
            "18650.979998350143\n",
            "Results 100 AUC-val 0.747 0.673 0.536 0.496 0.494 AUC-train 0.964\n",
            "Shapley [0.02529183 0.01938279 0.00879929 0.03989103 0.01524547] [0.04044782]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.145179\n",
            "         Iterations 8\n",
            "25322.956495285034\n",
            "Results 100 AUC-val 0.715 0.613 0.545 0.429 0.498 AUC-train 0.975\n",
            "Shapley [0.02071716 0.01945673 0.00781198 0.02920851 0.01193574] [0.02046873]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.148142\n",
            "         Iterations 8\n",
            "31751.51096343994\n",
            "Results 100 AUC-val 0.761 0.629 0.509 0.412 0.436 AUC-train 0.994\n",
            "Shapley [0.01961374 0.02142931 0.00941668 0.0305394  0.01778638] [0.00919781]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.148791\n",
            "         Iterations 8\n",
            "38657.633378982544\n",
            "38657.633378982544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTWOOAvXtaps",
        "outputId": "af8dc4fc-21c9-43e6-fc48-5c522adb5500"
      },
      "source": [
        "    # Cross validation\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/cross_fc1_reps50_robu2.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=5;\n",
        "    epochs = 100;\n",
        "    k=0\n",
        "    for dates in [[1870,2016],[1870,1939],[1946,2016],[1970,2016]]: #\n",
        "        end_year=dates[1];\n",
        "        start_year=dates[0];\n",
        "            \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = start_year, end_year = end_year,y_shift = 1, normalize = False);\n",
        "\n",
        "        t = time.time();\n",
        "        if(k>0):\n",
        "          f.write(cross_validation2(reps=1,mm=0,epochs=1,nlags=1,reg_weight=[0],df=df3,fcast_horizon=1,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "          f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "          f.write(cross_validation2(reps=1,mm=0,epochs=1,nlags=5,reg_weight=[0],df=df3,fcast_horizon=1,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "          f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "          f.write(cross_validation2(reps=reps,hiddenlayers=2,mm=2,nlags=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "          f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "          f.write(cross_validation2(reps=reps,hiddenlayers=2,mm=2,nlags=5,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "          f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);        \n",
        "          f.write(cross_validation2(reps=reps,mm=3,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "          f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "          f.write(cross_validation2(reps=reps,mm=3,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "          f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "          f.write(cross_validation2(reps=reps,mm=4,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=4,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=5,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=5,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        k=k+1\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "0.0\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Results 100 AUC-val 0.718 0.644 0.513 0.465 0.474 AUC-train 0.984\n",
            "Shapley [0.01777603 0.02099869 0.00797901 0.02850738 0.00932487] [0.01808234]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.146740\n",
            "         Iterations 8\n",
            "10327.553663015366\n",
            "Results 100 AUC-val 0.714 0.624 0.488 0.443 0.483 AUC-train 0.996\n",
            "Shapley [0.01235973 0.01487241 0.00581523 0.02407406 0.00700387] [0.0035496]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.150220\n",
            "         Iterations 8\n",
            "29641.665521383286\n",
            "Results 100 AUC-val 0.729 0.638 0.527 0.478 0.493 AUC-train 0.993\n",
            "Shapley [0.01892354 0.01858309 0.00758387 0.02714349 0.01053292] [0.00996118]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.150259\n",
            "         Iterations 8\n",
            "39745.675827264786\n",
            "cpi_g mean 1.7881396229960618 std 13.37340208549705\n",
            "rgdp_g mean 2.952711113627556 std 7.5998044715370865\n",
            "ca/gdp mean -0.9451919655294233 std 4.612566246255624\n",
            "debtgdp_g mean 2.5640586641149437 std 18.933366347540524\n",
            "tloansgdp_g mean 1.2798471773163658 std 10.331567388648747\n",
            "rsp_g mean 1.6035095703835456 std 17.72095719308985\n",
            "rhp_g mean 1.3192175470640735 std 12.309148793121668\n",
            "rtloans_g mean 4.019090727152438 std 10.99743360824836\n",
            "rtmort_g mean 6.111807296034939 std 14.034702388387414\n",
            "rthh_g mean 5.5530479660354395 std 10.27908592916021\n",
            "rtbus_g mean 2.1290199747978784 std 9.500641100490888\n",
            "ltrate mean 4.328929915300369 std 1.2718175502868831\n",
            "stir mean 4.06775090085249 std 1.7388531636527482\n",
            "Results 1 AUC-val 0.609 0.488 0.381 0.493 0.431 AUC-train 0.710\n",
            "Shapley [0.01836141 0.00463621 0.01859599 0.02335711 0.00825135] [0.05602629]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.235092\n",
            "         Iterations 8\n",
            "0.8906185626983643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.624 0.445 0.494 0.571 0.437 AUC-train 0.870\n",
            "Shapley [0.04585635 0.02515491 0.01901268 0.03781793 0.0276923 ] [0.02165578]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.210137\n",
            "         Iterations 8\n",
            "1.9617540836334229\n",
            "Results 100 AUC-val 0.672 0.579 0.572 0.609 0.665 AUC-train 0.960\n",
            "Shapley [0.02615362 0.02088031 0.04201926 0.04318045 0.01900642] [0.0796117]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.232245\n",
            "         Iterations 7\n",
            "1179.132499217987\n",
            "Results 100 AUC-val 0.653 0.615 0.617 0.610 0.403 AUC-train 0.999\n",
            "Shapley [0.04950187 0.03428073 0.02547888 0.05288353 0.01485507] [0.05667339]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.237112\n",
            "         Iterations 7\n",
            "2393.258410692215\n",
            "Results 100 AUC-val 0.682 0.533 0.363 0.515 0.369 AUC-train 0.683\n",
            "Shapley [0.04147118 0.04961972 0.03418145 0.10738005 0.04709991] [0.10827821]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.222114\n",
            "         Iterations 8\n",
            "7618.446769237518\n",
            "Results 100 AUC-val 0.666 0.493 0.336 0.510 0.385 AUC-train 0.731\n",
            "Shapley [0.03335559 0.03779246 0.03384487 0.09805796 0.05225144] [0.05569414]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.223734\n",
            "         Iterations 8\n",
            "10266.297292232513\n",
            "Results 100 AUC-val 0.639 0.432 0.374 0.495 0.414 AUC-train 0.929\n",
            "Shapley [0.0082215  0.01363111 0.01325268 0.03875452 0.01062383] [0.01457238]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.235570\n",
            "         Iterations 8\n",
            "16289.819834709167\n",
            "Results 100 AUC-val 0.678 0.492 0.410 0.553 0.511 AUC-train 0.988\n",
            "Shapley [0.02255639 0.02467223 0.01622146 0.04834219 0.01104204] [0.00922546]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.235408\n",
            "         Iterations 8\n",
            "18842.40114736557\n",
            "Results 100 AUC-val 0.686 0.525 0.426 0.599 0.427 AUC-train 0.994\n",
            "Shapley [0.0231527  0.0254198  0.01444609 0.04385588 0.00899483] [0.0030721]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.243967\n",
            "         Iterations 8\n",
            "24116.364328622818\n",
            "Results 100 AUC-val 0.643 0.498 0.365 0.534 0.554 AUC-train 0.964\n",
            "Shapley [0.01306761 0.01931142 0.01385382 0.04547063 0.01409448] [0.02280942]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.225735\n",
            "         Iterations 8\n",
            "26356.306770801544\n",
            "cpi_g mean 4.60844434062037 std 6.503176379106574\n",
            "rgdp_g mean 3.287903693001081 std 3.7469600505495744\n",
            "ca/gdp mean 0.30690559891024405 std 3.977787068221254\n",
            "debtgdp_g mean 0.8776440280729189 std 10.638501919437173\n",
            "tloansgdp_g mean 2.0507801965750296 std 5.830920448777627\n",
            "rsp_g mean 4.106616815782945 std 20.980971135222628\n",
            "rhp_g mean 2.7182573548756537 std 8.879195541513386\n",
            "rtloans_g mean 5.387028568961889 std 6.93796609377716\n",
            "rtmort_g mean 6.717579190250951 std 8.756324284136918\n",
            "rthh_g mean 6.614516405496418 std 8.659233385563313\n",
            "rtbus_g mean 4.624752260873402 std 9.026936943167287\n",
            "ltrate mean 6.534231493213482 std 3.57671142825475\n",
            "stir mean 5.467556014512751 std 4.079363821304169\n",
            "Results 1 AUC-val 0.621 0.616 0.568 0.474 0.505 AUC-train 0.683\n",
            "Shapley [0.0075186  0.00118642 0.00571752 0.00272243 0.00252183] [0.02339171]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.117263\n",
            "         Iterations 10\n",
            "2.9640729427337646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.673 0.696 0.624 0.472 0.553 AUC-train 0.835\n",
            "Shapley [0.00828439 0.01614614 0.01055835 0.01229799 0.02051735] [0.01081271]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.120385\n",
            "         Iterations 10\n",
            "6.23532509803772\n",
            "Results 100 AUC-val 0.756 0.726 0.684 0.517 0.437 AUC-train 0.905\n",
            "Shapley [0.00877044 0.00674986 0.00845845 0.01738717 0.0045595 ] [0.02324309]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.119673\n",
            "         Iterations 8\n",
            "4657.678389549255\n",
            "Results 100 AUC-val 0.711 0.637 0.309 0.162 0.410 AUC-train 0.888\n",
            "Shapley [0.00992088 0.01203204 0.00408317 0.05638199 0.01814732] [0.09546512]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.111034\n",
            "         Iterations 9\n",
            "9205.02585029602\n",
            "Results 100 AUC-val 0.793 0.772 0.639 0.598 0.566 AUC-train 0.937\n",
            "Shapley [0.00654087 0.01451384 0.00557351 0.01727044 0.00672788] [0.00426096]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.096539\n",
            "         Iterations 9\n",
            "26298.166528701782\n",
            "Results 100 AUC-val 0.813 0.776 0.657 0.594 0.534 AUC-train 0.958\n",
            "Shapley [0.0110784  0.02656478 0.01065624 0.02703389 0.01667679] [0.00897264]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.095051\n",
            "         Iterations 8\n",
            "35579.15821361542\n",
            "Results 100 AUC-val 0.789 0.731 0.511 0.403 0.531 AUC-train 0.998\n",
            "Shapley [0.00605592 0.01223787 0.00381194 0.01710405 0.00348882] [0.00100045]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.108052\n",
            "         Iterations 11\n",
            "54464.396064043045\n",
            "Results 100 AUC-val 0.817 0.713 0.497 0.496 0.579 AUC-train 0.997\n",
            "Shapley [0.01165363 0.02462534 0.01571715 0.03767906 0.01391594] [0.0103848]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.102922\n",
            "         Iterations 8\n",
            "63124.25309419632\n",
            "Results 100 AUC-val 0.774 0.763 0.490 0.336 0.480 AUC-train 0.991\n",
            "Shapley [0.01002333 0.0181458  0.00732382 0.02335583 0.00996938] [0.00453419]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.101755\n",
            "         Iterations 10\n",
            "80722.38662624359\n",
            "Results 100 AUC-val 0.768 0.703 0.513 0.519 0.545 AUC-train 0.996\n",
            "Shapley [0.01628757 0.03142251 0.01911321 0.05090438 0.01920826] [0.0190394]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.109565\n",
            "         Iterations 8\n",
            "89153.95602869987\n",
            "cpi_g mean 4.381527297045866 std 4.145862313755577\n",
            "rgdp_g mean 2.4965341343079355 std 2.9758598619611822\n",
            "ca/gdp mean 0.5210224414156656 std 4.371610578827272\n",
            "debtgdp_g mean 2.6697261889501607 std 10.501804250810867\n",
            "tloansgdp_g mean 1.809341956698375 std 5.007664719570753\n",
            "rsp_g mean 4.475527665001311 std 21.85636749066819\n",
            "rhp_g mean 2.029374535342964 std 7.241498800047153\n",
            "rtloans_g mean 4.34959199201426 std 5.964873391490648\n",
            "rtmort_g mean 5.600298140309238 std 6.838628764815888\n",
            "rthh_g mean 5.612714205861863 std 7.652298032694095\n",
            "rtbus_g mean 3.4901783095701417 std 8.281959067926582\n",
            "ltrate mean 6.923462557823677 std 3.8184266790062114\n",
            "stir mean 5.929161423517383 std 4.519009508156933\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "Shapley [0.01275172 0.00305675 0.00707763 0.00360387 0.00528522] [0.03338555]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.151512\n",
            "         Iterations 9\n",
            "2.3876147270202637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "Shapley [0.01209144 0.02345834 0.01576085 0.02003438 0.01699886] [0.01682664]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.157953\n",
            "         Iterations 9\n",
            "5.044509172439575\n",
            "Results 100 AUC-val 0.790 0.708 0.684 0.510 0.375 AUC-train 0.951\n",
            "Shapley [0.02176653 0.02251446 0.01429002 0.04695165 0.00939906] [0.09667884]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.145202\n",
            "         Iterations 8\n",
            "3654.0116198062897\n",
            "Results 100 AUC-val 0.728 0.591 0.325 0.191 0.465 AUC-train 0.934\n",
            "Shapley [0.00905622 0.01530037 0.00619243 0.05901941 0.0034498 ] [0.09281575]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.146172\n",
            "         Iterations 8\n",
            "7287.557973623276\n",
            "Results 100 AUC-val 0.764 0.732 0.652 0.565 0.485 AUC-train 0.957\n",
            "Shapley [0.01010169 0.03100666 0.00928905 0.02806211 0.01007005] [0.0027753]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.135845\n",
            "         Iterations 9\n",
            "20712.057158708572\n",
            "Results 100 AUC-val 0.782 0.734 0.661 0.523 0.439 AUC-train 0.967\n",
            "Shapley [0.01943012 0.04465267 0.01740454 0.04717963 0.02091077] [0.0395933]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.129860\n",
            "         Iterations 8\n",
            "27697.3959941864\n",
            "Results 100 AUC-val 0.756 0.698 0.436 0.400 0.535 AUC-train 0.998\n",
            "Shapley [0.00927601 0.02734401 0.00952196 0.02852395 0.00709061] [0.00215552]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.141593\n",
            "         Iterations 8\n",
            "43930.15062689781\n",
            "Results 100 AUC-val 0.801 0.666 0.446 0.413 0.512 AUC-train 0.998\n",
            "Shapley [0.02301763 0.05811913 0.02567894 0.09024756 0.02485804] [0.03824611]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.143391\n",
            "         Iterations 8\n",
            "50872.719249248505\n",
            "Results 100 AUC-val 0.768 0.725 0.415 0.348 0.465 AUC-train 0.997\n",
            "Shapley [0.01133688 0.02623115 0.00734132 0.03031735 0.00708174] [0.00356081]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.135256\n",
            "         Iterations 9\n",
            "64545.7128238678\n",
            "Results 100 AUC-val 0.767 0.722 0.488 0.414 0.418 AUC-train 0.995\n",
            "Shapley [0.02338297 0.05429541 0.01486815 0.08225819 0.02025926] [0.04290205]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.129581\n",
            "         Iterations 8\n",
            "70788.62086057663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Do1N0Otapt",
        "outputId": "18dd46ad-fcbd-43f7-decb-cbbdec35c588"
      },
      "source": [
        "    # Cross validation\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/cross_fc_25.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=5;\n",
        "    epochs = 100;\n",
        "    for fcast_horizon in [2,3,4,5]: #\n",
        "        end_year=2016;\n",
        "        start_year=1974;\n",
        "            \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "\n",
        "        \n",
        "        f.write(cross_validation2(mm=0,epochs=1,nlags=1,reg_weight=[0.0],df=df3,fcast_horizon=fcast_horizon,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(cross_validation2(mm=0,epochs=1,nlags=5,reg_weight=[0.0],df=df3,fcast_horizon=fcast_horizon,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(cross_validation2(reps=reps,mm=2,nlags=1,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(cross_validation2(reps=reps,mm=2,nlags=5,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(cross_validation2(reps=reps,mm=3,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(cross_validation2(reps=reps,mm=4,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(cross_validation2(reps=reps,mm=5,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(cross_validation2(reps=reps,mm=4,return_state=True,rnn_mode=3,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\\n\");f.flush();\n",
        "        \n",
        "        #f.write(cross_validation2(mm=3,return_state=True,rnn_mode=1,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(cross_validation2(mm=3,return_state=True,rnn_mode=2,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(cross_validation2(mm=4,return_state=True,rnn_mode=1,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(cross_validation2(mm=4,return_state=True,rnn_mode=2,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "\n",
        "        #f.write(cross_validation2(mm=5,return_state=True,rnn_mode=1,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(cross_validation2(mm=5,return_state=True,rnn_mode=2,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));       \n",
        "        #f.write(\"\\n\");f.flush();\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.561 0.655 0.683 0.689 0.562 AUC-train 0.711\n",
            "Shapley [0.01029577 0.01194302 0.00484827 0.00753242 0.00262135] [0.02971748]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.148789\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.659 0.689 0.752 0.478 0.394 AUC-train 0.863\n",
            "Shapley [0.01293017 0.02434606 0.01045862 0.02586587 0.01924943] [0.00950129]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.143347\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.705 0.743 0.746 0.628 0.369 AUC-train 0.892\n",
            "Shapley [0.02075216 0.01730628 0.01156437 0.03370706 0.00808043] [0.08359265]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.152224\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.761 0.776 0.687 0.352 0.225 AUC-train 0.968\n",
            "Shapley [0.01352306 0.01672426 0.00429483 0.04721603 0.00626563] [0.04667392]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.118280\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.742 0.780 0.753 0.652 0.418 AUC-train 0.956\n",
            "Shapley [0.00877925 0.02930219 0.01334927 0.02748509 0.01421227] [0.00718907]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.135745\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.757 0.870 0.779 0.539 0.413 AUC-train 0.998\n",
            "Shapley [0.01183201 0.02090132 0.01129579 0.03517341 0.00700814] [0.01003424]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.116660\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.722 0.863 0.758 0.526 0.466 AUC-train 0.994\n",
            "Shapley [0.01123844 0.01997615 0.00746812 0.03329589 0.00763871] [0.00715024]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.121878\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.729 0.867 0.747 0.521 0.407 AUC-train 0.999\n",
            "Shapley [0.01116934 0.02346118 0.010613   0.03162584 0.00534037] [0.00087591]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.118464\n",
            "         Iterations 16\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.559 0.674 0.671 0.696 0.558 AUC-train 0.726\n",
            "Shapley [0.01430253 0.01377967 0.00131625 0.00523034 0.00120973] [0.02902456]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.145705\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.499 0.732 0.724 0.591 0.397 AUC-train 0.892\n",
            "Shapley [0.01497494 0.01823925 0.00955411 0.03232813 0.01103647] [0.00693342]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.148039\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.621 0.761 0.757 0.656 0.424 AUC-train 0.908\n",
            "Shapley [0.02241251 0.02095869 0.00719048 0.03145122 0.01009678] [0.06456519]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.149487\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.536 0.760 0.829 0.445 0.302 AUC-train 0.983\n",
            "Shapley [0.00900724 0.0143613  0.00212628 0.03869654 0.00218231] [0.00932242]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.118503\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.603 0.752 0.814 0.712 0.532 AUC-train 0.972\n",
            "Shapley [0.00939314 0.01878075 0.00678829 0.02722627 0.0071006 ] [0.00442801]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.124821\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.632 0.810 0.873 0.707 0.565 AUC-train 0.998\n",
            "Shapley [0.00889787 0.0168543  0.00447012 0.03293067 0.00441419] [0.00163739]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.126984\n",
            "         Iterations 10\n",
            "Results 100 AUC-val 0.660 0.848 0.858 0.632 0.570 AUC-train 0.995\n",
            "Shapley [0.00885091 0.01661299 0.00484722 0.0367255  0.00404789] [0.00311162]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.127873\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.650 0.810 0.879 0.621 0.490 AUC-train 0.999\n",
            "Shapley [0.01107766 0.02354468 0.0046694  0.04244683 0.00596427] [0.00012401]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.134866\n",
            "         Iterations 28\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.555 0.684 0.688 0.695 0.535 AUC-train 0.762\n",
            "Shapley [0.01077844 0.01070929 0.0016706  0.01751142 0.00109076] [0.02990985]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.147056\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.430 0.530 0.684 0.746 0.536 AUC-train 0.897\n",
            "Shapley [0.01679212 0.01560711 0.01445093 0.03524058 0.01077503] [0.00636476]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.146185\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.572 0.689 0.713 0.660 0.442 AUC-train 0.815\n",
            "Shapley [0.01416226 0.01871912 0.00492429 0.03022904 0.00961437] [0.05902595]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.162552\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.336 0.474 0.723 0.784 0.463 AUC-train 0.978\n",
            "Shapley [0.00690619 0.01259554 0.00253381 0.04635331 0.00215613] [0.01319651]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.128551\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.488 0.695 0.826 0.845 0.692 AUC-train 0.978\n",
            "Shapley [0.0076699  0.01682216 0.0051812  0.03721917 0.00555219] [0.00268803]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.130647\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.563 0.733 0.793 0.835 0.686 AUC-train 0.997\n",
            "Shapley [0.0095846  0.0161228  0.00523112 0.03914542 0.0054845 ] [0.0029649]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.119759\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.458 0.705 0.790 0.784 0.606 AUC-train 0.993\n",
            "Shapley [0.00859516 0.01598456 0.00589464 0.03936749 0.00412678] [0.00267025]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.137374\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.549 0.730 0.781 0.803 0.632 AUC-train 0.999\n",
            "Shapley [0.01509808 0.01850822 0.00752511 0.04277592 0.00513795] [0.00521458]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.127153\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.544 0.626 0.645 0.601 0.411 AUC-train 0.615\n",
            "Shapley [0.00486559 0.00725221 0.00221287 0.00491533 0.00618113] [0.0421846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.165016\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.488 0.439 0.487 0.639 0.722 AUC-train 0.868\n",
            "Shapley [0.01676401 0.01971759 0.01985115 0.0371748  0.01553107] [0.010514]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.164199\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.483 0.464 0.538 0.500 0.593 AUC-train 0.822\n",
            "Shapley [0.01108094 0.01501007 0.00561942 0.01809633 0.0063347 ] [0.03720217]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.169452\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.436 0.223 0.393 0.684 0.793 AUC-train 0.985\n",
            "Shapley [0.01143139 0.01457934 0.00470612 0.05281829 0.00714723] [0.02536448]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.140809\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.425 0.478 0.728 0.780 0.806 AUC-train 0.983\n",
            "Shapley [0.00858402 0.01500159 0.00537131 0.04512505 0.00579416] [0.00258881]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.129382\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.442 0.482 0.591 0.715 0.823 AUC-train 0.997\n",
            "Shapley [0.01101199 0.02090879 0.00979296 0.04733391 0.01529714] [0.00477236]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.133377\n",
            "         Iterations 9\n",
            "Results 100 AUC-val 0.416 0.484 0.642 0.711 0.782 AUC-train 0.990\n",
            "Shapley [0.01137831 0.02220507 0.00678557 0.04627423 0.01182095] [0.00760972]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.142701\n",
            "         Iterations 8\n",
            "Results 100 AUC-val 0.422 0.521 0.672 0.771 0.818 AUC-train 0.998\n",
            "Shapley [0.01951747 0.02232978 0.01170674 0.0486585  0.01924783] [0.00292521]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.145145\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKZZYB43tapt"
      },
      "source": [
        "# Robustness check, units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE8F_r1htapt",
        "outputId": "4ccf71de-8f99-4870-ed80-5d1376155fd1"
      },
      "source": [
        "    # Cross validation\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/crossvalidation_robust_units_epochs100.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=1;\n",
        "    epochs = 100;\n",
        "    for units in range(1,21): #\n",
        "        end_year=2016;\n",
        "        start_year=1974;\n",
        "        fcast_horizon=1;    \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "\n",
        "        t = time.time();\n",
        "        \n",
        "        f.write(cross_validation2(mm=0,epochs=1,nlags=1,reg_weight=[0.00],df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(mm=0,epochs=1,nlags=5,reg_weight=[0.00],df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=2,nlags=1,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=2,nlags=5,reg_weight=[0.01,0,0,0.01],df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=3,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=4,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=5,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(reps=reps,mm=4,return_state=False,rnn_mode=3,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=3,return_state=False,rnn_mode=1,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=3,return_state=False,rnn_mode=2,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=4,return_state=False,rnn_mode=1,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=4,return_state=False,rnn_mode=2,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "\n",
        "        #f.write(cross_validation2(mm=5,return_state=False,rnn_mode=1,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(mm=5,return_state=False,rnn_mode=2,df=df3,units=units,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));       \n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "2.6269755363464355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "4.732346773147583\n",
            "Results 100 AUC-val 0.540 0.518 0.513 0.493 0.487 AUC-train 0.562\n",
            "249.6877989768982\n",
            "Results 100 AUC-val 0.707 0.538 0.492 0.292 0.533 AUC-train 0.708\n",
            "494.3068206310272\n",
            "Results 100 AUC-val 0.608 0.564 0.593 0.603 0.605 AUC-train 0.591\n",
            "1020.9386484622955\n",
            "Results 100 AUC-val 0.771 0.724 0.562 0.522 0.480 AUC-train 0.786\n",
            "1365.7616157531738\n",
            "Results 100 AUC-val 0.606 0.647 0.573 0.506 0.434 AUC-train 0.686\n",
            "1689.7333645820618\n",
            "Results 100 AUC-val 0.771 0.724 0.562 0.522 0.480 AUC-train 0.786\n",
            "2034.6241235733032\n",
            "2034.6241235733032\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.7134184837341309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.652235507965088\n",
            "Results 100 AUC-val 0.690 0.643 0.631 0.490 0.461 AUC-train 0.702\n",
            "236.56743478775024\n",
            "Results 100 AUC-val 0.718 0.537 0.392 0.254 0.547 AUC-train 0.841\n",
            "471.1870787143707\n",
            "Results 100 AUC-val 0.736 0.634 0.636 0.630 0.498 AUC-train 0.721\n",
            "992.903046131134\n",
            "Results 100 AUC-val 0.801 0.793 0.638 0.522 0.479 AUC-train 0.931\n",
            "1332.857033252716\n",
            "Results 100 AUC-val 0.632 0.678 0.667 0.516 0.563 AUC-train 0.703\n",
            "1656.056848526001\n",
            "Results 100 AUC-val 0.801 0.793 0.638 0.522 0.479 AUC-train 0.931\n",
            "1999.9941549301147\n",
            "1999.9941549301147\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.8311047554016113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.703098773956299\n",
            "Results 100 AUC-val 0.619 0.649 0.639 0.549 0.455 AUC-train 0.744\n",
            "239.0318741798401\n",
            "Results 100 AUC-val 0.705 0.514 0.425 0.232 0.499 AUC-train 0.880\n",
            "474.42046785354614\n",
            "Results 100 AUC-val 0.666 0.722 0.725 0.597 0.567 AUC-train 0.753\n",
            "1002.1523258686066\n",
            "Results 100 AUC-val 0.807 0.699 0.554 0.530 0.502 AUC-train 0.938\n",
            "1344.895879983902\n",
            "Results 100 AUC-val 0.712 0.639 0.609 0.479 0.453 AUC-train 0.809\n",
            "1671.0457513332367\n",
            "Results 100 AUC-val 0.807 0.699 0.554 0.530 0.502 AUC-train 0.938\n",
            "2018.4936995506287\n",
            "2018.4936995506287\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.636596441268921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.376944065093994\n",
            "Results 100 AUC-val 0.590 0.617 0.645 0.508 0.314 AUC-train 0.765\n",
            "234.49494981765747\n",
            "Results 100 AUC-val 0.754 0.605 0.358 0.219 0.495 AUC-train 0.935\n",
            "468.5062210559845\n",
            "Results 100 AUC-val 0.750 0.742 0.726 0.675 0.481 AUC-train 0.831\n",
            "991.5775904655457\n",
            "Results 100 AUC-val 0.787 0.687 0.507 0.418 0.401 AUC-train 0.910\n",
            "1332.9617261886597\n",
            "Results 100 AUC-val 0.757 0.734 0.648 0.501 0.424 AUC-train 0.952\n",
            "1654.810153722763\n",
            "Results 100 AUC-val 0.787 0.687 0.507 0.418 0.401 AUC-train 0.910\n",
            "1994.9885132312775\n",
            "1994.9885132312775\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.745333194732666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.591397762298584\n",
            "Results 100 AUC-val 0.669 0.699 0.687 0.496 0.446 AUC-train 0.783\n",
            "235.87628293037415\n",
            "Results 100 AUC-val 0.792 0.658 0.365 0.260 0.392 AUC-train 0.915\n",
            "467.985639333725\n",
            "Results 100 AUC-val 0.732 0.767 0.764 0.626 0.535 AUC-train 0.739\n",
            "989.928008556366\n",
            "Results 100 AUC-val 0.795 0.697 0.552 0.494 0.495 AUC-train 0.985\n",
            "1330.2381627559662\n",
            "Results 100 AUC-val 0.811 0.624 0.556 0.401 0.358 AUC-train 0.946\n",
            "1654.6168208122253\n",
            "Results 100 AUC-val 0.795 0.697 0.552 0.494 0.495 AUC-train 0.985\n",
            "1999.9643626213074\n",
            "1999.9643626213074\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.797224521636963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.7429921627044678\n",
            "Results 100 AUC-val 0.626 0.673 0.690 0.465 0.412 AUC-train 0.816\n",
            "240.39124035835266\n",
            "Results 100 AUC-val 0.740 0.622 0.350 0.227 0.460 AUC-train 0.949\n",
            "476.0730140209198\n",
            "Results 100 AUC-val 0.711 0.751 0.709 0.570 0.402 AUC-train 0.890\n",
            "1000.7221384048462\n",
            "Results 100 AUC-val 0.814 0.741 0.523 0.431 0.463 AUC-train 0.916\n",
            "1345.63090467453\n",
            "Results 100 AUC-val 0.809 0.732 0.588 0.416 0.397 AUC-train 0.960\n",
            "1672.27046585083\n",
            "Results 100 AUC-val 0.814 0.741 0.523 0.431 0.463 AUC-train 0.916\n",
            "2018.922574043274\n",
            "2018.9235734939575\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.5797746181488037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.3550283908843994\n",
            "Results 100 AUC-val 0.628 0.647 0.631 0.442 0.420 AUC-train 0.840\n",
            "235.45640587806702\n",
            "Results 100 AUC-val 0.790 0.555 0.389 0.352 0.444 AUC-train 0.855\n",
            "471.15217185020447\n",
            "Results 100 AUC-val 0.746 0.689 0.695 0.601 0.487 AUC-train 0.868\n",
            "995.4253256320953\n",
            "Results 100 AUC-val 0.810 0.717 0.532 0.434 0.403 AUC-train 0.959\n",
            "1343.8427059650421\n",
            "Results 100 AUC-val 0.751 0.634 0.553 0.445 0.470 AUC-train 0.989\n",
            "1668.9064936637878\n",
            "Results 100 AUC-val 0.810 0.717 0.532 0.434 0.403 AUC-train 0.959\n",
            "2011.9252836704254\n",
            "2011.9252836704254\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.7213973999023438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.6193227767944336\n",
            "Results 100 AUC-val 0.621 0.685 0.658 0.507 0.435 AUC-train 0.827\n",
            "236.86962795257568\n",
            "Results 100 AUC-val 0.738 0.605 0.342 0.237 0.467 AUC-train 0.953\n",
            "470.84925413131714\n",
            "Results 100 AUC-val 0.770 0.755 0.742 0.597 0.492 AUC-train 0.893\n",
            "992.238068819046\n",
            "Results 100 AUC-val 0.789 0.608 0.465 0.465 0.472 AUC-train 0.996\n",
            "1333.1325416564941\n",
            "Results 100 AUC-val 0.835 0.694 0.581 0.460 0.440 AUC-train 0.991\n",
            "1653.3951816558838\n",
            "Results 100 AUC-val 0.789 0.608 0.465 0.465 0.472 AUC-train 0.996\n",
            "1993.4618964195251\n",
            "1993.4618964195251\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.663522481918335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.443763256072998\n",
            "Results 100 AUC-val 0.647 0.676 0.694 0.526 0.405 AUC-train 0.835\n",
            "236.37395596504211\n",
            "Results 100 AUC-val 0.734 0.582 0.354 0.213 0.432 AUC-train 0.947\n",
            "470.01320004463196\n",
            "Results 100 AUC-val 0.751 0.688 0.707 0.615 0.444 AUC-train 0.937\n",
            "990.2900211811066\n",
            "Results 100 AUC-val 0.809 0.719 0.491 0.446 0.470 AUC-train 0.956\n",
            "1332.3284287452698\n",
            "Results 100 AUC-val 0.777 0.721 0.685 0.466 0.450 AUC-train 0.859\n",
            "1658.6568503379822\n",
            "Results 100 AUC-val 0.809 0.719 0.491 0.446 0.470 AUC-train 0.956\n",
            "2004.8252489566803\n",
            "2004.8252489566803\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.7064099311828613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.4128475189208984\n",
            "Results 100 AUC-val 0.651 0.720 0.710 0.517 0.386 AUC-train 0.860\n",
            "240.41511964797974\n",
            "Results 100 AUC-val 0.757 0.612 0.323 0.185 0.449 AUC-train 0.951\n",
            "477.7465262413025\n",
            "Results 100 AUC-val 0.780 0.692 0.723 0.577 0.439 AUC-train 0.947\n",
            "1001.0213570594788\n",
            "Results 100 AUC-val 0.833 0.691 0.446 0.423 0.452 AUC-train 0.989\n",
            "1345.7375829219818\n",
            "Results 100 AUC-val 0.796 0.694 0.566 0.444 0.385 AUC-train 0.976\n",
            "1673.2288982868195\n",
            "Results 100 AUC-val 0.833 0.691 0.446 0.423 0.452 AUC-train 0.989\n",
            "2017.924207687378\n",
            "2017.925205230713\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.712421178817749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.600400924682617\n",
            "Results 100 AUC-val 0.620 0.684 0.645 0.515 0.366 AUC-train 0.863\n",
            "236.99529147148132\n",
            "Results 100 AUC-val 0.772 0.577 0.387 0.256 0.431 AUC-train 0.829\n",
            "475.4147734642029\n",
            "Results 100 AUC-val 0.774 0.722 0.743 0.557 0.465 AUC-train 0.952\n",
            "997.4369699954987\n",
            "Results 100 AUC-val 0.797 0.711 0.506 0.475 0.475 AUC-train 0.998\n",
            "1341.1508767604828\n",
            "Results 100 AUC-val 0.804 0.694 0.539 0.413 0.481 AUC-train 0.995\n",
            "1668.282161951065\n",
            "Results 100 AUC-val 0.797 0.711 0.506 0.475 0.475 AUC-train 0.998\n",
            "2014.4395763874054\n",
            "2014.4405770301819\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.6964635848999023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.3919291496276855\n",
            "Results 100 AUC-val 0.667 0.738 0.670 0.520 0.405 AUC-train 0.864\n",
            "234.02723288536072\n",
            "Results 100 AUC-val 0.772 0.588 0.322 0.208 0.420 AUC-train 0.955\n",
            "469.54549765586853\n",
            "Results 100 AUC-val 0.742 0.799 0.766 0.599 0.405 AUC-train 0.919\n",
            "990.5024709701538\n",
            "Results 100 AUC-val 0.830 0.716 0.479 0.449 0.440 AUC-train 0.995\n",
            "1333.199124097824\n",
            "Results 100 AUC-val 0.806 0.631 0.491 0.416 0.449 AUC-train 0.995\n",
            "1656.6971416473389\n",
            "Results 100 AUC-val 0.830 0.716 0.479 0.449 0.440 AUC-train 0.995\n",
            "1997.7631261348724\n",
            "1997.7631261348724\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.63759446144104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.4766757488250732\n",
            "Results 100 AUC-val 0.638 0.749 0.670 0.549 0.373 AUC-train 0.866\n",
            "236.54247999191284\n",
            "Results 100 AUC-val 0.763 0.562 0.334 0.236 0.493 AUC-train 0.866\n",
            "469.5823800563812\n",
            "Results 100 AUC-val 0.773 0.738 0.666 0.486 0.447 AUC-train 0.940\n",
            "988.8239941596985\n",
            "Results 100 AUC-val 0.827 0.629 0.453 0.404 0.442 AUC-train 0.995\n",
            "1330.9002821445465\n",
            "Results 100 AUC-val 0.753 0.616 0.437 0.413 0.473 AUC-train 0.998\n",
            "1653.3570566177368\n",
            "Results 100 AUC-val 0.827 0.629 0.453 0.404 0.442 AUC-train 0.995\n",
            "1996.6012451648712\n",
            "1996.6012451648712\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.724388599395752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.5395348072052\n",
            "Results 100 AUC-val 0.641 0.686 0.685 0.474 0.390 AUC-train 0.869\n",
            "235.6499147415161\n",
            "Results 100 AUC-val 0.740 0.605 0.336 0.186 0.425 AUC-train 0.959\n",
            "468.23799300193787\n",
            "Results 100 AUC-val 0.797 0.716 0.682 0.546 0.458 AUC-train 0.921\n",
            "988.5457322597504\n",
            "Results 100 AUC-val 0.825 0.707 0.521 0.482 0.523 AUC-train 0.996\n",
            "1330.466436624527\n",
            "Results 100 AUC-val 0.797 0.610 0.503 0.390 0.399 AUC-train 0.998\n",
            "1657.2476761341095\n",
            "Results 100 AUC-val 0.825 0.707 0.521 0.482 0.523 AUC-train 0.996\n",
            "2002.6789863109589\n",
            "2002.6799838542938\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.8031766414642334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.6432576179504395\n",
            "Results 100 AUC-val 0.637 0.713 0.633 0.493 0.401 AUC-train 0.878\n",
            "239.56541800498962\n",
            "Results 100 AUC-val 0.754 0.586 0.306 0.197 0.448 AUC-train 0.962\n",
            "477.0693485736847\n",
            "Results 100 AUC-val 0.709 0.718 0.718 0.518 0.507 AUC-train 0.940\n",
            "1003.924574136734\n",
            "Results 100 AUC-val 0.827 0.707 0.504 0.466 0.530 AUC-train 0.998\n",
            "1347.6794216632843\n",
            "Results 100 AUC-val 0.808 0.732 0.502 0.405 0.458 AUC-train 0.999\n",
            "1673.8372747898102\n",
            "Results 100 AUC-val 0.827 0.707 0.504 0.466 0.530 AUC-train 0.998\n",
            "2019.9537830352783\n",
            "2019.9537830352783\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.7732298374176025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.6382429599761963\n",
            "Results 100 AUC-val 0.638 0.715 0.639 0.578 0.395 AUC-train 0.858\n",
            "234.8609824180603\n",
            "Results 100 AUC-val 0.742 0.567 0.340 0.189 0.421 AUC-train 0.961\n",
            "471.06838035583496\n",
            "Results 100 AUC-val 0.789 0.696 0.583 0.504 0.440 AUC-train 0.981\n",
            "992.5519685745239\n",
            "Results 100 AUC-val 0.806 0.679 0.472 0.455 0.506 AUC-train 0.999\n",
            "1330.0365591049194\n",
            "Results 100 AUC-val 0.775 0.681 0.536 0.401 0.441 AUC-train 0.988\n",
            "1646.4335355758667\n",
            "Results 100 AUC-val 0.806 0.679 0.472 0.455 0.506 AUC-train 0.999\n",
            "1982.7502479553223\n",
            "1982.7502479553223\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.745309591293335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.5454955101013184\n",
            "Results 100 AUC-val 0.652 0.723 0.643 0.508 0.376 AUC-train 0.874\n",
            "235.4673523902893\n",
            "Results 100 AUC-val 0.741 0.590 0.314 0.188 0.417 AUC-train 0.963\n",
            "469.82669281959534\n",
            "Results 100 AUC-val 0.773 0.791 0.741 0.525 0.483 AUC-train 0.980\n",
            "989.8471937179565\n",
            "Results 100 AUC-val 0.816 0.708 0.511 0.405 0.450 AUC-train 0.993\n",
            "1342.7056744098663\n",
            "Results 100 AUC-val 0.822 0.657 0.440 0.313 0.395 AUC-train 0.999\n",
            "1672.6643888950348\n",
            "Results 100 AUC-val 0.816 0.708 0.511 0.405 0.450 AUC-train 0.993\n",
            "2022.6964266300201\n",
            "2022.6964266300201\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "2.1193337440490723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "4.65455436706543\n",
            "Results 100 AUC-val 0.652 0.767 0.692 0.505 0.379 AUC-train 0.877\n",
            "245.00786662101746\n",
            "Results 100 AUC-val 0.760 0.673 0.306 0.176 0.374 AUC-train 0.958\n",
            "484.958256483078\n",
            "Results 100 AUC-val 0.759 0.740 0.689 0.523 0.414 AUC-train 0.960\n",
            "1016.7882056236267\n",
            "Results 100 AUC-val 0.814 0.665 0.476 0.458 0.492 AUC-train 0.997\n",
            "1373.7586674690247\n",
            "Results 100 AUC-val 0.811 0.644 0.488 0.381 0.439 AUC-train 0.997\n",
            "1713.370714187622\n",
            "Results 100 AUC-val 0.814 0.665 0.476 0.458 0.492 AUC-train 0.997\n",
            "2062.3535318374634\n",
            "2062.3535318374634\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.711392879486084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.6232802867889404\n",
            "Results 100 AUC-val 0.650 0.722 0.636 0.507 0.354 AUC-train 0.863\n",
            "258.6264190673828\n",
            "Results 100 AUC-val 0.747 0.640 0.335 0.195 0.450 AUC-train 0.952\n",
            "520.1660804748535\n",
            "Results 100 AUC-val 0.747 0.655 0.575 0.514 0.477 AUC-train 0.989\n",
            "1092.5329539775848\n",
            "Results 100 AUC-val 0.828 0.697 0.520 0.427 0.465 AUC-train 0.990\n",
            "1465.8656787872314\n",
            "Results 100 AUC-val 0.855 0.662 0.411 0.324 0.448 AUC-train 0.997\n",
            "1808.3339188098907\n",
            "Results 100 AUC-val 0.828 0.697 0.520 0.427 0.465 AUC-train 0.990\n",
            "2172.8991074562073\n",
            "2172.8991074562073\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "1.7014796733856201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "3.5315568447113037\n",
            "Results 100 AUC-val 0.652 0.718 0.671 0.515 0.330 AUC-train 0.869\n",
            "243.27250504493713\n",
            "Results 100 AUC-val 0.736 0.567 0.358 0.214 0.471 AUC-train 0.950\n",
            "481.97725534439087\n",
            "Results 100 AUC-val 0.749 0.749 0.802 0.581 0.424 AUC-train 0.892\n",
            "1011.031571149826\n",
            "Results 100 AUC-val 0.814 0.683 0.442 0.404 0.459 AUC-train 0.995\n",
            "1356.1138451099396\n",
            "Results 100 AUC-val 0.819 0.702 0.516 0.341 0.308 AUC-train 0.986\n",
            "1680.329915046692\n",
            "Results 100 AUC-val 0.814 0.683 0.442 0.404 0.459 AUC-train 0.995\n",
            "2024.4946410655975\n",
            "2024.4956395626068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjESF8wtapt"
      },
      "source": [
        "# Robustness check time steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lic52rTGtapt",
        "outputId": "b52e4568-b4a7-422c-de53-c478d1b31a90"
      },
      "source": [
        "    # Cross validation\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/cross_timestep_robu_rep5_epochs100.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=5;\n",
        "    epochs = 100;\n",
        "    fcast_horizon=1;\n",
        "    for timestep in [1,2,3,4,5,6,7,8,9,10]: #\n",
        "        end_year=2016;\n",
        "        start_year=1974;\n",
        "            \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "\n",
        "        t = time.time();\n",
        "        \n",
        "        f.write(cross_validation2(timestep=timestep,reg_weight=[0.00],mm=0,epochs=1,nlags=timestep,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(timestep=timestep,reps=reps,mm=2,nlags=timestep,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(timestep=timestep,reps=reps,mm=3,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(timestep=timestep,reps=reps,mm=4,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(cross_validation2(timestep=timestep,reps=reps,mm=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Results 1 AUC-val 0.611 0.600 0.604 0.544 0.524 AUC-train 0.688\n",
            "Shapley [0.0128134  0.00324356 0.00688445 0.00310169 0.00505084] [0.03301096]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.151670\n",
            "         Iterations 9\n",
            "1.769268274307251\n",
            "Results 100 AUC-val 0.603 0.684 0.678 0.523 0.413 AUC-train 0.729\n",
            "Shapley [0.01458043 0.00288743 0.00557755 0.01801213 0.00084404] [0.05781523]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.155848\n",
            "         Iterations 8\n",
            "2898.1999814510345\n",
            "Results 100 AUC-val 0.709 0.731 0.721 0.659 0.525 AUC-train 0.859\n",
            "Shapley [0.01347729 0.00625109 0.01141001 0.01366066 0.00388231] [0.01659553]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158576\n",
            "         Iterations 8\n",
            "7196.368851423264\n",
            "Results 100 AUC-val 0.750 0.731 0.697 0.609 0.472 AUC-train 0.919\n",
            "Shapley [0.01115798 0.0075882  0.00979068 0.01801235 0.00325403] [0.01108635]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.154237\n",
            "         Iterations 8\n",
            "11511.683866262436\n",
            "Results 100 AUC-val 0.767 0.726 0.681 0.562 0.488 AUC-train 0.956\n",
            "Shapley [0.0122276  0.01072426 0.01301023 0.02208281 0.00517162] [0.00696325]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158772\n",
            "         Iterations 8\n",
            "15510.500331640244\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.606 0.683 0.656 0.539 0.495 AUC-train 0.710\n",
            "Shapley [0.01257361 0.01132432 0.00748984 0.00665061 0.00570363] [0.02891678]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.155318\n",
            "         Iterations 9\n",
            "1.8909428119659424\n",
            "Results 100 AUC-val 0.706 0.767 0.728 0.376 0.240 AUC-train 0.841\n",
            "Shapley [0.01536181 0.0095755  0.00661833 0.03020324 0.0016598 ] [0.06295692]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.153944\n",
            "         Iterations 8\n",
            "2799.0401775836945\n",
            "Results 100 AUC-val 0.771 0.775 0.721 0.632 0.429 AUC-train 0.963\n",
            "Shapley [0.01288448 0.01563519 0.01572177 0.02146949 0.00837168] [0.00777804]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.144594\n",
            "         Iterations 8\n",
            "7350.428829669952\n",
            "Results 100 AUC-val 0.791 0.776 0.723 0.561 0.409 AUC-train 0.996\n",
            "Shapley [0.01287024 0.01355884 0.015124   0.02692082 0.00639963] [0.00553723]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.149440\n",
            "         Iterations 8\n",
            "11588.13240981102\n",
            "Results 100 AUC-val 0.790 0.788 0.714 0.472 0.413 AUC-train 0.997\n",
            "Shapley [0.01257271 0.01674169 0.01316689 0.02535621 0.00890263] [0.00810965]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.142833\n",
            "         Iterations 8\n",
            "15571.179051160812\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.632 0.734 0.615 0.537 0.446 AUC-train 0.759\n",
            "Shapley [0.01153356 0.01821778 0.00959901 0.01026516 0.00905398] [0.02392087]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.152362\n",
            "         Iterations 9\n",
            "2.318798303604126\n",
            "Results 100 AUC-val 0.741 0.719 0.528 0.250 0.333 AUC-train 0.909\n",
            "Shapley [0.02437768 0.02921613 0.01113442 0.10134852 0.01091097] [0.15245262]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.131852\n",
            "         Iterations 8\n",
            "2718.0427980422974\n",
            "Results 100 AUC-val 0.765 0.757 0.720 0.567 0.383 AUC-train 0.956\n",
            "Shapley [0.01634353 0.03605193 0.01469828 0.02994495 0.0114755 ] [0.0112119]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.143457\n",
            "         Iterations 8\n",
            "7524.877281427383\n",
            "Results 100 AUC-val 0.806 0.816 0.707 0.446 0.413 AUC-train 0.907\n",
            "Shapley [0.02615973 0.03720734 0.02451597 0.08570673 0.01916916] [0.09856813]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.144659\n",
            "         Iterations 8\n",
            "11856.454292535782\n",
            "Results 100 AUC-val 0.847 0.782 0.648 0.406 0.423 AUC-train 0.998\n",
            "Shapley [0.02413369 0.05290071 0.02205253 0.0594708  0.01338951] [0.01232811]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.138834\n",
            "         Iterations 8\n",
            "15828.949152469635\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.692 0.627 0.574 0.451 0.520 AUC-train 0.835\n",
            "Shapley [0.01029521 0.02154162 0.01397015 0.02071849 0.01428258] [0.01766045]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.154977\n",
            "         Iterations 9\n",
            "2.6668684482574463\n",
            "Results 100 AUC-val 0.774 0.542 0.269 0.159 0.483 AUC-train 0.907\n",
            "Shapley [0.02693197 0.04728784 0.01485295 0.15813122 0.03417026] [0.22168455]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.128335\n",
            "         Iterations 8\n",
            "2834.4305288791656\n",
            "Results 100 AUC-val 0.788 0.747 0.748 0.551 0.458 AUC-train 0.953\n",
            "Shapley [0.01689852 0.04451218 0.01482417 0.04086757 0.01702336] [0.01078638]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.143788\n",
            "         Iterations 8\n",
            "7862.820477247238\n",
            "Results 100 AUC-val 0.830 0.717 0.517 0.394 0.486 AUC-train 0.999\n",
            "Shapley [0.02182148 0.05518583 0.03040324 0.10100004 0.03359196] [0.06258742]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.131972\n",
            "         Iterations 8\n",
            "12127.114941596985\n",
            "Results 100 AUC-val 0.835 0.744 0.576 0.388 0.450 AUC-train 0.997\n",
            "Shapley [0.02425298 0.07475634 0.04122973 0.1251169  0.04138854] [0.07678661]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.120943\n",
            "         Iterations 8\n",
            "16103.375730514526\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.642 0.652 0.576 0.432 0.508 AUC-train 0.843\n",
            "Shapley [0.01209144 0.02345834 0.01576085 0.02003438 0.01699886] [0.01682664]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.157953\n",
            "         Iterations 9\n",
            "2.9062280654907227\n",
            "Results 100 AUC-val 0.735 0.618 0.323 0.195 0.389 AUC-train 0.959\n",
            "Shapley [0.01465424 0.02630812 0.00938443 0.08787826 0.00872089] [0.12517555]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.142938\n",
            "         Iterations 8\n",
            "2834.601073026657\n",
            "Results 100 AUC-val 0.783 0.783 0.755 0.584 0.467 AUC-train 0.919\n",
            "Shapley [0.01636517 0.05009091 0.02123066 0.04240813 0.01705848] [0.02429568]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.136268\n",
            "         Iterations 8\n",
            "8112.851788759232\n",
            "Results 100 AUC-val 0.842 0.676 0.459 0.406 0.430 AUC-train 0.998\n",
            "Shapley [0.02910452 0.06693289 0.04085379 0.20226077 0.0564399 ] [0.22811451]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.138167\n",
            "         Iterations 8\n",
            "12539.813211917877\n",
            "Results 100 AUC-val 0.802 0.669 0.529 0.389 0.395 AUC-train 0.996\n",
            "Shapley [0.02974035 0.06678605 0.02180318 0.10220263 0.02759054] [0.06040464]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.145339\n",
            "         Iterations 8\n",
            "16519.158751249313\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.678 0.752 0.488 0.410 0.478 AUC-train 0.869\n",
            "Shapley [0.01285071 0.02576363 0.01306814 0.02468462 0.0200773 ] [0.00812769]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.144536\n",
            "         Iterations 9\n",
            "3.0707874298095703\n",
            "Results 100 AUC-val 0.776 0.622 0.359 0.264 0.474 AUC-train 0.903\n",
            "Shapley [0.02198039 0.03800938 0.01555768 0.10574147 0.03061786] [0.14060211]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.129210\n",
            "         Iterations 8\n",
            "2780.578552722931\n",
            "Results 100 AUC-val 0.838 0.776 0.732 0.583 0.420 AUC-train 0.943\n",
            "Shapley [0.02048567 0.05371992 0.02756843 0.06542092 0.0233142 ] [0.03491571]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.132530\n",
            "         Iterations 9\n",
            "8223.649467229843\n",
            "Results 100 AUC-val 0.847 0.759 0.570 0.439 0.436 AUC-train 0.994\n",
            "Shapley [0.02186617 0.05084502 0.02693254 0.11384285 0.01666672] [0.10851634]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.131079\n",
            "         Iterations 8\n",
            "12455.221446037292\n",
            "Results 100 AUC-val 0.855 0.741 0.545 0.433 0.457 AUC-train 0.994\n",
            "Shapley [0.02670998 0.04909401 0.02566109 0.08418651 0.01308334] [0.03309469]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.127105\n",
            "         Iterations 8\n",
            "16410.547224998474\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.693 0.643 0.481 0.309 0.339 AUC-train 0.905\n",
            "Shapley [0.01713566 0.02576891 0.01248925 0.02979896 0.0161408 ] [0.00456061]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.140631\n",
            "         Iterations 9\n",
            "3.355027198791504\n",
            "Results 100 AUC-val 0.862 0.501 0.345 0.208 0.350 AUC-train 0.990\n",
            "Shapley [0.01178854 0.02705414 0.00502204 0.05444866 0.00399261] [0.02984749]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.103994\n",
            "         Iterations 9\n",
            "2764.086658000946\n",
            "Results 100 AUC-val 0.823 0.774 0.731 0.581 0.369 AUC-train 0.909\n",
            "Shapley [0.01543685 0.03903624 0.02553301 0.03836899 0.01855081] [0.01305081]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.133614\n",
            "         Iterations 9\n",
            "8454.830191612244\n",
            "Results 100 AUC-val 0.867 0.656 0.558 0.466 0.469 AUC-train 0.998\n",
            "Shapley [0.01717111 0.03353548 0.01160235 0.06508985 0.00819048] [0.02842478]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.120230\n",
            "         Iterations 8\n",
            "12689.039119243622\n",
            "Results 100 AUC-val 0.865 0.769 0.624 0.474 0.432 AUC-train 0.996\n",
            "Shapley [0.02239687 0.03723299 0.0159804  0.05870126 0.00909301] [0.02548362]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.115599\n",
            "         Iterations 8\n",
            "16655.797320842743\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.680 0.620 0.544 0.342 0.376 AUC-train 0.909\n",
            "Shapley [0.01953597 0.02904019 0.01698561 0.02886042 0.02484738] [0.00370608]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.141248\n",
            "         Iterations 9\n",
            "3.322115898132324\n",
            "Results 100 AUC-val 0.840 0.523 0.337 0.242 0.419 AUC-train 0.988\n",
            "Shapley [0.01041937 0.02271286 0.00411575 0.04817293 0.00254282] [0.0214479]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.115011\n",
            "         Iterations 8\n",
            "2778.1111512184143\n",
            "Results 100 AUC-val 0.821 0.792 0.711 0.580 0.435 AUC-train 0.950\n",
            "Shapley [0.0200159  0.05088593 0.03052836 0.05814507 0.01995146] [0.0360082]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.119421\n",
            "         Iterations 9\n",
            "8603.809756994247\n",
            "Results 100 AUC-val 0.841 0.787 0.688 0.545 0.488 AUC-train 0.995\n",
            "Shapley [0.02707513 0.03840697 0.0219985  0.10931859 0.01674048] [0.10126409]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.123142\n",
            "         Iterations 8\n",
            "12818.302413463593\n",
            "Results 100 AUC-val 0.857 0.821 0.716 0.557 0.425 AUC-train 0.994\n",
            "Shapley [0.03892442 0.06349643 0.03732039 0.14215677 0.02135483] [0.12466801]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.128304\n",
            "         Iterations 8\n",
            "16756.420213460922\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.701 0.667 0.536 0.430 0.364 AUC-train 0.938\n",
            "Shapley [0.02801581 0.03834071 0.02795223 0.03603878 0.03939292] [0.00120301]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.141412\n",
            "         Iterations 10\n",
            "3.6392674446105957\n",
            "Results 100 AUC-val 0.798 0.530 0.346 0.212 0.349 AUC-train 0.993\n",
            "Shapley [0.01489972 0.03054874 0.00540816 0.06595925 0.00575312] [0.04232544]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.105359\n",
            "         Iterations 9\n",
            "2783.686208963394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-35-4b09b72a6250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_validation2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnlags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreg_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfcast_horizon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcast_horizon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_reliability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_year\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdo_shapley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_validation2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfcast_horizon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcast_horizon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_reliability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_year\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdo_shapley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_validation2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfcast_horizon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcast_horizon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_reliability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_year\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdo_shapley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-28-f860f39124dd>\u001b[0m in \u001b[0;36mcross_validation2\u001b[1;34m(mm, df, batch_size, epochs, units, Nf, reg_weight, timestep, algo, dropout, batchnormalization, print_epoch_stats, hiddenlayers, nlags, reps, patience, return_state, rnn_mode, learning_rate, fhandle, fcast_horizon, sub_epochs, class_weight, plot_reliability, validate, time_start, time_end, save_model, do_shapley, d2cgraph, code)\u001b[0m\n\u001b[0;32m    106\u001b[0m           \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogit_reg_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m           \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogit_reg_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# Calculate simple average of all training AUCs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-19-94c384d7bf81>\u001b[0m in \u001b[0;36mfitModel\u001b[1;34m(XTRAIN, YTRAIN, XTEST, YTEST, mod, ts_mode, timestep, nlags, batch_size, epochs, print_data, validate, patience, message, class_weight, logit_reg_weight)\u001b[0m\n\u001b[0;32m     35\u001b[0m           \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m           \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYTEST\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m           \u001b[0mAUC_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mYTRAIN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mXTRAIN\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m           \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training results, Accuracy %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AUC  %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mYTRAIN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mXTRAIN\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUhivmqItapu"
      },
      "source": [
        "# Plot distance 2 crisis graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJUHgSXXtapu",
        "outputId": "6c170382-5386-4576-b55d-e1be142ed8ec"
      },
      "source": [
        "    # Cross validation\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/disgard.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=1;\n",
        "    epochs = 1;\n",
        "    for fcast_horizon in [1,2,3,4,5]: #\n",
        "        end_year=2016;\n",
        "        start_year=1970;\n",
        "            \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = start_year, end_year = end_year,y_shift = 1, normalize = False);\n",
        "\n",
        "        t = time.time();\n",
        "        \n",
        "        f.write(cross_validation2(reps=reps,mm=0,nlags=1,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False,d2cgraph=True));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 4.381527297045866 std 4.145862313755577\n",
            "rgdp_g mean 2.4965341343079355 std 2.9758598619611822\n",
            "ca/gdp mean 0.5210224414156656 std 4.371610578827272\n",
            "debtgdp_g mean 2.6697261889501607 std 10.501804250810867\n",
            "tloansgdp_g mean 1.809341956698375 std 5.007664719570753\n",
            "rsp_g mean 4.475527665001311 std 21.85636749066819\n",
            "rhp_g mean 2.029374535342964 std 7.241498800047153\n",
            "rtloans_g mean 4.34959199201426 std 5.964873391490648\n",
            "rtmort_g mean 5.600298140309238 std 6.838628764815888\n",
            "rthh_g mean 5.612714205861863 std 7.652298032694095\n",
            "rtbus_g mean 3.4901783095701417 std 8.281959067926582\n",
            "ltrate mean 6.923462557823677 std 3.8184266790062114\n",
            "stir mean 5.929161423517383 std 4.519009508156933\n",
            "Stats - Epoch: 1 AUC-val 0.610  AUC-train 0.689\n",
            "Results 1 AUC-val 0.610 0.594 0.594 0.543 0.519 AUC-train 0.689\n",
            "0.9823734760284424\n",
            "cpi_g mean 4.381527297045866 std 4.145862313755577\n",
            "rgdp_g mean 2.4965341343079355 std 2.9758598619611822\n",
            "ca/gdp mean 0.5210224414156656 std 4.371610578827272\n",
            "debtgdp_g mean 2.6697261889501607 std 10.501804250810867\n",
            "tloansgdp_g mean 1.809341956698375 std 5.007664719570753\n",
            "rsp_g mean 4.475527665001311 std 21.85636749066819\n",
            "rhp_g mean 2.029374535342964 std 7.241498800047153\n",
            "rtloans_g mean 4.34959199201426 std 5.964873391490648\n",
            "rtmort_g mean 5.600298140309238 std 6.838628764815888\n",
            "rthh_g mean 5.612714205861863 std 7.652298032694095\n",
            "rtbus_g mean 3.4901783095701417 std 8.281959067926582\n",
            "ltrate mean 6.923462557823677 std 3.8184266790062114\n",
            "stir mean 5.929161423517383 std 4.519009508156933\n",
            "Stats - Epoch: 1 AUC-val 0.655  AUC-train 0.711\n",
            "Results 1 AUC-val 0.561 0.655 0.683 0.689 0.562 AUC-train 0.711\n",
            "1.025259017944336\n",
            "cpi_g mean 4.381527297045866 std 4.145862313755577\n",
            "rgdp_g mean 2.4965341343079355 std 2.9758598619611822\n",
            "ca/gdp mean 0.5210224414156656 std 4.371610578827272\n",
            "debtgdp_g mean 2.6697261889501607 std 10.501804250810867\n",
            "tloansgdp_g mean 1.809341956698375 std 5.007664719570753\n",
            "rsp_g mean 4.475527665001311 std 21.85636749066819\n",
            "rhp_g mean 2.029374535342964 std 7.241498800047153\n",
            "rtloans_g mean 4.34959199201426 std 5.964873391490648\n",
            "rtmort_g mean 5.600298140309238 std 6.838628764815888\n",
            "rthh_g mean 5.612714205861863 std 7.652298032694095\n",
            "rtbus_g mean 3.4901783095701417 std 8.281959067926582\n",
            "ltrate mean 6.923462557823677 std 3.8184266790062114\n",
            "stir mean 5.929161423517383 std 4.519009508156933\n",
            "Stats - Epoch: 1 AUC-val 0.671  AUC-train 0.726\n",
            "Results 1 AUC-val 0.559 0.674 0.671 0.696 0.558 AUC-train 0.726\n",
            "1.0272531509399414\n",
            "cpi_g mean 4.381527297045866 std 4.145862313755577\n",
            "rgdp_g mean 2.4965341343079355 std 2.9758598619611822\n",
            "ca/gdp mean 0.5210224414156656 std 4.371610578827272\n",
            "debtgdp_g mean 2.6697261889501607 std 10.501804250810867\n",
            "tloansgdp_g mean 1.809341956698375 std 5.007664719570753\n",
            "rsp_g mean 4.475527665001311 std 21.85636749066819\n",
            "rhp_g mean 2.029374535342964 std 7.241498800047153\n",
            "rtloans_g mean 4.34959199201426 std 5.964873391490648\n",
            "rtmort_g mean 5.600298140309238 std 6.838628764815888\n",
            "rthh_g mean 5.612714205861863 std 7.652298032694095\n",
            "rtbus_g mean 3.4901783095701417 std 8.281959067926582\n",
            "ltrate mean 6.923462557823677 std 3.8184266790062114\n",
            "stir mean 5.929161423517383 std 4.519009508156933\n",
            "Stats - Epoch: 1 AUC-val 0.695  AUC-train 0.762\n",
            "Results 1 AUC-val 0.555 0.684 0.688 0.695 0.535 AUC-train 0.762\n",
            "1.015315055847168\n",
            "cpi_g mean 4.381527297045866 std 4.145862313755577\n",
            "rgdp_g mean 2.4965341343079355 std 2.9758598619611822\n",
            "ca/gdp mean 0.5210224414156656 std 4.371610578827272\n",
            "debtgdp_g mean 2.6697261889501607 std 10.501804250810867\n",
            "tloansgdp_g mean 1.809341956698375 std 5.007664719570753\n",
            "rsp_g mean 4.475527665001311 std 21.85636749066819\n",
            "rhp_g mean 2.029374535342964 std 7.241498800047153\n",
            "rtloans_g mean 4.34959199201426 std 5.964873391490648\n",
            "rtmort_g mean 5.600298140309238 std 6.838628764815888\n",
            "rthh_g mean 5.612714205861863 std 7.652298032694095\n",
            "rtbus_g mean 3.4901783095701417 std 8.281959067926582\n",
            "ltrate mean 6.923462557823677 std 3.8184266790062114\n",
            "stir mean 5.929161423517383 std 4.519009508156933\n",
            "Stats - Epoch: 1 AUC-val 0.411  AUC-train 0.615\n",
            "Results 1 AUC-val 0.544 0.626 0.645 0.601 0.411 AUC-train 0.615\n",
            "1.0033152103424072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOh-06PDtapu"
      },
      "source": [
        "# Sequential evaluation 1-year, subsamples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKg5xMSYtapu",
        "outputId": "afc0a837-ab31-4997-d399-05d4401c829f"
      },
      "source": [
        "    import os\n",
        "    # Simulation params\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/seq_fc1_reps5.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    epochs = 100;\n",
        "    for dates in [[1970,1999,2000,2016],[1946,1999,2000,2016],[1870,1914,1920,1939],[1946,1989,1990,2016]]: #[1970,2016]\n",
        "    #for dates in [[1974,1999,2000,2016]]: #[1970,2016]\n",
        "        train_end_year=dates[1];\n",
        "        train_start_year=dates[0];\n",
        "        test_start_year=dates[2]; # Define test set\n",
        "        test_end_year=dates[3];\n",
        "        reps=50\n",
        "        print(dates)\n",
        "    \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "\n",
        "        \n",
        "        f.write(sequential_evaluation(reg_weight=[0.0],reps=1,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,nlags=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();     \n",
        "        f.write(sequential_evaluation(reg_weight=[0.0],reps=1,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,nlags=5,df=df3,fcast_horizon=1,plot_reliability=False,epochs=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=2,nlags=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=2,nlags=5,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=3,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));       \n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "    \n",
        "f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1970, 1999, 2000, 2016]\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.416  AUC-train 0.496\n",
            "Stats - Epoch: 2 AUC-val 0.429  AUC-train 0.572\n",
            "Stats - Epoch: 3 AUC-val 0.416  AUC-train 0.619\n",
            "Stats - Epoch: 4 AUC-val 0.436  AUC-train 0.648\n",
            "Stats - Epoch: 5 AUC-val 0.432  AUC-train 0.674\n",
            "Stats - Epoch: 6 AUC-val 0.427  AUC-train 0.704\n",
            "Stats - Epoch: 7 AUC-val 0.427  AUC-train 0.723\n",
            "Stats - Epoch: 8 AUC-val 0.429  AUC-train 0.735\n",
            "Stats - Epoch: 9 AUC-val 0.429  AUC-train 0.753\n",
            "Stats - Epoch: 10 AUC-val 0.429  AUC-train 0.773\n",
            "Stats - Epoch: 11 AUC-val 0.429  AUC-train 0.773\n",
            "Stats - Epoch: 12 AUC-val 0.426  AUC-train 0.795\n",
            "Stats - Epoch: 13 AUC-val 0.431  AUC-train 0.797\n",
            "Stats - Epoch: 14 AUC-val 0.424  AUC-train 0.812\n",
            "Stats - Epoch: 15 AUC-val 0.423  AUC-train 0.813\n",
            "Stats - Epoch: 16 AUC-val 0.417  AUC-train 0.821\n",
            "Stats - Epoch: 17 AUC-val 0.438  AUC-train 0.816\n",
            "Stats - Epoch: 18 AUC-val 0.431  AUC-train 0.827\n",
            "Stats - Epoch: 19 AUC-val 0.439  AUC-train 0.834\n",
            "Stats - Epoch: 20 AUC-val 0.445  AUC-train 0.835\n",
            "Stats - Epoch: 21 AUC-val 0.433  AUC-train 0.840\n",
            "Stats - Epoch: 22 AUC-val 0.437  AUC-train 0.844\n",
            "Stats - Epoch: 23 AUC-val 0.452  AUC-train 0.850\n",
            "Stats - Epoch: 24 AUC-val 0.438  AUC-train 0.849\n",
            "Stats - Epoch: 25 AUC-val 0.450  AUC-train 0.848\n",
            "Stats - Epoch: 26 AUC-val 0.446  AUC-train 0.851\n",
            "Stats - Epoch: 27 AUC-val 0.448  AUC-train 0.852\n",
            "Stats - Epoch: 28 AUC-val 0.443  AUC-train 0.853\n",
            "Stats - Epoch: 29 AUC-val 0.449  AUC-train 0.849\n",
            "Stats - Epoch: 30 AUC-val 0.448  AUC-train 0.862\n",
            "Stats - Epoch: 31 AUC-val 0.445  AUC-train 0.865\n",
            "Stats - Epoch: 32 AUC-val 0.452  AUC-train 0.861\n",
            "Stats - Epoch: 33 AUC-val 0.460  AUC-train 0.865\n",
            "Stats - Epoch: 34 AUC-val 0.452  AUC-train 0.861\n",
            "Stats - Epoch: 35 AUC-val 0.463  AUC-train 0.856\n",
            "Stats - Epoch: 36 AUC-val 0.463  AUC-train 0.861\n",
            "Stats - Epoch: 37 AUC-val 0.463  AUC-train 0.867\n",
            "Stats - Epoch: 38 AUC-val 0.457  AUC-train 0.866\n",
            "Stats - Epoch: 39 AUC-val 0.452  AUC-train 0.869\n",
            "Stats - Epoch: 40 AUC-val 0.453  AUC-train 0.872\n",
            "Stats - Epoch: 41 AUC-val 0.460  AUC-train 0.874\n",
            "Stats - Epoch: 42 AUC-val 0.460  AUC-train 0.872\n",
            "Stats - Epoch: 43 AUC-val 0.463  AUC-train 0.866\n",
            "Stats - Epoch: 44 AUC-val 0.464  AUC-train 0.870\n",
            "Stats - Epoch: 45 AUC-val 0.453  AUC-train 0.869\n",
            "Stats - Epoch: 46 AUC-val 0.457  AUC-train 0.875\n",
            "Stats - Epoch: 47 AUC-val 0.460  AUC-train 0.873\n",
            "Stats - Epoch: 48 AUC-val 0.458  AUC-train 0.874\n",
            "Stats - Epoch: 49 AUC-val 0.467  AUC-train 0.875\n",
            "Stats - Epoch: 50 AUC-val 0.472  AUC-train 0.873\n",
            "Stats - Epoch: 51 AUC-val 0.466  AUC-train 0.876\n",
            "Stats - Epoch: 52 AUC-val 0.463  AUC-train 0.871\n",
            "Stats - Epoch: 53 AUC-val 0.469  AUC-train 0.879\n",
            "Stats - Epoch: 54 AUC-val 0.461  AUC-train 0.880\n",
            "Stats - Epoch: 55 AUC-val 0.465  AUC-train 0.880\n",
            "Stats - Epoch: 56 AUC-val 0.470  AUC-train 0.874\n",
            "Stats - Epoch: 57 AUC-val 0.462  AUC-train 0.880\n",
            "Stats - Epoch: 58 AUC-val 0.478  AUC-train 0.878\n",
            "Stats - Epoch: 59 AUC-val 0.463  AUC-train 0.881\n",
            "Stats - Epoch: 60 AUC-val 0.459  AUC-train 0.882\n",
            "Stats - Epoch: 61 AUC-val 0.467  AUC-train 0.885\n",
            "Stats - Epoch: 62 AUC-val 0.465  AUC-train 0.887\n",
            "Stats - Epoch: 63 AUC-val 0.470  AUC-train 0.887\n",
            "Stats - Epoch: 64 AUC-val 0.469  AUC-train 0.876\n",
            "Stats - Epoch: 65 AUC-val 0.468  AUC-train 0.883\n",
            "Stats - Epoch: 66 AUC-val 0.466  AUC-train 0.887\n",
            "Stats - Epoch: 67 AUC-val 0.477  AUC-train 0.883\n",
            "Stats - Epoch: 68 AUC-val 0.476  AUC-train 0.886\n",
            "Stats - Epoch: 69 AUC-val 0.478  AUC-train 0.887\n",
            "Stats - Epoch: 70 AUC-val 0.462  AUC-train 0.888\n",
            "Stats - Epoch: 71 AUC-val 0.474  AUC-train 0.884\n",
            "Stats - Epoch: 72 AUC-val 0.476  AUC-train 0.886\n",
            "Stats - Epoch: 73 AUC-val 0.475  AUC-train 0.885\n",
            "Stats - Epoch: 74 AUC-val 0.479  AUC-train 0.883\n",
            "Stats - Epoch: 75 AUC-val 0.470  AUC-train 0.886\n",
            "Stats - Epoch: 76 AUC-val 0.484  AUC-train 0.883\n",
            "Stats - Epoch: 77 AUC-val 0.472  AUC-train 0.888\n",
            "Stats - Epoch: 78 AUC-val 0.483  AUC-train 0.886\n",
            "Stats - Epoch: 79 AUC-val 0.481  AUC-train 0.887\n",
            "Stats - Epoch: 80 AUC-val 0.482  AUC-train 0.892\n",
            "Stats - Epoch: 81 AUC-val 0.471  AUC-train 0.890\n",
            "Stats - Epoch: 82 AUC-val 0.475  AUC-train 0.889\n",
            "Stats - Epoch: 83 AUC-val 0.476  AUC-train 0.893\n",
            "Stats - Epoch: 84 AUC-val 0.472  AUC-train 0.890\n",
            "Stats - Epoch: 85 AUC-val 0.474  AUC-train 0.889\n",
            "Stats - Epoch: 86 AUC-val 0.480  AUC-train 0.889\n",
            "Stats - Epoch: 87 AUC-val 0.482  AUC-train 0.887\n",
            "Stats - Epoch: 88 AUC-val 0.479  AUC-train 0.892\n",
            "Stats - Epoch: 89 AUC-val 0.472  AUC-train 0.892\n",
            "Stats - Epoch: 90 AUC-val 0.479  AUC-train 0.885\n",
            "Stats - Epoch: 91 AUC-val 0.475  AUC-train 0.891\n",
            "Stats - Epoch: 92 AUC-val 0.464  AUC-train 0.889\n",
            "Stats - Epoch: 93 AUC-val 0.472  AUC-train 0.891\n",
            "Stats - Epoch: 94 AUC-val 0.469  AUC-train 0.893\n",
            "Stats - Epoch: 95 AUC-val 0.485  AUC-train 0.885\n",
            "Stats - Epoch: 96 AUC-val 0.479  AUC-train 0.891\n",
            "Stats - Epoch: 97 AUC-val 0.485  AUC-train 0.890\n",
            "Stats - Epoch: 98 AUC-val 0.483  AUC-train 0.893\n",
            "Stats - Epoch: 99 AUC-val 0.485  AUC-train 0.892\n",
            "Stats - Epoch: 100 AUC-val 0.474  AUC-train 0.894\n",
            "Results 100 AUC-val 0.485 0.517 0.566 0.493 0.620 AUC-train 0.885\n",
            "Shapley [0.00761172 0.00683173 0.0187178  0.01143717 0.0036587 ] [0.0201179]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.189441\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.214  AUC-train 0.565\n",
            "Stats - Epoch: 2 AUC-val 0.275  AUC-train 0.752\n",
            "Stats - Epoch: 3 AUC-val 0.275  AUC-train 0.837\n",
            "Stats - Epoch: 4 AUC-val 0.309  AUC-train 0.885\n",
            "Stats - Epoch: 5 AUC-val 0.322  AUC-train 0.917\n",
            "Stats - Epoch: 6 AUC-val 0.322  AUC-train 0.941\n",
            "Stats - Epoch: 7 AUC-val 0.320  AUC-train 0.950\n",
            "Stats - Epoch: 8 AUC-val 0.349  AUC-train 0.952\n",
            "Stats - Epoch: 9 AUC-val 0.351  AUC-train 0.964\n",
            "Stats - Epoch: 10 AUC-val 0.359  AUC-train 0.970\n",
            "Stats - Epoch: 11 AUC-val 0.376  AUC-train 0.974\n",
            "Stats - Epoch: 12 AUC-val 0.372  AUC-train 0.981\n",
            "Stats - Epoch: 13 AUC-val 0.376  AUC-train 0.980\n",
            "Stats - Epoch: 14 AUC-val 0.397  AUC-train 0.982\n",
            "Stats - Epoch: 15 AUC-val 0.371  AUC-train 0.985\n",
            "Stats - Epoch: 16 AUC-val 0.401  AUC-train 0.986\n",
            "Stats - Epoch: 17 AUC-val 0.402  AUC-train 0.980\n",
            "Stats - Epoch: 18 AUC-val 0.400  AUC-train 0.984\n",
            "Stats - Epoch: 19 AUC-val 0.399  AUC-train 0.987\n",
            "Stats - Epoch: 20 AUC-val 0.387  AUC-train 0.984\n",
            "Stats - Epoch: 21 AUC-val 0.388  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.409  AUC-train 0.982\n",
            "Stats - Epoch: 23 AUC-val 0.389  AUC-train 0.982\n",
            "Stats - Epoch: 24 AUC-val 0.413  AUC-train 0.987\n",
            "Stats - Epoch: 25 AUC-val 0.398  AUC-train 0.985\n",
            "Stats - Epoch: 26 AUC-val 0.440  AUC-train 0.985\n",
            "Stats - Epoch: 27 AUC-val 0.431  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.409  AUC-train 0.984\n",
            "Stats - Epoch: 29 AUC-val 0.407  AUC-train 0.986\n",
            "Stats - Epoch: 30 AUC-val 0.429  AUC-train 0.987\n",
            "Stats - Epoch: 31 AUC-val 0.427  AUC-train 0.991\n",
            "Stats - Epoch: 32 AUC-val 0.421  AUC-train 0.988\n",
            "Stats - Epoch: 33 AUC-val 0.395  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.422  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.445  AUC-train 0.985\n",
            "Stats - Epoch: 36 AUC-val 0.419  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.433  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.452  AUC-train 0.986\n",
            "Stats - Epoch: 39 AUC-val 0.432  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 41 AUC-val 0.422  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.438  AUC-train 0.981\n",
            "Stats - Epoch: 43 AUC-val 0.415  AUC-train 0.977\n",
            "Stats - Epoch: 44 AUC-val 0.416  AUC-train 0.985\n",
            "Stats - Epoch: 45 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.414  AUC-train 0.986\n",
            "Stats - Epoch: 47 AUC-val 0.436  AUC-train 0.983\n",
            "Stats - Epoch: 48 AUC-val 0.462  AUC-train 0.982\n",
            "Stats - Epoch: 49 AUC-val 0.443  AUC-train 0.981\n",
            "Stats - Epoch: 50 AUC-val 0.426  AUC-train 0.981\n",
            "Stats - Epoch: 51 AUC-val 0.436  AUC-train 0.982\n",
            "Stats - Epoch: 52 AUC-val 0.419  AUC-train 0.984\n",
            "Stats - Epoch: 53 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 54 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 55 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 56 AUC-val 0.449  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.460  AUC-train 0.981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.462  AUC-train 0.984\n",
            "Stats - Epoch: 59 AUC-val 0.436  AUC-train 0.979\n",
            "Stats - Epoch: 60 AUC-val 0.434  AUC-train 0.983\n",
            "Stats - Epoch: 61 AUC-val 0.449  AUC-train 0.982\n",
            "Stats - Epoch: 62 AUC-val 0.435  AUC-train 0.985\n",
            "Stats - Epoch: 63 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 64 AUC-val 0.446  AUC-train 0.979\n",
            "Stats - Epoch: 65 AUC-val 0.456  AUC-train 0.984\n",
            "Stats - Epoch: 66 AUC-val 0.426  AUC-train 0.986\n",
            "Stats - Epoch: 67 AUC-val 0.457  AUC-train 0.980\n",
            "Stats - Epoch: 68 AUC-val 0.450  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.450  AUC-train 0.985\n",
            "Stats - Epoch: 70 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 71 AUC-val 0.445  AUC-train 0.981\n",
            "Stats - Epoch: 72 AUC-val 0.432  AUC-train 0.979\n",
            "Stats - Epoch: 73 AUC-val 0.448  AUC-train 0.982\n",
            "Stats - Epoch: 74 AUC-val 0.450  AUC-train 0.981\n",
            "Stats - Epoch: 75 AUC-val 0.450  AUC-train 0.979\n",
            "Stats - Epoch: 76 AUC-val 0.469  AUC-train 0.974\n",
            "Stats - Epoch: 77 AUC-val 0.470  AUC-train 0.979\n",
            "Stats - Epoch: 78 AUC-val 0.462  AUC-train 0.971\n",
            "Stats - Epoch: 79 AUC-val 0.435  AUC-train 0.981\n",
            "Stats - Epoch: 80 AUC-val 0.435  AUC-train 0.982\n",
            "Stats - Epoch: 81 AUC-val 0.445  AUC-train 0.983\n",
            "Stats - Epoch: 82 AUC-val 0.442  AUC-train 0.981\n",
            "Stats - Epoch: 83 AUC-val 0.467  AUC-train 0.982\n",
            "Stats - Epoch: 84 AUC-val 0.447  AUC-train 0.983\n",
            "Stats - Epoch: 85 AUC-val 0.456  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.458  AUC-train 0.983\n",
            "Stats - Epoch: 87 AUC-val 0.445  AUC-train 0.983\n",
            "Stats - Epoch: 88 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 89 AUC-val 0.445  AUC-train 0.980\n",
            "Stats - Epoch: 90 AUC-val 0.441  AUC-train 0.980\n",
            "Stats - Epoch: 91 AUC-val 0.465  AUC-train 0.981\n",
            "Stats - Epoch: 92 AUC-val 0.432  AUC-train 0.977\n",
            "Stats - Epoch: 93 AUC-val 0.447  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.474  AUC-train 0.978\n",
            "Stats - Epoch: 95 AUC-val 0.438  AUC-train 0.979\n",
            "Stats - Epoch: 96 AUC-val 0.436  AUC-train 0.977\n",
            "Stats - Epoch: 97 AUC-val 0.437  AUC-train 0.979\n",
            "Stats - Epoch: 98 AUC-val 0.440  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.434  AUC-train 0.976\n",
            "Stats - Epoch: 100 AUC-val 0.435  AUC-train 0.978\n",
            "Results 100 AUC-val 0.474 0.439 0.356 0.200 0.576 AUC-train 0.978\n",
            "Shapley [0.02639601 0.00839862 0.00984904 0.04017125 0.00713525] [0.03441029]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.177211\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.210  AUC-train 0.592\n",
            "Stats - Epoch: 2 AUC-val 0.188  AUC-train 0.618\n",
            "Stats - Epoch: 3 AUC-val 0.217  AUC-train 0.680\n",
            "Stats - Epoch: 4 AUC-val 0.245  AUC-train 0.729\n",
            "Stats - Epoch: 5 AUC-val 0.322  AUC-train 0.764\n",
            "Stats - Epoch: 6 AUC-val 0.319  AUC-train 0.788\n",
            "Stats - Epoch: 7 AUC-val 0.410  AUC-train 0.806\n",
            "Stats - Epoch: 8 AUC-val 0.452  AUC-train 0.815\n",
            "Stats - Epoch: 9 AUC-val 0.480  AUC-train 0.826\n",
            "Stats - Epoch: 10 AUC-val 0.467  AUC-train 0.838\n",
            "Stats - Epoch: 11 AUC-val 0.565  AUC-train 0.843\n",
            "Stats - Epoch: 12 AUC-val 0.505  AUC-train 0.850\n",
            "Stats - Epoch: 13 AUC-val 0.547  AUC-train 0.853\n",
            "Stats - Epoch: 14 AUC-val 0.550  AUC-train 0.859\n",
            "Stats - Epoch: 15 AUC-val 0.548  AUC-train 0.857\n",
            "Stats - Epoch: 16 AUC-val 0.569  AUC-train 0.860\n",
            "Stats - Epoch: 17 AUC-val 0.552  AUC-train 0.865\n",
            "Stats - Epoch: 18 AUC-val 0.537  AUC-train 0.868\n",
            "Stats - Epoch: 19 AUC-val 0.548  AUC-train 0.867\n",
            "Stats - Epoch: 20 AUC-val 0.566  AUC-train 0.873\n",
            "Stats - Epoch: 21 AUC-val 0.587  AUC-train 0.872\n",
            "Stats - Epoch: 22 AUC-val 0.572  AUC-train 0.874\n",
            "Stats - Epoch: 23 AUC-val 0.558  AUC-train 0.881\n",
            "Stats - Epoch: 24 AUC-val 0.573  AUC-train 0.879\n",
            "Stats - Epoch: 25 AUC-val 0.612  AUC-train 0.881\n",
            "Stats - Epoch: 26 AUC-val 0.602  AUC-train 0.885\n",
            "Stats - Epoch: 27 AUC-val 0.591  AUC-train 0.886\n",
            "Stats - Epoch: 28 AUC-val 0.597  AUC-train 0.888\n",
            "Stats - Epoch: 29 AUC-val 0.589  AUC-train 0.889\n",
            "Stats - Epoch: 30 AUC-val 0.593  AUC-train 0.885\n",
            "Stats - Epoch: 31 AUC-val 0.593  AUC-train 0.891\n",
            "Stats - Epoch: 32 AUC-val 0.614  AUC-train 0.894\n",
            "Stats - Epoch: 33 AUC-val 0.584  AUC-train 0.896\n",
            "Stats - Epoch: 34 AUC-val 0.610  AUC-train 0.896\n",
            "Stats - Epoch: 35 AUC-val 0.586  AUC-train 0.898\n",
            "Stats - Epoch: 36 AUC-val 0.586  AUC-train 0.900\n",
            "Stats - Epoch: 37 AUC-val 0.573  AUC-train 0.902\n",
            "Stats - Epoch: 38 AUC-val 0.602  AUC-train 0.903\n",
            "Stats - Epoch: 39 AUC-val 0.606  AUC-train 0.906\n",
            "Stats - Epoch: 40 AUC-val 0.591  AUC-train 0.906\n",
            "Stats - Epoch: 41 AUC-val 0.619  AUC-train 0.908\n",
            "Stats - Epoch: 42 AUC-val 0.600  AUC-train 0.915\n",
            "Stats - Epoch: 43 AUC-val 0.599  AUC-train 0.911\n",
            "Stats - Epoch: 44 AUC-val 0.594  AUC-train 0.913\n",
            "Stats - Epoch: 45 AUC-val 0.616  AUC-train 0.912\n",
            "Stats - Epoch: 46 AUC-val 0.594  AUC-train 0.914\n",
            "Stats - Epoch: 47 AUC-val 0.615  AUC-train 0.916\n",
            "Stats - Epoch: 48 AUC-val 0.599  AUC-train 0.916\n",
            "Stats - Epoch: 49 AUC-val 0.617  AUC-train 0.914\n",
            "Stats - Epoch: 50 AUC-val 0.608  AUC-train 0.911\n",
            "Stats - Epoch: 51 AUC-val 0.621  AUC-train 0.916\n",
            "Stats - Epoch: 52 AUC-val 0.612  AUC-train 0.917\n",
            "Stats - Epoch: 53 AUC-val 0.622  AUC-train 0.915\n",
            "Stats - Epoch: 54 AUC-val 0.614  AUC-train 0.916\n",
            "Stats - Epoch: 55 AUC-val 0.603  AUC-train 0.915\n",
            "Stats - Epoch: 56 AUC-val 0.617  AUC-train 0.918\n",
            "Stats - Epoch: 57 AUC-val 0.622  AUC-train 0.922\n",
            "Stats - Epoch: 58 AUC-val 0.641  AUC-train 0.922\n",
            "Stats - Epoch: 59 AUC-val 0.628  AUC-train 0.918\n",
            "Stats - Epoch: 60 AUC-val 0.606  AUC-train 0.924\n",
            "Stats - Epoch: 61 AUC-val 0.613  AUC-train 0.925\n",
            "Stats - Epoch: 62 AUC-val 0.598  AUC-train 0.924\n",
            "Stats - Epoch: 63 AUC-val 0.638  AUC-train 0.922\n",
            "Stats - Epoch: 64 AUC-val 0.640  AUC-train 0.917\n",
            "Stats - Epoch: 65 AUC-val 0.626  AUC-train 0.918\n",
            "Stats - Epoch: 66 AUC-val 0.618  AUC-train 0.920\n",
            "Stats - Epoch: 67 AUC-val 0.641  AUC-train 0.920\n",
            "Stats - Epoch: 68 AUC-val 0.651  AUC-train 0.925\n",
            "Stats - Epoch: 69 AUC-val 0.633  AUC-train 0.924\n",
            "Stats - Epoch: 70 AUC-val 0.606  AUC-train 0.924\n",
            "Stats - Epoch: 71 AUC-val 0.640  AUC-train 0.922\n",
            "Stats - Epoch: 72 AUC-val 0.624  AUC-train 0.922\n",
            "Stats - Epoch: 73 AUC-val 0.615  AUC-train 0.922\n",
            "Stats - Epoch: 74 AUC-val 0.620  AUC-train 0.924\n",
            "Stats - Epoch: 75 AUC-val 0.650  AUC-train 0.927\n",
            "Stats - Epoch: 76 AUC-val 0.622  AUC-train 0.928\n",
            "Stats - Epoch: 77 AUC-val 0.636  AUC-train 0.929\n",
            "Stats - Epoch: 78 AUC-val 0.634  AUC-train 0.930\n",
            "Stats - Epoch: 79 AUC-val 0.629  AUC-train 0.930\n",
            "Stats - Epoch: 80 AUC-val 0.598  AUC-train 0.927\n",
            "Stats - Epoch: 81 AUC-val 0.610  AUC-train 0.933\n",
            "Stats - Epoch: 82 AUC-val 0.607  AUC-train 0.934\n",
            "Stats - Epoch: 83 AUC-val 0.605  AUC-train 0.935\n",
            "Stats - Epoch: 84 AUC-val 0.604  AUC-train 0.936\n",
            "Stats - Epoch: 85 AUC-val 0.599  AUC-train 0.936\n",
            "Stats - Epoch: 86 AUC-val 0.601  AUC-train 0.938\n",
            "Stats - Epoch: 87 AUC-val 0.634  AUC-train 0.936\n",
            "Stats - Epoch: 88 AUC-val 0.633  AUC-train 0.932\n",
            "Stats - Epoch: 89 AUC-val 0.616  AUC-train 0.933\n",
            "Stats - Epoch: 90 AUC-val 0.564  AUC-train 0.939\n",
            "Stats - Epoch: 91 AUC-val 0.586  AUC-train 0.932\n",
            "Stats - Epoch: 92 AUC-val 0.590  AUC-train 0.938\n",
            "Stats - Epoch: 93 AUC-val 0.602  AUC-train 0.942\n",
            "Stats - Epoch: 94 AUC-val 0.586  AUC-train 0.939\n",
            "Stats - Epoch: 95 AUC-val 0.574  AUC-train 0.942\n",
            "Stats - Epoch: 96 AUC-val 0.605  AUC-train 0.939\n",
            "Stats - Epoch: 97 AUC-val 0.605  AUC-train 0.945\n",
            "Stats - Epoch: 98 AUC-val 0.593  AUC-train 0.940\n",
            "Stats - Epoch: 99 AUC-val 0.588  AUC-train 0.938\n",
            "Stats - Epoch: 100 AUC-val 0.582  AUC-train 0.938\n",
            "Results 100 AUC-val 0.651 0.617 0.591 0.545 0.632 AUC-train 0.925\n",
            "Shapley [0.01427282 0.0108813  0.01605212 0.01209641 0.0050925 ] [0.00446316]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199138\n",
            "         Iterations 7\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.376  AUC-train 0.574\n",
            "Stats - Epoch: 2 AUC-val 0.488  AUC-train 0.736\n",
            "Stats - Epoch: 3 AUC-val 0.603  AUC-train 0.808\n",
            "Stats - Epoch: 4 AUC-val 0.639  AUC-train 0.844\n",
            "Stats - Epoch: 5 AUC-val 0.653  AUC-train 0.867\n",
            "Stats - Epoch: 6 AUC-val 0.678  AUC-train 0.887\n",
            "Stats - Epoch: 7 AUC-val 0.690  AUC-train 0.903\n",
            "Stats - Epoch: 8 AUC-val 0.683  AUC-train 0.919\n",
            "Stats - Epoch: 9 AUC-val 0.702  AUC-train 0.930\n",
            "Stats - Epoch: 10 AUC-val 0.716  AUC-train 0.939\n",
            "Stats - Epoch: 11 AUC-val 0.719  AUC-train 0.949\n",
            "Stats - Epoch: 12 AUC-val 0.721  AUC-train 0.956\n",
            "Stats - Epoch: 13 AUC-val 0.723  AUC-train 0.964\n",
            "Stats - Epoch: 14 AUC-val 0.733  AUC-train 0.967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.721  AUC-train 0.974\n",
            "Stats - Epoch: 16 AUC-val 0.716  AUC-train 0.979\n",
            "Stats - Epoch: 17 AUC-val 0.710  AUC-train 0.982\n",
            "Stats - Epoch: 18 AUC-val 0.709  AUC-train 0.982\n",
            "Stats - Epoch: 19 AUC-val 0.686  AUC-train 0.985\n",
            "Stats - Epoch: 20 AUC-val 0.726  AUC-train 0.985\n",
            "Stats - Epoch: 21 AUC-val 0.737  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.716  AUC-train 0.990\n",
            "Stats - Epoch: 23 AUC-val 0.736  AUC-train 0.992\n",
            "Stats - Epoch: 24 AUC-val 0.731  AUC-train 0.992\n",
            "Stats - Epoch: 25 AUC-val 0.731  AUC-train 0.994\n",
            "Stats - Epoch: 26 AUC-val 0.743  AUC-train 0.995\n",
            "Stats - Epoch: 27 AUC-val 0.721  AUC-train 0.995\n",
            "Stats - Epoch: 28 AUC-val 0.726  AUC-train 0.995\n",
            "Stats - Epoch: 29 AUC-val 0.701  AUC-train 0.996\n",
            "Stats - Epoch: 30 AUC-val 0.713  AUC-train 0.997\n",
            "Stats - Epoch: 31 AUC-val 0.716  AUC-train 0.996\n",
            "Stats - Epoch: 32 AUC-val 0.722  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.716  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.708  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.709  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.728  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.699  AUC-train 0.993\n",
            "Stats - Epoch: 40 AUC-val 0.690  AUC-train 0.995\n",
            "Stats - Epoch: 41 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.723  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.706  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.723  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.701  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.700  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.733  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.717  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.695  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.690  AUC-train 0.996\n",
            "Stats - Epoch: 52 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.700  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.703  AUC-train 0.995\n",
            "Stats - Epoch: 58 AUC-val 0.695  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.707  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.740  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.708  AUC-train 0.998\n",
            "Stats - Epoch: 62 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.699  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.714  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.698  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.710  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.675  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.690  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.698  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.698  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.706  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.691  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.698  AUC-train 0.997\n",
            "Stats - Epoch: 76 AUC-val 0.683  AUC-train 0.997\n",
            "Stats - Epoch: 77 AUC-val 0.698  AUC-train 0.995\n",
            "Stats - Epoch: 78 AUC-val 0.686  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.707  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.702  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.701  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.739  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.700  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.698  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.688  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.717  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.689  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.692  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.680  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.722  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.689  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.668  AUC-train 0.994\n",
            "Stats - Epoch: 95 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.650  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.656  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.677  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.694  AUC-train 0.998\n",
            "Results 100 AUC-val 0.743 0.621 0.462 0.405 0.559 AUC-train 0.995\n",
            "Shapley [0.01931924 0.02078854 0.01428986 0.03983718 0.01800003] [0.01258376]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.194237\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.488  AUC-train 0.494\n",
            "Stats - Epoch: 2 AUC-val 0.547  AUC-train 0.666\n",
            "Stats - Epoch: 3 AUC-val 0.600  AUC-train 0.753\n",
            "Stats - Epoch: 4 AUC-val 0.603  AUC-train 0.796\n",
            "Stats - Epoch: 5 AUC-val 0.613  AUC-train 0.829\n",
            "Stats - Epoch: 6 AUC-val 0.610  AUC-train 0.848\n",
            "Stats - Epoch: 7 AUC-val 0.622  AUC-train 0.865\n",
            "Stats - Epoch: 8 AUC-val 0.594  AUC-train 0.878\n",
            "Stats - Epoch: 9 AUC-val 0.607  AUC-train 0.888\n",
            "Stats - Epoch: 10 AUC-val 0.606  AUC-train 0.900\n",
            "Stats - Epoch: 11 AUC-val 0.605  AUC-train 0.909\n",
            "Stats - Epoch: 12 AUC-val 0.600  AUC-train 0.918\n",
            "Stats - Epoch: 13 AUC-val 0.614  AUC-train 0.923\n",
            "Stats - Epoch: 14 AUC-val 0.602  AUC-train 0.930\n",
            "Stats - Epoch: 15 AUC-val 0.614  AUC-train 0.938\n",
            "Stats - Epoch: 16 AUC-val 0.598  AUC-train 0.946\n",
            "Stats - Epoch: 17 AUC-val 0.648  AUC-train 0.953\n",
            "Stats - Epoch: 18 AUC-val 0.662  AUC-train 0.954\n",
            "Stats - Epoch: 19 AUC-val 0.612  AUC-train 0.961\n",
            "Stats - Epoch: 20 AUC-val 0.636  AUC-train 0.968\n",
            "Stats - Epoch: 21 AUC-val 0.631  AUC-train 0.968\n",
            "Stats - Epoch: 22 AUC-val 0.611  AUC-train 0.972\n",
            "Stats - Epoch: 23 AUC-val 0.619  AUC-train 0.976\n",
            "Stats - Epoch: 24 AUC-val 0.603  AUC-train 0.979\n",
            "Stats - Epoch: 25 AUC-val 0.617  AUC-train 0.982\n",
            "Stats - Epoch: 26 AUC-val 0.617  AUC-train 0.983\n",
            "Stats - Epoch: 27 AUC-val 0.628  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.636  AUC-train 0.981\n",
            "Stats - Epoch: 29 AUC-val 0.608  AUC-train 0.985\n",
            "Stats - Epoch: 30 AUC-val 0.678  AUC-train 0.986\n",
            "Stats - Epoch: 31 AUC-val 0.645  AUC-train 0.987\n",
            "Stats - Epoch: 32 AUC-val 0.641  AUC-train 0.989\n",
            "Stats - Epoch: 33 AUC-val 0.655  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.650  AUC-train 0.989\n",
            "Stats - Epoch: 35 AUC-val 0.691  AUC-train 0.991\n",
            "Stats - Epoch: 36 AUC-val 0.655  AUC-train 0.992\n",
            "Stats - Epoch: 37 AUC-val 0.664  AUC-train 0.993\n",
            "Stats - Epoch: 38 AUC-val 0.676  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.693  AUC-train 0.991\n",
            "Stats - Epoch: 40 AUC-val 0.698  AUC-train 0.994\n",
            "Stats - Epoch: 41 AUC-val 0.673  AUC-train 0.992\n",
            "Stats - Epoch: 42 AUC-val 0.670  AUC-train 0.994\n",
            "Stats - Epoch: 43 AUC-val 0.685  AUC-train 0.995\n",
            "Stats - Epoch: 44 AUC-val 0.664  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.680  AUC-train 0.994\n",
            "Stats - Epoch: 46 AUC-val 0.694  AUC-train 0.995\n",
            "Stats - Epoch: 47 AUC-val 0.652  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.645  AUC-train 0.996\n",
            "Stats - Epoch: 49 AUC-val 0.656  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.666  AUC-train 0.991\n",
            "Stats - Epoch: 51 AUC-val 0.673  AUC-train 0.994\n",
            "Stats - Epoch: 52 AUC-val 0.663  AUC-train 0.992\n",
            "Stats - Epoch: 53 AUC-val 0.660  AUC-train 0.991\n",
            "Stats - Epoch: 54 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 55 AUC-val 0.701  AUC-train 0.992\n",
            "Stats - Epoch: 56 AUC-val 0.682  AUC-train 0.994\n",
            "Stats - Epoch: 57 AUC-val 0.679  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.683  AUC-train 0.993\n",
            "Stats - Epoch: 59 AUC-val 0.677  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.699  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.692  AUC-train 0.995\n",
            "Stats - Epoch: 62 AUC-val 0.703  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.713  AUC-train 0.995\n",
            "Stats - Epoch: 64 AUC-val 0.703  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.728  AUC-train 0.995\n",
            "Stats - Epoch: 66 AUC-val 0.694  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.717  AUC-train 0.992\n",
            "Stats - Epoch: 68 AUC-val 0.699  AUC-train 0.991\n",
            "Stats - Epoch: 69 AUC-val 0.734  AUC-train 0.995\n",
            "Stats - Epoch: 70 AUC-val 0.713  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.705  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.728  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.709  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.710  AUC-train 0.996\n",
            "Stats - Epoch: 75 AUC-val 0.723  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.697  AUC-train 0.993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.700  AUC-train 0.992\n",
            "Stats - Epoch: 78 AUC-val 0.648  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.705  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.684  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.684  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.705  AUC-train 0.991\n",
            "Stats - Epoch: 84 AUC-val 0.702  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.680  AUC-train 0.994\n",
            "Stats - Epoch: 86 AUC-val 0.673  AUC-train 0.992\n",
            "Stats - Epoch: 87 AUC-val 0.688  AUC-train 0.994\n",
            "Stats - Epoch: 88 AUC-val 0.702  AUC-train 0.995\n",
            "Stats - Epoch: 89 AUC-val 0.679  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.721  AUC-train 0.990\n",
            "Stats - Epoch: 91 AUC-val 0.653  AUC-train 0.993\n",
            "Stats - Epoch: 92 AUC-val 0.650  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.696  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.686  AUC-train 0.992\n",
            "Stats - Epoch: 95 AUC-val 0.716  AUC-train 0.992\n",
            "Stats - Epoch: 96 AUC-val 0.726  AUC-train 0.991\n",
            "Stats - Epoch: 97 AUC-val 0.688  AUC-train 0.993\n",
            "Stats - Epoch: 98 AUC-val 0.726  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.701  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.683  AUC-train 0.991\n",
            "Results 100 AUC-val 0.734 0.764 0.623 0.466 0.585 AUC-train 0.995\n",
            "Shapley [0.01235962 0.01416675 0.00769338 0.01743501 0.00556639] [0.004728]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.200182\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.166  AUC-train 0.702\n",
            "Stats - Epoch: 2 AUC-val 0.386  AUC-train 0.860\n",
            "Stats - Epoch: 3 AUC-val 0.416  AUC-train 0.905\n",
            "Stats - Epoch: 4 AUC-val 0.437  AUC-train 0.934\n",
            "Stats - Epoch: 5 AUC-val 0.445  AUC-train 0.950\n",
            "Stats - Epoch: 6 AUC-val 0.460  AUC-train 0.963\n",
            "Stats - Epoch: 7 AUC-val 0.457  AUC-train 0.973\n",
            "Stats - Epoch: 8 AUC-val 0.461  AUC-train 0.979\n",
            "Stats - Epoch: 9 AUC-val 0.484  AUC-train 0.985\n",
            "Stats - Epoch: 10 AUC-val 0.497  AUC-train 0.989\n",
            "Stats - Epoch: 11 AUC-val 0.495  AUC-train 0.991\n",
            "Stats - Epoch: 12 AUC-val 0.495  AUC-train 0.994\n",
            "Stats - Epoch: 13 AUC-val 0.482  AUC-train 0.996\n",
            "Stats - Epoch: 14 AUC-val 0.516  AUC-train 0.997\n",
            "Stats - Epoch: 15 AUC-val 0.540  AUC-train 0.998\n",
            "Stats - Epoch: 16 AUC-val 0.522  AUC-train 0.998\n",
            "Stats - Epoch: 17 AUC-val 0.528  AUC-train 0.998\n",
            "Stats - Epoch: 18 AUC-val 0.549  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.521  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.552  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.550  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.545  AUC-train 1.000\n",
            "Stats - Epoch: 23 AUC-val 0.573  AUC-train 1.000\n",
            "Stats - Epoch: 24 AUC-val 0.539  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.563  AUC-train 1.000\n",
            "Stats - Epoch: 26 AUC-val 0.576  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.583  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.565  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.572  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.588  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.564  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.570  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.566  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.571  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.564  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.563  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.579  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.573  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.590  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.574  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.563  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.564  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.562  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.576  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.565  AUC-train 1.000\n",
            "Stats - Epoch: 46 AUC-val 0.580  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.575  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.549  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 50 AUC-val 0.557  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.532  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.566  AUC-train 0.994\n",
            "Stats - Epoch: 53 AUC-val 0.548  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.566  AUC-train 0.997\n",
            "Stats - Epoch: 55 AUC-val 0.539  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.556  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.555  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.566  AUC-train 1.000\n",
            "Stats - Epoch: 59 AUC-val 0.583  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.583  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.588  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.593  AUC-train 1.000\n",
            "Stats - Epoch: 63 AUC-val 0.593  AUC-train 1.000\n",
            "Stats - Epoch: 64 AUC-val 0.572  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.565  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.593  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.550  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.538  AUC-train 1.000\n",
            "Stats - Epoch: 69 AUC-val 0.561  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.562  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.584  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.570  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.534  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.655  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.568  AUC-train 0.998\n",
            "Stats - Epoch: 76 AUC-val 0.551  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.584  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.570  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.560  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.551  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.551  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.578  AUC-train 1.000\n",
            "Stats - Epoch: 83 AUC-val 0.544  AUC-train 1.000\n",
            "Stats - Epoch: 84 AUC-val 0.560  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.561  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.555  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.547  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.571  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.597  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.565  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.595  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.585  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.582  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.588  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.561  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.580  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.570  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.603  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.569  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.534  AUC-train 0.997\n",
            "Results 100 AUC-val 0.655 0.589 0.470 0.495 0.635 AUC-train 0.995\n",
            "Shapley [0.02135211 0.02391498 0.01377417 0.03962025 0.02392843] [0.00054485]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.185678\n",
            "         Iterations 8\n",
            "[1946, 1999, 2000, 2016]\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.524  AUC-train 0.800\n",
            "Results 1 AUC-val 0.524 0.475 0.515 0.427 0.611 AUC-train 0.800\n",
            "Shapley [0.00371391 0.00175179 0.0152941  0.00740373 0.00314268] [0.0094731]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184775\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.395  AUC-train 0.903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.395 0.280 0.284 0.495 0.733 AUC-train 0.903\n",
            "Shapley [0.01945742 0.00655104 0.00782182 0.0320611  0.01794236] [0.00204186]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187120\n",
            "         Iterations 12\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.476  AUC-train 0.486\n",
            "Stats - Epoch: 2 AUC-val 0.435  AUC-train 0.588\n",
            "Stats - Epoch: 3 AUC-val 0.448  AUC-train 0.637\n",
            "Stats - Epoch: 4 AUC-val 0.455  AUC-train 0.667\n",
            "Stats - Epoch: 5 AUC-val 0.442  AUC-train 0.707\n",
            "Stats - Epoch: 6 AUC-val 0.455  AUC-train 0.719\n",
            "Stats - Epoch: 7 AUC-val 0.446  AUC-train 0.747\n",
            "Stats - Epoch: 8 AUC-val 0.433  AUC-train 0.760\n",
            "Stats - Epoch: 9 AUC-val 0.428  AUC-train 0.764\n",
            "Stats - Epoch: 10 AUC-val 0.443  AUC-train 0.781\n",
            "Stats - Epoch: 11 AUC-val 0.441  AUC-train 0.786\n",
            "Stats - Epoch: 12 AUC-val 0.447  AUC-train 0.801\n",
            "Stats - Epoch: 13 AUC-val 0.450  AUC-train 0.807\n",
            "Stats - Epoch: 14 AUC-val 0.450  AUC-train 0.819\n",
            "Stats - Epoch: 15 AUC-val 0.441  AUC-train 0.817\n",
            "Stats - Epoch: 16 AUC-val 0.461  AUC-train 0.820\n",
            "Stats - Epoch: 17 AUC-val 0.458  AUC-train 0.815\n",
            "Stats - Epoch: 18 AUC-val 0.465  AUC-train 0.827\n",
            "Stats - Epoch: 19 AUC-val 0.465  AUC-train 0.829\n",
            "Stats - Epoch: 20 AUC-val 0.462  AUC-train 0.832\n",
            "Stats - Epoch: 21 AUC-val 0.474  AUC-train 0.838\n",
            "Stats - Epoch: 22 AUC-val 0.472  AUC-train 0.837\n",
            "Stats - Epoch: 23 AUC-val 0.464  AUC-train 0.845\n",
            "Stats - Epoch: 24 AUC-val 0.469  AUC-train 0.847\n",
            "Stats - Epoch: 25 AUC-val 0.479  AUC-train 0.847\n",
            "Stats - Epoch: 26 AUC-val 0.478  AUC-train 0.844\n",
            "Stats - Epoch: 27 AUC-val 0.475  AUC-train 0.849\n",
            "Stats - Epoch: 28 AUC-val 0.476  AUC-train 0.851\n",
            "Stats - Epoch: 29 AUC-val 0.494  AUC-train 0.850\n",
            "Stats - Epoch: 30 AUC-val 0.481  AUC-train 0.852\n",
            "Stats - Epoch: 31 AUC-val 0.481  AUC-train 0.856\n",
            "Stats - Epoch: 32 AUC-val 0.490  AUC-train 0.855\n",
            "Stats - Epoch: 33 AUC-val 0.481  AUC-train 0.855\n",
            "Stats - Epoch: 34 AUC-val 0.493  AUC-train 0.857\n",
            "Stats - Epoch: 35 AUC-val 0.486  AUC-train 0.858\n",
            "Stats - Epoch: 36 AUC-val 0.484  AUC-train 0.855\n",
            "Stats - Epoch: 37 AUC-val 0.494  AUC-train 0.854\n",
            "Stats - Epoch: 38 AUC-val 0.500  AUC-train 0.856\n",
            "Stats - Epoch: 39 AUC-val 0.490  AUC-train 0.858\n",
            "Stats - Epoch: 40 AUC-val 0.504  AUC-train 0.864\n",
            "Stats - Epoch: 41 AUC-val 0.496  AUC-train 0.857\n",
            "Stats - Epoch: 42 AUC-val 0.484  AUC-train 0.849\n",
            "Stats - Epoch: 43 AUC-val 0.495  AUC-train 0.859\n",
            "Stats - Epoch: 44 AUC-val 0.498  AUC-train 0.859\n",
            "Stats - Epoch: 45 AUC-val 0.503  AUC-train 0.861\n",
            "Stats - Epoch: 46 AUC-val 0.498  AUC-train 0.863\n",
            "Stats - Epoch: 47 AUC-val 0.491  AUC-train 0.859\n",
            "Stats - Epoch: 48 AUC-val 0.495  AUC-train 0.861\n",
            "Stats - Epoch: 49 AUC-val 0.495  AUC-train 0.865\n",
            "Stats - Epoch: 50 AUC-val 0.501  AUC-train 0.861\n",
            "Stats - Epoch: 51 AUC-val 0.497  AUC-train 0.853\n",
            "Stats - Epoch: 52 AUC-val 0.495  AUC-train 0.860\n",
            "Stats - Epoch: 53 AUC-val 0.492  AUC-train 0.862\n",
            "Stats - Epoch: 54 AUC-val 0.503  AUC-train 0.863\n",
            "Stats - Epoch: 55 AUC-val 0.500  AUC-train 0.864\n",
            "Stats - Epoch: 56 AUC-val 0.499  AUC-train 0.861\n",
            "Stats - Epoch: 57 AUC-val 0.495  AUC-train 0.863\n",
            "Stats - Epoch: 58 AUC-val 0.502  AUC-train 0.867\n",
            "Stats - Epoch: 59 AUC-val 0.495  AUC-train 0.864\n",
            "Stats - Epoch: 60 AUC-val 0.506  AUC-train 0.864\n",
            "Stats - Epoch: 61 AUC-val 0.506  AUC-train 0.864\n",
            "Stats - Epoch: 62 AUC-val 0.499  AUC-train 0.864\n",
            "Stats - Epoch: 63 AUC-val 0.512  AUC-train 0.865\n",
            "Stats - Epoch: 64 AUC-val 0.499  AUC-train 0.863\n",
            "Stats - Epoch: 65 AUC-val 0.501  AUC-train 0.866\n",
            "Stats - Epoch: 66 AUC-val 0.505  AUC-train 0.867\n",
            "Stats - Epoch: 67 AUC-val 0.509  AUC-train 0.862\n",
            "Stats - Epoch: 68 AUC-val 0.495  AUC-train 0.865\n",
            "Stats - Epoch: 69 AUC-val 0.505  AUC-train 0.866\n",
            "Stats - Epoch: 70 AUC-val 0.503  AUC-train 0.863\n",
            "Stats - Epoch: 71 AUC-val 0.512  AUC-train 0.865\n",
            "Stats - Epoch: 72 AUC-val 0.497  AUC-train 0.864\n",
            "Stats - Epoch: 73 AUC-val 0.498  AUC-train 0.865\n",
            "Stats - Epoch: 74 AUC-val 0.505  AUC-train 0.862\n",
            "Stats - Epoch: 75 AUC-val 0.498  AUC-train 0.864\n",
            "Stats - Epoch: 76 AUC-val 0.503  AUC-train 0.864\n",
            "Stats - Epoch: 77 AUC-val 0.512  AUC-train 0.868\n",
            "Stats - Epoch: 78 AUC-val 0.505  AUC-train 0.865\n",
            "Stats - Epoch: 79 AUC-val 0.502  AUC-train 0.865\n",
            "Stats - Epoch: 80 AUC-val 0.512  AUC-train 0.868\n",
            "Stats - Epoch: 81 AUC-val 0.499  AUC-train 0.867\n",
            "Stats - Epoch: 82 AUC-val 0.512  AUC-train 0.867\n",
            "Stats - Epoch: 83 AUC-val 0.502  AUC-train 0.864\n",
            "Stats - Epoch: 84 AUC-val 0.503  AUC-train 0.866\n",
            "Stats - Epoch: 85 AUC-val 0.501  AUC-train 0.863\n",
            "Stats - Epoch: 86 AUC-val 0.500  AUC-train 0.870\n",
            "Stats - Epoch: 87 AUC-val 0.503  AUC-train 0.863\n",
            "Stats - Epoch: 88 AUC-val 0.505  AUC-train 0.867\n",
            "Stats - Epoch: 89 AUC-val 0.498  AUC-train 0.862\n",
            "Stats - Epoch: 90 AUC-val 0.498  AUC-train 0.866\n",
            "Stats - Epoch: 91 AUC-val 0.503  AUC-train 0.865\n",
            "Stats - Epoch: 92 AUC-val 0.506  AUC-train 0.865\n",
            "Stats - Epoch: 93 AUC-val 0.501  AUC-train 0.864\n",
            "Stats - Epoch: 94 AUC-val 0.497  AUC-train 0.860\n",
            "Stats - Epoch: 95 AUC-val 0.500  AUC-train 0.863\n",
            "Stats - Epoch: 96 AUC-val 0.503  AUC-train 0.864\n",
            "Stats - Epoch: 97 AUC-val 0.506  AUC-train 0.864\n",
            "Stats - Epoch: 98 AUC-val 0.503  AUC-train 0.866\n",
            "Stats - Epoch: 99 AUC-val 0.504  AUC-train 0.866\n",
            "Stats - Epoch: 100 AUC-val 0.498  AUC-train 0.863\n",
            "Results 100 AUC-val 0.512 0.508 0.560 0.479 0.628 AUC-train 0.868\n",
            "Shapley [0.00468703 0.00387599 0.01659773 0.00711582 0.00465203] [0.01307539]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187508\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.409  AUC-train 0.599\n",
            "Stats - Epoch: 2 AUC-val 0.402  AUC-train 0.769\n",
            "Stats - Epoch: 3 AUC-val 0.361  AUC-train 0.851\n",
            "Stats - Epoch: 4 AUC-val 0.351  AUC-train 0.901\n",
            "Stats - Epoch: 5 AUC-val 0.350  AUC-train 0.928\n",
            "Stats - Epoch: 6 AUC-val 0.372  AUC-train 0.936\n",
            "Stats - Epoch: 7 AUC-val 0.389  AUC-train 0.951\n",
            "Stats - Epoch: 8 AUC-val 0.395  AUC-train 0.954\n",
            "Stats - Epoch: 9 AUC-val 0.409  AUC-train 0.958\n",
            "Stats - Epoch: 10 AUC-val 0.416  AUC-train 0.958\n",
            "Stats - Epoch: 11 AUC-val 0.418  AUC-train 0.956\n",
            "Stats - Epoch: 12 AUC-val 0.419  AUC-train 0.957\n",
            "Stats - Epoch: 13 AUC-val 0.443  AUC-train 0.956\n",
            "Stats - Epoch: 14 AUC-val 0.436  AUC-train 0.958\n",
            "Stats - Epoch: 15 AUC-val 0.445  AUC-train 0.957\n",
            "Stats - Epoch: 16 AUC-val 0.448  AUC-train 0.954\n",
            "Stats - Epoch: 17 AUC-val 0.450  AUC-train 0.951\n",
            "Stats - Epoch: 18 AUC-val 0.442  AUC-train 0.950\n",
            "Stats - Epoch: 19 AUC-val 0.448  AUC-train 0.952\n",
            "Stats - Epoch: 20 AUC-val 0.451  AUC-train 0.955\n",
            "Stats - Epoch: 21 AUC-val 0.462  AUC-train 0.955\n",
            "Stats - Epoch: 22 AUC-val 0.436  AUC-train 0.956\n",
            "Stats - Epoch: 23 AUC-val 0.452  AUC-train 0.947\n",
            "Stats - Epoch: 24 AUC-val 0.453  AUC-train 0.945\n",
            "Stats - Epoch: 25 AUC-val 0.455  AUC-train 0.953\n",
            "Stats - Epoch: 26 AUC-val 0.446  AUC-train 0.947\n",
            "Stats - Epoch: 27 AUC-val 0.451  AUC-train 0.948\n",
            "Stats - Epoch: 28 AUC-val 0.454  AUC-train 0.947\n",
            "Stats - Epoch: 29 AUC-val 0.450  AUC-train 0.949\n",
            "Stats - Epoch: 30 AUC-val 0.452  AUC-train 0.950\n",
            "Stats - Epoch: 31 AUC-val 0.493  AUC-train 0.946\n",
            "Stats - Epoch: 32 AUC-val 0.457  AUC-train 0.950\n",
            "Stats - Epoch: 33 AUC-val 0.468  AUC-train 0.943\n",
            "Stats - Epoch: 34 AUC-val 0.447  AUC-train 0.941\n",
            "Stats - Epoch: 35 AUC-val 0.455  AUC-train 0.943\n",
            "Stats - Epoch: 36 AUC-val 0.469  AUC-train 0.942\n",
            "Stats - Epoch: 37 AUC-val 0.444  AUC-train 0.942\n",
            "Stats - Epoch: 38 AUC-val 0.452  AUC-train 0.941\n",
            "Stats - Epoch: 39 AUC-val 0.469  AUC-train 0.939\n",
            "Stats - Epoch: 40 AUC-val 0.459  AUC-train 0.930\n",
            "Stats - Epoch: 41 AUC-val 0.470  AUC-train 0.928\n",
            "Stats - Epoch: 42 AUC-val 0.436  AUC-train 0.929\n",
            "Stats - Epoch: 43 AUC-val 0.449  AUC-train 0.931\n",
            "Stats - Epoch: 44 AUC-val 0.434  AUC-train 0.930\n",
            "Stats - Epoch: 45 AUC-val 0.440  AUC-train 0.933\n",
            "Stats - Epoch: 46 AUC-val 0.452  AUC-train 0.933\n",
            "Stats - Epoch: 47 AUC-val 0.441  AUC-train 0.937\n",
            "Stats - Epoch: 48 AUC-val 0.457  AUC-train 0.934\n",
            "Stats - Epoch: 49 AUC-val 0.461  AUC-train 0.934\n",
            "Stats - Epoch: 50 AUC-val 0.426  AUC-train 0.926\n",
            "Stats - Epoch: 51 AUC-val 0.451  AUC-train 0.921\n",
            "Stats - Epoch: 52 AUC-val 0.428  AUC-train 0.932\n",
            "Stats - Epoch: 53 AUC-val 0.440  AUC-train 0.932\n",
            "Stats - Epoch: 54 AUC-val 0.429  AUC-train 0.930\n",
            "Stats - Epoch: 55 AUC-val 0.462  AUC-train 0.923\n",
            "Stats - Epoch: 56 AUC-val 0.451  AUC-train 0.924\n",
            "Stats - Epoch: 57 AUC-val 0.456  AUC-train 0.924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.452  AUC-train 0.928\n",
            "Stats - Epoch: 59 AUC-val 0.454  AUC-train 0.926\n",
            "Stats - Epoch: 60 AUC-val 0.459  AUC-train 0.927\n",
            "Stats - Epoch: 61 AUC-val 0.442  AUC-train 0.924\n",
            "Stats - Epoch: 62 AUC-val 0.457  AUC-train 0.927\n",
            "Stats - Epoch: 63 AUC-val 0.459  AUC-train 0.926\n",
            "Stats - Epoch: 64 AUC-val 0.427  AUC-train 0.925\n",
            "Stats - Epoch: 65 AUC-val 0.446  AUC-train 0.930\n",
            "Stats - Epoch: 66 AUC-val 0.441  AUC-train 0.929\n",
            "Stats - Epoch: 67 AUC-val 0.429  AUC-train 0.927\n",
            "Stats - Epoch: 68 AUC-val 0.442  AUC-train 0.927\n",
            "Stats - Epoch: 69 AUC-val 0.453  AUC-train 0.926\n",
            "Stats - Epoch: 70 AUC-val 0.450  AUC-train 0.932\n",
            "Stats - Epoch: 71 AUC-val 0.446  AUC-train 0.925\n",
            "Stats - Epoch: 72 AUC-val 0.455  AUC-train 0.924\n",
            "Stats - Epoch: 73 AUC-val 0.449  AUC-train 0.919\n",
            "Stats - Epoch: 74 AUC-val 0.457  AUC-train 0.915\n",
            "Stats - Epoch: 75 AUC-val 0.431  AUC-train 0.917\n",
            "Stats - Epoch: 76 AUC-val 0.421  AUC-train 0.912\n",
            "Stats - Epoch: 77 AUC-val 0.431  AUC-train 0.913\n",
            "Stats - Epoch: 78 AUC-val 0.427  AUC-train 0.911\n",
            "Stats - Epoch: 79 AUC-val 0.423  AUC-train 0.917\n",
            "Stats - Epoch: 80 AUC-val 0.420  AUC-train 0.923\n",
            "Stats - Epoch: 81 AUC-val 0.423  AUC-train 0.919\n",
            "Stats - Epoch: 82 AUC-val 0.428  AUC-train 0.914\n",
            "Stats - Epoch: 83 AUC-val 0.454  AUC-train 0.915\n",
            "Stats - Epoch: 84 AUC-val 0.419  AUC-train 0.915\n",
            "Stats - Epoch: 85 AUC-val 0.420  AUC-train 0.914\n",
            "Stats - Epoch: 86 AUC-val 0.445  AUC-train 0.916\n",
            "Stats - Epoch: 87 AUC-val 0.433  AUC-train 0.912\n",
            "Stats - Epoch: 88 AUC-val 0.406  AUC-train 0.917\n",
            "Stats - Epoch: 89 AUC-val 0.435  AUC-train 0.913\n",
            "Stats - Epoch: 90 AUC-val 0.419  AUC-train 0.914\n",
            "Stats - Epoch: 91 AUC-val 0.407  AUC-train 0.913\n",
            "Stats - Epoch: 92 AUC-val 0.419  AUC-train 0.915\n",
            "Stats - Epoch: 93 AUC-val 0.434  AUC-train 0.915\n",
            "Stats - Epoch: 94 AUC-val 0.424  AUC-train 0.911\n",
            "Stats - Epoch: 95 AUC-val 0.448  AUC-train 0.907\n",
            "Stats - Epoch: 96 AUC-val 0.427  AUC-train 0.910\n",
            "Stats - Epoch: 97 AUC-val 0.437  AUC-train 0.916\n",
            "Stats - Epoch: 98 AUC-val 0.421  AUC-train 0.907\n",
            "Stats - Epoch: 99 AUC-val 0.440  AUC-train 0.907\n",
            "Stats - Epoch: 100 AUC-val 0.436  AUC-train 0.914\n",
            "Results 100 AUC-val 0.493 0.327 0.241 0.122 0.486 AUC-train 0.946\n",
            "Shapley [0.01942833 0.00684066 0.0103029  0.03611569 0.01534893] [0.03528608]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188982\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.249  AUC-train 0.610\n",
            "Stats - Epoch: 2 AUC-val 0.242  AUC-train 0.680\n",
            "Stats - Epoch: 3 AUC-val 0.283  AUC-train 0.734\n",
            "Stats - Epoch: 4 AUC-val 0.299  AUC-train 0.775\n",
            "Stats - Epoch: 5 AUC-val 0.355  AUC-train 0.808\n",
            "Stats - Epoch: 6 AUC-val 0.409  AUC-train 0.828\n",
            "Stats - Epoch: 7 AUC-val 0.465  AUC-train 0.842\n",
            "Stats - Epoch: 8 AUC-val 0.451  AUC-train 0.849\n",
            "Stats - Epoch: 9 AUC-val 0.474  AUC-train 0.855\n",
            "Stats - Epoch: 10 AUC-val 0.506  AUC-train 0.851\n",
            "Stats - Epoch: 11 AUC-val 0.525  AUC-train 0.856\n",
            "Stats - Epoch: 12 AUC-val 0.525  AUC-train 0.860\n",
            "Stats - Epoch: 13 AUC-val 0.550  AUC-train 0.865\n",
            "Stats - Epoch: 14 AUC-val 0.531  AUC-train 0.868\n",
            "Stats - Epoch: 15 AUC-val 0.576  AUC-train 0.867\n",
            "Stats - Epoch: 16 AUC-val 0.568  AUC-train 0.863\n",
            "Stats - Epoch: 17 AUC-val 0.539  AUC-train 0.868\n",
            "Stats - Epoch: 18 AUC-val 0.515  AUC-train 0.876\n",
            "Stats - Epoch: 19 AUC-val 0.557  AUC-train 0.870\n",
            "Stats - Epoch: 20 AUC-val 0.568  AUC-train 0.872\n",
            "Stats - Epoch: 21 AUC-val 0.572  AUC-train 0.875\n",
            "Stats - Epoch: 22 AUC-val 0.563  AUC-train 0.875\n",
            "Stats - Epoch: 23 AUC-val 0.538  AUC-train 0.878\n",
            "Stats - Epoch: 24 AUC-val 0.543  AUC-train 0.883\n",
            "Stats - Epoch: 25 AUC-val 0.535  AUC-train 0.882\n",
            "Stats - Epoch: 26 AUC-val 0.562  AUC-train 0.884\n",
            "Stats - Epoch: 27 AUC-val 0.559  AUC-train 0.888\n",
            "Stats - Epoch: 28 AUC-val 0.581  AUC-train 0.891\n",
            "Stats - Epoch: 29 AUC-val 0.597  AUC-train 0.885\n",
            "Stats - Epoch: 30 AUC-val 0.560  AUC-train 0.885\n",
            "Stats - Epoch: 31 AUC-val 0.580  AUC-train 0.888\n",
            "Stats - Epoch: 32 AUC-val 0.595  AUC-train 0.888\n",
            "Stats - Epoch: 33 AUC-val 0.569  AUC-train 0.888\n",
            "Stats - Epoch: 34 AUC-val 0.549  AUC-train 0.898\n",
            "Stats - Epoch: 35 AUC-val 0.567  AUC-train 0.891\n",
            "Stats - Epoch: 36 AUC-val 0.579  AUC-train 0.896\n",
            "Stats - Epoch: 37 AUC-val 0.570  AUC-train 0.896\n",
            "Stats - Epoch: 38 AUC-val 0.596  AUC-train 0.901\n",
            "Stats - Epoch: 39 AUC-val 0.581  AUC-train 0.898\n",
            "Stats - Epoch: 40 AUC-val 0.584  AUC-train 0.899\n",
            "Stats - Epoch: 41 AUC-val 0.590  AUC-train 0.898\n",
            "Stats - Epoch: 42 AUC-val 0.611  AUC-train 0.900\n",
            "Stats - Epoch: 43 AUC-val 0.598  AUC-train 0.897\n",
            "Stats - Epoch: 44 AUC-val 0.569  AUC-train 0.903\n",
            "Stats - Epoch: 45 AUC-val 0.575  AUC-train 0.906\n",
            "Stats - Epoch: 46 AUC-val 0.591  AUC-train 0.905\n",
            "Stats - Epoch: 47 AUC-val 0.584  AUC-train 0.900\n",
            "Stats - Epoch: 48 AUC-val 0.627  AUC-train 0.904\n",
            "Stats - Epoch: 49 AUC-val 0.589  AUC-train 0.903\n",
            "Stats - Epoch: 50 AUC-val 0.565  AUC-train 0.903\n",
            "Stats - Epoch: 51 AUC-val 0.586  AUC-train 0.904\n",
            "Stats - Epoch: 52 AUC-val 0.593  AUC-train 0.910\n",
            "Stats - Epoch: 53 AUC-val 0.593  AUC-train 0.909\n",
            "Stats - Epoch: 54 AUC-val 0.590  AUC-train 0.903\n",
            "Stats - Epoch: 55 AUC-val 0.569  AUC-train 0.907\n",
            "Stats - Epoch: 56 AUC-val 0.581  AUC-train 0.910\n",
            "Stats - Epoch: 57 AUC-val 0.644  AUC-train 0.911\n",
            "Stats - Epoch: 58 AUC-val 0.628  AUC-train 0.910\n",
            "Stats - Epoch: 59 AUC-val 0.609  AUC-train 0.913\n",
            "Stats - Epoch: 60 AUC-val 0.597  AUC-train 0.914\n",
            "Stats - Epoch: 61 AUC-val 0.609  AUC-train 0.919\n",
            "Stats - Epoch: 62 AUC-val 0.636  AUC-train 0.913\n",
            "Stats - Epoch: 63 AUC-val 0.595  AUC-train 0.917\n",
            "Stats - Epoch: 64 AUC-val 0.592  AUC-train 0.921\n",
            "Stats - Epoch: 65 AUC-val 0.603  AUC-train 0.919\n",
            "Stats - Epoch: 66 AUC-val 0.607  AUC-train 0.918\n",
            "Stats - Epoch: 67 AUC-val 0.614  AUC-train 0.919\n",
            "Stats - Epoch: 68 AUC-val 0.588  AUC-train 0.922\n",
            "Stats - Epoch: 69 AUC-val 0.572  AUC-train 0.918\n",
            "Stats - Epoch: 70 AUC-val 0.613  AUC-train 0.921\n",
            "Stats - Epoch: 71 AUC-val 0.601  AUC-train 0.916\n",
            "Stats - Epoch: 72 AUC-val 0.652  AUC-train 0.919\n",
            "Stats - Epoch: 73 AUC-val 0.629  AUC-train 0.916\n",
            "Stats - Epoch: 74 AUC-val 0.630  AUC-train 0.914\n",
            "Stats - Epoch: 75 AUC-val 0.641  AUC-train 0.917\n",
            "Stats - Epoch: 76 AUC-val 0.628  AUC-train 0.916\n",
            "Stats - Epoch: 77 AUC-val 0.631  AUC-train 0.915\n",
            "Stats - Epoch: 78 AUC-val 0.604  AUC-train 0.913\n",
            "Stats - Epoch: 79 AUC-val 0.592  AUC-train 0.918\n",
            "Stats - Epoch: 80 AUC-val 0.609  AUC-train 0.916\n",
            "Stats - Epoch: 81 AUC-val 0.596  AUC-train 0.916\n",
            "Stats - Epoch: 82 AUC-val 0.602  AUC-train 0.917\n",
            "Stats - Epoch: 83 AUC-val 0.614  AUC-train 0.919\n",
            "Stats - Epoch: 84 AUC-val 0.600  AUC-train 0.914\n",
            "Stats - Epoch: 85 AUC-val 0.607  AUC-train 0.917\n",
            "Stats - Epoch: 86 AUC-val 0.602  AUC-train 0.920\n",
            "Stats - Epoch: 87 AUC-val 0.580  AUC-train 0.920\n",
            "Stats - Epoch: 88 AUC-val 0.622  AUC-train 0.922\n",
            "Stats - Epoch: 89 AUC-val 0.593  AUC-train 0.919\n",
            "Stats - Epoch: 90 AUC-val 0.610  AUC-train 0.924\n",
            "Stats - Epoch: 91 AUC-val 0.579  AUC-train 0.924\n",
            "Stats - Epoch: 92 AUC-val 0.582  AUC-train 0.925\n",
            "Stats - Epoch: 93 AUC-val 0.605  AUC-train 0.924\n",
            "Stats - Epoch: 94 AUC-val 0.599  AUC-train 0.926\n",
            "Stats - Epoch: 95 AUC-val 0.596  AUC-train 0.931\n",
            "Stats - Epoch: 96 AUC-val 0.589  AUC-train 0.930\n",
            "Stats - Epoch: 97 AUC-val 0.614  AUC-train 0.928\n",
            "Stats - Epoch: 98 AUC-val 0.603  AUC-train 0.927\n",
            "Stats - Epoch: 99 AUC-val 0.590  AUC-train 0.923\n",
            "Stats - Epoch: 100 AUC-val 0.606  AUC-train 0.922\n",
            "Results 100 AUC-val 0.652 0.627 0.571 0.493 0.574 AUC-train 0.919\n",
            "Shapley [0.013694   0.00839976 0.01786664 0.01170705 0.00577158] [0.00475249]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.191774\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.410  AUC-train 0.635\n",
            "Stats - Epoch: 2 AUC-val 0.544  AUC-train 0.782\n",
            "Stats - Epoch: 3 AUC-val 0.592  AUC-train 0.826\n",
            "Stats - Epoch: 4 AUC-val 0.624  AUC-train 0.848\n",
            "Stats - Epoch: 5 AUC-val 0.640  AUC-train 0.862\n",
            "Stats - Epoch: 6 AUC-val 0.643  AUC-train 0.877\n",
            "Stats - Epoch: 7 AUC-val 0.687  AUC-train 0.889\n",
            "Stats - Epoch: 8 AUC-val 0.680  AUC-train 0.902\n",
            "Stats - Epoch: 9 AUC-val 0.689  AUC-train 0.910\n",
            "Stats - Epoch: 10 AUC-val 0.684  AUC-train 0.916\n",
            "Stats - Epoch: 11 AUC-val 0.686  AUC-train 0.925\n",
            "Stats - Epoch: 12 AUC-val 0.694  AUC-train 0.934\n",
            "Stats - Epoch: 13 AUC-val 0.693  AUC-train 0.936\n",
            "Stats - Epoch: 14 AUC-val 0.700  AUC-train 0.943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.697  AUC-train 0.950\n",
            "Stats - Epoch: 16 AUC-val 0.705  AUC-train 0.949\n",
            "Stats - Epoch: 17 AUC-val 0.719  AUC-train 0.955\n",
            "Stats - Epoch: 18 AUC-val 0.696  AUC-train 0.958\n",
            "Stats - Epoch: 19 AUC-val 0.693  AUC-train 0.962\n",
            "Stats - Epoch: 20 AUC-val 0.696  AUC-train 0.967\n",
            "Stats - Epoch: 21 AUC-val 0.703  AUC-train 0.968\n",
            "Stats - Epoch: 22 AUC-val 0.671  AUC-train 0.970\n",
            "Stats - Epoch: 23 AUC-val 0.693  AUC-train 0.973\n",
            "Stats - Epoch: 24 AUC-val 0.705  AUC-train 0.974\n",
            "Stats - Epoch: 25 AUC-val 0.656  AUC-train 0.974\n",
            "Stats - Epoch: 26 AUC-val 0.726  AUC-train 0.976\n",
            "Stats - Epoch: 27 AUC-val 0.682  AUC-train 0.974\n",
            "Stats - Epoch: 28 AUC-val 0.697  AUC-train 0.974\n",
            "Stats - Epoch: 29 AUC-val 0.726  AUC-train 0.979\n",
            "Stats - Epoch: 30 AUC-val 0.691  AUC-train 0.980\n",
            "Stats - Epoch: 31 AUC-val 0.705  AUC-train 0.982\n",
            "Stats - Epoch: 32 AUC-val 0.721  AUC-train 0.984\n",
            "Stats - Epoch: 33 AUC-val 0.698  AUC-train 0.984\n",
            "Stats - Epoch: 34 AUC-val 0.691  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.685  AUC-train 0.988\n",
            "Stats - Epoch: 36 AUC-val 0.672  AUC-train 0.988\n",
            "Stats - Epoch: 37 AUC-val 0.698  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.698  AUC-train 0.986\n",
            "Stats - Epoch: 39 AUC-val 0.702  AUC-train 0.988\n",
            "Stats - Epoch: 40 AUC-val 0.692  AUC-train 0.981\n",
            "Stats - Epoch: 41 AUC-val 0.684  AUC-train 0.984\n",
            "Stats - Epoch: 42 AUC-val 0.659  AUC-train 0.988\n",
            "Stats - Epoch: 43 AUC-val 0.660  AUC-train 0.986\n",
            "Stats - Epoch: 44 AUC-val 0.682  AUC-train 0.988\n",
            "Stats - Epoch: 45 AUC-val 0.690  AUC-train 0.988\n",
            "Stats - Epoch: 46 AUC-val 0.667  AUC-train 0.989\n",
            "Stats - Epoch: 47 AUC-val 0.674  AUC-train 0.989\n",
            "Stats - Epoch: 48 AUC-val 0.685  AUC-train 0.989\n",
            "Stats - Epoch: 49 AUC-val 0.687  AUC-train 0.991\n",
            "Stats - Epoch: 50 AUC-val 0.690  AUC-train 0.988\n",
            "Stats - Epoch: 51 AUC-val 0.701  AUC-train 0.988\n",
            "Stats - Epoch: 52 AUC-val 0.719  AUC-train 0.988\n",
            "Stats - Epoch: 53 AUC-val 0.700  AUC-train 0.990\n",
            "Stats - Epoch: 54 AUC-val 0.684  AUC-train 0.990\n",
            "Stats - Epoch: 55 AUC-val 0.693  AUC-train 0.988\n",
            "Stats - Epoch: 56 AUC-val 0.690  AUC-train 0.989\n",
            "Stats - Epoch: 57 AUC-val 0.688  AUC-train 0.990\n",
            "Stats - Epoch: 58 AUC-val 0.683  AUC-train 0.993\n",
            "Stats - Epoch: 59 AUC-val 0.655  AUC-train 0.991\n",
            "Stats - Epoch: 60 AUC-val 0.686  AUC-train 0.991\n",
            "Stats - Epoch: 61 AUC-val 0.724  AUC-train 0.990\n",
            "Stats - Epoch: 62 AUC-val 0.710  AUC-train 0.989\n",
            "Stats - Epoch: 63 AUC-val 0.670  AUC-train 0.991\n",
            "Stats - Epoch: 64 AUC-val 0.684  AUC-train 0.992\n",
            "Stats - Epoch: 65 AUC-val 0.707  AUC-train 0.993\n",
            "Stats - Epoch: 66 AUC-val 0.674  AUC-train 0.989\n",
            "Stats - Epoch: 67 AUC-val 0.683  AUC-train 0.992\n",
            "Stats - Epoch: 68 AUC-val 0.717  AUC-train 0.994\n",
            "Stats - Epoch: 69 AUC-val 0.683  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.677  AUC-train 0.992\n",
            "Stats - Epoch: 71 AUC-val 0.663  AUC-train 0.991\n",
            "Stats - Epoch: 72 AUC-val 0.622  AUC-train 0.991\n",
            "Stats - Epoch: 73 AUC-val 0.668  AUC-train 0.987\n",
            "Stats - Epoch: 74 AUC-val 0.664  AUC-train 0.993\n",
            "Stats - Epoch: 75 AUC-val 0.676  AUC-train 0.989\n",
            "Stats - Epoch: 76 AUC-val 0.677  AUC-train 0.992\n",
            "Stats - Epoch: 77 AUC-val 0.693  AUC-train 0.992\n",
            "Stats - Epoch: 78 AUC-val 0.652  AUC-train 0.993\n",
            "Stats - Epoch: 79 AUC-val 0.663  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.651  AUC-train 0.991\n",
            "Stats - Epoch: 81 AUC-val 0.697  AUC-train 0.991\n",
            "Stats - Epoch: 82 AUC-val 0.702  AUC-train 0.992\n",
            "Stats - Epoch: 83 AUC-val 0.678  AUC-train 0.992\n",
            "Stats - Epoch: 84 AUC-val 0.688  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.684  AUC-train 0.992\n",
            "Stats - Epoch: 86 AUC-val 0.676  AUC-train 0.993\n",
            "Stats - Epoch: 87 AUC-val 0.670  AUC-train 0.994\n",
            "Stats - Epoch: 88 AUC-val 0.671  AUC-train 0.995\n",
            "Stats - Epoch: 89 AUC-val 0.650  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.684  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.663  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.686  AUC-train 0.992\n",
            "Stats - Epoch: 93 AUC-val 0.663  AUC-train 0.993\n",
            "Stats - Epoch: 94 AUC-val 0.687  AUC-train 0.994\n",
            "Stats - Epoch: 95 AUC-val 0.679  AUC-train 0.991\n",
            "Stats - Epoch: 96 AUC-val 0.718  AUC-train 0.996\n",
            "Stats - Epoch: 97 AUC-val 0.678  AUC-train 0.994\n",
            "Stats - Epoch: 98 AUC-val 0.714  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.678  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.691  AUC-train 0.996\n",
            "Results 100 AUC-val 0.726 0.606 0.439 0.383 0.527 AUC-train 0.979\n",
            "Shapley [0.01483962 0.00831864 0.0142812  0.02437301 0.01266624] [0.00629052]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.193801\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.529  AUC-train 0.546\n",
            "Stats - Epoch: 2 AUC-val 0.541  AUC-train 0.718\n",
            "Stats - Epoch: 3 AUC-val 0.555  AUC-train 0.796\n",
            "Stats - Epoch: 4 AUC-val 0.590  AUC-train 0.825\n",
            "Stats - Epoch: 5 AUC-val 0.591  AUC-train 0.844\n",
            "Stats - Epoch: 6 AUC-val 0.575  AUC-train 0.861\n",
            "Stats - Epoch: 7 AUC-val 0.543  AUC-train 0.869\n",
            "Stats - Epoch: 8 AUC-val 0.534  AUC-train 0.885\n",
            "Stats - Epoch: 9 AUC-val 0.528  AUC-train 0.892\n",
            "Stats - Epoch: 10 AUC-val 0.544  AUC-train 0.912\n",
            "Stats - Epoch: 11 AUC-val 0.519  AUC-train 0.912\n",
            "Stats - Epoch: 12 AUC-val 0.525  AUC-train 0.922\n",
            "Stats - Epoch: 13 AUC-val 0.547  AUC-train 0.927\n",
            "Stats - Epoch: 14 AUC-val 0.536  AUC-train 0.937\n",
            "Stats - Epoch: 15 AUC-val 0.526  AUC-train 0.938\n",
            "Stats - Epoch: 16 AUC-val 0.494  AUC-train 0.941\n",
            "Stats - Epoch: 17 AUC-val 0.528  AUC-train 0.951\n",
            "Stats - Epoch: 18 AUC-val 0.544  AUC-train 0.954\n",
            "Stats - Epoch: 19 AUC-val 0.520  AUC-train 0.955\n",
            "Stats - Epoch: 20 AUC-val 0.510  AUC-train 0.960\n",
            "Stats - Epoch: 21 AUC-val 0.488  AUC-train 0.962\n",
            "Stats - Epoch: 22 AUC-val 0.508  AUC-train 0.964\n",
            "Stats - Epoch: 23 AUC-val 0.466  AUC-train 0.965\n",
            "Stats - Epoch: 24 AUC-val 0.503  AUC-train 0.966\n",
            "Stats - Epoch: 25 AUC-val 0.501  AUC-train 0.970\n",
            "Stats - Epoch: 26 AUC-val 0.511  AUC-train 0.971\n",
            "Stats - Epoch: 27 AUC-val 0.509  AUC-train 0.974\n",
            "Stats - Epoch: 28 AUC-val 0.510  AUC-train 0.968\n",
            "Stats - Epoch: 29 AUC-val 0.500  AUC-train 0.972\n",
            "Stats - Epoch: 30 AUC-val 0.498  AUC-train 0.973\n",
            "Stats - Epoch: 31 AUC-val 0.545  AUC-train 0.975\n",
            "Stats - Epoch: 32 AUC-val 0.541  AUC-train 0.976\n",
            "Stats - Epoch: 33 AUC-val 0.496  AUC-train 0.979\n",
            "Stats - Epoch: 34 AUC-val 0.500  AUC-train 0.981\n",
            "Stats - Epoch: 35 AUC-val 0.516  AUC-train 0.982\n",
            "Stats - Epoch: 36 AUC-val 0.516  AUC-train 0.981\n",
            "Stats - Epoch: 37 AUC-val 0.535  AUC-train 0.981\n",
            "Stats - Epoch: 38 AUC-val 0.585  AUC-train 0.985\n",
            "Stats - Epoch: 39 AUC-val 0.579  AUC-train 0.985\n",
            "Stats - Epoch: 40 AUC-val 0.576  AUC-train 0.984\n",
            "Stats - Epoch: 41 AUC-val 0.590  AUC-train 0.983\n",
            "Stats - Epoch: 42 AUC-val 0.527  AUC-train 0.986\n",
            "Stats - Epoch: 43 AUC-val 0.617  AUC-train 0.983\n",
            "Stats - Epoch: 44 AUC-val 0.568  AUC-train 0.987\n",
            "Stats - Epoch: 45 AUC-val 0.528  AUC-train 0.987\n",
            "Stats - Epoch: 46 AUC-val 0.546  AUC-train 0.988\n",
            "Stats - Epoch: 47 AUC-val 0.548  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.548  AUC-train 0.985\n",
            "Stats - Epoch: 49 AUC-val 0.565  AUC-train 0.989\n",
            "Stats - Epoch: 50 AUC-val 0.565  AUC-train 0.989\n",
            "Stats - Epoch: 51 AUC-val 0.573  AUC-train 0.988\n",
            "Stats - Epoch: 52 AUC-val 0.561  AUC-train 0.985\n",
            "Stats - Epoch: 53 AUC-val 0.550  AUC-train 0.987\n",
            "Stats - Epoch: 54 AUC-val 0.578  AUC-train 0.988\n",
            "Stats - Epoch: 55 AUC-val 0.585  AUC-train 0.986\n",
            "Stats - Epoch: 56 AUC-val 0.547  AUC-train 0.990\n",
            "Stats - Epoch: 57 AUC-val 0.583  AUC-train 0.990\n",
            "Stats - Epoch: 58 AUC-val 0.583  AUC-train 0.990\n",
            "Stats - Epoch: 59 AUC-val 0.578  AUC-train 0.992\n",
            "Stats - Epoch: 60 AUC-val 0.589  AUC-train 0.991\n",
            "Stats - Epoch: 61 AUC-val 0.540  AUC-train 0.992\n",
            "Stats - Epoch: 62 AUC-val 0.600  AUC-train 0.991\n",
            "Stats - Epoch: 63 AUC-val 0.590  AUC-train 0.993\n",
            "Stats - Epoch: 64 AUC-val 0.606  AUC-train 0.993\n",
            "Stats - Epoch: 65 AUC-val 0.579  AUC-train 0.992\n",
            "Stats - Epoch: 66 AUC-val 0.602  AUC-train 0.995\n",
            "Stats - Epoch: 67 AUC-val 0.626  AUC-train 0.994\n",
            "Stats - Epoch: 68 AUC-val 0.620  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.586  AUC-train 0.996\n",
            "Stats - Epoch: 70 AUC-val 0.613  AUC-train 0.993\n",
            "Stats - Epoch: 71 AUC-val 0.578  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.622  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.639  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.621  AUC-train 0.994\n",
            "Stats - Epoch: 75 AUC-val 0.562  AUC-train 0.990\n",
            "Stats - Epoch: 76 AUC-val 0.610  AUC-train 0.992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.613  AUC-train 0.990\n",
            "Stats - Epoch: 78 AUC-val 0.617  AUC-train 0.993\n",
            "Stats - Epoch: 79 AUC-val 0.601  AUC-train 0.993\n",
            "Stats - Epoch: 80 AUC-val 0.571  AUC-train 0.993\n",
            "Stats - Epoch: 81 AUC-val 0.596  AUC-train 0.993\n",
            "Stats - Epoch: 82 AUC-val 0.594  AUC-train 0.993\n",
            "Stats - Epoch: 83 AUC-val 0.584  AUC-train 0.988\n",
            "Stats - Epoch: 84 AUC-val 0.568  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.614  AUC-train 0.992\n",
            "Stats - Epoch: 86 AUC-val 0.600  AUC-train 0.993\n",
            "Stats - Epoch: 87 AUC-val 0.628  AUC-train 0.992\n",
            "Stats - Epoch: 88 AUC-val 0.592  AUC-train 0.995\n",
            "Stats - Epoch: 89 AUC-val 0.598  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.619  AUC-train 0.995\n",
            "Stats - Epoch: 91 AUC-val 0.585  AUC-train 0.994\n",
            "Stats - Epoch: 92 AUC-val 0.612  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.599  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.608  AUC-train 0.993\n",
            "Stats - Epoch: 95 AUC-val 0.612  AUC-train 0.995\n",
            "Stats - Epoch: 96 AUC-val 0.609  AUC-train 0.993\n",
            "Stats - Epoch: 97 AUC-val 0.597  AUC-train 0.994\n",
            "Stats - Epoch: 98 AUC-val 0.613  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.645  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.645  AUC-train 0.993\n",
            "Results 100 AUC-val 0.645 0.766 0.556 0.481 0.585 AUC-train 0.997\n",
            "Shapley [0.01525399 0.00855842 0.01139967 0.02073636 0.00681156] [0.00378714]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199999\n",
            "         Iterations 7\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.236  AUC-train 0.758\n",
            "Stats - Epoch: 2 AUC-val 0.391  AUC-train 0.892\n",
            "Stats - Epoch: 3 AUC-val 0.409  AUC-train 0.931\n",
            "Stats - Epoch: 4 AUC-val 0.464  AUC-train 0.951\n",
            "Stats - Epoch: 5 AUC-val 0.477  AUC-train 0.962\n",
            "Stats - Epoch: 6 AUC-val 0.462  AUC-train 0.975\n",
            "Stats - Epoch: 7 AUC-val 0.452  AUC-train 0.983\n",
            "Stats - Epoch: 8 AUC-val 0.466  AUC-train 0.989\n",
            "Stats - Epoch: 9 AUC-val 0.488  AUC-train 0.990\n",
            "Stats - Epoch: 10 AUC-val 0.481  AUC-train 0.992\n",
            "Stats - Epoch: 11 AUC-val 0.506  AUC-train 0.994\n",
            "Stats - Epoch: 12 AUC-val 0.499  AUC-train 0.996\n",
            "Stats - Epoch: 13 AUC-val 0.517  AUC-train 0.998\n",
            "Stats - Epoch: 14 AUC-val 0.509  AUC-train 0.997\n",
            "Stats - Epoch: 15 AUC-val 0.520  AUC-train 0.998\n",
            "Stats - Epoch: 16 AUC-val 0.482  AUC-train 0.997\n",
            "Stats - Epoch: 17 AUC-val 0.513  AUC-train 0.998\n",
            "Stats - Epoch: 18 AUC-val 0.489  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.468  AUC-train 0.998\n",
            "Stats - Epoch: 20 AUC-val 0.488  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.519  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.523  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.504  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.534  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.533  AUC-train 1.000\n",
            "Stats - Epoch: 26 AUC-val 0.530  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.540  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.493  AUC-train 0.998\n",
            "Stats - Epoch: 29 AUC-val 0.488  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.465  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.482  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.502  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.507  AUC-train 1.000\n",
            "Stats - Epoch: 34 AUC-val 0.499  AUC-train 1.000\n",
            "Stats - Epoch: 35 AUC-val 0.497  AUC-train 0.997\n",
            "Stats - Epoch: 36 AUC-val 0.497  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.532  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.508  AUC-train 1.000\n",
            "Stats - Epoch: 39 AUC-val 0.503  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.512  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.471  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.483  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.496  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.503  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.502  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.442  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.505  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.519  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.474  AUC-train 0.996\n",
            "Stats - Epoch: 50 AUC-val 0.492  AUC-train 0.996\n",
            "Stats - Epoch: 51 AUC-val 0.476  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.466  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.509  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.514  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.489  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.493  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.495  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.535  AUC-train 1.000\n",
            "Stats - Epoch: 59 AUC-val 0.526  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.524  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.553  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.541  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.547  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.534  AUC-train 0.999\n",
            "Stats - Epoch: 65 AUC-val 0.551  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.488  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.498  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.518  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.505  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.490  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.501  AUC-train 1.000\n",
            "Stats - Epoch: 72 AUC-val 0.540  AUC-train 0.995\n",
            "Stats - Epoch: 73 AUC-val 0.532  AUC-train 0.998\n",
            "Stats - Epoch: 74 AUC-val 0.567  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.553  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.542  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.528  AUC-train 1.000\n",
            "Stats - Epoch: 78 AUC-val 0.536  AUC-train 1.000\n",
            "Stats - Epoch: 79 AUC-val 0.502  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.492  AUC-train 0.996\n",
            "Stats - Epoch: 81 AUC-val 0.526  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.505  AUC-train 0.999\n",
            "Stats - Epoch: 83 AUC-val 0.513  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.499  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.517  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.548  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.510  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.500  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.498  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.498  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.482  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.524  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.475  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.529  AUC-train 1.000\n",
            "Stats - Epoch: 95 AUC-val 0.495  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.545  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.514  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.505  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.506  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.508  AUC-train 0.998\n",
            "Results 100 AUC-val 0.567 0.535 0.548 0.538 0.631 AUC-train 0.998\n",
            "Shapley [0.01776246 0.01279719 0.01704595 0.03558996 0.02515981] [0.00089474]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188356\n",
            "         Iterations 8\n",
            "[1870, 1914, 1920, 1939]\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:8\n",
            "Crises test:11\n",
            "Stats - Epoch: 1 AUC-val 0.621  AUC-train 0.788\n",
            "Results 1 AUC-val 0.621 0.523 0.376 0.451 0.356 AUC-train 0.788\n",
            "Shapley [0.00741669 0.0127628  0.00644433 0.10093205 0.01653485] [0.02703986]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.273517\n",
            "         Iterations 7\n",
            "Crises train:8\n",
            "Crises test:11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 1 AUC-val 0.657  AUC-train 0.939\n",
            "Results 1 AUC-val 0.657 0.451 0.577 0.547 0.471 AUC-train 0.939\n",
            "Shapley [0.06999274 0.05349722 0.03563564 0.12114798 0.04961312] [0.00102884]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.260782\n",
            "         Iterations 7\n",
            "Crises train:8\n",
            "Crises test:11\n",
            "Stats - Epoch: 1 AUC-val 0.405  AUC-train 0.516\n",
            "Stats - Epoch: 2 AUC-val 0.559  AUC-train 0.571\n",
            "Stats - Epoch: 3 AUC-val 0.597  AUC-train 0.629\n",
            "Stats - Epoch: 4 AUC-val 0.622  AUC-train 0.683\n",
            "Stats - Epoch: 5 AUC-val 0.646  AUC-train 0.726\n",
            "Stats - Epoch: 6 AUC-val 0.652  AUC-train 0.754\n",
            "Stats - Epoch: 7 AUC-val 0.652  AUC-train 0.782\n",
            "Stats - Epoch: 8 AUC-val 0.650  AUC-train 0.800\n",
            "Stats - Epoch: 9 AUC-val 0.639  AUC-train 0.818\n",
            "Stats - Epoch: 10 AUC-val 0.645  AUC-train 0.833\n",
            "Stats - Epoch: 11 AUC-val 0.635  AUC-train 0.847\n",
            "Stats - Epoch: 12 AUC-val 0.634  AUC-train 0.861\n",
            "Stats - Epoch: 13 AUC-val 0.640  AUC-train 0.871\n",
            "Stats - Epoch: 14 AUC-val 0.639  AUC-train 0.878\n",
            "Stats - Epoch: 15 AUC-val 0.632  AUC-train 0.889\n",
            "Stats - Epoch: 16 AUC-val 0.627  AUC-train 0.897\n",
            "Stats - Epoch: 17 AUC-val 0.625  AUC-train 0.906\n",
            "Stats - Epoch: 18 AUC-val 0.622  AUC-train 0.911\n",
            "Stats - Epoch: 19 AUC-val 0.625  AUC-train 0.918\n",
            "Stats - Epoch: 20 AUC-val 0.627  AUC-train 0.923\n",
            "Stats - Epoch: 21 AUC-val 0.624  AUC-train 0.929\n",
            "Stats - Epoch: 22 AUC-val 0.621  AUC-train 0.934\n",
            "Stats - Epoch: 23 AUC-val 0.622  AUC-train 0.938\n",
            "Stats - Epoch: 24 AUC-val 0.626  AUC-train 0.941\n",
            "Stats - Epoch: 25 AUC-val 0.627  AUC-train 0.944\n",
            "Stats - Epoch: 26 AUC-val 0.628  AUC-train 0.949\n",
            "Stats - Epoch: 27 AUC-val 0.627  AUC-train 0.952\n",
            "Stats - Epoch: 28 AUC-val 0.637  AUC-train 0.954\n",
            "Stats - Epoch: 29 AUC-val 0.631  AUC-train 0.956\n",
            "Stats - Epoch: 30 AUC-val 0.636  AUC-train 0.958\n",
            "Stats - Epoch: 31 AUC-val 0.633  AUC-train 0.960\n",
            "Stats - Epoch: 32 AUC-val 0.634  AUC-train 0.962\n",
            "Stats - Epoch: 33 AUC-val 0.633  AUC-train 0.964\n",
            "Stats - Epoch: 34 AUC-val 0.640  AUC-train 0.966\n",
            "Stats - Epoch: 35 AUC-val 0.636  AUC-train 0.968\n",
            "Stats - Epoch: 36 AUC-val 0.630  AUC-train 0.969\n",
            "Stats - Epoch: 37 AUC-val 0.629  AUC-train 0.970\n",
            "Stats - Epoch: 38 AUC-val 0.631  AUC-train 0.971\n",
            "Stats - Epoch: 39 AUC-val 0.630  AUC-train 0.972\n",
            "Stats - Epoch: 40 AUC-val 0.633  AUC-train 0.974\n",
            "Stats - Epoch: 41 AUC-val 0.629  AUC-train 0.974\n",
            "Stats - Epoch: 42 AUC-val 0.624  AUC-train 0.975\n",
            "Stats - Epoch: 43 AUC-val 0.625  AUC-train 0.976\n",
            "Stats - Epoch: 44 AUC-val 0.623  AUC-train 0.978\n",
            "Stats - Epoch: 45 AUC-val 0.622  AUC-train 0.978\n",
            "Stats - Epoch: 46 AUC-val 0.627  AUC-train 0.979\n",
            "Stats - Epoch: 47 AUC-val 0.624  AUC-train 0.979\n",
            "Stats - Epoch: 48 AUC-val 0.624  AUC-train 0.979\n",
            "Stats - Epoch: 49 AUC-val 0.626  AUC-train 0.981\n",
            "Stats - Epoch: 50 AUC-val 0.624  AUC-train 0.981\n",
            "Stats - Epoch: 51 AUC-val 0.619  AUC-train 0.983\n",
            "Stats - Epoch: 52 AUC-val 0.621  AUC-train 0.982\n",
            "Stats - Epoch: 53 AUC-val 0.622  AUC-train 0.983\n",
            "Stats - Epoch: 54 AUC-val 0.628  AUC-train 0.983\n",
            "Stats - Epoch: 55 AUC-val 0.628  AUC-train 0.984\n",
            "Stats - Epoch: 56 AUC-val 0.626  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.622  AUC-train 0.984\n",
            "Stats - Epoch: 58 AUC-val 0.625  AUC-train 0.985\n",
            "Stats - Epoch: 59 AUC-val 0.624  AUC-train 0.986\n",
            "Stats - Epoch: 60 AUC-val 0.627  AUC-train 0.986\n",
            "Stats - Epoch: 61 AUC-val 0.626  AUC-train 0.986\n",
            "Stats - Epoch: 62 AUC-val 0.624  AUC-train 0.986\n",
            "Stats - Epoch: 63 AUC-val 0.623  AUC-train 0.987\n",
            "Stats - Epoch: 64 AUC-val 0.626  AUC-train 0.986\n",
            "Stats - Epoch: 65 AUC-val 0.624  AUC-train 0.987\n",
            "Stats - Epoch: 66 AUC-val 0.627  AUC-train 0.988\n",
            "Stats - Epoch: 67 AUC-val 0.627  AUC-train 0.988\n",
            "Stats - Epoch: 68 AUC-val 0.625  AUC-train 0.988\n",
            "Stats - Epoch: 69 AUC-val 0.623  AUC-train 0.989\n",
            "Stats - Epoch: 70 AUC-val 0.624  AUC-train 0.987\n",
            "Stats - Epoch: 71 AUC-val 0.626  AUC-train 0.989\n",
            "Stats - Epoch: 72 AUC-val 0.627  AUC-train 0.990\n",
            "Stats - Epoch: 73 AUC-val 0.622  AUC-train 0.990\n",
            "Stats - Epoch: 74 AUC-val 0.625  AUC-train 0.990\n",
            "Stats - Epoch: 75 AUC-val 0.627  AUC-train 0.991\n",
            "Stats - Epoch: 76 AUC-val 0.623  AUC-train 0.991\n",
            "Stats - Epoch: 77 AUC-val 0.624  AUC-train 0.991\n",
            "Stats - Epoch: 78 AUC-val 0.625  AUC-train 0.991\n",
            "Stats - Epoch: 79 AUC-val 0.625  AUC-train 0.992\n",
            "Stats - Epoch: 80 AUC-val 0.620  AUC-train 0.992\n",
            "Stats - Epoch: 81 AUC-val 0.624  AUC-train 0.992\n",
            "Stats - Epoch: 82 AUC-val 0.624  AUC-train 0.992\n",
            "Stats - Epoch: 83 AUC-val 0.622  AUC-train 0.992\n",
            "Stats - Epoch: 84 AUC-val 0.623  AUC-train 0.992\n",
            "Stats - Epoch: 85 AUC-val 0.622  AUC-train 0.992\n",
            "Stats - Epoch: 86 AUC-val 0.622  AUC-train 0.992\n",
            "Stats - Epoch: 87 AUC-val 0.623  AUC-train 0.993\n",
            "Stats - Epoch: 88 AUC-val 0.621  AUC-train 0.993\n",
            "Stats - Epoch: 89 AUC-val 0.622  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.620  AUC-train 0.993\n",
            "Stats - Epoch: 91 AUC-val 0.620  AUC-train 0.993\n",
            "Stats - Epoch: 92 AUC-val 0.617  AUC-train 0.993\n",
            "Stats - Epoch: 93 AUC-val 0.619  AUC-train 0.993\n",
            "Stats - Epoch: 94 AUC-val 0.618  AUC-train 0.993\n",
            "Stats - Epoch: 95 AUC-val 0.618  AUC-train 0.994\n",
            "Stats - Epoch: 96 AUC-val 0.620  AUC-train 0.994\n",
            "Stats - Epoch: 97 AUC-val 0.616  AUC-train 0.994\n",
            "Stats - Epoch: 98 AUC-val 0.616  AUC-train 0.993\n",
            "Stats - Epoch: 99 AUC-val 0.618  AUC-train 0.994\n",
            "Stats - Epoch: 100 AUC-val 0.622  AUC-train 0.994\n",
            "Results 100 AUC-val 0.652 0.551 0.410 0.483 0.377 AUC-train 0.754\n",
            "Shapley [0.02669093 0.01239519 0.00994709 0.07664847 0.02679224] [0.0895004]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.260840\n",
            "         Iterations 7\n",
            "Crises train:8\n",
            "Crises test:11\n",
            "Stats - Epoch: 1 AUC-val 0.463  AUC-train 0.593\n",
            "Stats - Epoch: 2 AUC-val 0.513  AUC-train 0.700\n",
            "Stats - Epoch: 3 AUC-val 0.510  AUC-train 0.806\n",
            "Stats - Epoch: 4 AUC-val 0.545  AUC-train 0.877\n",
            "Stats - Epoch: 5 AUC-val 0.560  AUC-train 0.921\n",
            "Stats - Epoch: 6 AUC-val 0.563  AUC-train 0.947\n",
            "Stats - Epoch: 7 AUC-val 0.557  AUC-train 0.962\n",
            "Stats - Epoch: 8 AUC-val 0.558  AUC-train 0.973\n",
            "Stats - Epoch: 9 AUC-val 0.547  AUC-train 0.981\n",
            "Stats - Epoch: 10 AUC-val 0.541  AUC-train 0.986\n",
            "Stats - Epoch: 11 AUC-val 0.539  AUC-train 0.990\n",
            "Stats - Epoch: 12 AUC-val 0.539  AUC-train 0.993\n",
            "Stats - Epoch: 13 AUC-val 0.538  AUC-train 0.995\n",
            "Stats - Epoch: 14 AUC-val 0.536  AUC-train 0.996\n",
            "Stats - Epoch: 15 AUC-val 0.536  AUC-train 0.996\n",
            "Stats - Epoch: 16 AUC-val 0.532  AUC-train 0.997\n",
            "Stats - Epoch: 17 AUC-val 0.537  AUC-train 0.998\n",
            "Stats - Epoch: 18 AUC-val 0.540  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.537  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.541  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.539  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.541  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.550  AUC-train 1.000\n",
            "Stats - Epoch: 24 AUC-val 0.551  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.556  AUC-train 1.000\n",
            "Stats - Epoch: 26 AUC-val 0.560  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.560  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.564  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.566  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.565  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.566  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.578  AUC-train 1.000\n",
            "Stats - Epoch: 33 AUC-val 0.576  AUC-train 1.000\n",
            "Stats - Epoch: 34 AUC-val 0.572  AUC-train 1.000\n",
            "Stats - Epoch: 35 AUC-val 0.577  AUC-train 1.000\n",
            "Stats - Epoch: 36 AUC-val 0.577  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.580  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 39 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.578  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 42 AUC-val 0.584  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.578  AUC-train 1.000\n",
            "Stats - Epoch: 44 AUC-val 0.577  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.582  AUC-train 1.000\n",
            "Stats - Epoch: 46 AUC-val 0.575  AUC-train 1.000\n",
            "Stats - Epoch: 47 AUC-val 0.585  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.568  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.591  AUC-train 1.000\n",
            "Stats - Epoch: 50 AUC-val 0.581  AUC-train 1.000\n",
            "Stats - Epoch: 51 AUC-val 0.572  AUC-train 1.000\n",
            "Stats - Epoch: 52 AUC-val 0.585  AUC-train 1.000\n",
            "Stats - Epoch: 53 AUC-val 0.568  AUC-train 1.000\n",
            "Stats - Epoch: 54 AUC-val 0.585  AUC-train 1.000\n",
            "Stats - Epoch: 55 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.588  AUC-train 1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 57 AUC-val 0.572  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.584  AUC-train 1.000\n",
            "Stats - Epoch: 59 AUC-val 0.570  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.573  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.590  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.583  AUC-train 1.000\n",
            "Stats - Epoch: 63 AUC-val 0.588  AUC-train 1.000\n",
            "Stats - Epoch: 64 AUC-val 0.580  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.593  AUC-train 1.000\n",
            "Stats - Epoch: 66 AUC-val 0.594  AUC-train 1.000\n",
            "Stats - Epoch: 67 AUC-val 0.578  AUC-train 1.000\n",
            "Stats - Epoch: 68 AUC-val 0.568  AUC-train 1.000\n",
            "Stats - Epoch: 69 AUC-val 0.564  AUC-train 1.000\n",
            "Stats - Epoch: 70 AUC-val 0.570  AUC-train 1.000\n",
            "Stats - Epoch: 71 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 72 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 73 AUC-val 0.578  AUC-train 1.000\n",
            "Stats - Epoch: 74 AUC-val 0.590  AUC-train 1.000\n",
            "Stats - Epoch: 75 AUC-val 0.576  AUC-train 1.000\n",
            "Stats - Epoch: 76 AUC-val 0.581  AUC-train 1.000\n",
            "Stats - Epoch: 77 AUC-val 0.581  AUC-train 1.000\n",
            "Stats - Epoch: 78 AUC-val 0.591  AUC-train 1.000\n",
            "Stats - Epoch: 79 AUC-val 0.581  AUC-train 1.000\n",
            "Stats - Epoch: 80 AUC-val 0.600  AUC-train 1.000\n",
            "Stats - Epoch: 81 AUC-val 0.580  AUC-train 1.000\n",
            "Stats - Epoch: 82 AUC-val 0.585  AUC-train 1.000\n",
            "Stats - Epoch: 83 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 84 AUC-val 0.597  AUC-train 1.000\n",
            "Stats - Epoch: 85 AUC-val 0.600  AUC-train 1.000\n",
            "Stats - Epoch: 86 AUC-val 0.601  AUC-train 1.000\n",
            "Stats - Epoch: 87 AUC-val 0.592  AUC-train 1.000\n",
            "Stats - Epoch: 88 AUC-val 0.595  AUC-train 1.000\n",
            "Stats - Epoch: 89 AUC-val 0.586  AUC-train 1.000\n",
            "Stats - Epoch: 90 AUC-val 0.586  AUC-train 1.000\n",
            "Stats - Epoch: 91 AUC-val 0.592  AUC-train 1.000\n",
            "Stats - Epoch: 92 AUC-val 0.592  AUC-train 1.000\n",
            "Stats - Epoch: 93 AUC-val 0.585  AUC-train 1.000\n",
            "Stats - Epoch: 94 AUC-val 0.590  AUC-train 1.000\n",
            "Stats - Epoch: 95 AUC-val 0.574  AUC-train 1.000\n",
            "Stats - Epoch: 96 AUC-val 0.585  AUC-train 1.000\n",
            "Stats - Epoch: 97 AUC-val 0.591  AUC-train 1.000\n",
            "Stats - Epoch: 98 AUC-val 0.596  AUC-train 1.000\n",
            "Stats - Epoch: 99 AUC-val 0.593  AUC-train 1.000\n",
            "Stats - Epoch: 100 AUC-val 0.595  AUC-train 1.000\n",
            "Results 100 AUC-val 0.601 0.495 0.652 0.519 0.502 AUC-train 1.000\n",
            "Shapley [0.04067539 0.04323312 0.0139455  0.07504989 0.01922265] [0.02615821]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.267195\n",
            "         Iterations 8\n",
            "Crises train:8\n",
            "Crises test:11\n",
            "Stats - Epoch: 1 AUC-val 0.648  AUC-train 0.633\n",
            "Stats - Epoch: 2 AUC-val 0.646  AUC-train 0.703\n",
            "Stats - Epoch: 3 AUC-val 0.659  AUC-train 0.733\n",
            "Stats - Epoch: 4 AUC-val 0.663  AUC-train 0.748\n",
            "Stats - Epoch: 5 AUC-val 0.666  AUC-train 0.767\n",
            "Stats - Epoch: 6 AUC-val 0.670  AUC-train 0.787\n",
            "Stats - Epoch: 7 AUC-val 0.676  AUC-train 0.806\n",
            "Stats - Epoch: 8 AUC-val 0.681  AUC-train 0.821\n",
            "Stats - Epoch: 9 AUC-val 0.684  AUC-train 0.836\n",
            "Stats - Epoch: 10 AUC-val 0.687  AUC-train 0.848\n",
            "Stats - Epoch: 11 AUC-val 0.690  AUC-train 0.858\n",
            "Stats - Epoch: 12 AUC-val 0.694  AUC-train 0.866\n",
            "Stats - Epoch: 13 AUC-val 0.695  AUC-train 0.872\n",
            "Stats - Epoch: 14 AUC-val 0.695  AUC-train 0.879\n",
            "Stats - Epoch: 15 AUC-val 0.700  AUC-train 0.884\n",
            "Stats - Epoch: 16 AUC-val 0.701  AUC-train 0.890\n",
            "Stats - Epoch: 17 AUC-val 0.694  AUC-train 0.895\n",
            "Stats - Epoch: 18 AUC-val 0.692  AUC-train 0.900\n",
            "Stats - Epoch: 19 AUC-val 0.693  AUC-train 0.904\n",
            "Stats - Epoch: 20 AUC-val 0.698  AUC-train 0.908\n",
            "Stats - Epoch: 21 AUC-val 0.699  AUC-train 0.911\n",
            "Stats - Epoch: 22 AUC-val 0.699  AUC-train 0.914\n",
            "Stats - Epoch: 23 AUC-val 0.692  AUC-train 0.918\n",
            "Stats - Epoch: 24 AUC-val 0.695  AUC-train 0.921\n",
            "Stats - Epoch: 25 AUC-val 0.699  AUC-train 0.924\n",
            "Stats - Epoch: 26 AUC-val 0.699  AUC-train 0.926\n",
            "Stats - Epoch: 27 AUC-val 0.698  AUC-train 0.927\n",
            "Stats - Epoch: 28 AUC-val 0.697  AUC-train 0.930\n",
            "Stats - Epoch: 29 AUC-val 0.695  AUC-train 0.933\n",
            "Stats - Epoch: 30 AUC-val 0.695  AUC-train 0.934\n",
            "Stats - Epoch: 31 AUC-val 0.698  AUC-train 0.937\n",
            "Stats - Epoch: 32 AUC-val 0.695  AUC-train 0.940\n",
            "Stats - Epoch: 33 AUC-val 0.692  AUC-train 0.941\n",
            "Stats - Epoch: 34 AUC-val 0.695  AUC-train 0.943\n",
            "Stats - Epoch: 35 AUC-val 0.695  AUC-train 0.945\n",
            "Stats - Epoch: 36 AUC-val 0.695  AUC-train 0.947\n",
            "Stats - Epoch: 37 AUC-val 0.699  AUC-train 0.949\n",
            "Stats - Epoch: 38 AUC-val 0.696  AUC-train 0.951\n",
            "Stats - Epoch: 39 AUC-val 0.688  AUC-train 0.952\n",
            "Stats - Epoch: 40 AUC-val 0.691  AUC-train 0.954\n",
            "Stats - Epoch: 41 AUC-val 0.687  AUC-train 0.955\n",
            "Stats - Epoch: 42 AUC-val 0.690  AUC-train 0.958\n",
            "Stats - Epoch: 43 AUC-val 0.695  AUC-train 0.959\n",
            "Stats - Epoch: 44 AUC-val 0.683  AUC-train 0.959\n",
            "Stats - Epoch: 45 AUC-val 0.690  AUC-train 0.961\n",
            "Stats - Epoch: 46 AUC-val 0.693  AUC-train 0.963\n",
            "Stats - Epoch: 47 AUC-val 0.687  AUC-train 0.965\n",
            "Stats - Epoch: 48 AUC-val 0.689  AUC-train 0.967\n",
            "Stats - Epoch: 49 AUC-val 0.686  AUC-train 0.968\n",
            "Stats - Epoch: 50 AUC-val 0.688  AUC-train 0.970\n",
            "Stats - Epoch: 51 AUC-val 0.681  AUC-train 0.970\n",
            "Stats - Epoch: 52 AUC-val 0.681  AUC-train 0.971\n",
            "Stats - Epoch: 53 AUC-val 0.680  AUC-train 0.972\n",
            "Stats - Epoch: 54 AUC-val 0.679  AUC-train 0.972\n",
            "Stats - Epoch: 55 AUC-val 0.672  AUC-train 0.974\n",
            "Stats - Epoch: 56 AUC-val 0.673  AUC-train 0.974\n",
            "Stats - Epoch: 57 AUC-val 0.676  AUC-train 0.974\n",
            "Stats - Epoch: 58 AUC-val 0.678  AUC-train 0.975\n",
            "Stats - Epoch: 59 AUC-val 0.666  AUC-train 0.976\n",
            "Stats - Epoch: 60 AUC-val 0.672  AUC-train 0.977\n",
            "Stats - Epoch: 61 AUC-val 0.677  AUC-train 0.978\n",
            "Stats - Epoch: 62 AUC-val 0.675  AUC-train 0.979\n",
            "Stats - Epoch: 63 AUC-val 0.680  AUC-train 0.980\n",
            "Stats - Epoch: 64 AUC-val 0.683  AUC-train 0.980\n",
            "Stats - Epoch: 65 AUC-val 0.682  AUC-train 0.980\n",
            "Stats - Epoch: 66 AUC-val 0.669  AUC-train 0.982\n",
            "Stats - Epoch: 67 AUC-val 0.675  AUC-train 0.982\n",
            "Stats - Epoch: 68 AUC-val 0.669  AUC-train 0.981\n",
            "Stats - Epoch: 69 AUC-val 0.672  AUC-train 0.983\n",
            "Stats - Epoch: 70 AUC-val 0.663  AUC-train 0.984\n",
            "Stats - Epoch: 71 AUC-val 0.664  AUC-train 0.985\n",
            "Stats - Epoch: 72 AUC-val 0.672  AUC-train 0.985\n",
            "Stats - Epoch: 73 AUC-val 0.673  AUC-train 0.986\n",
            "Stats - Epoch: 74 AUC-val 0.667  AUC-train 0.985\n",
            "Stats - Epoch: 75 AUC-val 0.675  AUC-train 0.986\n",
            "Stats - Epoch: 76 AUC-val 0.659  AUC-train 0.986\n",
            "Stats - Epoch: 77 AUC-val 0.663  AUC-train 0.988\n",
            "Stats - Epoch: 78 AUC-val 0.653  AUC-train 0.987\n",
            "Stats - Epoch: 79 AUC-val 0.652  AUC-train 0.988\n",
            "Stats - Epoch: 80 AUC-val 0.645  AUC-train 0.988\n",
            "Stats - Epoch: 81 AUC-val 0.645  AUC-train 0.987\n",
            "Stats - Epoch: 82 AUC-val 0.654  AUC-train 0.989\n",
            "Stats - Epoch: 83 AUC-val 0.644  AUC-train 0.990\n",
            "Stats - Epoch: 84 AUC-val 0.647  AUC-train 0.990\n",
            "Stats - Epoch: 85 AUC-val 0.649  AUC-train 0.991\n",
            "Stats - Epoch: 86 AUC-val 0.642  AUC-train 0.991\n",
            "Stats - Epoch: 87 AUC-val 0.637  AUC-train 0.992\n",
            "Stats - Epoch: 88 AUC-val 0.645  AUC-train 0.992\n",
            "Stats - Epoch: 89 AUC-val 0.647  AUC-train 0.991\n",
            "Stats - Epoch: 90 AUC-val 0.642  AUC-train 0.991\n",
            "Stats - Epoch: 91 AUC-val 0.646  AUC-train 0.992\n",
            "Stats - Epoch: 92 AUC-val 0.641  AUC-train 0.992\n",
            "Stats - Epoch: 93 AUC-val 0.646  AUC-train 0.992\n",
            "Stats - Epoch: 94 AUC-val 0.634  AUC-train 0.992\n",
            "Stats - Epoch: 95 AUC-val 0.640  AUC-train 0.993\n",
            "Stats - Epoch: 96 AUC-val 0.636  AUC-train 0.990\n",
            "Stats - Epoch: 97 AUC-val 0.640  AUC-train 0.992\n",
            "Stats - Epoch: 98 AUC-val 0.640  AUC-train 0.993\n",
            "Stats - Epoch: 99 AUC-val 0.653  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.650  AUC-train 0.994\n",
            "Results 100 AUC-val 0.701 0.499 0.330 0.585 0.452 AUC-train 0.890\n",
            "Shapley [0.02812022 0.01440231 0.00847303 0.09713326 0.05802255] [0.00927957]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.232646\n",
            "         Iterations 8\n",
            "Crises train:8\n",
            "Crises test:11\n",
            "Stats - Epoch: 1 AUC-val 0.669  AUC-train 0.638\n",
            "Stats - Epoch: 2 AUC-val 0.661  AUC-train 0.712\n",
            "Stats - Epoch: 3 AUC-val 0.658  AUC-train 0.773\n",
            "Stats - Epoch: 4 AUC-val 0.674  AUC-train 0.815\n",
            "Stats - Epoch: 5 AUC-val 0.699  AUC-train 0.847\n",
            "Stats - Epoch: 6 AUC-val 0.704  AUC-train 0.874\n",
            "Stats - Epoch: 7 AUC-val 0.717  AUC-train 0.895\n",
            "Stats - Epoch: 8 AUC-val 0.716  AUC-train 0.915\n",
            "Stats - Epoch: 9 AUC-val 0.717  AUC-train 0.929\n",
            "Stats - Epoch: 10 AUC-val 0.718  AUC-train 0.943\n",
            "Stats - Epoch: 11 AUC-val 0.722  AUC-train 0.954\n",
            "Stats - Epoch: 12 AUC-val 0.724  AUC-train 0.963\n",
            "Stats - Epoch: 13 AUC-val 0.722  AUC-train 0.970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 14 AUC-val 0.716  AUC-train 0.977\n",
            "Stats - Epoch: 15 AUC-val 0.707  AUC-train 0.981\n",
            "Stats - Epoch: 16 AUC-val 0.703  AUC-train 0.985\n",
            "Stats - Epoch: 17 AUC-val 0.695  AUC-train 0.988\n",
            "Stats - Epoch: 18 AUC-val 0.687  AUC-train 0.989\n",
            "Stats - Epoch: 19 AUC-val 0.689  AUC-train 0.992\n",
            "Stats - Epoch: 20 AUC-val 0.680  AUC-train 0.993\n",
            "Stats - Epoch: 21 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 22 AUC-val 0.675  AUC-train 0.996\n",
            "Stats - Epoch: 23 AUC-val 0.676  AUC-train 0.997\n",
            "Stats - Epoch: 24 AUC-val 0.667  AUC-train 0.997\n",
            "Stats - Epoch: 25 AUC-val 0.668  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.669  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.651  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.649  AUC-train 1.000\n",
            "Stats - Epoch: 35 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.644  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.647  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.647  AUC-train 1.000\n",
            "Stats - Epoch: 39 AUC-val 0.648  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.641  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.638  AUC-train 1.000\n",
            "Stats - Epoch: 42 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.661  AUC-train 1.000\n",
            "Stats - Epoch: 44 AUC-val 0.630  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.638  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.639  AUC-train 1.000\n",
            "Stats - Epoch: 47 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.631  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.640  AUC-train 1.000\n",
            "Stats - Epoch: 51 AUC-val 0.652  AUC-train 1.000\n",
            "Stats - Epoch: 52 AUC-val 0.651  AUC-train 1.000\n",
            "Stats - Epoch: 53 AUC-val 0.644  AUC-train 1.000\n",
            "Stats - Epoch: 54 AUC-val 0.644  AUC-train 1.000\n",
            "Stats - Epoch: 55 AUC-val 0.650  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.648  AUC-train 1.000\n",
            "Stats - Epoch: 57 AUC-val 0.658  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.636  AUC-train 0.996\n",
            "Stats - Epoch: 59 AUC-val 0.649  AUC-train 0.997\n",
            "Stats - Epoch: 60 AUC-val 0.647  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.646  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.647  AUC-train 1.000\n",
            "Stats - Epoch: 63 AUC-val 0.643  AUC-train 1.000\n",
            "Stats - Epoch: 64 AUC-val 0.645  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.631  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.648  AUC-train 1.000\n",
            "Stats - Epoch: 67 AUC-val 0.643  AUC-train 1.000\n",
            "Stats - Epoch: 68 AUC-val 0.642  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.643  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.646  AUC-train 1.000\n",
            "Stats - Epoch: 71 AUC-val 0.638  AUC-train 1.000\n",
            "Stats - Epoch: 72 AUC-val 0.646  AUC-train 1.000\n",
            "Stats - Epoch: 73 AUC-val 0.636  AUC-train 1.000\n",
            "Stats - Epoch: 74 AUC-val 0.636  AUC-train 1.000\n",
            "Stats - Epoch: 75 AUC-val 0.636  AUC-train 1.000\n",
            "Stats - Epoch: 76 AUC-val 0.640  AUC-train 0.998\n",
            "Stats - Epoch: 77 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.631  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.636  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.624  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.624  AUC-train 1.000\n",
            "Stats - Epoch: 82 AUC-val 0.633  AUC-train 1.000\n",
            "Stats - Epoch: 83 AUC-val 0.625  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.645  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.623  AUC-train 0.999\n",
            "Stats - Epoch: 86 AUC-val 0.624  AUC-train 1.000\n",
            "Stats - Epoch: 87 AUC-val 0.622  AUC-train 1.000\n",
            "Stats - Epoch: 88 AUC-val 0.622  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.624  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.623  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.626  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.627  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.632  AUC-train 1.000\n",
            "Stats - Epoch: 94 AUC-val 0.647  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.617  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.642  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.627  AUC-train 0.999\n",
            "Stats - Epoch: 98 AUC-val 0.629  AUC-train 1.000\n",
            "Stats - Epoch: 99 AUC-val 0.624  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.634  AUC-train 0.999\n",
            "Results 100 AUC-val 0.724 0.544 0.386 0.506 0.448 AUC-train 0.963\n",
            "Shapley [0.01428998 0.01525653 0.00716335 0.06719919 0.01355749] [0.01894392]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.261938\n",
            "         Iterations 7\n",
            "Crises train:8\n",
            "Crises test:11\n",
            "Stats - Epoch: 1 AUC-val 0.515  AUC-train 0.523\n",
            "Stats - Epoch: 2 AUC-val 0.577  AUC-train 0.619\n",
            "Stats - Epoch: 3 AUC-val 0.608  AUC-train 0.719\n",
            "Stats - Epoch: 4 AUC-val 0.627  AUC-train 0.786\n",
            "Stats - Epoch: 5 AUC-val 0.631  AUC-train 0.828\n",
            "Stats - Epoch: 6 AUC-val 0.640  AUC-train 0.857\n",
            "Stats - Epoch: 7 AUC-val 0.646  AUC-train 0.878\n",
            "Stats - Epoch: 8 AUC-val 0.648  AUC-train 0.893\n",
            "Stats - Epoch: 9 AUC-val 0.653  AUC-train 0.907\n",
            "Stats - Epoch: 10 AUC-val 0.651  AUC-train 0.920\n",
            "Stats - Epoch: 11 AUC-val 0.649  AUC-train 0.930\n",
            "Stats - Epoch: 12 AUC-val 0.649  AUC-train 0.941\n",
            "Stats - Epoch: 13 AUC-val 0.648  AUC-train 0.947\n",
            "Stats - Epoch: 14 AUC-val 0.649  AUC-train 0.955\n",
            "Stats - Epoch: 15 AUC-val 0.649  AUC-train 0.960\n",
            "Stats - Epoch: 16 AUC-val 0.658  AUC-train 0.964\n",
            "Stats - Epoch: 17 AUC-val 0.652  AUC-train 0.969\n",
            "Stats - Epoch: 18 AUC-val 0.658  AUC-train 0.972\n",
            "Stats - Epoch: 19 AUC-val 0.654  AUC-train 0.975\n",
            "Stats - Epoch: 20 AUC-val 0.647  AUC-train 0.978\n",
            "Stats - Epoch: 21 AUC-val 0.647  AUC-train 0.981\n",
            "Stats - Epoch: 22 AUC-val 0.646  AUC-train 0.983\n",
            "Stats - Epoch: 23 AUC-val 0.646  AUC-train 0.985\n",
            "Stats - Epoch: 24 AUC-val 0.648  AUC-train 0.987\n",
            "Stats - Epoch: 25 AUC-val 0.644  AUC-train 0.988\n",
            "Stats - Epoch: 26 AUC-val 0.645  AUC-train 0.989\n",
            "Stats - Epoch: 27 AUC-val 0.645  AUC-train 0.990\n",
            "Stats - Epoch: 28 AUC-val 0.647  AUC-train 0.991\n",
            "Stats - Epoch: 29 AUC-val 0.643  AUC-train 0.992\n",
            "Stats - Epoch: 30 AUC-val 0.645  AUC-train 0.993\n",
            "Stats - Epoch: 31 AUC-val 0.645  AUC-train 0.994\n",
            "Stats - Epoch: 32 AUC-val 0.647  AUC-train 0.995\n",
            "Stats - Epoch: 33 AUC-val 0.645  AUC-train 0.995\n",
            "Stats - Epoch: 34 AUC-val 0.640  AUC-train 0.995\n",
            "Stats - Epoch: 35 AUC-val 0.641  AUC-train 0.995\n",
            "Stats - Epoch: 36 AUC-val 0.645  AUC-train 0.996\n",
            "Stats - Epoch: 37 AUC-val 0.653  AUC-train 0.995\n",
            "Stats - Epoch: 38 AUC-val 0.647  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.648  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.648  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.641  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.645  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.648  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.649  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.647  AUC-train 1.000\n",
            "Stats - Epoch: 52 AUC-val 0.645  AUC-train 1.000\n",
            "Stats - Epoch: 53 AUC-val 0.648  AUC-train 1.000\n",
            "Stats - Epoch: 54 AUC-val 0.649  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.654  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.654  AUC-train 1.000\n",
            "Stats - Epoch: 57 AUC-val 0.654  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 59 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.649  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.658  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.658  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 70 AUC-val 0.653  AUC-train 1.000\n",
            "Stats - Epoch: 71 AUC-val 0.654  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.656  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 75 AUC-val 0.653  AUC-train 0.999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 76 AUC-val 0.649  AUC-train 1.000\n",
            "Stats - Epoch: 77 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.650  AUC-train 1.000\n",
            "Stats - Epoch: 81 AUC-val 0.650  AUC-train 1.000\n",
            "Stats - Epoch: 82 AUC-val 0.645  AUC-train 1.000\n",
            "Stats - Epoch: 83 AUC-val 0.639  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.640  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.636  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.636  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.638  AUC-train 1.000\n",
            "Stats - Epoch: 88 AUC-val 0.635  AUC-train 1.000\n",
            "Stats - Epoch: 89 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.640  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.646  AUC-train 1.000\n",
            "Stats - Epoch: 93 AUC-val 0.640  AUC-train 1.000\n",
            "Stats - Epoch: 94 AUC-val 0.643  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.649  AUC-train 1.000\n",
            "Stats - Epoch: 96 AUC-val 0.645  AUC-train 1.000\n",
            "Stats - Epoch: 97 AUC-val 0.640  AUC-train 1.000\n",
            "Stats - Epoch: 98 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.637  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.639  AUC-train 0.999\n",
            "Results 100 AUC-val 0.667 0.464 0.271 0.379 0.356 AUC-train 0.999\n",
            "Shapley [0.03514516 0.03164357 0.00904707 0.15268993 0.02511248] [0.00614178]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.260711\n",
            "         Iterations 7\n",
            "Crises train:8\n",
            "Crises test:11\n",
            "Stats - Epoch: 1 AUC-val 0.632  AUC-train 0.648\n",
            "Stats - Epoch: 2 AUC-val 0.655  AUC-train 0.749\n",
            "Stats - Epoch: 3 AUC-val 0.698  AUC-train 0.825\n",
            "Stats - Epoch: 4 AUC-val 0.718  AUC-train 0.873\n",
            "Stats - Epoch: 5 AUC-val 0.727  AUC-train 0.905\n",
            "Stats - Epoch: 6 AUC-val 0.728  AUC-train 0.930\n",
            "Stats - Epoch: 7 AUC-val 0.729  AUC-train 0.950\n",
            "Stats - Epoch: 8 AUC-val 0.731  AUC-train 0.966\n",
            "Stats - Epoch: 9 AUC-val 0.729  AUC-train 0.975\n",
            "Stats - Epoch: 10 AUC-val 0.723  AUC-train 0.985\n",
            "Stats - Epoch: 11 AUC-val 0.722  AUC-train 0.990\n",
            "Stats - Epoch: 12 AUC-val 0.713  AUC-train 0.994\n",
            "Stats - Epoch: 13 AUC-val 0.717  AUC-train 0.995\n",
            "Stats - Epoch: 14 AUC-val 0.704  AUC-train 0.998\n",
            "Stats - Epoch: 15 AUC-val 0.708  AUC-train 0.998\n",
            "Stats - Epoch: 16 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 17 AUC-val 0.696  AUC-train 0.999\n",
            "Stats - Epoch: 18 AUC-val 0.693  AUC-train 1.000\n",
            "Stats - Epoch: 19 AUC-val 0.690  AUC-train 1.000\n",
            "Stats - Epoch: 20 AUC-val 0.693  AUC-train 1.000\n",
            "Stats - Epoch: 21 AUC-val 0.681  AUC-train 1.000\n",
            "Stats - Epoch: 22 AUC-val 0.682  AUC-train 1.000\n",
            "Stats - Epoch: 23 AUC-val 0.684  AUC-train 1.000\n",
            "Stats - Epoch: 24 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.674  AUC-train 1.000\n",
            "Stats - Epoch: 26 AUC-val 0.674  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.675  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.675  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 33 AUC-val 0.674  AUC-train 1.000\n",
            "Stats - Epoch: 34 AUC-val 0.668  AUC-train 1.000\n",
            "Stats - Epoch: 35 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 36 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.673  AUC-train 1.000\n",
            "Stats - Epoch: 39 AUC-val 0.687  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.694  AUC-train 1.000\n",
            "Stats - Epoch: 42 AUC-val 0.669  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 44 AUC-val 0.675  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.680  AUC-train 1.000\n",
            "Stats - Epoch: 46 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.675  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.675  AUC-train 1.000\n",
            "Stats - Epoch: 50 AUC-val 0.669  AUC-train 1.000\n",
            "Stats - Epoch: 51 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.673  AUC-train 1.000\n",
            "Stats - Epoch: 53 AUC-val 0.677  AUC-train 0.996\n",
            "Stats - Epoch: 54 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.671  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.669  AUC-train 1.000\n",
            "Stats - Epoch: 57 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 59 AUC-val 0.670  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 61 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 62 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.664  AUC-train 1.000\n",
            "Stats - Epoch: 64 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.671  AUC-train 1.000\n",
            "Stats - Epoch: 66 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 67 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 69 AUC-val 0.668  AUC-train 1.000\n",
            "Stats - Epoch: 70 AUC-val 0.663  AUC-train 1.000\n",
            "Stats - Epoch: 71 AUC-val 0.663  AUC-train 1.000\n",
            "Stats - Epoch: 72 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 73 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 75 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.663  AUC-train 1.000\n",
            "Stats - Epoch: 82 AUC-val 0.678  AUC-train 1.000\n",
            "Stats - Epoch: 83 AUC-val 0.667  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.679  AUC-train 1.000\n",
            "Stats - Epoch: 85 AUC-val 0.673  AUC-train 0.995\n",
            "Stats - Epoch: 86 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.684  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.676  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.663  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.658  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 93 AUC-val 0.656  AUC-train 1.000\n",
            "Stats - Epoch: 94 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 98 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.658  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.663  AUC-train 0.998\n",
            "Results 100 AUC-val 0.731 0.558 0.420 0.539 0.515 AUC-train 0.966\n",
            "Shapley [0.01873445 0.01511608 0.00756603 0.07018765 0.0212579 ] [0.0172338]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.253930\n",
            "         Iterations 7\n",
            "[1946, 1989, 1990, 2016]\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.600  AUC-train 0.884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.600 0.534 0.542 0.496 0.565 AUC-train 0.884\n",
            "Shapley [3.61698927e-03 2.03476657e-03 1.31740420e-02 2.82883886e-03\n",
            " 5.15860992e-06] [0.00403006]\n",
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 0.190502\n",
            "         Iterations: 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.521  AUC-train 0.986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.521 0.400 0.382 0.541 0.805 AUC-train 0.986\n",
            "Shapley [0.02205779 0.0075709  0.0224024  0.0521184  0.03263954] [2.5765003e-09]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.180954\n",
            "         Iterations 9\n",
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.381  AUC-train 0.438\n",
            "Stats - Epoch: 2 AUC-val 0.473  AUC-train 0.547\n",
            "Stats - Epoch: 3 AUC-val 0.472  AUC-train 0.611\n",
            "Stats - Epoch: 4 AUC-val 0.487  AUC-train 0.651\n",
            "Stats - Epoch: 5 AUC-val 0.500  AUC-train 0.685\n",
            "Stats - Epoch: 6 AUC-val 0.503  AUC-train 0.722\n",
            "Stats - Epoch: 7 AUC-val 0.506  AUC-train 0.749\n",
            "Stats - Epoch: 8 AUC-val 0.507  AUC-train 0.768\n",
            "Stats - Epoch: 9 AUC-val 0.506  AUC-train 0.787\n",
            "Stats - Epoch: 10 AUC-val 0.502  AUC-train 0.798\n",
            "Stats - Epoch: 11 AUC-val 0.504  AUC-train 0.814\n",
            "Stats - Epoch: 12 AUC-val 0.505  AUC-train 0.819\n",
            "Stats - Epoch: 13 AUC-val 0.506  AUC-train 0.831\n",
            "Stats - Epoch: 14 AUC-val 0.505  AUC-train 0.844\n",
            "Stats - Epoch: 15 AUC-val 0.509  AUC-train 0.858\n",
            "Stats - Epoch: 16 AUC-val 0.504  AUC-train 0.851\n",
            "Stats - Epoch: 17 AUC-val 0.508  AUC-train 0.864\n",
            "Stats - Epoch: 18 AUC-val 0.508  AUC-train 0.867\n",
            "Stats - Epoch: 19 AUC-val 0.514  AUC-train 0.875\n",
            "Stats - Epoch: 20 AUC-val 0.514  AUC-train 0.884\n",
            "Stats - Epoch: 21 AUC-val 0.513  AUC-train 0.889\n",
            "Stats - Epoch: 22 AUC-val 0.513  AUC-train 0.891\n",
            "Stats - Epoch: 23 AUC-val 0.511  AUC-train 0.895\n",
            "Stats - Epoch: 24 AUC-val 0.517  AUC-train 0.900\n",
            "Stats - Epoch: 25 AUC-val 0.516  AUC-train 0.896\n",
            "Stats - Epoch: 26 AUC-val 0.514  AUC-train 0.903\n",
            "Stats - Epoch: 27 AUC-val 0.513  AUC-train 0.906\n",
            "Stats - Epoch: 28 AUC-val 0.520  AUC-train 0.912\n",
            "Stats - Epoch: 29 AUC-val 0.518  AUC-train 0.905\n",
            "Stats - Epoch: 30 AUC-val 0.516  AUC-train 0.906\n",
            "Stats - Epoch: 31 AUC-val 0.524  AUC-train 0.915\n",
            "Stats - Epoch: 32 AUC-val 0.522  AUC-train 0.912\n",
            "Stats - Epoch: 33 AUC-val 0.525  AUC-train 0.918\n",
            "Stats - Epoch: 34 AUC-val 0.524  AUC-train 0.918\n",
            "Stats - Epoch: 35 AUC-val 0.517  AUC-train 0.916\n",
            "Stats - Epoch: 36 AUC-val 0.519  AUC-train 0.919\n",
            "Stats - Epoch: 37 AUC-val 0.529  AUC-train 0.920\n",
            "Stats - Epoch: 38 AUC-val 0.522  AUC-train 0.920\n",
            "Stats - Epoch: 39 AUC-val 0.529  AUC-train 0.923\n",
            "Stats - Epoch: 40 AUC-val 0.529  AUC-train 0.926\n",
            "Stats - Epoch: 41 AUC-val 0.529  AUC-train 0.922\n",
            "Stats - Epoch: 42 AUC-val 0.531  AUC-train 0.926\n",
            "Stats - Epoch: 43 AUC-val 0.528  AUC-train 0.926\n",
            "Stats - Epoch: 44 AUC-val 0.529  AUC-train 0.930\n",
            "Stats - Epoch: 45 AUC-val 0.529  AUC-train 0.922\n",
            "Stats - Epoch: 46 AUC-val 0.534  AUC-train 0.925\n",
            "Stats - Epoch: 47 AUC-val 0.535  AUC-train 0.930\n",
            "Stats - Epoch: 48 AUC-val 0.535  AUC-train 0.930\n",
            "Stats - Epoch: 49 AUC-val 0.535  AUC-train 0.931\n",
            "Stats - Epoch: 50 AUC-val 0.537  AUC-train 0.931\n",
            "Stats - Epoch: 51 AUC-val 0.534  AUC-train 0.932\n",
            "Stats - Epoch: 52 AUC-val 0.534  AUC-train 0.928\n",
            "Stats - Epoch: 53 AUC-val 0.538  AUC-train 0.934\n",
            "Stats - Epoch: 54 AUC-val 0.539  AUC-train 0.932\n",
            "Stats - Epoch: 55 AUC-val 0.534  AUC-train 0.934\n",
            "Stats - Epoch: 56 AUC-val 0.542  AUC-train 0.930\n",
            "Stats - Epoch: 57 AUC-val 0.538  AUC-train 0.935\n",
            "Stats - Epoch: 58 AUC-val 0.536  AUC-train 0.934\n",
            "Stats - Epoch: 59 AUC-val 0.541  AUC-train 0.934\n",
            "Stats - Epoch: 60 AUC-val 0.539  AUC-train 0.933\n",
            "Stats - Epoch: 61 AUC-val 0.542  AUC-train 0.934\n",
            "Stats - Epoch: 62 AUC-val 0.542  AUC-train 0.935\n",
            "Stats - Epoch: 63 AUC-val 0.536  AUC-train 0.938\n",
            "Stats - Epoch: 64 AUC-val 0.544  AUC-train 0.937\n",
            "Stats - Epoch: 65 AUC-val 0.540  AUC-train 0.934\n",
            "Stats - Epoch: 66 AUC-val 0.539  AUC-train 0.937\n",
            "Stats - Epoch: 67 AUC-val 0.535  AUC-train 0.936\n",
            "Stats - Epoch: 68 AUC-val 0.542  AUC-train 0.935\n",
            "Stats - Epoch: 69 AUC-val 0.540  AUC-train 0.935\n",
            "Stats - Epoch: 70 AUC-val 0.540  AUC-train 0.941\n",
            "Stats - Epoch: 71 AUC-val 0.541  AUC-train 0.940\n",
            "Stats - Epoch: 72 AUC-val 0.542  AUC-train 0.939\n",
            "Stats - Epoch: 73 AUC-val 0.543  AUC-train 0.938\n",
            "Stats - Epoch: 74 AUC-val 0.537  AUC-train 0.937\n",
            "Stats - Epoch: 75 AUC-val 0.545  AUC-train 0.938\n",
            "Stats - Epoch: 76 AUC-val 0.545  AUC-train 0.940\n",
            "Stats - Epoch: 77 AUC-val 0.540  AUC-train 0.939\n",
            "Stats - Epoch: 78 AUC-val 0.542  AUC-train 0.941\n",
            "Stats - Epoch: 79 AUC-val 0.543  AUC-train 0.938\n",
            "Stats - Epoch: 80 AUC-val 0.540  AUC-train 0.943\n",
            "Stats - Epoch: 81 AUC-val 0.539  AUC-train 0.939\n",
            "Stats - Epoch: 82 AUC-val 0.542  AUC-train 0.942\n",
            "Stats - Epoch: 83 AUC-val 0.544  AUC-train 0.943\n",
            "Stats - Epoch: 84 AUC-val 0.538  AUC-train 0.941\n",
            "Stats - Epoch: 85 AUC-val 0.543  AUC-train 0.941\n",
            "Stats - Epoch: 86 AUC-val 0.541  AUC-train 0.941\n",
            "Stats - Epoch: 87 AUC-val 0.540  AUC-train 0.939\n",
            "Stats - Epoch: 88 AUC-val 0.537  AUC-train 0.939\n",
            "Stats - Epoch: 89 AUC-val 0.540  AUC-train 0.942\n",
            "Stats - Epoch: 90 AUC-val 0.541  AUC-train 0.944\n",
            "Stats - Epoch: 91 AUC-val 0.537  AUC-train 0.938\n",
            "Stats - Epoch: 92 AUC-val 0.540  AUC-train 0.942\n",
            "Stats - Epoch: 93 AUC-val 0.539  AUC-train 0.941\n",
            "Stats - Epoch: 94 AUC-val 0.536  AUC-train 0.942\n",
            "Stats - Epoch: 95 AUC-val 0.542  AUC-train 0.943\n",
            "Stats - Epoch: 96 AUC-val 0.539  AUC-train 0.943\n",
            "Stats - Epoch: 97 AUC-val 0.541  AUC-train 0.942\n",
            "Stats - Epoch: 98 AUC-val 0.543  AUC-train 0.944\n",
            "Stats - Epoch: 99 AUC-val 0.541  AUC-train 0.941\n",
            "Stats - Epoch: 100 AUC-val 0.538  AUC-train 0.943\n",
            "Results 100 AUC-val 0.545 0.549 0.546 0.488 0.584 AUC-train 0.940\n",
            "Shapley [0.00687191 0.00736457 0.02617047 0.00647566 0.00303102] [0.0074589]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.178433\n",
            "         Iterations 8\n",
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.300  AUC-train 0.539\n",
            "Stats - Epoch: 2 AUC-val 0.416  AUC-train 0.755\n",
            "Stats - Epoch: 3 AUC-val 0.413  AUC-train 0.864\n",
            "Stats - Epoch: 4 AUC-val 0.423  AUC-train 0.914\n",
            "Stats - Epoch: 5 AUC-val 0.435  AUC-train 0.947\n",
            "Stats - Epoch: 6 AUC-val 0.432  AUC-train 0.963\n",
            "Stats - Epoch: 7 AUC-val 0.451  AUC-train 0.971\n",
            "Stats - Epoch: 8 AUC-val 0.450  AUC-train 0.980\n",
            "Stats - Epoch: 9 AUC-val 0.462  AUC-train 0.983\n",
            "Stats - Epoch: 10 AUC-val 0.427  AUC-train 0.986\n",
            "Stats - Epoch: 11 AUC-val 0.458  AUC-train 0.986\n",
            "Stats - Epoch: 12 AUC-val 0.462  AUC-train 0.989\n",
            "Stats - Epoch: 13 AUC-val 0.466  AUC-train 0.991\n",
            "Stats - Epoch: 14 AUC-val 0.473  AUC-train 0.993\n",
            "Stats - Epoch: 15 AUC-val 0.454  AUC-train 0.993\n",
            "Stats - Epoch: 16 AUC-val 0.444  AUC-train 0.992\n",
            "Stats - Epoch: 17 AUC-val 0.460  AUC-train 0.995\n",
            "Stats - Epoch: 18 AUC-val 0.482  AUC-train 0.993\n",
            "Stats - Epoch: 19 AUC-val 0.468  AUC-train 0.994\n",
            "Stats - Epoch: 20 AUC-val 0.467  AUC-train 0.994\n",
            "Stats - Epoch: 21 AUC-val 0.464  AUC-train 0.993\n",
            "Stats - Epoch: 22 AUC-val 0.471  AUC-train 0.994\n",
            "Stats - Epoch: 23 AUC-val 0.460  AUC-train 0.994\n",
            "Stats - Epoch: 24 AUC-val 0.474  AUC-train 0.995\n",
            "Stats - Epoch: 25 AUC-val 0.477  AUC-train 0.993\n",
            "Stats - Epoch: 26 AUC-val 0.486  AUC-train 0.994\n",
            "Stats - Epoch: 27 AUC-val 0.490  AUC-train 0.995\n",
            "Stats - Epoch: 28 AUC-val 0.463  AUC-train 0.993\n",
            "Stats - Epoch: 29 AUC-val 0.465  AUC-train 0.994\n",
            "Stats - Epoch: 30 AUC-val 0.478  AUC-train 0.992\n",
            "Stats - Epoch: 31 AUC-val 0.479  AUC-train 0.993\n",
            "Stats - Epoch: 32 AUC-val 0.481  AUC-train 0.993\n",
            "Stats - Epoch: 33 AUC-val 0.478  AUC-train 0.994\n",
            "Stats - Epoch: 34 AUC-val 0.472  AUC-train 0.994\n",
            "Stats - Epoch: 35 AUC-val 0.484  AUC-train 0.989\n",
            "Stats - Epoch: 36 AUC-val 0.467  AUC-train 0.993\n",
            "Stats - Epoch: 37 AUC-val 0.483  AUC-train 0.991\n",
            "Stats - Epoch: 38 AUC-val 0.480  AUC-train 0.993\n",
            "Stats - Epoch: 39 AUC-val 0.476  AUC-train 0.992\n",
            "Stats - Epoch: 40 AUC-val 0.480  AUC-train 0.992\n",
            "Stats - Epoch: 41 AUC-val 0.467  AUC-train 0.992\n",
            "Stats - Epoch: 42 AUC-val 0.477  AUC-train 0.992\n",
            "Stats - Epoch: 43 AUC-val 0.466  AUC-train 0.992\n",
            "Stats - Epoch: 44 AUC-val 0.465  AUC-train 0.993\n",
            "Stats - Epoch: 45 AUC-val 0.469  AUC-train 0.991\n",
            "Stats - Epoch: 46 AUC-val 0.488  AUC-train 0.991\n",
            "Stats - Epoch: 47 AUC-val 0.475  AUC-train 0.992\n",
            "Stats - Epoch: 48 AUC-val 0.473  AUC-train 0.992\n",
            "Stats - Epoch: 49 AUC-val 0.486  AUC-train 0.990\n",
            "Stats - Epoch: 50 AUC-val 0.480  AUC-train 0.990\n",
            "Stats - Epoch: 51 AUC-val 0.469  AUC-train 0.993\n",
            "Stats - Epoch: 52 AUC-val 0.476  AUC-train 0.991\n",
            "Stats - Epoch: 53 AUC-val 0.486  AUC-train 0.990\n",
            "Stats - Epoch: 54 AUC-val 0.486  AUC-train 0.990\n",
            "Stats - Epoch: 55 AUC-val 0.480  AUC-train 0.991\n",
            "Stats - Epoch: 56 AUC-val 0.482  AUC-train 0.988\n",
            "Stats - Epoch: 57 AUC-val 0.486  AUC-train 0.986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.470  AUC-train 0.990\n",
            "Stats - Epoch: 59 AUC-val 0.474  AUC-train 0.990\n",
            "Stats - Epoch: 60 AUC-val 0.476  AUC-train 0.988\n",
            "Stats - Epoch: 61 AUC-val 0.480  AUC-train 0.987\n",
            "Stats - Epoch: 62 AUC-val 0.473  AUC-train 0.990\n",
            "Stats - Epoch: 63 AUC-val 0.474  AUC-train 0.990\n",
            "Stats - Epoch: 64 AUC-val 0.488  AUC-train 0.988\n",
            "Stats - Epoch: 65 AUC-val 0.475  AUC-train 0.988\n",
            "Stats - Epoch: 66 AUC-val 0.482  AUC-train 0.988\n",
            "Stats - Epoch: 67 AUC-val 0.471  AUC-train 0.988\n",
            "Stats - Epoch: 68 AUC-val 0.478  AUC-train 0.986\n",
            "Stats - Epoch: 69 AUC-val 0.477  AUC-train 0.988\n",
            "Stats - Epoch: 70 AUC-val 0.467  AUC-train 0.990\n",
            "Stats - Epoch: 71 AUC-val 0.488  AUC-train 0.985\n",
            "Stats - Epoch: 72 AUC-val 0.479  AUC-train 0.987\n",
            "Stats - Epoch: 73 AUC-val 0.476  AUC-train 0.988\n",
            "Stats - Epoch: 74 AUC-val 0.474  AUC-train 0.988\n",
            "Stats - Epoch: 75 AUC-val 0.484  AUC-train 0.987\n",
            "Stats - Epoch: 76 AUC-val 0.476  AUC-train 0.987\n",
            "Stats - Epoch: 77 AUC-val 0.472  AUC-train 0.987\n",
            "Stats - Epoch: 78 AUC-val 0.466  AUC-train 0.987\n",
            "Stats - Epoch: 79 AUC-val 0.476  AUC-train 0.988\n",
            "Stats - Epoch: 80 AUC-val 0.476  AUC-train 0.987\n",
            "Stats - Epoch: 81 AUC-val 0.481  AUC-train 0.985\n",
            "Stats - Epoch: 82 AUC-val 0.475  AUC-train 0.987\n",
            "Stats - Epoch: 83 AUC-val 0.469  AUC-train 0.986\n",
            "Stats - Epoch: 84 AUC-val 0.480  AUC-train 0.982\n",
            "Stats - Epoch: 85 AUC-val 0.485  AUC-train 0.985\n",
            "Stats - Epoch: 86 AUC-val 0.484  AUC-train 0.984\n",
            "Stats - Epoch: 87 AUC-val 0.473  AUC-train 0.987\n",
            "Stats - Epoch: 88 AUC-val 0.480  AUC-train 0.984\n",
            "Stats - Epoch: 89 AUC-val 0.473  AUC-train 0.985\n",
            "Stats - Epoch: 90 AUC-val 0.485  AUC-train 0.984\n",
            "Stats - Epoch: 91 AUC-val 0.468  AUC-train 0.985\n",
            "Stats - Epoch: 92 AUC-val 0.483  AUC-train 0.984\n",
            "Stats - Epoch: 93 AUC-val 0.484  AUC-train 0.983\n",
            "Stats - Epoch: 94 AUC-val 0.461  AUC-train 0.985\n",
            "Stats - Epoch: 95 AUC-val 0.485  AUC-train 0.982\n",
            "Stats - Epoch: 96 AUC-val 0.472  AUC-train 0.983\n",
            "Stats - Epoch: 97 AUC-val 0.488  AUC-train 0.982\n",
            "Stats - Epoch: 98 AUC-val 0.462  AUC-train 0.986\n",
            "Stats - Epoch: 99 AUC-val 0.478  AUC-train 0.985\n",
            "Stats - Epoch: 100 AUC-val 0.479  AUC-train 0.985\n",
            "Results 100 AUC-val 0.490 0.277 0.116 0.146 0.721 AUC-train 0.995\n",
            "Shapley [0.00742617 0.00643231 0.01006306 0.02588766 0.01519626] [0.0110572]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.162100\n",
            "         Iterations 10\n",
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.396  AUC-train 0.486\n",
            "Stats - Epoch: 2 AUC-val 0.377  AUC-train 0.579\n",
            "Stats - Epoch: 3 AUC-val 0.368  AUC-train 0.677\n",
            "Stats - Epoch: 4 AUC-val 0.398  AUC-train 0.735\n",
            "Stats - Epoch: 5 AUC-val 0.434  AUC-train 0.776\n",
            "Stats - Epoch: 6 AUC-val 0.454  AUC-train 0.811\n",
            "Stats - Epoch: 7 AUC-val 0.515  AUC-train 0.839\n",
            "Stats - Epoch: 8 AUC-val 0.461  AUC-train 0.856\n",
            "Stats - Epoch: 9 AUC-val 0.485  AUC-train 0.871\n",
            "Stats - Epoch: 10 AUC-val 0.500  AUC-train 0.886\n",
            "Stats - Epoch: 11 AUC-val 0.499  AUC-train 0.894\n",
            "Stats - Epoch: 12 AUC-val 0.519  AUC-train 0.900\n",
            "Stats - Epoch: 13 AUC-val 0.507  AUC-train 0.906\n",
            "Stats - Epoch: 14 AUC-val 0.555  AUC-train 0.910\n",
            "Stats - Epoch: 15 AUC-val 0.570  AUC-train 0.911\n",
            "Stats - Epoch: 16 AUC-val 0.527  AUC-train 0.913\n",
            "Stats - Epoch: 17 AUC-val 0.510  AUC-train 0.918\n",
            "Stats - Epoch: 18 AUC-val 0.531  AUC-train 0.923\n",
            "Stats - Epoch: 19 AUC-val 0.576  AUC-train 0.924\n",
            "Stats - Epoch: 20 AUC-val 0.526  AUC-train 0.927\n",
            "Stats - Epoch: 21 AUC-val 0.537  AUC-train 0.930\n",
            "Stats - Epoch: 22 AUC-val 0.533  AUC-train 0.930\n",
            "Stats - Epoch: 23 AUC-val 0.532  AUC-train 0.932\n",
            "Stats - Epoch: 24 AUC-val 0.562  AUC-train 0.932\n",
            "Stats - Epoch: 25 AUC-val 0.549  AUC-train 0.931\n",
            "Stats - Epoch: 26 AUC-val 0.540  AUC-train 0.937\n",
            "Stats - Epoch: 27 AUC-val 0.547  AUC-train 0.938\n",
            "Stats - Epoch: 28 AUC-val 0.531  AUC-train 0.937\n",
            "Stats - Epoch: 29 AUC-val 0.505  AUC-train 0.934\n",
            "Stats - Epoch: 30 AUC-val 0.529  AUC-train 0.935\n",
            "Stats - Epoch: 31 AUC-val 0.528  AUC-train 0.940\n",
            "Stats - Epoch: 32 AUC-val 0.524  AUC-train 0.942\n",
            "Stats - Epoch: 33 AUC-val 0.513  AUC-train 0.942\n",
            "Stats - Epoch: 34 AUC-val 0.528  AUC-train 0.941\n",
            "Stats - Epoch: 35 AUC-val 0.520  AUC-train 0.943\n",
            "Stats - Epoch: 36 AUC-val 0.544  AUC-train 0.945\n",
            "Stats - Epoch: 37 AUC-val 0.533  AUC-train 0.946\n",
            "Stats - Epoch: 38 AUC-val 0.523  AUC-train 0.947\n",
            "Stats - Epoch: 39 AUC-val 0.558  AUC-train 0.945\n",
            "Stats - Epoch: 40 AUC-val 0.560  AUC-train 0.947\n",
            "Stats - Epoch: 41 AUC-val 0.522  AUC-train 0.946\n",
            "Stats - Epoch: 42 AUC-val 0.511  AUC-train 0.952\n",
            "Stats - Epoch: 43 AUC-val 0.516  AUC-train 0.949\n",
            "Stats - Epoch: 44 AUC-val 0.506  AUC-train 0.949\n",
            "Stats - Epoch: 45 AUC-val 0.496  AUC-train 0.946\n",
            "Stats - Epoch: 46 AUC-val 0.525  AUC-train 0.949\n",
            "Stats - Epoch: 47 AUC-val 0.534  AUC-train 0.948\n",
            "Stats - Epoch: 48 AUC-val 0.527  AUC-train 0.947\n",
            "Stats - Epoch: 49 AUC-val 0.505  AUC-train 0.951\n",
            "Stats - Epoch: 50 AUC-val 0.524  AUC-train 0.948\n",
            "Stats - Epoch: 51 AUC-val 0.507  AUC-train 0.951\n",
            "Stats - Epoch: 52 AUC-val 0.519  AUC-train 0.954\n",
            "Stats - Epoch: 53 AUC-val 0.518  AUC-train 0.954\n",
            "Stats - Epoch: 54 AUC-val 0.511  AUC-train 0.955\n",
            "Stats - Epoch: 55 AUC-val 0.521  AUC-train 0.957\n",
            "Stats - Epoch: 56 AUC-val 0.502  AUC-train 0.956\n",
            "Stats - Epoch: 57 AUC-val 0.516  AUC-train 0.957\n",
            "Stats - Epoch: 58 AUC-val 0.498  AUC-train 0.953\n",
            "Stats - Epoch: 59 AUC-val 0.533  AUC-train 0.953\n",
            "Stats - Epoch: 60 AUC-val 0.493  AUC-train 0.955\n",
            "Stats - Epoch: 61 AUC-val 0.499  AUC-train 0.956\n",
            "Stats - Epoch: 62 AUC-val 0.494  AUC-train 0.951\n",
            "Stats - Epoch: 63 AUC-val 0.498  AUC-train 0.952\n",
            "Stats - Epoch: 64 AUC-val 0.511  AUC-train 0.954\n",
            "Stats - Epoch: 65 AUC-val 0.493  AUC-train 0.957\n",
            "Stats - Epoch: 66 AUC-val 0.491  AUC-train 0.958\n",
            "Stats - Epoch: 67 AUC-val 0.497  AUC-train 0.957\n",
            "Stats - Epoch: 68 AUC-val 0.486  AUC-train 0.958\n",
            "Stats - Epoch: 69 AUC-val 0.495  AUC-train 0.957\n",
            "Stats - Epoch: 70 AUC-val 0.496  AUC-train 0.958\n",
            "Stats - Epoch: 71 AUC-val 0.511  AUC-train 0.959\n",
            "Stats - Epoch: 72 AUC-val 0.504  AUC-train 0.956\n",
            "Stats - Epoch: 73 AUC-val 0.511  AUC-train 0.956\n",
            "Stats - Epoch: 74 AUC-val 0.520  AUC-train 0.954\n",
            "Stats - Epoch: 75 AUC-val 0.526  AUC-train 0.957\n",
            "Stats - Epoch: 76 AUC-val 0.541  AUC-train 0.957\n",
            "Stats - Epoch: 77 AUC-val 0.529  AUC-train 0.959\n",
            "Stats - Epoch: 78 AUC-val 0.508  AUC-train 0.957\n",
            "Stats - Epoch: 79 AUC-val 0.505  AUC-train 0.955\n",
            "Stats - Epoch: 80 AUC-val 0.536  AUC-train 0.954\n",
            "Stats - Epoch: 81 AUC-val 0.525  AUC-train 0.957\n",
            "Stats - Epoch: 82 AUC-val 0.498  AUC-train 0.957\n",
            "Stats - Epoch: 83 AUC-val 0.521  AUC-train 0.957\n",
            "Stats - Epoch: 84 AUC-val 0.521  AUC-train 0.959\n",
            "Stats - Epoch: 85 AUC-val 0.516  AUC-train 0.955\n",
            "Stats - Epoch: 86 AUC-val 0.523  AUC-train 0.957\n",
            "Stats - Epoch: 87 AUC-val 0.524  AUC-train 0.959\n",
            "Stats - Epoch: 88 AUC-val 0.552  AUC-train 0.960\n",
            "Stats - Epoch: 89 AUC-val 0.555  AUC-train 0.960\n",
            "Stats - Epoch: 90 AUC-val 0.517  AUC-train 0.961\n",
            "Stats - Epoch: 91 AUC-val 0.510  AUC-train 0.961\n",
            "Stats - Epoch: 92 AUC-val 0.512  AUC-train 0.959\n",
            "Stats - Epoch: 93 AUC-val 0.513  AUC-train 0.961\n",
            "Stats - Epoch: 94 AUC-val 0.529  AUC-train 0.961\n",
            "Stats - Epoch: 95 AUC-val 0.538  AUC-train 0.958\n",
            "Stats - Epoch: 96 AUC-val 0.531  AUC-train 0.957\n",
            "Stats - Epoch: 97 AUC-val 0.524  AUC-train 0.956\n",
            "Stats - Epoch: 98 AUC-val 0.512  AUC-train 0.958\n",
            "Stats - Epoch: 99 AUC-val 0.520  AUC-train 0.958\n",
            "Stats - Epoch: 100 AUC-val 0.521  AUC-train 0.960\n",
            "Results 100 AUC-val 0.576 0.596 0.610 0.617 0.661 AUC-train 0.924\n",
            "Shapley [0.00382364 0.00487047 0.01085754 0.0052856  0.00507494] [0.00407913]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.180591\n",
            "         Iterations 9\n",
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.438  AUC-train 0.505\n",
            "Stats - Epoch: 2 AUC-val 0.555  AUC-train 0.742\n",
            "Stats - Epoch: 3 AUC-val 0.642  AUC-train 0.866\n",
            "Stats - Epoch: 4 AUC-val 0.668  AUC-train 0.911\n",
            "Stats - Epoch: 5 AUC-val 0.673  AUC-train 0.931\n",
            "Stats - Epoch: 6 AUC-val 0.676  AUC-train 0.941\n",
            "Stats - Epoch: 7 AUC-val 0.684  AUC-train 0.952\n",
            "Stats - Epoch: 8 AUC-val 0.687  AUC-train 0.959\n",
            "Stats - Epoch: 9 AUC-val 0.684  AUC-train 0.965\n",
            "Stats - Epoch: 10 AUC-val 0.673  AUC-train 0.972\n",
            "Stats - Epoch: 11 AUC-val 0.666  AUC-train 0.974\n",
            "Stats - Epoch: 12 AUC-val 0.681  AUC-train 0.976\n",
            "Stats - Epoch: 13 AUC-val 0.679  AUC-train 0.979\n",
            "Stats - Epoch: 14 AUC-val 0.686  AUC-train 0.980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.683  AUC-train 0.983\n",
            "Stats - Epoch: 16 AUC-val 0.690  AUC-train 0.982\n",
            "Stats - Epoch: 17 AUC-val 0.684  AUC-train 0.984\n",
            "Stats - Epoch: 18 AUC-val 0.686  AUC-train 0.986\n",
            "Stats - Epoch: 19 AUC-val 0.682  AUC-train 0.986\n",
            "Stats - Epoch: 20 AUC-val 0.682  AUC-train 0.989\n",
            "Stats - Epoch: 21 AUC-val 0.688  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.684  AUC-train 0.989\n",
            "Stats - Epoch: 23 AUC-val 0.697  AUC-train 0.990\n",
            "Stats - Epoch: 24 AUC-val 0.672  AUC-train 0.988\n",
            "Stats - Epoch: 25 AUC-val 0.684  AUC-train 0.990\n",
            "Stats - Epoch: 26 AUC-val 0.695  AUC-train 0.990\n",
            "Stats - Epoch: 27 AUC-val 0.672  AUC-train 0.990\n",
            "Stats - Epoch: 28 AUC-val 0.680  AUC-train 0.992\n",
            "Stats - Epoch: 29 AUC-val 0.679  AUC-train 0.993\n",
            "Stats - Epoch: 30 AUC-val 0.681  AUC-train 0.993\n",
            "Stats - Epoch: 31 AUC-val 0.691  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.674  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.660  AUC-train 0.992\n",
            "Stats - Epoch: 34 AUC-val 0.683  AUC-train 0.992\n",
            "Stats - Epoch: 35 AUC-val 0.680  AUC-train 0.994\n",
            "Stats - Epoch: 36 AUC-val 0.692  AUC-train 0.994\n",
            "Stats - Epoch: 37 AUC-val 0.679  AUC-train 0.995\n",
            "Stats - Epoch: 38 AUC-val 0.684  AUC-train 0.994\n",
            "Stats - Epoch: 39 AUC-val 0.672  AUC-train 0.994\n",
            "Stats - Epoch: 40 AUC-val 0.676  AUC-train 0.995\n",
            "Stats - Epoch: 41 AUC-val 0.685  AUC-train 0.995\n",
            "Stats - Epoch: 42 AUC-val 0.691  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.685  AUC-train 0.996\n",
            "Stats - Epoch: 44 AUC-val 0.665  AUC-train 0.995\n",
            "Stats - Epoch: 45 AUC-val 0.663  AUC-train 0.995\n",
            "Stats - Epoch: 46 AUC-val 0.671  AUC-train 0.994\n",
            "Stats - Epoch: 47 AUC-val 0.676  AUC-train 0.994\n",
            "Stats - Epoch: 48 AUC-val 0.662  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.667  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.678  AUC-train 0.994\n",
            "Stats - Epoch: 51 AUC-val 0.653  AUC-train 0.995\n",
            "Stats - Epoch: 52 AUC-val 0.658  AUC-train 0.995\n",
            "Stats - Epoch: 53 AUC-val 0.654  AUC-train 0.996\n",
            "Stats - Epoch: 54 AUC-val 0.660  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.671  AUC-train 0.996\n",
            "Stats - Epoch: 56 AUC-val 0.653  AUC-train 0.996\n",
            "Stats - Epoch: 57 AUC-val 0.695  AUC-train 0.996\n",
            "Stats - Epoch: 58 AUC-val 0.702  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.661  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.686  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.670  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.675  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.675  AUC-train 0.996\n",
            "Stats - Epoch: 64 AUC-val 0.650  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.691  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.661  AUC-train 0.997\n",
            "Stats - Epoch: 67 AUC-val 0.654  AUC-train 0.997\n",
            "Stats - Epoch: 68 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.665  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.655  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.663  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.662  AUC-train 0.996\n",
            "Stats - Epoch: 74 AUC-val 0.672  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.675  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.686  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.683  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.685  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 80 AUC-val 0.654  AUC-train 0.996\n",
            "Stats - Epoch: 81 AUC-val 0.667  AUC-train 0.996\n",
            "Stats - Epoch: 82 AUC-val 0.653  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.653  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.675  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.670  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.676  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.667  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.655  AUC-train 0.994\n",
            "Stats - Epoch: 89 AUC-val 0.650  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.635  AUC-train 0.995\n",
            "Stats - Epoch: 91 AUC-val 0.642  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.653  AUC-train 0.992\n",
            "Stats - Epoch: 94 AUC-val 0.650  AUC-train 0.995\n",
            "Stats - Epoch: 95 AUC-val 0.678  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.652  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.663  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.634  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.627  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.650  AUC-train 0.997\n",
            "Results 100 AUC-val 0.702 0.554 0.404 0.434 0.637 AUC-train 0.997\n",
            "Shapley [0.01224264 0.01034526 0.0218475  0.03341372 0.02714032] [0.0030542]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.179788\n",
            "         Iterations 8\n",
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.431  AUC-train 0.511\n",
            "Stats - Epoch: 2 AUC-val 0.494  AUC-train 0.696\n",
            "Stats - Epoch: 3 AUC-val 0.550  AUC-train 0.789\n",
            "Stats - Epoch: 4 AUC-val 0.598  AUC-train 0.847\n",
            "Stats - Epoch: 5 AUC-val 0.593  AUC-train 0.880\n",
            "Stats - Epoch: 6 AUC-val 0.605  AUC-train 0.901\n",
            "Stats - Epoch: 7 AUC-val 0.608  AUC-train 0.922\n",
            "Stats - Epoch: 8 AUC-val 0.613  AUC-train 0.934\n",
            "Stats - Epoch: 9 AUC-val 0.624  AUC-train 0.945\n",
            "Stats - Epoch: 10 AUC-val 0.620  AUC-train 0.954\n",
            "Stats - Epoch: 11 AUC-val 0.625  AUC-train 0.964\n",
            "Stats - Epoch: 12 AUC-val 0.623  AUC-train 0.972\n",
            "Stats - Epoch: 13 AUC-val 0.628  AUC-train 0.975\n",
            "Stats - Epoch: 14 AUC-val 0.627  AUC-train 0.978\n",
            "Stats - Epoch: 15 AUC-val 0.602  AUC-train 0.982\n",
            "Stats - Epoch: 16 AUC-val 0.618  AUC-train 0.982\n",
            "Stats - Epoch: 17 AUC-val 0.629  AUC-train 0.985\n",
            "Stats - Epoch: 18 AUC-val 0.630  AUC-train 0.987\n",
            "Stats - Epoch: 19 AUC-val 0.633  AUC-train 0.990\n",
            "Stats - Epoch: 20 AUC-val 0.628  AUC-train 0.991\n",
            "Stats - Epoch: 21 AUC-val 0.632  AUC-train 0.992\n",
            "Stats - Epoch: 22 AUC-val 0.633  AUC-train 0.992\n",
            "Stats - Epoch: 23 AUC-val 0.628  AUC-train 0.994\n",
            "Stats - Epoch: 24 AUC-val 0.608  AUC-train 0.994\n",
            "Stats - Epoch: 25 AUC-val 0.628  AUC-train 0.995\n",
            "Stats - Epoch: 26 AUC-val 0.629  AUC-train 0.995\n",
            "Stats - Epoch: 27 AUC-val 0.644  AUC-train 0.996\n",
            "Stats - Epoch: 28 AUC-val 0.653  AUC-train 0.996\n",
            "Stats - Epoch: 29 AUC-val 0.658  AUC-train 0.996\n",
            "Stats - Epoch: 30 AUC-val 0.635  AUC-train 0.996\n",
            "Stats - Epoch: 31 AUC-val 0.629  AUC-train 0.996\n",
            "Stats - Epoch: 32 AUC-val 0.624  AUC-train 0.995\n",
            "Stats - Epoch: 33 AUC-val 0.626  AUC-train 0.996\n",
            "Stats - Epoch: 34 AUC-val 0.649  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.620  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 39 AUC-val 0.656  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.648  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.652  AUC-train 0.997\n",
            "Stats - Epoch: 42 AUC-val 0.667  AUC-train 0.992\n",
            "Stats - Epoch: 43 AUC-val 0.638  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.656  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.649  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.651  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.647  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.656  AUC-train 0.998\n",
            "Stats - Epoch: 64 AUC-val 0.665  AUC-train 0.997\n",
            "Stats - Epoch: 65 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 67 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 70 AUC-val 0.670  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.654  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.630  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.629  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.649  AUC-train 0.998\n",
            "Stats - Epoch: 76 AUC-val 0.647  AUC-train 0.999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.633  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.637  AUC-train 1.000\n",
            "Stats - Epoch: 81 AUC-val 0.643  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.631  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.638  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.616  AUC-train 0.994\n",
            "Stats - Epoch: 85 AUC-val 0.641  AUC-train 0.995\n",
            "Stats - Epoch: 86 AUC-val 0.618  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.591  AUC-train 0.996\n",
            "Stats - Epoch: 88 AUC-val 0.606  AUC-train 0.995\n",
            "Stats - Epoch: 89 AUC-val 0.596  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.612  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.608  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.628  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.647  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.621  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.637  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.662  AUC-train 0.995\n",
            "Stats - Epoch: 98 AUC-val 0.645  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.644  AUC-train 0.995\n",
            "Stats - Epoch: 100 AUC-val 0.626  AUC-train 0.994\n",
            "Results 100 AUC-val 0.685 0.631 0.508 0.438 0.599 AUC-train 0.999\n",
            "Shapley [0.00741742 0.00527114 0.01823871 0.02108131 0.01186833] [0.00370721]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.178130\n",
            "         Iterations 8\n",
            "Crises train:7\n",
            "Crises test:17\n",
            "Stats - Epoch: 1 AUC-val 0.353  AUC-train 0.636\n",
            "Stats - Epoch: 2 AUC-val 0.526  AUC-train 0.889\n",
            "Stats - Epoch: 3 AUC-val 0.577  AUC-train 0.945\n",
            "Stats - Epoch: 4 AUC-val 0.588  AUC-train 0.966\n",
            "Stats - Epoch: 5 AUC-val 0.595  AUC-train 0.978\n",
            "Stats - Epoch: 6 AUC-val 0.596  AUC-train 0.982\n",
            "Stats - Epoch: 7 AUC-val 0.609  AUC-train 0.988\n",
            "Stats - Epoch: 8 AUC-val 0.612  AUC-train 0.992\n",
            "Stats - Epoch: 9 AUC-val 0.616  AUC-train 0.994\n",
            "Stats - Epoch: 10 AUC-val 0.615  AUC-train 0.996\n",
            "Stats - Epoch: 11 AUC-val 0.610  AUC-train 0.997\n",
            "Stats - Epoch: 12 AUC-val 0.625  AUC-train 0.998\n",
            "Stats - Epoch: 13 AUC-val 0.613  AUC-train 0.998\n",
            "Stats - Epoch: 14 AUC-val 0.595  AUC-train 0.998\n",
            "Stats - Epoch: 15 AUC-val 0.620  AUC-train 0.998\n",
            "Stats - Epoch: 16 AUC-val 0.591  AUC-train 0.999\n",
            "Stats - Epoch: 17 AUC-val 0.593  AUC-train 0.999\n",
            "Stats - Epoch: 18 AUC-val 0.604  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.603  AUC-train 1.000\n",
            "Stats - Epoch: 20 AUC-val 0.602  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.578  AUC-train 1.000\n",
            "Stats - Epoch: 22 AUC-val 0.592  AUC-train 1.000\n",
            "Stats - Epoch: 23 AUC-val 0.585  AUC-train 1.000\n",
            "Stats - Epoch: 24 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.574  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.575  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.579  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.608  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.591  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.571  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.591  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.585  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.597  AUC-train 1.000\n",
            "Stats - Epoch: 34 AUC-val 0.575  AUC-train 1.000\n",
            "Stats - Epoch: 35 AUC-val 0.542  AUC-train 1.000\n",
            "Stats - Epoch: 36 AUC-val 0.571  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.579  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.593  AUC-train 1.000\n",
            "Stats - Epoch: 39 AUC-val 0.584  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.605  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.573  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.554  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.545  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.597  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.589  AUC-train 1.000\n",
            "Stats - Epoch: 46 AUC-val 0.551  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.566  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.571  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.557  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.549  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.533  AUC-train 0.998\n",
            "Stats - Epoch: 52 AUC-val 0.533  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.555  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.545  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.536  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.524  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.572  AUC-train 0.997\n",
            "Stats - Epoch: 58 AUC-val 0.566  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.574  AUC-train 0.998\n",
            "Stats - Epoch: 60 AUC-val 0.574  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.570  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.559  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.535  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.557  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.539  AUC-train 1.000\n",
            "Stats - Epoch: 66 AUC-val 0.563  AUC-train 1.000\n",
            "Stats - Epoch: 67 AUC-val 0.561  AUC-train 1.000\n",
            "Stats - Epoch: 68 AUC-val 0.563  AUC-train 1.000\n",
            "Stats - Epoch: 69 AUC-val 0.563  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.573  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.576  AUC-train 0.999\n",
            "Stats - Epoch: 72 AUC-val 0.580  AUC-train 1.000\n",
            "Stats - Epoch: 73 AUC-val 0.585  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.548  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.592  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.548  AUC-train 0.998\n",
            "Stats - Epoch: 77 AUC-val 0.578  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.554  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.575  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.583  AUC-train 1.000\n",
            "Stats - Epoch: 81 AUC-val 0.551  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.548  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.572  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.547  AUC-train 0.995\n",
            "Stats - Epoch: 85 AUC-val 0.548  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.558  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.537  AUC-train 1.000\n",
            "Stats - Epoch: 88 AUC-val 0.541  AUC-train 1.000\n",
            "Stats - Epoch: 89 AUC-val 0.550  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.546  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.533  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.543  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.545  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.549  AUC-train 1.000\n",
            "Stats - Epoch: 95 AUC-val 0.586  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.540  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.551  AUC-train 0.999\n",
            "Stats - Epoch: 98 AUC-val 0.548  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.581  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.566  AUC-train 0.999\n",
            "Results 100 AUC-val 0.625 0.505 0.492 0.527 0.639 AUC-train 0.998\n",
            "Shapley [0.01419113 0.01439358 0.03207519 0.04358115 0.03330973] [0.00162986]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.176970\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlh9RVQ5tapv"
      },
      "source": [
        "# Sequential evaluation, longer horizons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbSgfC9ctapv",
        "outputId": "d2ce4002-b14e-407e-e3e3-3831243cc070"
      },
      "source": [
        "    # Simulation params\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/seq_fc_2345_reps50.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    epochs = 100;\n",
        "    for fcast_horizon in [2,3,4,5]:\n",
        "        dates =[1970,1999,2000,2016] #[1970,2016]\n",
        "        train_end_year=dates[1];\n",
        "        train_start_year=dates[0];\n",
        "        test_start_year=dates[2]; # Define test set\n",
        "        test_end_year=dates[3];\n",
        "        reps=50;\n",
        "        \n",
        "    \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "        \n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,reg_weight=[0.0],nlags=1,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=1,reps=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,reg_weight=[0.0],nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=1,reps=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();     \n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=2,nlags=1,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=2,nlags=5,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();        \n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=3,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,epochs=epochs,do_shapley=True));       \n",
        "        #f.write(\"\\n\");f.flush();\n",
        "    \n",
        "f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.592  AUC-train 0.794\n",
            "Results 1 AUC-val 0.586 0.592 0.700 0.558 0.632 AUC-train 0.794\n",
            "Shapley [0.00926852 0.00849775 0.01385959 0.00014899 0.00617076] [0.01440522]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.180899\n",
            "         Iterations 18\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.243  AUC-train 0.917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.543 0.243 0.285 0.507 0.699 AUC-train 0.917\n",
            "Shapley [0.03229282 0.00968519 0.00812244 0.0324561  0.01912601] [0.00441971]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.164567\n",
            "         Iterations 15\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.387  AUC-train 0.553\n",
            "Stats - Epoch: 2 AUC-val 0.516  AUC-train 0.664\n",
            "Stats - Epoch: 3 AUC-val 0.540  AUC-train 0.729\n",
            "Stats - Epoch: 4 AUC-val 0.567  AUC-train 0.770\n",
            "Stats - Epoch: 5 AUC-val 0.578  AUC-train 0.798\n",
            "Stats - Epoch: 6 AUC-val 0.589  AUC-train 0.818\n",
            "Stats - Epoch: 7 AUC-val 0.586  AUC-train 0.833\n",
            "Stats - Epoch: 8 AUC-val 0.592  AUC-train 0.845\n",
            "Stats - Epoch: 9 AUC-val 0.603  AUC-train 0.854\n",
            "Stats - Epoch: 10 AUC-val 0.596  AUC-train 0.859\n",
            "Stats - Epoch: 11 AUC-val 0.610  AUC-train 0.870\n",
            "Stats - Epoch: 12 AUC-val 0.603  AUC-train 0.875\n",
            "Stats - Epoch: 13 AUC-val 0.619  AUC-train 0.882\n",
            "Stats - Epoch: 14 AUC-val 0.613  AUC-train 0.887\n",
            "Stats - Epoch: 15 AUC-val 0.623  AUC-train 0.890\n",
            "Stats - Epoch: 16 AUC-val 0.620  AUC-train 0.894\n",
            "Stats - Epoch: 17 AUC-val 0.623  AUC-train 0.898\n",
            "Stats - Epoch: 18 AUC-val 0.621  AUC-train 0.899\n",
            "Stats - Epoch: 19 AUC-val 0.616  AUC-train 0.901\n",
            "Stats - Epoch: 20 AUC-val 0.627  AUC-train 0.905\n",
            "Stats - Epoch: 21 AUC-val 0.635  AUC-train 0.908\n",
            "Stats - Epoch: 22 AUC-val 0.628  AUC-train 0.908\n",
            "Stats - Epoch: 23 AUC-val 0.634  AUC-train 0.912\n",
            "Stats - Epoch: 24 AUC-val 0.641  AUC-train 0.914\n",
            "Stats - Epoch: 25 AUC-val 0.630  AUC-train 0.913\n",
            "Stats - Epoch: 26 AUC-val 0.640  AUC-train 0.915\n",
            "Stats - Epoch: 27 AUC-val 0.639  AUC-train 0.911\n",
            "Stats - Epoch: 28 AUC-val 0.633  AUC-train 0.912\n",
            "Stats - Epoch: 29 AUC-val 0.650  AUC-train 0.917\n",
            "Stats - Epoch: 30 AUC-val 0.639  AUC-train 0.920\n",
            "Stats - Epoch: 31 AUC-val 0.640  AUC-train 0.920\n",
            "Stats - Epoch: 32 AUC-val 0.644  AUC-train 0.918\n",
            "Stats - Epoch: 33 AUC-val 0.645  AUC-train 0.921\n",
            "Stats - Epoch: 34 AUC-val 0.638  AUC-train 0.925\n",
            "Stats - Epoch: 35 AUC-val 0.645  AUC-train 0.918\n",
            "Stats - Epoch: 36 AUC-val 0.643  AUC-train 0.917\n",
            "Stats - Epoch: 37 AUC-val 0.639  AUC-train 0.927\n",
            "Stats - Epoch: 38 AUC-val 0.650  AUC-train 0.924\n",
            "Stats - Epoch: 39 AUC-val 0.647  AUC-train 0.928\n",
            "Stats - Epoch: 40 AUC-val 0.654  AUC-train 0.928\n",
            "Stats - Epoch: 41 AUC-val 0.659  AUC-train 0.928\n",
            "Stats - Epoch: 42 AUC-val 0.655  AUC-train 0.927\n",
            "Stats - Epoch: 43 AUC-val 0.647  AUC-train 0.930\n",
            "Stats - Epoch: 44 AUC-val 0.646  AUC-train 0.929\n",
            "Stats - Epoch: 45 AUC-val 0.654  AUC-train 0.925\n",
            "Stats - Epoch: 46 AUC-val 0.652  AUC-train 0.931\n",
            "Stats - Epoch: 47 AUC-val 0.654  AUC-train 0.930\n",
            "Stats - Epoch: 48 AUC-val 0.656  AUC-train 0.929\n",
            "Stats - Epoch: 49 AUC-val 0.650  AUC-train 0.933\n",
            "Stats - Epoch: 50 AUC-val 0.647  AUC-train 0.935\n",
            "Stats - Epoch: 51 AUC-val 0.659  AUC-train 0.933\n",
            "Stats - Epoch: 52 AUC-val 0.651  AUC-train 0.928\n",
            "Stats - Epoch: 53 AUC-val 0.653  AUC-train 0.933\n",
            "Stats - Epoch: 54 AUC-val 0.654  AUC-train 0.932\n",
            "Stats - Epoch: 55 AUC-val 0.653  AUC-train 0.931\n",
            "Stats - Epoch: 56 AUC-val 0.656  AUC-train 0.933\n",
            "Stats - Epoch: 57 AUC-val 0.655  AUC-train 0.932\n",
            "Stats - Epoch: 58 AUC-val 0.658  AUC-train 0.934\n",
            "Stats - Epoch: 59 AUC-val 0.650  AUC-train 0.932\n",
            "Stats - Epoch: 60 AUC-val 0.667  AUC-train 0.935\n",
            "Stats - Epoch: 61 AUC-val 0.654  AUC-train 0.932\n",
            "Stats - Epoch: 62 AUC-val 0.656  AUC-train 0.935\n",
            "Stats - Epoch: 63 AUC-val 0.653  AUC-train 0.937\n",
            "Stats - Epoch: 64 AUC-val 0.667  AUC-train 0.936\n",
            "Stats - Epoch: 65 AUC-val 0.658  AUC-train 0.931\n",
            "Stats - Epoch: 66 AUC-val 0.653  AUC-train 0.938\n",
            "Stats - Epoch: 67 AUC-val 0.669  AUC-train 0.935\n",
            "Stats - Epoch: 68 AUC-val 0.655  AUC-train 0.935\n",
            "Stats - Epoch: 69 AUC-val 0.656  AUC-train 0.939\n",
            "Stats - Epoch: 70 AUC-val 0.658  AUC-train 0.938\n",
            "Stats - Epoch: 71 AUC-val 0.657  AUC-train 0.938\n",
            "Stats - Epoch: 72 AUC-val 0.651  AUC-train 0.938\n",
            "Stats - Epoch: 73 AUC-val 0.657  AUC-train 0.939\n",
            "Stats - Epoch: 74 AUC-val 0.658  AUC-train 0.939\n",
            "Stats - Epoch: 75 AUC-val 0.659  AUC-train 0.940\n",
            "Stats - Epoch: 76 AUC-val 0.651  AUC-train 0.941\n",
            "Stats - Epoch: 77 AUC-val 0.660  AUC-train 0.940\n",
            "Stats - Epoch: 78 AUC-val 0.664  AUC-train 0.939\n",
            "Stats - Epoch: 79 AUC-val 0.662  AUC-train 0.937\n",
            "Stats - Epoch: 80 AUC-val 0.666  AUC-train 0.940\n",
            "Stats - Epoch: 81 AUC-val 0.654  AUC-train 0.943\n",
            "Stats - Epoch: 82 AUC-val 0.668  AUC-train 0.938\n",
            "Stats - Epoch: 83 AUC-val 0.657  AUC-train 0.940\n",
            "Stats - Epoch: 84 AUC-val 0.663  AUC-train 0.940\n",
            "Stats - Epoch: 85 AUC-val 0.658  AUC-train 0.937\n",
            "Stats - Epoch: 86 AUC-val 0.656  AUC-train 0.940\n",
            "Stats - Epoch: 87 AUC-val 0.655  AUC-train 0.942\n",
            "Stats - Epoch: 88 AUC-val 0.655  AUC-train 0.941\n",
            "Stats - Epoch: 89 AUC-val 0.654  AUC-train 0.941\n",
            "Stats - Epoch: 90 AUC-val 0.660  AUC-train 0.939\n",
            "Stats - Epoch: 91 AUC-val 0.652  AUC-train 0.942\n",
            "Stats - Epoch: 92 AUC-val 0.649  AUC-train 0.944\n",
            "Stats - Epoch: 93 AUC-val 0.665  AUC-train 0.941\n",
            "Stats - Epoch: 94 AUC-val 0.651  AUC-train 0.943\n",
            "Stats - Epoch: 95 AUC-val 0.660  AUC-train 0.939\n",
            "Stats - Epoch: 96 AUC-val 0.657  AUC-train 0.941\n",
            "Stats - Epoch: 97 AUC-val 0.655  AUC-train 0.944\n",
            "Stats - Epoch: 98 AUC-val 0.663  AUC-train 0.940\n",
            "Stats - Epoch: 99 AUC-val 0.647  AUC-train 0.943\n",
            "Stats - Epoch: 100 AUC-val 0.662  AUC-train 0.943\n",
            "Results 100 AUC-val 0.652 0.669 0.764 0.564 0.499 AUC-train 0.935\n",
            "Shapley [0.02078019 0.01597589 0.02374964 0.02118888 0.01571073] [0.05521168]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.194825\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.273  AUC-train 0.508\n",
            "Stats - Epoch: 2 AUC-val 0.253  AUC-train 0.708\n",
            "Stats - Epoch: 3 AUC-val 0.261  AUC-train 0.823\n",
            "Stats - Epoch: 4 AUC-val 0.243  AUC-train 0.879\n",
            "Stats - Epoch: 5 AUC-val 0.249  AUC-train 0.918\n",
            "Stats - Epoch: 6 AUC-val 0.239  AUC-train 0.948\n",
            "Stats - Epoch: 7 AUC-val 0.252  AUC-train 0.960\n",
            "Stats - Epoch: 8 AUC-val 0.269  AUC-train 0.969\n",
            "Stats - Epoch: 9 AUC-val 0.281  AUC-train 0.972\n",
            "Stats - Epoch: 10 AUC-val 0.310  AUC-train 0.978\n",
            "Stats - Epoch: 11 AUC-val 0.309  AUC-train 0.984\n",
            "Stats - Epoch: 12 AUC-val 0.321  AUC-train 0.988\n",
            "Stats - Epoch: 13 AUC-val 0.321  AUC-train 0.987\n",
            "Stats - Epoch: 14 AUC-val 0.316  AUC-train 0.990\n",
            "Stats - Epoch: 15 AUC-val 0.336  AUC-train 0.989\n",
            "Stats - Epoch: 16 AUC-val 0.344  AUC-train 0.990\n",
            "Stats - Epoch: 17 AUC-val 0.351  AUC-train 0.991\n",
            "Stats - Epoch: 18 AUC-val 0.346  AUC-train 0.990\n",
            "Stats - Epoch: 19 AUC-val 0.347  AUC-train 0.988\n",
            "Stats - Epoch: 20 AUC-val 0.366  AUC-train 0.991\n",
            "Stats - Epoch: 21 AUC-val 0.373  AUC-train 0.992\n",
            "Stats - Epoch: 22 AUC-val 0.383  AUC-train 0.992\n",
            "Stats - Epoch: 23 AUC-val 0.363  AUC-train 0.990\n",
            "Stats - Epoch: 24 AUC-val 0.390  AUC-train 0.991\n",
            "Stats - Epoch: 25 AUC-val 0.411  AUC-train 0.991\n",
            "Stats - Epoch: 26 AUC-val 0.423  AUC-train 0.991\n",
            "Stats - Epoch: 27 AUC-val 0.396  AUC-train 0.992\n",
            "Stats - Epoch: 28 AUC-val 0.397  AUC-train 0.993\n",
            "Stats - Epoch: 29 AUC-val 0.409  AUC-train 0.994\n",
            "Stats - Epoch: 30 AUC-val 0.420  AUC-train 0.994\n",
            "Stats - Epoch: 31 AUC-val 0.428  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.429  AUC-train 0.992\n",
            "Stats - Epoch: 33 AUC-val 0.419  AUC-train 0.992\n",
            "Stats - Epoch: 34 AUC-val 0.436  AUC-train 0.992\n",
            "Stats - Epoch: 35 AUC-val 0.429  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.431  AUC-train 0.991\n",
            "Stats - Epoch: 37 AUC-val 0.435  AUC-train 0.993\n",
            "Stats - Epoch: 38 AUC-val 0.472  AUC-train 0.993\n",
            "Stats - Epoch: 39 AUC-val 0.420  AUC-train 0.992\n",
            "Stats - Epoch: 40 AUC-val 0.445  AUC-train 0.993\n",
            "Stats - Epoch: 41 AUC-val 0.447  AUC-train 0.993\n",
            "Stats - Epoch: 42 AUC-val 0.450  AUC-train 0.994\n",
            "Stats - Epoch: 43 AUC-val 0.475  AUC-train 0.993\n",
            "Stats - Epoch: 44 AUC-val 0.445  AUC-train 0.992\n",
            "Stats - Epoch: 45 AUC-val 0.450  AUC-train 0.990\n",
            "Stats - Epoch: 46 AUC-val 0.451  AUC-train 0.991\n",
            "Stats - Epoch: 47 AUC-val 0.466  AUC-train 0.991\n",
            "Stats - Epoch: 48 AUC-val 0.440  AUC-train 0.991\n",
            "Stats - Epoch: 49 AUC-val 0.460  AUC-train 0.992\n",
            "Stats - Epoch: 50 AUC-val 0.466  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.455  AUC-train 0.989\n",
            "Stats - Epoch: 52 AUC-val 0.443  AUC-train 0.990\n",
            "Stats - Epoch: 53 AUC-val 0.452  AUC-train 0.991\n",
            "Stats - Epoch: 54 AUC-val 0.444  AUC-train 0.991\n",
            "Stats - Epoch: 55 AUC-val 0.452  AUC-train 0.990\n",
            "Stats - Epoch: 56 AUC-val 0.452  AUC-train 0.991\n",
            "Stats - Epoch: 57 AUC-val 0.473  AUC-train 0.990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.461  AUC-train 0.991\n",
            "Stats - Epoch: 59 AUC-val 0.459  AUC-train 0.989\n",
            "Stats - Epoch: 60 AUC-val 0.450  AUC-train 0.989\n",
            "Stats - Epoch: 61 AUC-val 0.452  AUC-train 0.990\n",
            "Stats - Epoch: 62 AUC-val 0.471  AUC-train 0.991\n",
            "Stats - Epoch: 63 AUC-val 0.468  AUC-train 0.989\n",
            "Stats - Epoch: 64 AUC-val 0.468  AUC-train 0.989\n",
            "Stats - Epoch: 65 AUC-val 0.462  AUC-train 0.990\n",
            "Stats - Epoch: 66 AUC-val 0.464  AUC-train 0.990\n",
            "Stats - Epoch: 67 AUC-val 0.464  AUC-train 0.990\n",
            "Stats - Epoch: 68 AUC-val 0.472  AUC-train 0.989\n",
            "Stats - Epoch: 69 AUC-val 0.459  AUC-train 0.989\n",
            "Stats - Epoch: 70 AUC-val 0.465  AUC-train 0.989\n",
            "Stats - Epoch: 71 AUC-val 0.477  AUC-train 0.991\n",
            "Stats - Epoch: 72 AUC-val 0.473  AUC-train 0.989\n",
            "Stats - Epoch: 73 AUC-val 0.474  AUC-train 0.989\n",
            "Stats - Epoch: 74 AUC-val 0.454  AUC-train 0.989\n",
            "Stats - Epoch: 75 AUC-val 0.464  AUC-train 0.987\n",
            "Stats - Epoch: 76 AUC-val 0.468  AUC-train 0.989\n",
            "Stats - Epoch: 77 AUC-val 0.466  AUC-train 0.988\n",
            "Stats - Epoch: 78 AUC-val 0.463  AUC-train 0.987\n",
            "Stats - Epoch: 79 AUC-val 0.475  AUC-train 0.988\n",
            "Stats - Epoch: 80 AUC-val 0.472  AUC-train 0.989\n",
            "Stats - Epoch: 81 AUC-val 0.468  AUC-train 0.989\n",
            "Stats - Epoch: 82 AUC-val 0.472  AUC-train 0.989\n",
            "Stats - Epoch: 83 AUC-val 0.452  AUC-train 0.988\n",
            "Stats - Epoch: 84 AUC-val 0.451  AUC-train 0.989\n",
            "Stats - Epoch: 85 AUC-val 0.466  AUC-train 0.990\n",
            "Stats - Epoch: 86 AUC-val 0.455  AUC-train 0.990\n",
            "Stats - Epoch: 87 AUC-val 0.463  AUC-train 0.986\n",
            "Stats - Epoch: 88 AUC-val 0.463  AUC-train 0.989\n",
            "Stats - Epoch: 89 AUC-val 0.461  AUC-train 0.988\n",
            "Stats - Epoch: 90 AUC-val 0.456  AUC-train 0.989\n",
            "Stats - Epoch: 91 AUC-val 0.468  AUC-train 0.987\n",
            "Stats - Epoch: 92 AUC-val 0.460  AUC-train 0.989\n",
            "Stats - Epoch: 93 AUC-val 0.465  AUC-train 0.987\n",
            "Stats - Epoch: 94 AUC-val 0.472  AUC-train 0.990\n",
            "Stats - Epoch: 95 AUC-val 0.474  AUC-train 0.988\n",
            "Stats - Epoch: 96 AUC-val 0.457  AUC-train 0.987\n",
            "Stats - Epoch: 97 AUC-val 0.477  AUC-train 0.989\n",
            "Stats - Epoch: 98 AUC-val 0.454  AUC-train 0.988\n",
            "Stats - Epoch: 99 AUC-val 0.485  AUC-train 0.987\n",
            "Stats - Epoch: 100 AUC-val 0.463  AUC-train 0.988\n",
            "Results 100 AUC-val 0.692 0.485 0.568 0.723 0.215 AUC-train 0.987\n",
            "Shapley [0.02776191 0.01643696 0.00595091 0.04056532 0.01036215] [0.03882794]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.193500\n",
            "         Iterations 9\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.264  AUC-train 0.514\n",
            "Stats - Epoch: 2 AUC-val 0.334  AUC-train 0.587\n",
            "Stats - Epoch: 3 AUC-val 0.443  AUC-train 0.683\n",
            "Stats - Epoch: 4 AUC-val 0.518  AUC-train 0.743\n",
            "Stats - Epoch: 5 AUC-val 0.584  AUC-train 0.779\n",
            "Stats - Epoch: 6 AUC-val 0.601  AUC-train 0.816\n",
            "Stats - Epoch: 7 AUC-val 0.613  AUC-train 0.836\n",
            "Stats - Epoch: 8 AUC-val 0.627  AUC-train 0.855\n",
            "Stats - Epoch: 9 AUC-val 0.658  AUC-train 0.869\n",
            "Stats - Epoch: 10 AUC-val 0.659  AUC-train 0.881\n",
            "Stats - Epoch: 11 AUC-val 0.649  AUC-train 0.887\n",
            "Stats - Epoch: 12 AUC-val 0.682  AUC-train 0.895\n",
            "Stats - Epoch: 13 AUC-val 0.676  AUC-train 0.899\n",
            "Stats - Epoch: 14 AUC-val 0.666  AUC-train 0.909\n",
            "Stats - Epoch: 15 AUC-val 0.675  AUC-train 0.912\n",
            "Stats - Epoch: 16 AUC-val 0.676  AUC-train 0.915\n",
            "Stats - Epoch: 17 AUC-val 0.665  AUC-train 0.918\n",
            "Stats - Epoch: 18 AUC-val 0.666  AUC-train 0.921\n",
            "Stats - Epoch: 19 AUC-val 0.665  AUC-train 0.921\n",
            "Stats - Epoch: 20 AUC-val 0.650  AUC-train 0.924\n",
            "Stats - Epoch: 21 AUC-val 0.675  AUC-train 0.927\n",
            "Stats - Epoch: 22 AUC-val 0.659  AUC-train 0.934\n",
            "Stats - Epoch: 23 AUC-val 0.656  AUC-train 0.937\n",
            "Stats - Epoch: 24 AUC-val 0.671  AUC-train 0.935\n",
            "Stats - Epoch: 25 AUC-val 0.665  AUC-train 0.939\n",
            "Stats - Epoch: 26 AUC-val 0.679  AUC-train 0.938\n",
            "Stats - Epoch: 27 AUC-val 0.675  AUC-train 0.942\n",
            "Stats - Epoch: 28 AUC-val 0.653  AUC-train 0.948\n",
            "Stats - Epoch: 29 AUC-val 0.689  AUC-train 0.945\n",
            "Stats - Epoch: 30 AUC-val 0.656  AUC-train 0.948\n",
            "Stats - Epoch: 31 AUC-val 0.659  AUC-train 0.952\n",
            "Stats - Epoch: 32 AUC-val 0.679  AUC-train 0.956\n",
            "Stats - Epoch: 33 AUC-val 0.649  AUC-train 0.957\n",
            "Stats - Epoch: 34 AUC-val 0.646  AUC-train 0.959\n",
            "Stats - Epoch: 35 AUC-val 0.669  AUC-train 0.961\n",
            "Stats - Epoch: 36 AUC-val 0.663  AUC-train 0.962\n",
            "Stats - Epoch: 37 AUC-val 0.681  AUC-train 0.960\n",
            "Stats - Epoch: 38 AUC-val 0.654  AUC-train 0.962\n",
            "Stats - Epoch: 39 AUC-val 0.651  AUC-train 0.961\n",
            "Stats - Epoch: 40 AUC-val 0.665  AUC-train 0.960\n",
            "Stats - Epoch: 41 AUC-val 0.647  AUC-train 0.963\n",
            "Stats - Epoch: 42 AUC-val 0.666  AUC-train 0.964\n",
            "Stats - Epoch: 43 AUC-val 0.667  AUC-train 0.964\n",
            "Stats - Epoch: 44 AUC-val 0.670  AUC-train 0.965\n",
            "Stats - Epoch: 45 AUC-val 0.649  AUC-train 0.967\n",
            "Stats - Epoch: 46 AUC-val 0.657  AUC-train 0.965\n",
            "Stats - Epoch: 47 AUC-val 0.665  AUC-train 0.966\n",
            "Stats - Epoch: 48 AUC-val 0.666  AUC-train 0.970\n",
            "Stats - Epoch: 49 AUC-val 0.669  AUC-train 0.972\n",
            "Stats - Epoch: 50 AUC-val 0.631  AUC-train 0.971\n",
            "Stats - Epoch: 51 AUC-val 0.644  AUC-train 0.971\n",
            "Stats - Epoch: 52 AUC-val 0.612  AUC-train 0.972\n",
            "Stats - Epoch: 53 AUC-val 0.647  AUC-train 0.977\n",
            "Stats - Epoch: 54 AUC-val 0.662  AUC-train 0.974\n",
            "Stats - Epoch: 55 AUC-val 0.679  AUC-train 0.974\n",
            "Stats - Epoch: 56 AUC-val 0.666  AUC-train 0.974\n",
            "Stats - Epoch: 57 AUC-val 0.661  AUC-train 0.976\n",
            "Stats - Epoch: 58 AUC-val 0.653  AUC-train 0.974\n",
            "Stats - Epoch: 59 AUC-val 0.649  AUC-train 0.974\n",
            "Stats - Epoch: 60 AUC-val 0.646  AUC-train 0.973\n",
            "Stats - Epoch: 61 AUC-val 0.663  AUC-train 0.970\n",
            "Stats - Epoch: 62 AUC-val 0.652  AUC-train 0.969\n",
            "Stats - Epoch: 63 AUC-val 0.637  AUC-train 0.968\n",
            "Stats - Epoch: 64 AUC-val 0.654  AUC-train 0.969\n",
            "Stats - Epoch: 65 AUC-val 0.652  AUC-train 0.973\n",
            "Stats - Epoch: 66 AUC-val 0.657  AUC-train 0.968\n",
            "Stats - Epoch: 67 AUC-val 0.632  AUC-train 0.974\n",
            "Stats - Epoch: 68 AUC-val 0.654  AUC-train 0.973\n",
            "Stats - Epoch: 69 AUC-val 0.638  AUC-train 0.974\n",
            "Stats - Epoch: 70 AUC-val 0.663  AUC-train 0.975\n",
            "Stats - Epoch: 71 AUC-val 0.634  AUC-train 0.977\n",
            "Stats - Epoch: 72 AUC-val 0.671  AUC-train 0.978\n",
            "Stats - Epoch: 73 AUC-val 0.651  AUC-train 0.979\n",
            "Stats - Epoch: 74 AUC-val 0.663  AUC-train 0.978\n",
            "Stats - Epoch: 75 AUC-val 0.645  AUC-train 0.977\n",
            "Stats - Epoch: 76 AUC-val 0.661  AUC-train 0.979\n",
            "Stats - Epoch: 77 AUC-val 0.656  AUC-train 0.980\n",
            "Stats - Epoch: 78 AUC-val 0.667  AUC-train 0.979\n",
            "Stats - Epoch: 79 AUC-val 0.669  AUC-train 0.981\n",
            "Stats - Epoch: 80 AUC-val 0.646  AUC-train 0.981\n",
            "Stats - Epoch: 81 AUC-val 0.672  AUC-train 0.982\n",
            "Stats - Epoch: 82 AUC-val 0.686  AUC-train 0.980\n",
            "Stats - Epoch: 83 AUC-val 0.663  AUC-train 0.981\n",
            "Stats - Epoch: 84 AUC-val 0.661  AUC-train 0.979\n",
            "Stats - Epoch: 85 AUC-val 0.660  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.672  AUC-train 0.980\n",
            "Stats - Epoch: 87 AUC-val 0.662  AUC-train 0.977\n",
            "Stats - Epoch: 88 AUC-val 0.667  AUC-train 0.981\n",
            "Stats - Epoch: 89 AUC-val 0.656  AUC-train 0.981\n",
            "Stats - Epoch: 90 AUC-val 0.672  AUC-train 0.979\n",
            "Stats - Epoch: 91 AUC-val 0.687  AUC-train 0.982\n",
            "Stats - Epoch: 92 AUC-val 0.660  AUC-train 0.984\n",
            "Stats - Epoch: 93 AUC-val 0.686  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.692  AUC-train 0.982\n",
            "Stats - Epoch: 95 AUC-val 0.674  AUC-train 0.982\n",
            "Stats - Epoch: 96 AUC-val 0.650  AUC-train 0.982\n",
            "Stats - Epoch: 97 AUC-val 0.679  AUC-train 0.981\n",
            "Stats - Epoch: 98 AUC-val 0.660  AUC-train 0.982\n",
            "Stats - Epoch: 99 AUC-val 0.640  AUC-train 0.984\n",
            "Stats - Epoch: 100 AUC-val 0.648  AUC-train 0.985\n",
            "Results 100 AUC-val 0.638 0.692 0.731 0.617 0.602 AUC-train 0.982\n",
            "Shapley [0.01299845 0.01525818 0.01070086 0.01303363 0.0075532 ] [0.00502505]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.202240\n",
            "         Iterations 7\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.302  AUC-train 0.530\n",
            "Stats - Epoch: 2 AUC-val 0.544  AUC-train 0.752\n",
            "Stats - Epoch: 3 AUC-val 0.675  AUC-train 0.831\n",
            "Stats - Epoch: 4 AUC-val 0.697  AUC-train 0.869\n",
            "Stats - Epoch: 5 AUC-val 0.693  AUC-train 0.893\n",
            "Stats - Epoch: 6 AUC-val 0.702  AUC-train 0.915\n",
            "Stats - Epoch: 7 AUC-val 0.713  AUC-train 0.929\n",
            "Stats - Epoch: 8 AUC-val 0.718  AUC-train 0.942\n",
            "Stats - Epoch: 9 AUC-val 0.734  AUC-train 0.948\n",
            "Stats - Epoch: 10 AUC-val 0.753  AUC-train 0.957\n",
            "Stats - Epoch: 11 AUC-val 0.750  AUC-train 0.962\n",
            "Stats - Epoch: 12 AUC-val 0.746  AUC-train 0.966\n",
            "Stats - Epoch: 13 AUC-val 0.734  AUC-train 0.974\n",
            "Stats - Epoch: 14 AUC-val 0.736  AUC-train 0.975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.731  AUC-train 0.977\n",
            "Stats - Epoch: 16 AUC-val 0.739  AUC-train 0.980\n",
            "Stats - Epoch: 17 AUC-val 0.729  AUC-train 0.982\n",
            "Stats - Epoch: 18 AUC-val 0.737  AUC-train 0.983\n",
            "Stats - Epoch: 19 AUC-val 0.737  AUC-train 0.986\n",
            "Stats - Epoch: 20 AUC-val 0.737  AUC-train 0.988\n",
            "Stats - Epoch: 21 AUC-val 0.736  AUC-train 0.989\n",
            "Stats - Epoch: 22 AUC-val 0.744  AUC-train 0.990\n",
            "Stats - Epoch: 23 AUC-val 0.722  AUC-train 0.991\n",
            "Stats - Epoch: 24 AUC-val 0.745  AUC-train 0.992\n",
            "Stats - Epoch: 25 AUC-val 0.759  AUC-train 0.992\n",
            "Stats - Epoch: 26 AUC-val 0.728  AUC-train 0.994\n",
            "Stats - Epoch: 27 AUC-val 0.757  AUC-train 0.994\n",
            "Stats - Epoch: 28 AUC-val 0.750  AUC-train 0.995\n",
            "Stats - Epoch: 29 AUC-val 0.749  AUC-train 0.995\n",
            "Stats - Epoch: 30 AUC-val 0.746  AUC-train 0.994\n",
            "Stats - Epoch: 31 AUC-val 0.751  AUC-train 0.996\n",
            "Stats - Epoch: 32 AUC-val 0.732  AUC-train 0.996\n",
            "Stats - Epoch: 33 AUC-val 0.757  AUC-train 0.997\n",
            "Stats - Epoch: 34 AUC-val 0.754  AUC-train 0.994\n",
            "Stats - Epoch: 35 AUC-val 0.758  AUC-train 0.996\n",
            "Stats - Epoch: 36 AUC-val 0.750  AUC-train 0.997\n",
            "Stats - Epoch: 37 AUC-val 0.745  AUC-train 0.997\n",
            "Stats - Epoch: 38 AUC-val 0.743  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.760  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.751  AUC-train 0.996\n",
            "Stats - Epoch: 41 AUC-val 0.754  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.748  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.738  AUC-train 0.996\n",
            "Stats - Epoch: 44 AUC-val 0.752  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.737  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.732  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.734  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.751  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.726  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.766  AUC-train 0.997\n",
            "Stats - Epoch: 51 AUC-val 0.737  AUC-train 0.997\n",
            "Stats - Epoch: 52 AUC-val 0.730  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.730  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.744  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.734  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.710  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.753  AUC-train 0.997\n",
            "Stats - Epoch: 58 AUC-val 0.753  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.761  AUC-train 0.997\n",
            "Stats - Epoch: 60 AUC-val 0.765  AUC-train 0.997\n",
            "Stats - Epoch: 61 AUC-val 0.726  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.734  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.762  AUC-train 0.997\n",
            "Stats - Epoch: 64 AUC-val 0.766  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.768  AUC-train 0.998\n",
            "Stats - Epoch: 66 AUC-val 0.764  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.757  AUC-train 0.997\n",
            "Stats - Epoch: 68 AUC-val 0.764  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.756  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.746  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.756  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.774  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.761  AUC-train 0.998\n",
            "Stats - Epoch: 74 AUC-val 0.752  AUC-train 0.999\n",
            "Stats - Epoch: 75 AUC-val 0.743  AUC-train 0.998\n",
            "Stats - Epoch: 76 AUC-val 0.764  AUC-train 0.997\n",
            "Stats - Epoch: 77 AUC-val 0.765  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.755  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.757  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.775  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.773  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.754  AUC-train 0.999\n",
            "Stats - Epoch: 83 AUC-val 0.756  AUC-train 0.999\n",
            "Stats - Epoch: 84 AUC-val 0.756  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.760  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.781  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.783  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.760  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.775  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.766  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.753  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.729  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.752  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.749  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.735  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.725  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.740  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.753  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.767  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.776  AUC-train 0.998\n",
            "Results 100 AUC-val 0.729 0.783 0.705 0.637 0.562 AUC-train 0.999\n",
            "Shapley [0.01782868 0.01947296 0.01258564 0.02520235 0.00865592] [0.00658139]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.169149\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.388  AUC-train 0.513\n",
            "Stats - Epoch: 2 AUC-val 0.494  AUC-train 0.669\n",
            "Stats - Epoch: 3 AUC-val 0.563  AUC-train 0.767\n",
            "Stats - Epoch: 4 AUC-val 0.622  AUC-train 0.825\n",
            "Stats - Epoch: 5 AUC-val 0.662  AUC-train 0.863\n",
            "Stats - Epoch: 6 AUC-val 0.679  AUC-train 0.896\n",
            "Stats - Epoch: 7 AUC-val 0.695  AUC-train 0.916\n",
            "Stats - Epoch: 8 AUC-val 0.713  AUC-train 0.927\n",
            "Stats - Epoch: 9 AUC-val 0.740  AUC-train 0.940\n",
            "Stats - Epoch: 10 AUC-val 0.733  AUC-train 0.950\n",
            "Stats - Epoch: 11 AUC-val 0.753  AUC-train 0.959\n",
            "Stats - Epoch: 12 AUC-val 0.750  AUC-train 0.966\n",
            "Stats - Epoch: 13 AUC-val 0.764  AUC-train 0.973\n",
            "Stats - Epoch: 14 AUC-val 0.781  AUC-train 0.977\n",
            "Stats - Epoch: 15 AUC-val 0.791  AUC-train 0.979\n",
            "Stats - Epoch: 16 AUC-val 0.778  AUC-train 0.984\n",
            "Stats - Epoch: 17 AUC-val 0.787  AUC-train 0.985\n",
            "Stats - Epoch: 18 AUC-val 0.792  AUC-train 0.988\n",
            "Stats - Epoch: 19 AUC-val 0.799  AUC-train 0.989\n",
            "Stats - Epoch: 20 AUC-val 0.787  AUC-train 0.989\n",
            "Stats - Epoch: 21 AUC-val 0.814  AUC-train 0.991\n",
            "Stats - Epoch: 22 AUC-val 0.812  AUC-train 0.991\n",
            "Stats - Epoch: 23 AUC-val 0.805  AUC-train 0.993\n",
            "Stats - Epoch: 24 AUC-val 0.814  AUC-train 0.995\n",
            "Stats - Epoch: 25 AUC-val 0.800  AUC-train 0.995\n",
            "Stats - Epoch: 26 AUC-val 0.809  AUC-train 0.995\n",
            "Stats - Epoch: 27 AUC-val 0.805  AUC-train 0.996\n",
            "Stats - Epoch: 28 AUC-val 0.837  AUC-train 0.997\n",
            "Stats - Epoch: 29 AUC-val 0.850  AUC-train 0.996\n",
            "Stats - Epoch: 30 AUC-val 0.815  AUC-train 0.997\n",
            "Stats - Epoch: 31 AUC-val 0.824  AUC-train 0.997\n",
            "Stats - Epoch: 32 AUC-val 0.829  AUC-train 0.998\n",
            "Stats - Epoch: 33 AUC-val 0.831  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.815  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.819  AUC-train 0.997\n",
            "Stats - Epoch: 36 AUC-val 0.822  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.807  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.814  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.832  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.821  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.830  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.813  AUC-train 0.996\n",
            "Stats - Epoch: 43 AUC-val 0.823  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.800  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.810  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.817  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.823  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.819  AUC-train 0.997\n",
            "Stats - Epoch: 49 AUC-val 0.812  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.821  AUC-train 0.997\n",
            "Stats - Epoch: 51 AUC-val 0.810  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.830  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.814  AUC-train 0.997\n",
            "Stats - Epoch: 54 AUC-val 0.813  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.810  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.813  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.834  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.835  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.848  AUC-train 0.998\n",
            "Stats - Epoch: 60 AUC-val 0.826  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.830  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.810  AUC-train 1.000\n",
            "Stats - Epoch: 63 AUC-val 0.815  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.815  AUC-train 0.999\n",
            "Stats - Epoch: 65 AUC-val 0.812  AUC-train 1.000\n",
            "Stats - Epoch: 66 AUC-val 0.798  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.808  AUC-train 1.000\n",
            "Stats - Epoch: 68 AUC-val 0.826  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.811  AUC-train 0.998\n",
            "Stats - Epoch: 70 AUC-val 0.794  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.796  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.799  AUC-train 0.999\n",
            "Stats - Epoch: 73 AUC-val 0.798  AUC-train 0.998\n",
            "Stats - Epoch: 74 AUC-val 0.823  AUC-train 0.999\n",
            "Stats - Epoch: 75 AUC-val 0.816  AUC-train 0.998\n",
            "Stats - Epoch: 76 AUC-val 0.803  AUC-train 0.998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.803  AUC-train 0.995\n",
            "Stats - Epoch: 78 AUC-val 0.809  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.798  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.790  AUC-train 0.994\n",
            "Stats - Epoch: 81 AUC-val 0.801  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.824  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.811  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.798  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.803  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.791  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.822  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.780  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.809  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.830  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.807  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.805  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.817  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.826  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.806  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.806  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.818  AUC-train 0.998\n",
            "Stats - Epoch: 98 AUC-val 0.818  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.821  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.787  AUC-train 0.998\n",
            "Results 100 AUC-val 0.764 0.850 0.838 0.629 0.599 AUC-train 0.996\n",
            "Shapley [0.01428098 0.02642814 0.01615955 0.02915838 0.01426717] [0.00502302]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.144658\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.256  AUC-train 0.680\n",
            "Stats - Epoch: 2 AUC-val 0.632  AUC-train 0.881\n",
            "Stats - Epoch: 3 AUC-val 0.642  AUC-train 0.935\n",
            "Stats - Epoch: 4 AUC-val 0.665  AUC-train 0.961\n",
            "Stats - Epoch: 5 AUC-val 0.667  AUC-train 0.974\n",
            "Stats - Epoch: 6 AUC-val 0.667  AUC-train 0.981\n",
            "Stats - Epoch: 7 AUC-val 0.679  AUC-train 0.986\n",
            "Stats - Epoch: 8 AUC-val 0.695  AUC-train 0.990\n",
            "Stats - Epoch: 9 AUC-val 0.700  AUC-train 0.991\n",
            "Stats - Epoch: 10 AUC-val 0.721  AUC-train 0.994\n",
            "Stats - Epoch: 11 AUC-val 0.715  AUC-train 0.996\n",
            "Stats - Epoch: 12 AUC-val 0.715  AUC-train 0.997\n",
            "Stats - Epoch: 13 AUC-val 0.730  AUC-train 0.998\n",
            "Stats - Epoch: 14 AUC-val 0.725  AUC-train 0.998\n",
            "Stats - Epoch: 15 AUC-val 0.738  AUC-train 0.999\n",
            "Stats - Epoch: 16 AUC-val 0.739  AUC-train 0.999\n",
            "Stats - Epoch: 17 AUC-val 0.740  AUC-train 0.999\n",
            "Stats - Epoch: 18 AUC-val 0.745  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.734  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.729  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.731  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.755  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.741  AUC-train 1.000\n",
            "Stats - Epoch: 24 AUC-val 0.731  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.734  AUC-train 1.000\n",
            "Stats - Epoch: 26 AUC-val 0.753  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.754  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.773  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.775  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.768  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.776  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.757  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.768  AUC-train 1.000\n",
            "Stats - Epoch: 34 AUC-val 0.762  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.772  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.759  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.779  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.785  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.771  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.765  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.775  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.761  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.759  AUC-train 1.000\n",
            "Stats - Epoch: 44 AUC-val 0.768  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.755  AUC-train 1.000\n",
            "Stats - Epoch: 46 AUC-val 0.756  AUC-train 1.000\n",
            "Stats - Epoch: 47 AUC-val 0.776  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.745  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.766  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.754  AUC-train 1.000\n",
            "Stats - Epoch: 51 AUC-val 0.753  AUC-train 1.000\n",
            "Stats - Epoch: 52 AUC-val 0.743  AUC-train 1.000\n",
            "Stats - Epoch: 53 AUC-val 0.748  AUC-train 1.000\n",
            "Stats - Epoch: 54 AUC-val 0.759  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.742  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.763  AUC-train 1.000\n",
            "Stats - Epoch: 57 AUC-val 0.741  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.743  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.744  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.738  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.732  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.756  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.739  AUC-train 0.998\n",
            "Stats - Epoch: 64 AUC-val 0.776  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.768  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.773  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.751  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.772  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.768  AUC-train 0.998\n",
            "Stats - Epoch: 70 AUC-val 0.774  AUC-train 1.000\n",
            "Stats - Epoch: 71 AUC-val 0.773  AUC-train 1.000\n",
            "Stats - Epoch: 72 AUC-val 0.785  AUC-train 1.000\n",
            "Stats - Epoch: 73 AUC-val 0.789  AUC-train 1.000\n",
            "Stats - Epoch: 74 AUC-val 0.764  AUC-train 1.000\n",
            "Stats - Epoch: 75 AUC-val 0.788  AUC-train 1.000\n",
            "Stats - Epoch: 76 AUC-val 0.796  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.785  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.793  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.769  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.776  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.791  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.803  AUC-train 0.999\n",
            "Stats - Epoch: 83 AUC-val 0.796  AUC-train 1.000\n",
            "Stats - Epoch: 84 AUC-val 0.801  AUC-train 1.000\n",
            "Stats - Epoch: 85 AUC-val 0.792  AUC-train 1.000\n",
            "Stats - Epoch: 86 AUC-val 0.792  AUC-train 1.000\n",
            "Stats - Epoch: 87 AUC-val 0.787  AUC-train 1.000\n",
            "Stats - Epoch: 88 AUC-val 0.801  AUC-train 1.000\n",
            "Stats - Epoch: 89 AUC-val 0.810  AUC-train 1.000\n",
            "Stats - Epoch: 90 AUC-val 0.811  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.810  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.785  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.763  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.773  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.775  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.764  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.790  AUC-train 1.000\n",
            "Stats - Epoch: 98 AUC-val 0.789  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.803  AUC-train 1.000\n",
            "Stats - Epoch: 100 AUC-val 0.796  AUC-train 0.998\n",
            "Results 100 AUC-val 0.718 0.811 0.731 0.631 0.418 AUC-train 0.998\n",
            "Shapley [0.0194913  0.02794991 0.01318734 0.02321751 0.00593368] [0.00031049]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.136503\n",
            "         Iterations 9\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.716  AUC-train 0.679\n",
            "Results 1 AUC-val 0.630 0.668 0.716 0.635 0.556 AUC-train 0.679\n",
            "Shapley [0.00815217 0.00653983 0.00010995 0.00028626 0.00219292] [0.02073148]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.178664\n",
            "         Iterations 15\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.251  AUC-train 0.852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.569 0.505 0.251 0.202 0.673 AUC-train 0.852\n",
            "Shapley [0.02460304 0.01162309 0.01147766 0.02459247 0.0086596 ] [0.00587733]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.180410\n",
            "         Iterations 14\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.443  AUC-train 0.443\n",
            "Stats - Epoch: 2 AUC-val 0.590  AUC-train 0.504\n",
            "Stats - Epoch: 3 AUC-val 0.675  AUC-train 0.558\n",
            "Stats - Epoch: 4 AUC-val 0.713  AUC-train 0.595\n",
            "Stats - Epoch: 5 AUC-val 0.729  AUC-train 0.613\n",
            "Stats - Epoch: 6 AUC-val 0.773  AUC-train 0.648\n",
            "Stats - Epoch: 7 AUC-val 0.768  AUC-train 0.663\n",
            "Stats - Epoch: 8 AUC-val 0.781  AUC-train 0.683\n",
            "Stats - Epoch: 9 AUC-val 0.775  AUC-train 0.696\n",
            "Stats - Epoch: 10 AUC-val 0.787  AUC-train 0.709\n",
            "Stats - Epoch: 11 AUC-val 0.773  AUC-train 0.717\n",
            "Stats - Epoch: 12 AUC-val 0.790  AUC-train 0.730\n",
            "Stats - Epoch: 13 AUC-val 0.782  AUC-train 0.736\n",
            "Stats - Epoch: 14 AUC-val 0.790  AUC-train 0.749\n",
            "Stats - Epoch: 15 AUC-val 0.794  AUC-train 0.766\n",
            "Stats - Epoch: 16 AUC-val 0.786  AUC-train 0.768\n",
            "Stats - Epoch: 17 AUC-val 0.795  AUC-train 0.782\n",
            "Stats - Epoch: 18 AUC-val 0.789  AUC-train 0.783\n",
            "Stats - Epoch: 19 AUC-val 0.790  AUC-train 0.799\n",
            "Stats - Epoch: 20 AUC-val 0.798  AUC-train 0.801\n",
            "Stats - Epoch: 21 AUC-val 0.793  AUC-train 0.804\n",
            "Stats - Epoch: 22 AUC-val 0.797  AUC-train 0.812\n",
            "Stats - Epoch: 23 AUC-val 0.781  AUC-train 0.817\n",
            "Stats - Epoch: 24 AUC-val 0.802  AUC-train 0.820\n",
            "Stats - Epoch: 25 AUC-val 0.790  AUC-train 0.816\n",
            "Stats - Epoch: 26 AUC-val 0.776  AUC-train 0.827\n",
            "Stats - Epoch: 27 AUC-val 0.789  AUC-train 0.839\n",
            "Stats - Epoch: 28 AUC-val 0.774  AUC-train 0.839\n",
            "Stats - Epoch: 29 AUC-val 0.761  AUC-train 0.850\n",
            "Stats - Epoch: 30 AUC-val 0.776  AUC-train 0.849\n",
            "Stats - Epoch: 31 AUC-val 0.785  AUC-train 0.855\n",
            "Stats - Epoch: 32 AUC-val 0.772  AUC-train 0.855\n",
            "Stats - Epoch: 33 AUC-val 0.781  AUC-train 0.854\n",
            "Stats - Epoch: 34 AUC-val 0.783  AUC-train 0.856\n",
            "Stats - Epoch: 35 AUC-val 0.779  AUC-train 0.861\n",
            "Stats - Epoch: 36 AUC-val 0.788  AUC-train 0.869\n",
            "Stats - Epoch: 37 AUC-val 0.787  AUC-train 0.864\n",
            "Stats - Epoch: 38 AUC-val 0.778  AUC-train 0.859\n",
            "Stats - Epoch: 39 AUC-val 0.779  AUC-train 0.870\n",
            "Stats - Epoch: 40 AUC-val 0.781  AUC-train 0.875\n",
            "Stats - Epoch: 41 AUC-val 0.787  AUC-train 0.874\n",
            "Stats - Epoch: 42 AUC-val 0.798  AUC-train 0.873\n",
            "Stats - Epoch: 43 AUC-val 0.790  AUC-train 0.881\n",
            "Stats - Epoch: 44 AUC-val 0.768  AUC-train 0.873\n",
            "Stats - Epoch: 45 AUC-val 0.786  AUC-train 0.883\n",
            "Stats - Epoch: 46 AUC-val 0.783  AUC-train 0.883\n",
            "Stats - Epoch: 47 AUC-val 0.778  AUC-train 0.878\n",
            "Stats - Epoch: 48 AUC-val 0.785  AUC-train 0.890\n",
            "Stats - Epoch: 49 AUC-val 0.780  AUC-train 0.888\n",
            "Stats - Epoch: 50 AUC-val 0.791  AUC-train 0.883\n",
            "Stats - Epoch: 51 AUC-val 0.782  AUC-train 0.886\n",
            "Stats - Epoch: 52 AUC-val 0.776  AUC-train 0.883\n",
            "Stats - Epoch: 53 AUC-val 0.788  AUC-train 0.885\n",
            "Stats - Epoch: 54 AUC-val 0.787  AUC-train 0.889\n",
            "Stats - Epoch: 55 AUC-val 0.792  AUC-train 0.890\n",
            "Stats - Epoch: 56 AUC-val 0.783  AUC-train 0.887\n",
            "Stats - Epoch: 57 AUC-val 0.780  AUC-train 0.892\n",
            "Stats - Epoch: 58 AUC-val 0.783  AUC-train 0.896\n",
            "Stats - Epoch: 59 AUC-val 0.785  AUC-train 0.892\n",
            "Stats - Epoch: 60 AUC-val 0.789  AUC-train 0.892\n",
            "Stats - Epoch: 61 AUC-val 0.783  AUC-train 0.892\n",
            "Stats - Epoch: 62 AUC-val 0.784  AUC-train 0.893\n",
            "Stats - Epoch: 63 AUC-val 0.774  AUC-train 0.895\n",
            "Stats - Epoch: 64 AUC-val 0.778  AUC-train 0.899\n",
            "Stats - Epoch: 65 AUC-val 0.782  AUC-train 0.889\n",
            "Stats - Epoch: 66 AUC-val 0.775  AUC-train 0.899\n",
            "Stats - Epoch: 67 AUC-val 0.781  AUC-train 0.897\n",
            "Stats - Epoch: 68 AUC-val 0.779  AUC-train 0.896\n",
            "Stats - Epoch: 69 AUC-val 0.781  AUC-train 0.893\n",
            "Stats - Epoch: 70 AUC-val 0.780  AUC-train 0.891\n",
            "Stats - Epoch: 71 AUC-val 0.796  AUC-train 0.897\n",
            "Stats - Epoch: 72 AUC-val 0.786  AUC-train 0.900\n",
            "Stats - Epoch: 73 AUC-val 0.773  AUC-train 0.901\n",
            "Stats - Epoch: 74 AUC-val 0.792  AUC-train 0.895\n",
            "Stats - Epoch: 75 AUC-val 0.776  AUC-train 0.902\n",
            "Stats - Epoch: 76 AUC-val 0.780  AUC-train 0.904\n",
            "Stats - Epoch: 77 AUC-val 0.782  AUC-train 0.903\n",
            "Stats - Epoch: 78 AUC-val 0.775  AUC-train 0.899\n",
            "Stats - Epoch: 79 AUC-val 0.773  AUC-train 0.907\n",
            "Stats - Epoch: 80 AUC-val 0.789  AUC-train 0.903\n",
            "Stats - Epoch: 81 AUC-val 0.782  AUC-train 0.903\n",
            "Stats - Epoch: 82 AUC-val 0.771  AUC-train 0.899\n",
            "Stats - Epoch: 83 AUC-val 0.788  AUC-train 0.908\n",
            "Stats - Epoch: 84 AUC-val 0.784  AUC-train 0.910\n",
            "Stats - Epoch: 85 AUC-val 0.780  AUC-train 0.904\n",
            "Stats - Epoch: 86 AUC-val 0.772  AUC-train 0.903\n",
            "Stats - Epoch: 87 AUC-val 0.784  AUC-train 0.910\n",
            "Stats - Epoch: 88 AUC-val 0.781  AUC-train 0.898\n",
            "Stats - Epoch: 89 AUC-val 0.779  AUC-train 0.905\n",
            "Stats - Epoch: 90 AUC-val 0.782  AUC-train 0.912\n",
            "Stats - Epoch: 91 AUC-val 0.773  AUC-train 0.904\n",
            "Stats - Epoch: 92 AUC-val 0.776  AUC-train 0.910\n",
            "Stats - Epoch: 93 AUC-val 0.790  AUC-train 0.905\n",
            "Stats - Epoch: 94 AUC-val 0.777  AUC-train 0.912\n",
            "Stats - Epoch: 95 AUC-val 0.781  AUC-train 0.898\n",
            "Stats - Epoch: 96 AUC-val 0.778  AUC-train 0.906\n",
            "Stats - Epoch: 97 AUC-val 0.788  AUC-train 0.915\n",
            "Stats - Epoch: 98 AUC-val 0.774  AUC-train 0.914\n",
            "Stats - Epoch: 99 AUC-val 0.779  AUC-train 0.912\n",
            "Stats - Epoch: 100 AUC-val 0.780  AUC-train 0.917\n",
            "Results 100 AUC-val 0.635 0.701 0.802 0.661 0.415 AUC-train 0.820\n",
            "Shapley [0.01657141 0.0143162  0.00831886 0.02077628 0.01005052] [0.05951477]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.175901\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.565  AUC-train 0.476\n",
            "Stats - Epoch: 2 AUC-val 0.407  AUC-train 0.629\n",
            "Stats - Epoch: 3 AUC-val 0.412  AUC-train 0.731\n",
            "Stats - Epoch: 4 AUC-val 0.357  AUC-train 0.794\n",
            "Stats - Epoch: 5 AUC-val 0.346  AUC-train 0.845\n",
            "Stats - Epoch: 6 AUC-val 0.404  AUC-train 0.878\n",
            "Stats - Epoch: 7 AUC-val 0.388  AUC-train 0.907\n",
            "Stats - Epoch: 8 AUC-val 0.418  AUC-train 0.919\n",
            "Stats - Epoch: 9 AUC-val 0.385  AUC-train 0.934\n",
            "Stats - Epoch: 10 AUC-val 0.442  AUC-train 0.938\n",
            "Stats - Epoch: 11 AUC-val 0.450  AUC-train 0.947\n",
            "Stats - Epoch: 12 AUC-val 0.462  AUC-train 0.951\n",
            "Stats - Epoch: 13 AUC-val 0.508  AUC-train 0.956\n",
            "Stats - Epoch: 14 AUC-val 0.498  AUC-train 0.958\n",
            "Stats - Epoch: 15 AUC-val 0.510  AUC-train 0.960\n",
            "Stats - Epoch: 16 AUC-val 0.521  AUC-train 0.963\n",
            "Stats - Epoch: 17 AUC-val 0.520  AUC-train 0.967\n",
            "Stats - Epoch: 18 AUC-val 0.562  AUC-train 0.964\n",
            "Stats - Epoch: 19 AUC-val 0.537  AUC-train 0.970\n",
            "Stats - Epoch: 20 AUC-val 0.567  AUC-train 0.971\n",
            "Stats - Epoch: 21 AUC-val 0.547  AUC-train 0.965\n",
            "Stats - Epoch: 22 AUC-val 0.548  AUC-train 0.968\n",
            "Stats - Epoch: 23 AUC-val 0.531  AUC-train 0.974\n",
            "Stats - Epoch: 24 AUC-val 0.596  AUC-train 0.973\n",
            "Stats - Epoch: 25 AUC-val 0.563  AUC-train 0.973\n",
            "Stats - Epoch: 26 AUC-val 0.586  AUC-train 0.972\n",
            "Stats - Epoch: 27 AUC-val 0.576  AUC-train 0.973\n",
            "Stats - Epoch: 28 AUC-val 0.577  AUC-train 0.974\n",
            "Stats - Epoch: 29 AUC-val 0.578  AUC-train 0.973\n",
            "Stats - Epoch: 30 AUC-val 0.586  AUC-train 0.974\n",
            "Stats - Epoch: 31 AUC-val 0.567  AUC-train 0.972\n",
            "Stats - Epoch: 32 AUC-val 0.578  AUC-train 0.972\n",
            "Stats - Epoch: 33 AUC-val 0.581  AUC-train 0.974\n",
            "Stats - Epoch: 34 AUC-val 0.588  AUC-train 0.977\n",
            "Stats - Epoch: 35 AUC-val 0.587  AUC-train 0.977\n",
            "Stats - Epoch: 36 AUC-val 0.581  AUC-train 0.975\n",
            "Stats - Epoch: 37 AUC-val 0.592  AUC-train 0.978\n",
            "Stats - Epoch: 38 AUC-val 0.583  AUC-train 0.973\n",
            "Stats - Epoch: 39 AUC-val 0.605  AUC-train 0.976\n",
            "Stats - Epoch: 40 AUC-val 0.577  AUC-train 0.972\n",
            "Stats - Epoch: 41 AUC-val 0.578  AUC-train 0.977\n",
            "Stats - Epoch: 42 AUC-val 0.608  AUC-train 0.975\n",
            "Stats - Epoch: 43 AUC-val 0.582  AUC-train 0.971\n",
            "Stats - Epoch: 44 AUC-val 0.593  AUC-train 0.976\n",
            "Stats - Epoch: 45 AUC-val 0.594  AUC-train 0.974\n",
            "Stats - Epoch: 46 AUC-val 0.588  AUC-train 0.975\n",
            "Stats - Epoch: 47 AUC-val 0.590  AUC-train 0.975\n",
            "Stats - Epoch: 48 AUC-val 0.599  AUC-train 0.976\n",
            "Stats - Epoch: 49 AUC-val 0.586  AUC-train 0.976\n",
            "Stats - Epoch: 50 AUC-val 0.614  AUC-train 0.972\n",
            "Stats - Epoch: 51 AUC-val 0.598  AUC-train 0.974\n",
            "Stats - Epoch: 52 AUC-val 0.620  AUC-train 0.975\n",
            "Stats - Epoch: 53 AUC-val 0.611  AUC-train 0.974\n",
            "Stats - Epoch: 54 AUC-val 0.610  AUC-train 0.974\n",
            "Stats - Epoch: 55 AUC-val 0.606  AUC-train 0.972\n",
            "Stats - Epoch: 56 AUC-val 0.615  AUC-train 0.973\n",
            "Stats - Epoch: 57 AUC-val 0.615  AUC-train 0.975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.616  AUC-train 0.970\n",
            "Stats - Epoch: 59 AUC-val 0.642  AUC-train 0.972\n",
            "Stats - Epoch: 60 AUC-val 0.624  AUC-train 0.974\n",
            "Stats - Epoch: 61 AUC-val 0.647  AUC-train 0.974\n",
            "Stats - Epoch: 62 AUC-val 0.627  AUC-train 0.971\n",
            "Stats - Epoch: 63 AUC-val 0.642  AUC-train 0.970\n",
            "Stats - Epoch: 64 AUC-val 0.623  AUC-train 0.974\n",
            "Stats - Epoch: 65 AUC-val 0.640  AUC-train 0.973\n",
            "Stats - Epoch: 66 AUC-val 0.616  AUC-train 0.974\n",
            "Stats - Epoch: 67 AUC-val 0.626  AUC-train 0.970\n",
            "Stats - Epoch: 68 AUC-val 0.641  AUC-train 0.972\n",
            "Stats - Epoch: 69 AUC-val 0.623  AUC-train 0.972\n",
            "Stats - Epoch: 70 AUC-val 0.631  AUC-train 0.971\n",
            "Stats - Epoch: 71 AUC-val 0.642  AUC-train 0.975\n",
            "Stats - Epoch: 72 AUC-val 0.665  AUC-train 0.972\n",
            "Stats - Epoch: 73 AUC-val 0.656  AUC-train 0.972\n",
            "Stats - Epoch: 74 AUC-val 0.664  AUC-train 0.970\n",
            "Stats - Epoch: 75 AUC-val 0.643  AUC-train 0.972\n",
            "Stats - Epoch: 76 AUC-val 0.658  AUC-train 0.972\n",
            "Stats - Epoch: 77 AUC-val 0.647  AUC-train 0.971\n",
            "Stats - Epoch: 78 AUC-val 0.669  AUC-train 0.972\n",
            "Stats - Epoch: 79 AUC-val 0.665  AUC-train 0.972\n",
            "Stats - Epoch: 80 AUC-val 0.662  AUC-train 0.970\n",
            "Stats - Epoch: 81 AUC-val 0.658  AUC-train 0.972\n",
            "Stats - Epoch: 82 AUC-val 0.665  AUC-train 0.970\n",
            "Stats - Epoch: 83 AUC-val 0.642  AUC-train 0.971\n",
            "Stats - Epoch: 84 AUC-val 0.671  AUC-train 0.973\n",
            "Stats - Epoch: 85 AUC-val 0.668  AUC-train 0.967\n",
            "Stats - Epoch: 86 AUC-val 0.687  AUC-train 0.967\n",
            "Stats - Epoch: 87 AUC-val 0.694  AUC-train 0.970\n",
            "Stats - Epoch: 88 AUC-val 0.664  AUC-train 0.971\n",
            "Stats - Epoch: 89 AUC-val 0.688  AUC-train 0.971\n",
            "Stats - Epoch: 90 AUC-val 0.657  AUC-train 0.971\n",
            "Stats - Epoch: 91 AUC-val 0.681  AUC-train 0.973\n",
            "Stats - Epoch: 92 AUC-val 0.664  AUC-train 0.972\n",
            "Stats - Epoch: 93 AUC-val 0.695  AUC-train 0.974\n",
            "Stats - Epoch: 94 AUC-val 0.692  AUC-train 0.970\n",
            "Stats - Epoch: 95 AUC-val 0.683  AUC-train 0.969\n",
            "Stats - Epoch: 96 AUC-val 0.700  AUC-train 0.971\n",
            "Stats - Epoch: 97 AUC-val 0.678  AUC-train 0.973\n",
            "Stats - Epoch: 98 AUC-val 0.681  AUC-train 0.973\n",
            "Stats - Epoch: 99 AUC-val 0.715  AUC-train 0.974\n",
            "Stats - Epoch: 100 AUC-val 0.699  AUC-train 0.973\n",
            "Results 100 AUC-val 0.661 0.831 0.715 0.476 0.506 AUC-train 0.974\n",
            "Shapley [0.01235501 0.00922552 0.00254486 0.016788   0.00303741] [0.02396288]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.201669\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.247  AUC-train 0.471\n",
            "Stats - Epoch: 2 AUC-val 0.358  AUC-train 0.540\n",
            "Stats - Epoch: 3 AUC-val 0.482  AUC-train 0.621\n",
            "Stats - Epoch: 4 AUC-val 0.567  AUC-train 0.689\n",
            "Stats - Epoch: 5 AUC-val 0.648  AUC-train 0.747\n",
            "Stats - Epoch: 6 AUC-val 0.679  AUC-train 0.781\n",
            "Stats - Epoch: 7 AUC-val 0.685  AUC-train 0.802\n",
            "Stats - Epoch: 8 AUC-val 0.709  AUC-train 0.819\n",
            "Stats - Epoch: 9 AUC-val 0.691  AUC-train 0.837\n",
            "Stats - Epoch: 10 AUC-val 0.691  AUC-train 0.853\n",
            "Stats - Epoch: 11 AUC-val 0.701  AUC-train 0.862\n",
            "Stats - Epoch: 12 AUC-val 0.737  AUC-train 0.873\n",
            "Stats - Epoch: 13 AUC-val 0.692  AUC-train 0.879\n",
            "Stats - Epoch: 14 AUC-val 0.723  AUC-train 0.885\n",
            "Stats - Epoch: 15 AUC-val 0.724  AUC-train 0.892\n",
            "Stats - Epoch: 16 AUC-val 0.713  AUC-train 0.896\n",
            "Stats - Epoch: 17 AUC-val 0.692  AUC-train 0.900\n",
            "Stats - Epoch: 18 AUC-val 0.695  AUC-train 0.899\n",
            "Stats - Epoch: 19 AUC-val 0.697  AUC-train 0.907\n",
            "Stats - Epoch: 20 AUC-val 0.703  AUC-train 0.911\n",
            "Stats - Epoch: 21 AUC-val 0.683  AUC-train 0.913\n",
            "Stats - Epoch: 22 AUC-val 0.694  AUC-train 0.917\n",
            "Stats - Epoch: 23 AUC-val 0.702  AUC-train 0.922\n",
            "Stats - Epoch: 24 AUC-val 0.702  AUC-train 0.922\n",
            "Stats - Epoch: 25 AUC-val 0.684  AUC-train 0.926\n",
            "Stats - Epoch: 26 AUC-val 0.695  AUC-train 0.922\n",
            "Stats - Epoch: 27 AUC-val 0.711  AUC-train 0.927\n",
            "Stats - Epoch: 28 AUC-val 0.718  AUC-train 0.933\n",
            "Stats - Epoch: 29 AUC-val 0.769  AUC-train 0.930\n",
            "Stats - Epoch: 30 AUC-val 0.737  AUC-train 0.933\n",
            "Stats - Epoch: 31 AUC-val 0.722  AUC-train 0.934\n",
            "Stats - Epoch: 32 AUC-val 0.715  AUC-train 0.933\n",
            "Stats - Epoch: 33 AUC-val 0.713  AUC-train 0.934\n",
            "Stats - Epoch: 34 AUC-val 0.736  AUC-train 0.936\n",
            "Stats - Epoch: 35 AUC-val 0.716  AUC-train 0.935\n",
            "Stats - Epoch: 36 AUC-val 0.702  AUC-train 0.939\n",
            "Stats - Epoch: 37 AUC-val 0.682  AUC-train 0.943\n",
            "Stats - Epoch: 38 AUC-val 0.674  AUC-train 0.942\n",
            "Stats - Epoch: 39 AUC-val 0.702  AUC-train 0.943\n",
            "Stats - Epoch: 40 AUC-val 0.695  AUC-train 0.949\n",
            "Stats - Epoch: 41 AUC-val 0.691  AUC-train 0.946\n",
            "Stats - Epoch: 42 AUC-val 0.728  AUC-train 0.945\n",
            "Stats - Epoch: 43 AUC-val 0.680  AUC-train 0.947\n",
            "Stats - Epoch: 44 AUC-val 0.692  AUC-train 0.947\n",
            "Stats - Epoch: 45 AUC-val 0.709  AUC-train 0.946\n",
            "Stats - Epoch: 46 AUC-val 0.712  AUC-train 0.952\n",
            "Stats - Epoch: 47 AUC-val 0.703  AUC-train 0.954\n",
            "Stats - Epoch: 48 AUC-val 0.704  AUC-train 0.953\n",
            "Stats - Epoch: 49 AUC-val 0.705  AUC-train 0.954\n",
            "Stats - Epoch: 50 AUC-val 0.687  AUC-train 0.953\n",
            "Stats - Epoch: 51 AUC-val 0.709  AUC-train 0.950\n",
            "Stats - Epoch: 52 AUC-val 0.717  AUC-train 0.958\n",
            "Stats - Epoch: 53 AUC-val 0.709  AUC-train 0.956\n",
            "Stats - Epoch: 54 AUC-val 0.719  AUC-train 0.957\n",
            "Stats - Epoch: 55 AUC-val 0.709  AUC-train 0.960\n",
            "Stats - Epoch: 56 AUC-val 0.693  AUC-train 0.956\n",
            "Stats - Epoch: 57 AUC-val 0.682  AUC-train 0.958\n",
            "Stats - Epoch: 58 AUC-val 0.705  AUC-train 0.959\n",
            "Stats - Epoch: 59 AUC-val 0.700  AUC-train 0.960\n",
            "Stats - Epoch: 60 AUC-val 0.682  AUC-train 0.962\n",
            "Stats - Epoch: 61 AUC-val 0.695  AUC-train 0.963\n",
            "Stats - Epoch: 62 AUC-val 0.703  AUC-train 0.963\n",
            "Stats - Epoch: 63 AUC-val 0.671  AUC-train 0.964\n",
            "Stats - Epoch: 64 AUC-val 0.709  AUC-train 0.965\n",
            "Stats - Epoch: 65 AUC-val 0.716  AUC-train 0.963\n",
            "Stats - Epoch: 66 AUC-val 0.731  AUC-train 0.962\n",
            "Stats - Epoch: 67 AUC-val 0.699  AUC-train 0.963\n",
            "Stats - Epoch: 68 AUC-val 0.716  AUC-train 0.962\n",
            "Stats - Epoch: 69 AUC-val 0.695  AUC-train 0.964\n",
            "Stats - Epoch: 70 AUC-val 0.697  AUC-train 0.967\n",
            "Stats - Epoch: 71 AUC-val 0.702  AUC-train 0.968\n",
            "Stats - Epoch: 72 AUC-val 0.700  AUC-train 0.966\n",
            "Stats - Epoch: 73 AUC-val 0.703  AUC-train 0.965\n",
            "Stats - Epoch: 74 AUC-val 0.702  AUC-train 0.965\n",
            "Stats - Epoch: 75 AUC-val 0.712  AUC-train 0.963\n",
            "Stats - Epoch: 76 AUC-val 0.725  AUC-train 0.962\n",
            "Stats - Epoch: 77 AUC-val 0.746  AUC-train 0.961\n",
            "Stats - Epoch: 78 AUC-val 0.723  AUC-train 0.957\n",
            "Stats - Epoch: 79 AUC-val 0.707  AUC-train 0.961\n",
            "Stats - Epoch: 80 AUC-val 0.697  AUC-train 0.962\n",
            "Stats - Epoch: 81 AUC-val 0.714  AUC-train 0.962\n",
            "Stats - Epoch: 82 AUC-val 0.720  AUC-train 0.964\n",
            "Stats - Epoch: 83 AUC-val 0.711  AUC-train 0.964\n",
            "Stats - Epoch: 84 AUC-val 0.695  AUC-train 0.964\n",
            "Stats - Epoch: 85 AUC-val 0.719  AUC-train 0.966\n",
            "Stats - Epoch: 86 AUC-val 0.712  AUC-train 0.968\n",
            "Stats - Epoch: 87 AUC-val 0.687  AUC-train 0.969\n",
            "Stats - Epoch: 88 AUC-val 0.691  AUC-train 0.968\n",
            "Stats - Epoch: 89 AUC-val 0.674  AUC-train 0.966\n",
            "Stats - Epoch: 90 AUC-val 0.685  AUC-train 0.964\n",
            "Stats - Epoch: 91 AUC-val 0.698  AUC-train 0.963\n",
            "Stats - Epoch: 92 AUC-val 0.716  AUC-train 0.969\n",
            "Stats - Epoch: 93 AUC-val 0.691  AUC-train 0.968\n",
            "Stats - Epoch: 94 AUC-val 0.742  AUC-train 0.966\n",
            "Stats - Epoch: 95 AUC-val 0.708  AUC-train 0.964\n",
            "Stats - Epoch: 96 AUC-val 0.711  AUC-train 0.966\n",
            "Stats - Epoch: 97 AUC-val 0.691  AUC-train 0.966\n",
            "Stats - Epoch: 98 AUC-val 0.689  AUC-train 0.967\n",
            "Stats - Epoch: 99 AUC-val 0.695  AUC-train 0.967\n",
            "Stats - Epoch: 100 AUC-val 0.723  AUC-train 0.969\n",
            "Results 100 AUC-val 0.564 0.715 0.769 0.733 0.509 AUC-train 0.930\n",
            "Shapley [0.0090685  0.00821377 0.00945884 0.01621083 0.00865063] [0.00549274]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197199\n",
            "         Iterations 7\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.342  AUC-train 0.528\n",
            "Stats - Epoch: 2 AUC-val 0.579  AUC-train 0.692\n",
            "Stats - Epoch: 3 AUC-val 0.752  AUC-train 0.801\n",
            "Stats - Epoch: 4 AUC-val 0.772  AUC-train 0.846\n",
            "Stats - Epoch: 5 AUC-val 0.758  AUC-train 0.872\n",
            "Stats - Epoch: 6 AUC-val 0.767  AUC-train 0.891\n",
            "Stats - Epoch: 7 AUC-val 0.770  AUC-train 0.905\n",
            "Stats - Epoch: 8 AUC-val 0.770  AUC-train 0.920\n",
            "Stats - Epoch: 9 AUC-val 0.784  AUC-train 0.931\n",
            "Stats - Epoch: 10 AUC-val 0.774  AUC-train 0.935\n",
            "Stats - Epoch: 11 AUC-val 0.765  AUC-train 0.943\n",
            "Stats - Epoch: 12 AUC-val 0.750  AUC-train 0.951\n",
            "Stats - Epoch: 13 AUC-val 0.761  AUC-train 0.955\n",
            "Stats - Epoch: 14 AUC-val 0.753  AUC-train 0.961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.757  AUC-train 0.964\n",
            "Stats - Epoch: 16 AUC-val 0.757  AUC-train 0.967\n",
            "Stats - Epoch: 17 AUC-val 0.766  AUC-train 0.969\n",
            "Stats - Epoch: 18 AUC-val 0.753  AUC-train 0.973\n",
            "Stats - Epoch: 19 AUC-val 0.752  AUC-train 0.974\n",
            "Stats - Epoch: 20 AUC-val 0.747  AUC-train 0.978\n",
            "Stats - Epoch: 21 AUC-val 0.745  AUC-train 0.982\n",
            "Stats - Epoch: 22 AUC-val 0.734  AUC-train 0.982\n",
            "Stats - Epoch: 23 AUC-val 0.737  AUC-train 0.984\n",
            "Stats - Epoch: 24 AUC-val 0.760  AUC-train 0.982\n",
            "Stats - Epoch: 25 AUC-val 0.743  AUC-train 0.985\n",
            "Stats - Epoch: 26 AUC-val 0.744  AUC-train 0.985\n",
            "Stats - Epoch: 27 AUC-val 0.742  AUC-train 0.986\n",
            "Stats - Epoch: 28 AUC-val 0.730  AUC-train 0.989\n",
            "Stats - Epoch: 29 AUC-val 0.747  AUC-train 0.989\n",
            "Stats - Epoch: 30 AUC-val 0.726  AUC-train 0.989\n",
            "Stats - Epoch: 31 AUC-val 0.734  AUC-train 0.990\n",
            "Stats - Epoch: 32 AUC-val 0.723  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.715  AUC-train 0.991\n",
            "Stats - Epoch: 34 AUC-val 0.729  AUC-train 0.992\n",
            "Stats - Epoch: 35 AUC-val 0.709  AUC-train 0.993\n",
            "Stats - Epoch: 36 AUC-val 0.725  AUC-train 0.994\n",
            "Stats - Epoch: 37 AUC-val 0.725  AUC-train 0.993\n",
            "Stats - Epoch: 38 AUC-val 0.725  AUC-train 0.993\n",
            "Stats - Epoch: 39 AUC-val 0.723  AUC-train 0.993\n",
            "Stats - Epoch: 40 AUC-val 0.719  AUC-train 0.994\n",
            "Stats - Epoch: 41 AUC-val 0.717  AUC-train 0.995\n",
            "Stats - Epoch: 42 AUC-val 0.730  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.731  AUC-train 0.995\n",
            "Stats - Epoch: 44 AUC-val 0.695  AUC-train 0.994\n",
            "Stats - Epoch: 45 AUC-val 0.723  AUC-train 0.996\n",
            "Stats - Epoch: 46 AUC-val 0.707  AUC-train 0.996\n",
            "Stats - Epoch: 47 AUC-val 0.726  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.709  AUC-train 0.997\n",
            "Stats - Epoch: 49 AUC-val 0.694  AUC-train 0.996\n",
            "Stats - Epoch: 50 AUC-val 0.722  AUC-train 0.996\n",
            "Stats - Epoch: 51 AUC-val 0.699  AUC-train 0.996\n",
            "Stats - Epoch: 52 AUC-val 0.709  AUC-train 0.996\n",
            "Stats - Epoch: 53 AUC-val 0.724  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.710  AUC-train 0.997\n",
            "Stats - Epoch: 55 AUC-val 0.712  AUC-train 0.997\n",
            "Stats - Epoch: 56 AUC-val 0.725  AUC-train 0.996\n",
            "Stats - Epoch: 57 AUC-val 0.692  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.709  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.692  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.723  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.733  AUC-train 0.993\n",
            "Stats - Epoch: 62 AUC-val 0.705  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.698  AUC-train 0.996\n",
            "Stats - Epoch: 64 AUC-val 0.730  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.693  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.709  AUC-train 0.998\n",
            "Stats - Epoch: 67 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.692  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.701  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.705  AUC-train 0.998\n",
            "Stats - Epoch: 71 AUC-val 0.688  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.688  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.730  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.765  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.721  AUC-train 0.997\n",
            "Stats - Epoch: 77 AUC-val 0.694  AUC-train 0.997\n",
            "Stats - Epoch: 78 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.689  AUC-train 0.998\n",
            "Stats - Epoch: 80 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.668  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.682  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.697  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 86 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 87 AUC-val 0.675  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.688  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.674  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.690  AUC-train 0.994\n",
            "Stats - Epoch: 94 AUC-val 0.675  AUC-train 0.994\n",
            "Stats - Epoch: 95 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.710  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.733  AUC-train 0.996\n",
            "Stats - Epoch: 99 AUC-val 0.695  AUC-train 0.995\n",
            "Stats - Epoch: 100 AUC-val 0.709  AUC-train 0.992\n",
            "Results 100 AUC-val 0.641 0.741 0.784 0.749 0.528 AUC-train 0.931\n",
            "Shapley [0.00881475 0.00999435 0.02522844 0.02219811 0.00652943] [0.00918711]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.152636\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.436  AUC-train 0.424\n",
            "Stats - Epoch: 2 AUC-val 0.522  AUC-train 0.533\n",
            "Stats - Epoch: 3 AUC-val 0.620  AUC-train 0.638\n",
            "Stats - Epoch: 4 AUC-val 0.670  AUC-train 0.710\n",
            "Stats - Epoch: 5 AUC-val 0.708  AUC-train 0.759\n",
            "Stats - Epoch: 6 AUC-val 0.743  AUC-train 0.804\n",
            "Stats - Epoch: 7 AUC-val 0.755  AUC-train 0.838\n",
            "Stats - Epoch: 8 AUC-val 0.776  AUC-train 0.859\n",
            "Stats - Epoch: 9 AUC-val 0.775  AUC-train 0.881\n",
            "Stats - Epoch: 10 AUC-val 0.786  AUC-train 0.897\n",
            "Stats - Epoch: 11 AUC-val 0.800  AUC-train 0.909\n",
            "Stats - Epoch: 12 AUC-val 0.794  AUC-train 0.923\n",
            "Stats - Epoch: 13 AUC-val 0.800  AUC-train 0.933\n",
            "Stats - Epoch: 14 AUC-val 0.795  AUC-train 0.940\n",
            "Stats - Epoch: 15 AUC-val 0.810  AUC-train 0.951\n",
            "Stats - Epoch: 16 AUC-val 0.815  AUC-train 0.950\n",
            "Stats - Epoch: 17 AUC-val 0.798  AUC-train 0.960\n",
            "Stats - Epoch: 18 AUC-val 0.798  AUC-train 0.963\n",
            "Stats - Epoch: 19 AUC-val 0.818  AUC-train 0.969\n",
            "Stats - Epoch: 20 AUC-val 0.816  AUC-train 0.969\n",
            "Stats - Epoch: 21 AUC-val 0.810  AUC-train 0.971\n",
            "Stats - Epoch: 22 AUC-val 0.798  AUC-train 0.974\n",
            "Stats - Epoch: 23 AUC-val 0.808  AUC-train 0.977\n",
            "Stats - Epoch: 24 AUC-val 0.791  AUC-train 0.980\n",
            "Stats - Epoch: 25 AUC-val 0.799  AUC-train 0.983\n",
            "Stats - Epoch: 26 AUC-val 0.805  AUC-train 0.984\n",
            "Stats - Epoch: 27 AUC-val 0.788  AUC-train 0.986\n",
            "Stats - Epoch: 28 AUC-val 0.804  AUC-train 0.988\n",
            "Stats - Epoch: 29 AUC-val 0.786  AUC-train 0.989\n",
            "Stats - Epoch: 30 AUC-val 0.800  AUC-train 0.987\n",
            "Stats - Epoch: 31 AUC-val 0.791  AUC-train 0.990\n",
            "Stats - Epoch: 32 AUC-val 0.790  AUC-train 0.989\n",
            "Stats - Epoch: 33 AUC-val 0.807  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.805  AUC-train 0.992\n",
            "Stats - Epoch: 35 AUC-val 0.801  AUC-train 0.993\n",
            "Stats - Epoch: 36 AUC-val 0.795  AUC-train 0.994\n",
            "Stats - Epoch: 37 AUC-val 0.797  AUC-train 0.994\n",
            "Stats - Epoch: 38 AUC-val 0.782  AUC-train 0.995\n",
            "Stats - Epoch: 39 AUC-val 0.789  AUC-train 0.993\n",
            "Stats - Epoch: 40 AUC-val 0.777  AUC-train 0.993\n",
            "Stats - Epoch: 41 AUC-val 0.782  AUC-train 0.994\n",
            "Stats - Epoch: 42 AUC-val 0.781  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.798  AUC-train 0.995\n",
            "Stats - Epoch: 44 AUC-val 0.763  AUC-train 0.993\n",
            "Stats - Epoch: 45 AUC-val 0.765  AUC-train 0.996\n",
            "Stats - Epoch: 46 AUC-val 0.751  AUC-train 0.993\n",
            "Stats - Epoch: 47 AUC-val 0.768  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.788  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.803  AUC-train 0.996\n",
            "Stats - Epoch: 50 AUC-val 0.782  AUC-train 0.995\n",
            "Stats - Epoch: 51 AUC-val 0.802  AUC-train 0.995\n",
            "Stats - Epoch: 52 AUC-val 0.780  AUC-train 0.995\n",
            "Stats - Epoch: 53 AUC-val 0.781  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.757  AUC-train 0.995\n",
            "Stats - Epoch: 55 AUC-val 0.780  AUC-train 0.995\n",
            "Stats - Epoch: 56 AUC-val 0.788  AUC-train 0.995\n",
            "Stats - Epoch: 57 AUC-val 0.784  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.780  AUC-train 0.994\n",
            "Stats - Epoch: 59 AUC-val 0.751  AUC-train 0.996\n",
            "Stats - Epoch: 60 AUC-val 0.777  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.800  AUC-train 0.993\n",
            "Stats - Epoch: 62 AUC-val 0.780  AUC-train 0.995\n",
            "Stats - Epoch: 63 AUC-val 0.767  AUC-train 0.993\n",
            "Stats - Epoch: 64 AUC-val 0.740  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.786  AUC-train 0.987\n",
            "Stats - Epoch: 66 AUC-val 0.773  AUC-train 0.994\n",
            "Stats - Epoch: 67 AUC-val 0.778  AUC-train 0.996\n",
            "Stats - Epoch: 68 AUC-val 0.791  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.764  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.760  AUC-train 0.991\n",
            "Stats - Epoch: 71 AUC-val 0.766  AUC-train 0.994\n",
            "Stats - Epoch: 72 AUC-val 0.797  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.781  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.779  AUC-train 0.996\n",
            "Stats - Epoch: 75 AUC-val 0.777  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.774  AUC-train 0.995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.787  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.765  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.777  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.766  AUC-train 0.994\n",
            "Stats - Epoch: 81 AUC-val 0.764  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.771  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.781  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.776  AUC-train 0.995\n",
            "Stats - Epoch: 85 AUC-val 0.766  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.760  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.769  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.790  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.785  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.770  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.792  AUC-train 0.987\n",
            "Stats - Epoch: 92 AUC-val 0.782  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.798  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.801  AUC-train 0.996\n",
            "Stats - Epoch: 95 AUC-val 0.780  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.780  AUC-train 0.996\n",
            "Stats - Epoch: 97 AUC-val 0.776  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.807  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.810  AUC-train 0.994\n",
            "Stats - Epoch: 100 AUC-val 0.793  AUC-train 0.983\n",
            "Results 100 AUC-val 0.664 0.800 0.818 0.720 0.576 AUC-train 0.969\n",
            "Shapley [0.01132523 0.01077468 0.01270799 0.02116728 0.00674159] [0.00672434]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.169454\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.510  AUC-train 0.639\n",
            "Stats - Epoch: 2 AUC-val 0.792  AUC-train 0.823\n",
            "Stats - Epoch: 3 AUC-val 0.790  AUC-train 0.896\n",
            "Stats - Epoch: 4 AUC-val 0.791  AUC-train 0.933\n",
            "Stats - Epoch: 5 AUC-val 0.783  AUC-train 0.951\n",
            "Stats - Epoch: 6 AUC-val 0.798  AUC-train 0.962\n",
            "Stats - Epoch: 7 AUC-val 0.788  AUC-train 0.969\n",
            "Stats - Epoch: 8 AUC-val 0.798  AUC-train 0.977\n",
            "Stats - Epoch: 9 AUC-val 0.793  AUC-train 0.982\n",
            "Stats - Epoch: 10 AUC-val 0.802  AUC-train 0.986\n",
            "Stats - Epoch: 11 AUC-val 0.782  AUC-train 0.989\n",
            "Stats - Epoch: 12 AUC-val 0.794  AUC-train 0.991\n",
            "Stats - Epoch: 13 AUC-val 0.786  AUC-train 0.992\n",
            "Stats - Epoch: 14 AUC-val 0.793  AUC-train 0.994\n",
            "Stats - Epoch: 15 AUC-val 0.787  AUC-train 0.995\n",
            "Stats - Epoch: 16 AUC-val 0.785  AUC-train 0.997\n",
            "Stats - Epoch: 17 AUC-val 0.791  AUC-train 0.996\n",
            "Stats - Epoch: 18 AUC-val 0.788  AUC-train 0.997\n",
            "Stats - Epoch: 19 AUC-val 0.793  AUC-train 0.998\n",
            "Stats - Epoch: 20 AUC-val 0.783  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.783  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.774  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.773  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.782  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.772  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.774  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.779  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.779  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.776  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.769  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.770  AUC-train 0.998\n",
            "Stats - Epoch: 32 AUC-val 0.774  AUC-train 0.998\n",
            "Stats - Epoch: 33 AUC-val 0.774  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.768  AUC-train 1.000\n",
            "Stats - Epoch: 35 AUC-val 0.775  AUC-train 1.000\n",
            "Stats - Epoch: 36 AUC-val 0.764  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.746  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.786  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.780  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.782  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.786  AUC-train 1.000\n",
            "Stats - Epoch: 42 AUC-val 0.761  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.767  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.760  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.763  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.768  AUC-train 1.000\n",
            "Stats - Epoch: 47 AUC-val 0.759  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.748  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.765  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.753  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.763  AUC-train 0.998\n",
            "Stats - Epoch: 52 AUC-val 0.777  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.775  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.788  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.768  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.770  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.762  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.747  AUC-train 1.000\n",
            "Stats - Epoch: 59 AUC-val 0.747  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.774  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.747  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.733  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.749  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.777  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.760  AUC-train 1.000\n",
            "Stats - Epoch: 66 AUC-val 0.766  AUC-train 0.997\n",
            "Stats - Epoch: 67 AUC-val 0.753  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.747  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.762  AUC-train 1.000\n",
            "Stats - Epoch: 70 AUC-val 0.734  AUC-train 1.000\n",
            "Stats - Epoch: 71 AUC-val 0.746  AUC-train 1.000\n",
            "Stats - Epoch: 72 AUC-val 0.751  AUC-train 1.000\n",
            "Stats - Epoch: 73 AUC-val 0.772  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.747  AUC-train 1.000\n",
            "Stats - Epoch: 75 AUC-val 0.727  AUC-train 1.000\n",
            "Stats - Epoch: 76 AUC-val 0.750  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.736  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.726  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.746  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.780  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.734  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.743  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.744  AUC-train 1.000\n",
            "Stats - Epoch: 84 AUC-val 0.790  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.771  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.743  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.780  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.762  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.766  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.767  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.757  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.764  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.762  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.759  AUC-train 1.000\n",
            "Stats - Epoch: 95 AUC-val 0.742  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.753  AUC-train 1.000\n",
            "Stats - Epoch: 97 AUC-val 0.736  AUC-train 1.000\n",
            "Stats - Epoch: 98 AUC-val 0.741  AUC-train 1.000\n",
            "Stats - Epoch: 99 AUC-val 0.782  AUC-train 1.000\n",
            "Stats - Epoch: 100 AUC-val 0.743  AUC-train 1.000\n",
            "Results 100 AUC-val 0.582 0.717 0.802 0.796 0.468 AUC-train 0.986\n",
            "Shapley [0.01776111 0.01479238 0.01207058 0.02482405 0.00990355] [0.00289146]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.156429\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.694  AUC-train 0.742\n",
            "Results 1 AUC-val 0.683 0.724 0.780 0.694 0.495 AUC-train 0.742\n",
            "Shapley [0.01082566 0.00206631 0.00123501 0.006544   0.00057399] [0.01839268]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.204484\n",
            "         Iterations 10\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.517  AUC-train 0.806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.607 0.545 0.571 0.517 0.306 AUC-train 0.806\n",
            "Shapley [0.01159544 0.00355861 0.01074116 0.00830104 0.00521527] [0.00645049]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.230340\n",
            "         Iterations 9\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.451  AUC-train 0.370\n",
            "Stats - Epoch: 2 AUC-val 0.532  AUC-train 0.408\n",
            "Stats - Epoch: 3 AUC-val 0.566  AUC-train 0.474\n",
            "Stats - Epoch: 4 AUC-val 0.595  AUC-train 0.533\n",
            "Stats - Epoch: 5 AUC-val 0.558  AUC-train 0.553\n",
            "Stats - Epoch: 6 AUC-val 0.588  AUC-train 0.596\n",
            "Stats - Epoch: 7 AUC-val 0.518  AUC-train 0.601\n",
            "Stats - Epoch: 8 AUC-val 0.540  AUC-train 0.630\n",
            "Stats - Epoch: 9 AUC-val 0.535  AUC-train 0.653\n",
            "Stats - Epoch: 10 AUC-val 0.492  AUC-train 0.652\n",
            "Stats - Epoch: 11 AUC-val 0.523  AUC-train 0.689\n",
            "Stats - Epoch: 12 AUC-val 0.491  AUC-train 0.684\n",
            "Stats - Epoch: 13 AUC-val 0.513  AUC-train 0.708\n",
            "Stats - Epoch: 14 AUC-val 0.490  AUC-train 0.696\n",
            "Stats - Epoch: 15 AUC-val 0.516  AUC-train 0.729\n",
            "Stats - Epoch: 16 AUC-val 0.492  AUC-train 0.736\n",
            "Stats - Epoch: 17 AUC-val 0.484  AUC-train 0.750\n",
            "Stats - Epoch: 18 AUC-val 0.505  AUC-train 0.765\n",
            "Stats - Epoch: 19 AUC-val 0.510  AUC-train 0.759\n",
            "Stats - Epoch: 20 AUC-val 0.475  AUC-train 0.768\n",
            "Stats - Epoch: 21 AUC-val 0.497  AUC-train 0.779\n",
            "Stats - Epoch: 22 AUC-val 0.496  AUC-train 0.781\n",
            "Stats - Epoch: 23 AUC-val 0.514  AUC-train 0.800\n",
            "Stats - Epoch: 24 AUC-val 0.492  AUC-train 0.795\n",
            "Stats - Epoch: 25 AUC-val 0.485  AUC-train 0.796\n",
            "Stats - Epoch: 26 AUC-val 0.505  AUC-train 0.807\n",
            "Stats - Epoch: 27 AUC-val 0.499  AUC-train 0.808\n",
            "Stats - Epoch: 28 AUC-val 0.512  AUC-train 0.817\n",
            "Stats - Epoch: 29 AUC-val 0.492  AUC-train 0.811\n",
            "Stats - Epoch: 30 AUC-val 0.508  AUC-train 0.821\n",
            "Stats - Epoch: 31 AUC-val 0.501  AUC-train 0.828\n",
            "Stats - Epoch: 32 AUC-val 0.514  AUC-train 0.827\n",
            "Stats - Epoch: 33 AUC-val 0.500  AUC-train 0.833\n",
            "Stats - Epoch: 34 AUC-val 0.518  AUC-train 0.828\n",
            "Stats - Epoch: 35 AUC-val 0.508  AUC-train 0.834\n",
            "Stats - Epoch: 36 AUC-val 0.519  AUC-train 0.840\n",
            "Stats - Epoch: 37 AUC-val 0.520  AUC-train 0.843\n",
            "Stats - Epoch: 38 AUC-val 0.528  AUC-train 0.841\n",
            "Stats - Epoch: 39 AUC-val 0.525  AUC-train 0.829\n",
            "Stats - Epoch: 40 AUC-val 0.540  AUC-train 0.845\n",
            "Stats - Epoch: 41 AUC-val 0.521  AUC-train 0.842\n",
            "Stats - Epoch: 42 AUC-val 0.500  AUC-train 0.837\n",
            "Stats - Epoch: 43 AUC-val 0.539  AUC-train 0.849\n",
            "Stats - Epoch: 44 AUC-val 0.532  AUC-train 0.854\n",
            "Stats - Epoch: 45 AUC-val 0.523  AUC-train 0.842\n",
            "Stats - Epoch: 46 AUC-val 0.520  AUC-train 0.845\n",
            "Stats - Epoch: 47 AUC-val 0.543  AUC-train 0.857\n",
            "Stats - Epoch: 48 AUC-val 0.529  AUC-train 0.849\n",
            "Stats - Epoch: 49 AUC-val 0.544  AUC-train 0.852\n",
            "Stats - Epoch: 50 AUC-val 0.542  AUC-train 0.855\n",
            "Stats - Epoch: 51 AUC-val 0.530  AUC-train 0.850\n",
            "Stats - Epoch: 52 AUC-val 0.538  AUC-train 0.855\n",
            "Stats - Epoch: 53 AUC-val 0.542  AUC-train 0.854\n",
            "Stats - Epoch: 54 AUC-val 0.554  AUC-train 0.855\n",
            "Stats - Epoch: 55 AUC-val 0.538  AUC-train 0.862\n",
            "Stats - Epoch: 56 AUC-val 0.545  AUC-train 0.855\n",
            "Stats - Epoch: 57 AUC-val 0.543  AUC-train 0.870\n",
            "Stats - Epoch: 58 AUC-val 0.530  AUC-train 0.854\n",
            "Stats - Epoch: 59 AUC-val 0.529  AUC-train 0.862\n",
            "Stats - Epoch: 60 AUC-val 0.550  AUC-train 0.865\n",
            "Stats - Epoch: 61 AUC-val 0.550  AUC-train 0.866\n",
            "Stats - Epoch: 62 AUC-val 0.540  AUC-train 0.861\n",
            "Stats - Epoch: 63 AUC-val 0.553  AUC-train 0.861\n",
            "Stats - Epoch: 64 AUC-val 0.556  AUC-train 0.864\n",
            "Stats - Epoch: 65 AUC-val 0.562  AUC-train 0.865\n",
            "Stats - Epoch: 66 AUC-val 0.556  AUC-train 0.867\n",
            "Stats - Epoch: 67 AUC-val 0.571  AUC-train 0.864\n",
            "Stats - Epoch: 68 AUC-val 0.552  AUC-train 0.861\n",
            "Stats - Epoch: 69 AUC-val 0.550  AUC-train 0.858\n",
            "Stats - Epoch: 70 AUC-val 0.561  AUC-train 0.868\n",
            "Stats - Epoch: 71 AUC-val 0.558  AUC-train 0.870\n",
            "Stats - Epoch: 72 AUC-val 0.559  AUC-train 0.861\n",
            "Stats - Epoch: 73 AUC-val 0.563  AUC-train 0.870\n",
            "Stats - Epoch: 74 AUC-val 0.565  AUC-train 0.877\n",
            "Stats - Epoch: 75 AUC-val 0.552  AUC-train 0.861\n",
            "Stats - Epoch: 76 AUC-val 0.572  AUC-train 0.868\n",
            "Stats - Epoch: 77 AUC-val 0.559  AUC-train 0.873\n",
            "Stats - Epoch: 78 AUC-val 0.557  AUC-train 0.873\n",
            "Stats - Epoch: 79 AUC-val 0.563  AUC-train 0.868\n",
            "Stats - Epoch: 80 AUC-val 0.566  AUC-train 0.872\n",
            "Stats - Epoch: 81 AUC-val 0.563  AUC-train 0.875\n",
            "Stats - Epoch: 82 AUC-val 0.569  AUC-train 0.879\n",
            "Stats - Epoch: 83 AUC-val 0.571  AUC-train 0.874\n",
            "Stats - Epoch: 84 AUC-val 0.571  AUC-train 0.877\n",
            "Stats - Epoch: 85 AUC-val 0.566  AUC-train 0.871\n",
            "Stats - Epoch: 86 AUC-val 0.569  AUC-train 0.884\n",
            "Stats - Epoch: 87 AUC-val 0.568  AUC-train 0.879\n",
            "Stats - Epoch: 88 AUC-val 0.560  AUC-train 0.878\n",
            "Stats - Epoch: 89 AUC-val 0.567  AUC-train 0.878\n",
            "Stats - Epoch: 90 AUC-val 0.575  AUC-train 0.879\n",
            "Stats - Epoch: 91 AUC-val 0.568  AUC-train 0.881\n",
            "Stats - Epoch: 92 AUC-val 0.575  AUC-train 0.874\n",
            "Stats - Epoch: 93 AUC-val 0.566  AUC-train 0.879\n",
            "Stats - Epoch: 94 AUC-val 0.574  AUC-train 0.880\n",
            "Stats - Epoch: 95 AUC-val 0.567  AUC-train 0.882\n",
            "Stats - Epoch: 96 AUC-val 0.565  AUC-train 0.877\n",
            "Stats - Epoch: 97 AUC-val 0.581  AUC-train 0.875\n",
            "Stats - Epoch: 98 AUC-val 0.573  AUC-train 0.879\n",
            "Stats - Epoch: 99 AUC-val 0.569  AUC-train 0.880\n",
            "Stats - Epoch: 100 AUC-val 0.568  AUC-train 0.879\n",
            "Results 100 AUC-val 0.659 0.592 0.691 0.595 0.416 AUC-train 0.533\n",
            "Shapley [0.01751162 0.01834263 0.02294114 0.06180359 0.04496382] [0.1410332]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.200044\n",
            "         Iterations 9\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.383  AUC-train 0.453\n",
            "Stats - Epoch: 2 AUC-val 0.422  AUC-train 0.590\n",
            "Stats - Epoch: 3 AUC-val 0.374  AUC-train 0.694\n",
            "Stats - Epoch: 4 AUC-val 0.389  AUC-train 0.762\n",
            "Stats - Epoch: 5 AUC-val 0.348  AUC-train 0.816\n",
            "Stats - Epoch: 6 AUC-val 0.408  AUC-train 0.853\n",
            "Stats - Epoch: 7 AUC-val 0.372  AUC-train 0.882\n",
            "Stats - Epoch: 8 AUC-val 0.395  AUC-train 0.904\n",
            "Stats - Epoch: 9 AUC-val 0.385  AUC-train 0.916\n",
            "Stats - Epoch: 10 AUC-val 0.445  AUC-train 0.925\n",
            "Stats - Epoch: 11 AUC-val 0.422  AUC-train 0.933\n",
            "Stats - Epoch: 12 AUC-val 0.422  AUC-train 0.946\n",
            "Stats - Epoch: 13 AUC-val 0.436  AUC-train 0.951\n",
            "Stats - Epoch: 14 AUC-val 0.418  AUC-train 0.952\n",
            "Stats - Epoch: 15 AUC-val 0.440  AUC-train 0.960\n",
            "Stats - Epoch: 16 AUC-val 0.425  AUC-train 0.961\n",
            "Stats - Epoch: 17 AUC-val 0.460  AUC-train 0.965\n",
            "Stats - Epoch: 18 AUC-val 0.456  AUC-train 0.964\n",
            "Stats - Epoch: 19 AUC-val 0.457  AUC-train 0.964\n",
            "Stats - Epoch: 20 AUC-val 0.459  AUC-train 0.969\n",
            "Stats - Epoch: 21 AUC-val 0.448  AUC-train 0.968\n",
            "Stats - Epoch: 22 AUC-val 0.466  AUC-train 0.967\n",
            "Stats - Epoch: 23 AUC-val 0.479  AUC-train 0.969\n",
            "Stats - Epoch: 24 AUC-val 0.491  AUC-train 0.970\n",
            "Stats - Epoch: 25 AUC-val 0.461  AUC-train 0.972\n",
            "Stats - Epoch: 26 AUC-val 0.477  AUC-train 0.971\n",
            "Stats - Epoch: 27 AUC-val 0.455  AUC-train 0.973\n",
            "Stats - Epoch: 28 AUC-val 0.480  AUC-train 0.975\n",
            "Stats - Epoch: 29 AUC-val 0.488  AUC-train 0.975\n",
            "Stats - Epoch: 30 AUC-val 0.497  AUC-train 0.977\n",
            "Stats - Epoch: 31 AUC-val 0.503  AUC-train 0.978\n",
            "Stats - Epoch: 32 AUC-val 0.516  AUC-train 0.974\n",
            "Stats - Epoch: 33 AUC-val 0.483  AUC-train 0.979\n",
            "Stats - Epoch: 34 AUC-val 0.500  AUC-train 0.975\n",
            "Stats - Epoch: 35 AUC-val 0.500  AUC-train 0.973\n",
            "Stats - Epoch: 36 AUC-val 0.524  AUC-train 0.976\n",
            "Stats - Epoch: 37 AUC-val 0.487  AUC-train 0.977\n",
            "Stats - Epoch: 38 AUC-val 0.491  AUC-train 0.977\n",
            "Stats - Epoch: 39 AUC-val 0.514  AUC-train 0.970\n",
            "Stats - Epoch: 40 AUC-val 0.475  AUC-train 0.975\n",
            "Stats - Epoch: 41 AUC-val 0.500  AUC-train 0.975\n",
            "Stats - Epoch: 42 AUC-val 0.520  AUC-train 0.979\n",
            "Stats - Epoch: 43 AUC-val 0.537  AUC-train 0.977\n",
            "Stats - Epoch: 44 AUC-val 0.528  AUC-train 0.978\n",
            "Stats - Epoch: 45 AUC-val 0.509  AUC-train 0.975\n",
            "Stats - Epoch: 46 AUC-val 0.534  AUC-train 0.973\n",
            "Stats - Epoch: 47 AUC-val 0.533  AUC-train 0.977\n",
            "Stats - Epoch: 48 AUC-val 0.534  AUC-train 0.978\n",
            "Stats - Epoch: 49 AUC-val 0.539  AUC-train 0.977\n",
            "Stats - Epoch: 50 AUC-val 0.527  AUC-train 0.975\n",
            "Stats - Epoch: 51 AUC-val 0.547  AUC-train 0.973\n",
            "Stats - Epoch: 52 AUC-val 0.547  AUC-train 0.978\n",
            "Stats - Epoch: 53 AUC-val 0.549  AUC-train 0.973\n",
            "Stats - Epoch: 54 AUC-val 0.582  AUC-train 0.970\n",
            "Stats - Epoch: 55 AUC-val 0.531  AUC-train 0.975\n",
            "Stats - Epoch: 56 AUC-val 0.550  AUC-train 0.972\n",
            "Stats - Epoch: 57 AUC-val 0.567  AUC-train 0.973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.555  AUC-train 0.972\n",
            "Stats - Epoch: 59 AUC-val 0.568  AUC-train 0.974\n",
            "Stats - Epoch: 60 AUC-val 0.591  AUC-train 0.972\n",
            "Stats - Epoch: 61 AUC-val 0.571  AUC-train 0.976\n",
            "Stats - Epoch: 62 AUC-val 0.564  AUC-train 0.974\n",
            "Stats - Epoch: 63 AUC-val 0.569  AUC-train 0.974\n",
            "Stats - Epoch: 64 AUC-val 0.581  AUC-train 0.975\n",
            "Stats - Epoch: 65 AUC-val 0.593  AUC-train 0.971\n",
            "Stats - Epoch: 66 AUC-val 0.593  AUC-train 0.975\n",
            "Stats - Epoch: 67 AUC-val 0.598  AUC-train 0.975\n",
            "Stats - Epoch: 68 AUC-val 0.574  AUC-train 0.973\n",
            "Stats - Epoch: 69 AUC-val 0.575  AUC-train 0.973\n",
            "Stats - Epoch: 70 AUC-val 0.583  AUC-train 0.972\n",
            "Stats - Epoch: 71 AUC-val 0.607  AUC-train 0.973\n",
            "Stats - Epoch: 72 AUC-val 0.592  AUC-train 0.973\n",
            "Stats - Epoch: 73 AUC-val 0.605  AUC-train 0.974\n",
            "Stats - Epoch: 74 AUC-val 0.604  AUC-train 0.976\n",
            "Stats - Epoch: 75 AUC-val 0.597  AUC-train 0.974\n",
            "Stats - Epoch: 76 AUC-val 0.597  AUC-train 0.971\n",
            "Stats - Epoch: 77 AUC-val 0.597  AUC-train 0.974\n",
            "Stats - Epoch: 78 AUC-val 0.589  AUC-train 0.975\n",
            "Stats - Epoch: 79 AUC-val 0.602  AUC-train 0.976\n",
            "Stats - Epoch: 80 AUC-val 0.623  AUC-train 0.971\n",
            "Stats - Epoch: 81 AUC-val 0.588  AUC-train 0.972\n",
            "Stats - Epoch: 82 AUC-val 0.633  AUC-train 0.974\n",
            "Stats - Epoch: 83 AUC-val 0.609  AUC-train 0.973\n",
            "Stats - Epoch: 84 AUC-val 0.638  AUC-train 0.975\n",
            "Stats - Epoch: 85 AUC-val 0.621  AUC-train 0.974\n",
            "Stats - Epoch: 86 AUC-val 0.625  AUC-train 0.976\n",
            "Stats - Epoch: 87 AUC-val 0.632  AUC-train 0.975\n",
            "Stats - Epoch: 88 AUC-val 0.608  AUC-train 0.974\n",
            "Stats - Epoch: 89 AUC-val 0.630  AUC-train 0.972\n",
            "Stats - Epoch: 90 AUC-val 0.624  AUC-train 0.971\n",
            "Stats - Epoch: 91 AUC-val 0.633  AUC-train 0.973\n",
            "Stats - Epoch: 92 AUC-val 0.619  AUC-train 0.973\n",
            "Stats - Epoch: 93 AUC-val 0.631  AUC-train 0.972\n",
            "Stats - Epoch: 94 AUC-val 0.617  AUC-train 0.971\n",
            "Stats - Epoch: 95 AUC-val 0.664  AUC-train 0.972\n",
            "Stats - Epoch: 96 AUC-val 0.609  AUC-train 0.972\n",
            "Stats - Epoch: 97 AUC-val 0.658  AUC-train 0.970\n",
            "Stats - Epoch: 98 AUC-val 0.648  AUC-train 0.972\n",
            "Stats - Epoch: 99 AUC-val 0.635  AUC-train 0.970\n",
            "Stats - Epoch: 100 AUC-val 0.668  AUC-train 0.973\n",
            "Results 100 AUC-val 0.513 0.597 0.359 0.668 0.345 AUC-train 0.973\n",
            "Shapley [0.01342932 0.00642368 0.00443173 0.02272656 0.00348984] [0.03210958]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.222572\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.339  AUC-train 0.473\n",
            "Stats - Epoch: 2 AUC-val 0.415  AUC-train 0.540\n",
            "Stats - Epoch: 3 AUC-val 0.468  AUC-train 0.602\n",
            "Stats - Epoch: 4 AUC-val 0.494  AUC-train 0.664\n",
            "Stats - Epoch: 5 AUC-val 0.501  AUC-train 0.719\n",
            "Stats - Epoch: 6 AUC-val 0.529  AUC-train 0.758\n",
            "Stats - Epoch: 7 AUC-val 0.554  AUC-train 0.787\n",
            "Stats - Epoch: 8 AUC-val 0.562  AUC-train 0.813\n",
            "Stats - Epoch: 9 AUC-val 0.577  AUC-train 0.830\n",
            "Stats - Epoch: 10 AUC-val 0.573  AUC-train 0.840\n",
            "Stats - Epoch: 11 AUC-val 0.586  AUC-train 0.852\n",
            "Stats - Epoch: 12 AUC-val 0.570  AUC-train 0.862\n",
            "Stats - Epoch: 13 AUC-val 0.582  AUC-train 0.867\n",
            "Stats - Epoch: 14 AUC-val 0.563  AUC-train 0.872\n",
            "Stats - Epoch: 15 AUC-val 0.568  AUC-train 0.882\n",
            "Stats - Epoch: 16 AUC-val 0.582  AUC-train 0.885\n",
            "Stats - Epoch: 17 AUC-val 0.588  AUC-train 0.893\n",
            "Stats - Epoch: 18 AUC-val 0.573  AUC-train 0.894\n",
            "Stats - Epoch: 19 AUC-val 0.565  AUC-train 0.895\n",
            "Stats - Epoch: 20 AUC-val 0.568  AUC-train 0.905\n",
            "Stats - Epoch: 21 AUC-val 0.596  AUC-train 0.909\n",
            "Stats - Epoch: 22 AUC-val 0.595  AUC-train 0.916\n",
            "Stats - Epoch: 23 AUC-val 0.596  AUC-train 0.917\n",
            "Stats - Epoch: 24 AUC-val 0.594  AUC-train 0.922\n",
            "Stats - Epoch: 25 AUC-val 0.599  AUC-train 0.923\n",
            "Stats - Epoch: 26 AUC-val 0.594  AUC-train 0.925\n",
            "Stats - Epoch: 27 AUC-val 0.591  AUC-train 0.929\n",
            "Stats - Epoch: 28 AUC-val 0.599  AUC-train 0.927\n",
            "Stats - Epoch: 29 AUC-val 0.592  AUC-train 0.926\n",
            "Stats - Epoch: 30 AUC-val 0.604  AUC-train 0.924\n",
            "Stats - Epoch: 31 AUC-val 0.611  AUC-train 0.929\n",
            "Stats - Epoch: 32 AUC-val 0.622  AUC-train 0.932\n",
            "Stats - Epoch: 33 AUC-val 0.635  AUC-train 0.937\n",
            "Stats - Epoch: 34 AUC-val 0.637  AUC-train 0.938\n",
            "Stats - Epoch: 35 AUC-val 0.667  AUC-train 0.940\n",
            "Stats - Epoch: 36 AUC-val 0.639  AUC-train 0.943\n",
            "Stats - Epoch: 37 AUC-val 0.622  AUC-train 0.941\n",
            "Stats - Epoch: 38 AUC-val 0.615  AUC-train 0.944\n",
            "Stats - Epoch: 39 AUC-val 0.615  AUC-train 0.946\n",
            "Stats - Epoch: 40 AUC-val 0.637  AUC-train 0.948\n",
            "Stats - Epoch: 41 AUC-val 0.613  AUC-train 0.946\n",
            "Stats - Epoch: 42 AUC-val 0.626  AUC-train 0.947\n",
            "Stats - Epoch: 43 AUC-val 0.637  AUC-train 0.949\n",
            "Stats - Epoch: 44 AUC-val 0.669  AUC-train 0.941\n",
            "Stats - Epoch: 45 AUC-val 0.667  AUC-train 0.943\n",
            "Stats - Epoch: 46 AUC-val 0.650  AUC-train 0.945\n",
            "Stats - Epoch: 47 AUC-val 0.645  AUC-train 0.943\n",
            "Stats - Epoch: 48 AUC-val 0.657  AUC-train 0.949\n",
            "Stats - Epoch: 49 AUC-val 0.628  AUC-train 0.950\n",
            "Stats - Epoch: 50 AUC-val 0.652  AUC-train 0.950\n",
            "Stats - Epoch: 51 AUC-val 0.658  AUC-train 0.955\n",
            "Stats - Epoch: 52 AUC-val 0.651  AUC-train 0.955\n",
            "Stats - Epoch: 53 AUC-val 0.667  AUC-train 0.952\n",
            "Stats - Epoch: 54 AUC-val 0.642  AUC-train 0.956\n",
            "Stats - Epoch: 55 AUC-val 0.672  AUC-train 0.956\n",
            "Stats - Epoch: 56 AUC-val 0.639  AUC-train 0.956\n",
            "Stats - Epoch: 57 AUC-val 0.636  AUC-train 0.955\n",
            "Stats - Epoch: 58 AUC-val 0.642  AUC-train 0.955\n",
            "Stats - Epoch: 59 AUC-val 0.653  AUC-train 0.956\n",
            "Stats - Epoch: 60 AUC-val 0.652  AUC-train 0.952\n",
            "Stats - Epoch: 61 AUC-val 0.650  AUC-train 0.954\n",
            "Stats - Epoch: 62 AUC-val 0.660  AUC-train 0.957\n",
            "Stats - Epoch: 63 AUC-val 0.705  AUC-train 0.957\n",
            "Stats - Epoch: 64 AUC-val 0.658  AUC-train 0.953\n",
            "Stats - Epoch: 65 AUC-val 0.660  AUC-train 0.953\n",
            "Stats - Epoch: 66 AUC-val 0.661  AUC-train 0.957\n",
            "Stats - Epoch: 67 AUC-val 0.652  AUC-train 0.955\n",
            "Stats - Epoch: 68 AUC-val 0.637  AUC-train 0.957\n",
            "Stats - Epoch: 69 AUC-val 0.665  AUC-train 0.958\n",
            "Stats - Epoch: 70 AUC-val 0.637  AUC-train 0.958\n",
            "Stats - Epoch: 71 AUC-val 0.670  AUC-train 0.951\n",
            "Stats - Epoch: 72 AUC-val 0.683  AUC-train 0.955\n",
            "Stats - Epoch: 73 AUC-val 0.651  AUC-train 0.961\n",
            "Stats - Epoch: 74 AUC-val 0.661  AUC-train 0.961\n",
            "Stats - Epoch: 75 AUC-val 0.681  AUC-train 0.960\n",
            "Stats - Epoch: 76 AUC-val 0.659  AUC-train 0.961\n",
            "Stats - Epoch: 77 AUC-val 0.658  AUC-train 0.960\n",
            "Stats - Epoch: 78 AUC-val 0.633  AUC-train 0.960\n",
            "Stats - Epoch: 79 AUC-val 0.721  AUC-train 0.963\n",
            "Stats - Epoch: 80 AUC-val 0.710  AUC-train 0.964\n",
            "Stats - Epoch: 81 AUC-val 0.691  AUC-train 0.963\n",
            "Stats - Epoch: 82 AUC-val 0.669  AUC-train 0.962\n",
            "Stats - Epoch: 83 AUC-val 0.687  AUC-train 0.964\n",
            "Stats - Epoch: 84 AUC-val 0.679  AUC-train 0.962\n",
            "Stats - Epoch: 85 AUC-val 0.668  AUC-train 0.960\n",
            "Stats - Epoch: 86 AUC-val 0.642  AUC-train 0.962\n",
            "Stats - Epoch: 87 AUC-val 0.624  AUC-train 0.963\n",
            "Stats - Epoch: 88 AUC-val 0.696  AUC-train 0.960\n",
            "Stats - Epoch: 89 AUC-val 0.704  AUC-train 0.959\n",
            "Stats - Epoch: 90 AUC-val 0.696  AUC-train 0.959\n",
            "Stats - Epoch: 91 AUC-val 0.724  AUC-train 0.959\n",
            "Stats - Epoch: 92 AUC-val 0.698  AUC-train 0.960\n",
            "Stats - Epoch: 93 AUC-val 0.694  AUC-train 0.959\n",
            "Stats - Epoch: 94 AUC-val 0.705  AUC-train 0.961\n",
            "Stats - Epoch: 95 AUC-val 0.704  AUC-train 0.957\n",
            "Stats - Epoch: 96 AUC-val 0.698  AUC-train 0.955\n",
            "Stats - Epoch: 97 AUC-val 0.704  AUC-train 0.959\n",
            "Stats - Epoch: 98 AUC-val 0.695  AUC-train 0.961\n",
            "Stats - Epoch: 99 AUC-val 0.661  AUC-train 0.964\n",
            "Stats - Epoch: 100 AUC-val 0.690  AUC-train 0.966\n",
            "Results 100 AUC-val 0.430 0.495 0.709 0.724 0.746 AUC-train 0.959\n",
            "Shapley [0.00725785 0.0042373  0.00645783 0.0181723  0.00318148] [0.00344937]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.207763\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.357  AUC-train 0.522\n",
            "Stats - Epoch: 2 AUC-val 0.426  AUC-train 0.643\n",
            "Stats - Epoch: 3 AUC-val 0.601  AUC-train 0.753\n",
            "Stats - Epoch: 4 AUC-val 0.653  AUC-train 0.808\n",
            "Stats - Epoch: 5 AUC-val 0.662  AUC-train 0.838\n",
            "Stats - Epoch: 6 AUC-val 0.671  AUC-train 0.857\n",
            "Stats - Epoch: 7 AUC-val 0.682  AUC-train 0.872\n",
            "Stats - Epoch: 8 AUC-val 0.679  AUC-train 0.884\n",
            "Stats - Epoch: 9 AUC-val 0.702  AUC-train 0.895\n",
            "Stats - Epoch: 10 AUC-val 0.702  AUC-train 0.901\n",
            "Stats - Epoch: 11 AUC-val 0.688  AUC-train 0.912\n",
            "Stats - Epoch: 12 AUC-val 0.681  AUC-train 0.919\n",
            "Stats - Epoch: 13 AUC-val 0.703  AUC-train 0.927\n",
            "Stats - Epoch: 14 AUC-val 0.681  AUC-train 0.931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.674  AUC-train 0.935\n",
            "Stats - Epoch: 16 AUC-val 0.675  AUC-train 0.937\n",
            "Stats - Epoch: 17 AUC-val 0.676  AUC-train 0.942\n",
            "Stats - Epoch: 18 AUC-val 0.666  AUC-train 0.945\n",
            "Stats - Epoch: 19 AUC-val 0.678  AUC-train 0.947\n",
            "Stats - Epoch: 20 AUC-val 0.676  AUC-train 0.951\n",
            "Stats - Epoch: 21 AUC-val 0.676  AUC-train 0.955\n",
            "Stats - Epoch: 22 AUC-val 0.686  AUC-train 0.955\n",
            "Stats - Epoch: 23 AUC-val 0.670  AUC-train 0.958\n",
            "Stats - Epoch: 24 AUC-val 0.655  AUC-train 0.960\n",
            "Stats - Epoch: 25 AUC-val 0.657  AUC-train 0.963\n",
            "Stats - Epoch: 26 AUC-val 0.668  AUC-train 0.964\n",
            "Stats - Epoch: 27 AUC-val 0.701  AUC-train 0.964\n",
            "Stats - Epoch: 28 AUC-val 0.681  AUC-train 0.967\n",
            "Stats - Epoch: 29 AUC-val 0.674  AUC-train 0.968\n",
            "Stats - Epoch: 30 AUC-val 0.657  AUC-train 0.970\n",
            "Stats - Epoch: 31 AUC-val 0.687  AUC-train 0.970\n",
            "Stats - Epoch: 32 AUC-val 0.656  AUC-train 0.971\n",
            "Stats - Epoch: 33 AUC-val 0.669  AUC-train 0.973\n",
            "Stats - Epoch: 34 AUC-val 0.663  AUC-train 0.973\n",
            "Stats - Epoch: 35 AUC-val 0.685  AUC-train 0.974\n",
            "Stats - Epoch: 36 AUC-val 0.681  AUC-train 0.973\n",
            "Stats - Epoch: 37 AUC-val 0.667  AUC-train 0.976\n",
            "Stats - Epoch: 38 AUC-val 0.658  AUC-train 0.975\n",
            "Stats - Epoch: 39 AUC-val 0.674  AUC-train 0.977\n",
            "Stats - Epoch: 40 AUC-val 0.691  AUC-train 0.977\n",
            "Stats - Epoch: 41 AUC-val 0.672  AUC-train 0.979\n",
            "Stats - Epoch: 42 AUC-val 0.705  AUC-train 0.978\n",
            "Stats - Epoch: 43 AUC-val 0.684  AUC-train 0.979\n",
            "Stats - Epoch: 44 AUC-val 0.703  AUC-train 0.980\n",
            "Stats - Epoch: 45 AUC-val 0.696  AUC-train 0.980\n",
            "Stats - Epoch: 46 AUC-val 0.675  AUC-train 0.980\n",
            "Stats - Epoch: 47 AUC-val 0.694  AUC-train 0.979\n",
            "Stats - Epoch: 48 AUC-val 0.686  AUC-train 0.982\n",
            "Stats - Epoch: 49 AUC-val 0.672  AUC-train 0.983\n",
            "Stats - Epoch: 50 AUC-val 0.685  AUC-train 0.983\n",
            "Stats - Epoch: 51 AUC-val 0.696  AUC-train 0.983\n",
            "Stats - Epoch: 52 AUC-val 0.687  AUC-train 0.982\n",
            "Stats - Epoch: 53 AUC-val 0.641  AUC-train 0.981\n",
            "Stats - Epoch: 54 AUC-val 0.668  AUC-train 0.982\n",
            "Stats - Epoch: 55 AUC-val 0.681  AUC-train 0.982\n",
            "Stats - Epoch: 56 AUC-val 0.680  AUC-train 0.984\n",
            "Stats - Epoch: 57 AUC-val 0.663  AUC-train 0.983\n",
            "Stats - Epoch: 58 AUC-val 0.661  AUC-train 0.983\n",
            "Stats - Epoch: 59 AUC-val 0.673  AUC-train 0.984\n",
            "Stats - Epoch: 60 AUC-val 0.694  AUC-train 0.986\n",
            "Stats - Epoch: 61 AUC-val 0.676  AUC-train 0.985\n",
            "Stats - Epoch: 62 AUC-val 0.668  AUC-train 0.986\n",
            "Stats - Epoch: 63 AUC-val 0.682  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.696  AUC-train 0.986\n",
            "Stats - Epoch: 65 AUC-val 0.693  AUC-train 0.987\n",
            "Stats - Epoch: 66 AUC-val 0.667  AUC-train 0.985\n",
            "Stats - Epoch: 67 AUC-val 0.696  AUC-train 0.985\n",
            "Stats - Epoch: 68 AUC-val 0.703  AUC-train 0.983\n",
            "Stats - Epoch: 69 AUC-val 0.694  AUC-train 0.986\n",
            "Stats - Epoch: 70 AUC-val 0.649  AUC-train 0.984\n",
            "Stats - Epoch: 71 AUC-val 0.692  AUC-train 0.987\n",
            "Stats - Epoch: 72 AUC-val 0.666  AUC-train 0.988\n",
            "Stats - Epoch: 73 AUC-val 0.693  AUC-train 0.988\n",
            "Stats - Epoch: 74 AUC-val 0.694  AUC-train 0.987\n",
            "Stats - Epoch: 75 AUC-val 0.685  AUC-train 0.987\n",
            "Stats - Epoch: 76 AUC-val 0.716  AUC-train 0.986\n",
            "Stats - Epoch: 77 AUC-val 0.716  AUC-train 0.987\n",
            "Stats - Epoch: 78 AUC-val 0.711  AUC-train 0.988\n",
            "Stats - Epoch: 79 AUC-val 0.692  AUC-train 0.988\n",
            "Stats - Epoch: 80 AUC-val 0.692  AUC-train 0.989\n",
            "Stats - Epoch: 81 AUC-val 0.700  AUC-train 0.989\n",
            "Stats - Epoch: 82 AUC-val 0.673  AUC-train 0.987\n",
            "Stats - Epoch: 83 AUC-val 0.697  AUC-train 0.989\n",
            "Stats - Epoch: 84 AUC-val 0.692  AUC-train 0.989\n",
            "Stats - Epoch: 85 AUC-val 0.707  AUC-train 0.990\n",
            "Stats - Epoch: 86 AUC-val 0.724  AUC-train 0.990\n",
            "Stats - Epoch: 87 AUC-val 0.731  AUC-train 0.989\n",
            "Stats - Epoch: 88 AUC-val 0.699  AUC-train 0.989\n",
            "Stats - Epoch: 89 AUC-val 0.730  AUC-train 0.990\n",
            "Stats - Epoch: 90 AUC-val 0.716  AUC-train 0.990\n",
            "Stats - Epoch: 91 AUC-val 0.670  AUC-train 0.990\n",
            "Stats - Epoch: 92 AUC-val 0.713  AUC-train 0.988\n",
            "Stats - Epoch: 93 AUC-val 0.679  AUC-train 0.990\n",
            "Stats - Epoch: 94 AUC-val 0.715  AUC-train 0.987\n",
            "Stats - Epoch: 95 AUC-val 0.720  AUC-train 0.986\n",
            "Stats - Epoch: 96 AUC-val 0.728  AUC-train 0.988\n",
            "Stats - Epoch: 97 AUC-val 0.718  AUC-train 0.988\n",
            "Stats - Epoch: 98 AUC-val 0.715  AUC-train 0.988\n",
            "Stats - Epoch: 99 AUC-val 0.751  AUC-train 0.988\n",
            "Stats - Epoch: 100 AUC-val 0.714  AUC-train 0.990\n",
            "Results 100 AUC-val 0.575 0.580 0.626 0.751 0.769 AUC-train 0.988\n",
            "Shapley [0.01318509 0.00808106 0.01985728 0.0305487  0.00316763] [0.00478744]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.205447\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.291  AUC-train 0.404\n",
            "Stats - Epoch: 2 AUC-val 0.272  AUC-train 0.494\n",
            "Stats - Epoch: 3 AUC-val 0.276  AUC-train 0.595\n",
            "Stats - Epoch: 4 AUC-val 0.318  AUC-train 0.666\n",
            "Stats - Epoch: 5 AUC-val 0.336  AUC-train 0.727\n",
            "Stats - Epoch: 6 AUC-val 0.369  AUC-train 0.772\n",
            "Stats - Epoch: 7 AUC-val 0.390  AUC-train 0.800\n",
            "Stats - Epoch: 8 AUC-val 0.421  AUC-train 0.828\n",
            "Stats - Epoch: 9 AUC-val 0.426  AUC-train 0.856\n",
            "Stats - Epoch: 10 AUC-val 0.472  AUC-train 0.874\n",
            "Stats - Epoch: 11 AUC-val 0.500  AUC-train 0.893\n",
            "Stats - Epoch: 12 AUC-val 0.500  AUC-train 0.900\n",
            "Stats - Epoch: 13 AUC-val 0.510  AUC-train 0.912\n",
            "Stats - Epoch: 14 AUC-val 0.515  AUC-train 0.922\n",
            "Stats - Epoch: 15 AUC-val 0.502  AUC-train 0.933\n",
            "Stats - Epoch: 16 AUC-val 0.527  AUC-train 0.936\n",
            "Stats - Epoch: 17 AUC-val 0.527  AUC-train 0.942\n",
            "Stats - Epoch: 18 AUC-val 0.547  AUC-train 0.946\n",
            "Stats - Epoch: 19 AUC-val 0.514  AUC-train 0.954\n",
            "Stats - Epoch: 20 AUC-val 0.542  AUC-train 0.954\n",
            "Stats - Epoch: 21 AUC-val 0.550  AUC-train 0.956\n",
            "Stats - Epoch: 22 AUC-val 0.555  AUC-train 0.963\n",
            "Stats - Epoch: 23 AUC-val 0.538  AUC-train 0.964\n",
            "Stats - Epoch: 24 AUC-val 0.554  AUC-train 0.970\n",
            "Stats - Epoch: 25 AUC-val 0.555  AUC-train 0.970\n",
            "Stats - Epoch: 26 AUC-val 0.560  AUC-train 0.973\n",
            "Stats - Epoch: 27 AUC-val 0.586  AUC-train 0.974\n",
            "Stats - Epoch: 28 AUC-val 0.583  AUC-train 0.976\n",
            "Stats - Epoch: 29 AUC-val 0.583  AUC-train 0.973\n",
            "Stats - Epoch: 30 AUC-val 0.562  AUC-train 0.973\n",
            "Stats - Epoch: 31 AUC-val 0.566  AUC-train 0.973\n",
            "Stats - Epoch: 32 AUC-val 0.596  AUC-train 0.981\n",
            "Stats - Epoch: 33 AUC-val 0.577  AUC-train 0.979\n",
            "Stats - Epoch: 34 AUC-val 0.591  AUC-train 0.980\n",
            "Stats - Epoch: 35 AUC-val 0.604  AUC-train 0.982\n",
            "Stats - Epoch: 36 AUC-val 0.605  AUC-train 0.982\n",
            "Stats - Epoch: 37 AUC-val 0.562  AUC-train 0.982\n",
            "Stats - Epoch: 38 AUC-val 0.558  AUC-train 0.983\n",
            "Stats - Epoch: 39 AUC-val 0.606  AUC-train 0.984\n",
            "Stats - Epoch: 40 AUC-val 0.625  AUC-train 0.985\n",
            "Stats - Epoch: 41 AUC-val 0.617  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.593  AUC-train 0.988\n",
            "Stats - Epoch: 43 AUC-val 0.586  AUC-train 0.989\n",
            "Stats - Epoch: 44 AUC-val 0.590  AUC-train 0.987\n",
            "Stats - Epoch: 45 AUC-val 0.594  AUC-train 0.989\n",
            "Stats - Epoch: 46 AUC-val 0.621  AUC-train 0.984\n",
            "Stats - Epoch: 47 AUC-val 0.605  AUC-train 0.987\n",
            "Stats - Epoch: 48 AUC-val 0.576  AUC-train 0.985\n",
            "Stats - Epoch: 49 AUC-val 0.588  AUC-train 0.986\n",
            "Stats - Epoch: 50 AUC-val 0.610  AUC-train 0.987\n",
            "Stats - Epoch: 51 AUC-val 0.612  AUC-train 0.986\n",
            "Stats - Epoch: 52 AUC-val 0.637  AUC-train 0.985\n",
            "Stats - Epoch: 53 AUC-val 0.607  AUC-train 0.988\n",
            "Stats - Epoch: 54 AUC-val 0.623  AUC-train 0.988\n",
            "Stats - Epoch: 55 AUC-val 0.617  AUC-train 0.987\n",
            "Stats - Epoch: 56 AUC-val 0.651  AUC-train 0.987\n",
            "Stats - Epoch: 57 AUC-val 0.645  AUC-train 0.987\n",
            "Stats - Epoch: 58 AUC-val 0.660  AUC-train 0.990\n",
            "Stats - Epoch: 59 AUC-val 0.624  AUC-train 0.989\n",
            "Stats - Epoch: 60 AUC-val 0.632  AUC-train 0.988\n",
            "Stats - Epoch: 61 AUC-val 0.642  AUC-train 0.988\n",
            "Stats - Epoch: 62 AUC-val 0.617  AUC-train 0.988\n",
            "Stats - Epoch: 63 AUC-val 0.635  AUC-train 0.989\n",
            "Stats - Epoch: 64 AUC-val 0.650  AUC-train 0.990\n",
            "Stats - Epoch: 65 AUC-val 0.631  AUC-train 0.991\n",
            "Stats - Epoch: 66 AUC-val 0.632  AUC-train 0.990\n",
            "Stats - Epoch: 67 AUC-val 0.617  AUC-train 0.991\n",
            "Stats - Epoch: 68 AUC-val 0.633  AUC-train 0.992\n",
            "Stats - Epoch: 69 AUC-val 0.633  AUC-train 0.989\n",
            "Stats - Epoch: 70 AUC-val 0.632  AUC-train 0.993\n",
            "Stats - Epoch: 71 AUC-val 0.614  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.638  AUC-train 0.990\n",
            "Stats - Epoch: 73 AUC-val 0.657  AUC-train 0.991\n",
            "Stats - Epoch: 74 AUC-val 0.635  AUC-train 0.992\n",
            "Stats - Epoch: 75 AUC-val 0.610  AUC-train 0.993\n",
            "Stats - Epoch: 76 AUC-val 0.619  AUC-train 0.993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.594  AUC-train 0.992\n",
            "Stats - Epoch: 78 AUC-val 0.620  AUC-train 0.993\n",
            "Stats - Epoch: 79 AUC-val 0.630  AUC-train 0.993\n",
            "Stats - Epoch: 80 AUC-val 0.611  AUC-train 0.992\n",
            "Stats - Epoch: 81 AUC-val 0.626  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.635  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.622  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.619  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.640  AUC-train 0.995\n",
            "Stats - Epoch: 86 AUC-val 0.659  AUC-train 0.991\n",
            "Stats - Epoch: 87 AUC-val 0.602  AUC-train 0.992\n",
            "Stats - Epoch: 88 AUC-val 0.655  AUC-train 0.993\n",
            "Stats - Epoch: 89 AUC-val 0.647  AUC-train 0.991\n",
            "Stats - Epoch: 90 AUC-val 0.647  AUC-train 0.989\n",
            "Stats - Epoch: 91 AUC-val 0.655  AUC-train 0.989\n",
            "Stats - Epoch: 92 AUC-val 0.641  AUC-train 0.989\n",
            "Stats - Epoch: 93 AUC-val 0.627  AUC-train 0.991\n",
            "Stats - Epoch: 94 AUC-val 0.634  AUC-train 0.991\n",
            "Stats - Epoch: 95 AUC-val 0.616  AUC-train 0.989\n",
            "Stats - Epoch: 96 AUC-val 0.624  AUC-train 0.992\n",
            "Stats - Epoch: 97 AUC-val 0.611  AUC-train 0.992\n",
            "Stats - Epoch: 98 AUC-val 0.641  AUC-train 0.991\n",
            "Stats - Epoch: 99 AUC-val 0.623  AUC-train 0.991\n",
            "Stats - Epoch: 100 AUC-val 0.636  AUC-train 0.991\n",
            "Results 100 AUC-val 0.599 0.570 0.616 0.660 0.741 AUC-train 0.990\n",
            "Shapley [0.0105235  0.00676206 0.00944713 0.02496839 0.00357141] [0.00310239]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.230541\n",
            "         Iterations 8\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.406  AUC-train 0.598\n",
            "Stats - Epoch: 2 AUC-val 0.601  AUC-train 0.767\n",
            "Stats - Epoch: 3 AUC-val 0.601  AUC-train 0.855\n",
            "Stats - Epoch: 4 AUC-val 0.599  AUC-train 0.896\n",
            "Stats - Epoch: 5 AUC-val 0.590  AUC-train 0.920\n",
            "Stats - Epoch: 6 AUC-val 0.597  AUC-train 0.935\n",
            "Stats - Epoch: 7 AUC-val 0.580  AUC-train 0.948\n",
            "Stats - Epoch: 8 AUC-val 0.570  AUC-train 0.958\n",
            "Stats - Epoch: 9 AUC-val 0.598  AUC-train 0.968\n",
            "Stats - Epoch: 10 AUC-val 0.592  AUC-train 0.973\n",
            "Stats - Epoch: 11 AUC-val 0.581  AUC-train 0.980\n",
            "Stats - Epoch: 12 AUC-val 0.561  AUC-train 0.984\n",
            "Stats - Epoch: 13 AUC-val 0.603  AUC-train 0.988\n",
            "Stats - Epoch: 14 AUC-val 0.589  AUC-train 0.991\n",
            "Stats - Epoch: 15 AUC-val 0.593  AUC-train 0.993\n",
            "Stats - Epoch: 16 AUC-val 0.589  AUC-train 0.993\n",
            "Stats - Epoch: 17 AUC-val 0.616  AUC-train 0.994\n",
            "Stats - Epoch: 18 AUC-val 0.594  AUC-train 0.995\n",
            "Stats - Epoch: 19 AUC-val 0.576  AUC-train 0.997\n",
            "Stats - Epoch: 20 AUC-val 0.600  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.566  AUC-train 0.996\n",
            "Stats - Epoch: 22 AUC-val 0.593  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.557  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.598  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.584  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.588  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.602  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.599  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.615  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.564  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.593  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.584  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.595  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.527  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.574  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.590  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.595  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.538  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.569  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.580  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.595  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.568  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.582  AUC-train 1.000\n",
            "Stats - Epoch: 44 AUC-val 0.619  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.595  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.615  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.584  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.590  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.595  AUC-train 1.000\n",
            "Stats - Epoch: 50 AUC-val 0.636  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.597  AUC-train 0.998\n",
            "Stats - Epoch: 52 AUC-val 0.595  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.584  AUC-train 1.000\n",
            "Stats - Epoch: 54 AUC-val 0.615  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.599  AUC-train 1.000\n",
            "Stats - Epoch: 56 AUC-val 0.603  AUC-train 1.000\n",
            "Stats - Epoch: 57 AUC-val 0.612  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.609  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.643  AUC-train 0.996\n",
            "Stats - Epoch: 60 AUC-val 0.623  AUC-train 0.994\n",
            "Stats - Epoch: 61 AUC-val 0.596  AUC-train 0.998\n",
            "Stats - Epoch: 62 AUC-val 0.616  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.568  AUC-train 0.997\n",
            "Stats - Epoch: 64 AUC-val 0.601  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.595  AUC-train 0.998\n",
            "Stats - Epoch: 66 AUC-val 0.601  AUC-train 1.000\n",
            "Stats - Epoch: 67 AUC-val 0.608  AUC-train 1.000\n",
            "Stats - Epoch: 68 AUC-val 0.626  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.587  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.620  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.628  AUC-train 0.999\n",
            "Stats - Epoch: 72 AUC-val 0.618  AUC-train 0.994\n",
            "Stats - Epoch: 73 AUC-val 0.614  AUC-train 0.996\n",
            "Stats - Epoch: 74 AUC-val 0.596  AUC-train 0.993\n",
            "Stats - Epoch: 75 AUC-val 0.609  AUC-train 0.992\n",
            "Stats - Epoch: 76 AUC-val 0.638  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.622  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.635  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.622  AUC-train 1.000\n",
            "Stats - Epoch: 80 AUC-val 0.608  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.627  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.616  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.631  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.626  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.643  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.663  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.613  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.654  AUC-train 1.000\n",
            "Stats - Epoch: 89 AUC-val 0.640  AUC-train 1.000\n",
            "Stats - Epoch: 90 AUC-val 0.623  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.619  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.633  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.601  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.598  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.622  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.598  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.610  AUC-train 0.995\n",
            "Stats - Epoch: 98 AUC-val 0.609  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.605  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.627  AUC-train 0.998\n",
            "Results 100 AUC-val 0.544 0.592 0.613 0.663 0.723 AUC-train 0.998\n",
            "Shapley [0.01643041 0.00971985 0.01480212 0.03229143 0.00505228] [0.00039541]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.230073\n",
            "         Iterations 7\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.273  AUC-train 0.687\n",
            "Results 1 AUC-val 0.771 0.743 0.676 0.701 0.273 AUC-train 0.687\n",
            "Shapley [0.00320961 0.00497296 0.00257915 0.00780485 0.00426163] [0.01567887]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.210433\n",
            "         Iterations 10\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.566  AUC-train 0.848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.602 0.516 0.401 0.522 0.566 AUC-train 0.848\n",
            "Shapley [0.0111093  0.00643112 0.01712161 0.01343759 0.01589231] [0.00414688]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.226698\n",
            "         Iterations 10\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.402  AUC-train 0.381\n",
            "Stats - Epoch: 2 AUC-val 0.344  AUC-train 0.427\n",
            "Stats - Epoch: 3 AUC-val 0.362  AUC-train 0.459\n",
            "Stats - Epoch: 4 AUC-val 0.384  AUC-train 0.504\n",
            "Stats - Epoch: 5 AUC-val 0.400  AUC-train 0.532\n",
            "Stats - Epoch: 6 AUC-val 0.404  AUC-train 0.554\n",
            "Stats - Epoch: 7 AUC-val 0.417  AUC-train 0.580\n",
            "Stats - Epoch: 8 AUC-val 0.421  AUC-train 0.625\n",
            "Stats - Epoch: 9 AUC-val 0.414  AUC-train 0.647\n",
            "Stats - Epoch: 10 AUC-val 0.406  AUC-train 0.664\n",
            "Stats - Epoch: 11 AUC-val 0.415  AUC-train 0.695\n",
            "Stats - Epoch: 12 AUC-val 0.428  AUC-train 0.701\n",
            "Stats - Epoch: 13 AUC-val 0.426  AUC-train 0.738\n",
            "Stats - Epoch: 14 AUC-val 0.404  AUC-train 0.756\n",
            "Stats - Epoch: 15 AUC-val 0.428  AUC-train 0.754\n",
            "Stats - Epoch: 16 AUC-val 0.437  AUC-train 0.756\n",
            "Stats - Epoch: 17 AUC-val 0.425  AUC-train 0.791\n",
            "Stats - Epoch: 18 AUC-val 0.440  AUC-train 0.796\n",
            "Stats - Epoch: 19 AUC-val 0.437  AUC-train 0.812\n",
            "Stats - Epoch: 20 AUC-val 0.451  AUC-train 0.819\n",
            "Stats - Epoch: 21 AUC-val 0.446  AUC-train 0.822\n",
            "Stats - Epoch: 22 AUC-val 0.447  AUC-train 0.818\n",
            "Stats - Epoch: 23 AUC-val 0.450  AUC-train 0.847\n",
            "Stats - Epoch: 24 AUC-val 0.458  AUC-train 0.843\n",
            "Stats - Epoch: 25 AUC-val 0.456  AUC-train 0.838\n",
            "Stats - Epoch: 26 AUC-val 0.455  AUC-train 0.849\n",
            "Stats - Epoch: 27 AUC-val 0.465  AUC-train 0.865\n",
            "Stats - Epoch: 28 AUC-val 0.462  AUC-train 0.851\n",
            "Stats - Epoch: 29 AUC-val 0.469  AUC-train 0.865\n",
            "Stats - Epoch: 30 AUC-val 0.460  AUC-train 0.872\n",
            "Stats - Epoch: 31 AUC-val 0.471  AUC-train 0.871\n",
            "Stats - Epoch: 32 AUC-val 0.463  AUC-train 0.877\n",
            "Stats - Epoch: 33 AUC-val 0.474  AUC-train 0.883\n",
            "Stats - Epoch: 34 AUC-val 0.464  AUC-train 0.878\n",
            "Stats - Epoch: 35 AUC-val 0.474  AUC-train 0.876\n",
            "Stats - Epoch: 36 AUC-val 0.468  AUC-train 0.891\n",
            "Stats - Epoch: 37 AUC-val 0.467  AUC-train 0.889\n",
            "Stats - Epoch: 38 AUC-val 0.470  AUC-train 0.868\n",
            "Stats - Epoch: 39 AUC-val 0.467  AUC-train 0.885\n",
            "Stats - Epoch: 40 AUC-val 0.481  AUC-train 0.883\n",
            "Stats - Epoch: 41 AUC-val 0.473  AUC-train 0.892\n",
            "Stats - Epoch: 42 AUC-val 0.475  AUC-train 0.887\n",
            "Stats - Epoch: 43 AUC-val 0.468  AUC-train 0.888\n",
            "Stats - Epoch: 44 AUC-val 0.475  AUC-train 0.892\n",
            "Stats - Epoch: 45 AUC-val 0.478  AUC-train 0.887\n",
            "Stats - Epoch: 46 AUC-val 0.465  AUC-train 0.893\n",
            "Stats - Epoch: 47 AUC-val 0.481  AUC-train 0.887\n",
            "Stats - Epoch: 48 AUC-val 0.478  AUC-train 0.895\n",
            "Stats - Epoch: 49 AUC-val 0.484  AUC-train 0.897\n",
            "Stats - Epoch: 50 AUC-val 0.477  AUC-train 0.893\n",
            "Stats - Epoch: 51 AUC-val 0.482  AUC-train 0.897\n",
            "Stats - Epoch: 52 AUC-val 0.483  AUC-train 0.902\n",
            "Stats - Epoch: 53 AUC-val 0.501  AUC-train 0.891\n",
            "Stats - Epoch: 54 AUC-val 0.491  AUC-train 0.891\n",
            "Stats - Epoch: 55 AUC-val 0.488  AUC-train 0.901\n",
            "Stats - Epoch: 56 AUC-val 0.481  AUC-train 0.895\n",
            "Stats - Epoch: 57 AUC-val 0.490  AUC-train 0.904\n",
            "Stats - Epoch: 58 AUC-val 0.493  AUC-train 0.904\n",
            "Stats - Epoch: 59 AUC-val 0.490  AUC-train 0.898\n",
            "Stats - Epoch: 60 AUC-val 0.474  AUC-train 0.903\n",
            "Stats - Epoch: 61 AUC-val 0.485  AUC-train 0.907\n",
            "Stats - Epoch: 62 AUC-val 0.512  AUC-train 0.892\n",
            "Stats - Epoch: 63 AUC-val 0.495  AUC-train 0.906\n",
            "Stats - Epoch: 64 AUC-val 0.494  AUC-train 0.913\n",
            "Stats - Epoch: 65 AUC-val 0.486  AUC-train 0.909\n",
            "Stats - Epoch: 66 AUC-val 0.490  AUC-train 0.910\n",
            "Stats - Epoch: 67 AUC-val 0.489  AUC-train 0.910\n",
            "Stats - Epoch: 68 AUC-val 0.499  AUC-train 0.911\n",
            "Stats - Epoch: 69 AUC-val 0.495  AUC-train 0.911\n",
            "Stats - Epoch: 70 AUC-val 0.495  AUC-train 0.910\n",
            "Stats - Epoch: 71 AUC-val 0.507  AUC-train 0.908\n",
            "Stats - Epoch: 72 AUC-val 0.494  AUC-train 0.910\n",
            "Stats - Epoch: 73 AUC-val 0.495  AUC-train 0.910\n",
            "Stats - Epoch: 74 AUC-val 0.494  AUC-train 0.911\n",
            "Stats - Epoch: 75 AUC-val 0.494  AUC-train 0.902\n",
            "Stats - Epoch: 76 AUC-val 0.501  AUC-train 0.913\n",
            "Stats - Epoch: 77 AUC-val 0.496  AUC-train 0.910\n",
            "Stats - Epoch: 78 AUC-val 0.491  AUC-train 0.909\n",
            "Stats - Epoch: 79 AUC-val 0.507  AUC-train 0.915\n",
            "Stats - Epoch: 80 AUC-val 0.495  AUC-train 0.912\n",
            "Stats - Epoch: 81 AUC-val 0.489  AUC-train 0.914\n",
            "Stats - Epoch: 82 AUC-val 0.498  AUC-train 0.913\n",
            "Stats - Epoch: 83 AUC-val 0.497  AUC-train 0.913\n",
            "Stats - Epoch: 84 AUC-val 0.500  AUC-train 0.915\n",
            "Stats - Epoch: 85 AUC-val 0.502  AUC-train 0.917\n",
            "Stats - Epoch: 86 AUC-val 0.498  AUC-train 0.919\n",
            "Stats - Epoch: 87 AUC-val 0.502  AUC-train 0.912\n",
            "Stats - Epoch: 88 AUC-val 0.495  AUC-train 0.915\n",
            "Stats - Epoch: 89 AUC-val 0.499  AUC-train 0.916\n",
            "Stats - Epoch: 90 AUC-val 0.506  AUC-train 0.918\n",
            "Stats - Epoch: 91 AUC-val 0.508  AUC-train 0.916\n",
            "Stats - Epoch: 92 AUC-val 0.499  AUC-train 0.919\n",
            "Stats - Epoch: 93 AUC-val 0.501  AUC-train 0.919\n",
            "Stats - Epoch: 94 AUC-val 0.510  AUC-train 0.917\n",
            "Stats - Epoch: 95 AUC-val 0.493  AUC-train 0.917\n",
            "Stats - Epoch: 96 AUC-val 0.508  AUC-train 0.918\n",
            "Stats - Epoch: 97 AUC-val 0.490  AUC-train 0.920\n",
            "Stats - Epoch: 98 AUC-val 0.498  AUC-train 0.918\n",
            "Stats - Epoch: 99 AUC-val 0.490  AUC-train 0.915\n",
            "Stats - Epoch: 100 AUC-val 0.515  AUC-train 0.920\n",
            "Results 100 AUC-val 0.587 0.450 0.530 0.466 0.515 AUC-train 0.920\n",
            "Shapley [0.01205303 0.00671134 0.00690218 0.00580687 0.00495103] [0.02569967]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.240595\n",
            "         Iterations 8\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.347  AUC-train 0.484\n",
            "Stats - Epoch: 2 AUC-val 0.471  AUC-train 0.635\n",
            "Stats - Epoch: 3 AUC-val 0.534  AUC-train 0.744\n",
            "Stats - Epoch: 4 AUC-val 0.576  AUC-train 0.815\n",
            "Stats - Epoch: 5 AUC-val 0.641  AUC-train 0.867\n",
            "Stats - Epoch: 6 AUC-val 0.695  AUC-train 0.900\n",
            "Stats - Epoch: 7 AUC-val 0.678  AUC-train 0.922\n",
            "Stats - Epoch: 8 AUC-val 0.696  AUC-train 0.934\n",
            "Stats - Epoch: 9 AUC-val 0.697  AUC-train 0.951\n",
            "Stats - Epoch: 10 AUC-val 0.703  AUC-train 0.953\n",
            "Stats - Epoch: 11 AUC-val 0.702  AUC-train 0.966\n",
            "Stats - Epoch: 12 AUC-val 0.671  AUC-train 0.965\n",
            "Stats - Epoch: 13 AUC-val 0.673  AUC-train 0.969\n",
            "Stats - Epoch: 14 AUC-val 0.683  AUC-train 0.976\n",
            "Stats - Epoch: 15 AUC-val 0.672  AUC-train 0.978\n",
            "Stats - Epoch: 16 AUC-val 0.687  AUC-train 0.976\n",
            "Stats - Epoch: 17 AUC-val 0.666  AUC-train 0.982\n",
            "Stats - Epoch: 18 AUC-val 0.674  AUC-train 0.980\n",
            "Stats - Epoch: 19 AUC-val 0.654  AUC-train 0.979\n",
            "Stats - Epoch: 20 AUC-val 0.664  AUC-train 0.981\n",
            "Stats - Epoch: 21 AUC-val 0.659  AUC-train 0.984\n",
            "Stats - Epoch: 22 AUC-val 0.656  AUC-train 0.982\n",
            "Stats - Epoch: 23 AUC-val 0.661  AUC-train 0.986\n",
            "Stats - Epoch: 24 AUC-val 0.652  AUC-train 0.982\n",
            "Stats - Epoch: 25 AUC-val 0.641  AUC-train 0.983\n",
            "Stats - Epoch: 26 AUC-val 0.635  AUC-train 0.981\n",
            "Stats - Epoch: 27 AUC-val 0.657  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.648  AUC-train 0.986\n",
            "Stats - Epoch: 29 AUC-val 0.645  AUC-train 0.985\n",
            "Stats - Epoch: 30 AUC-val 0.654  AUC-train 0.986\n",
            "Stats - Epoch: 31 AUC-val 0.653  AUC-train 0.985\n",
            "Stats - Epoch: 32 AUC-val 0.638  AUC-train 0.984\n",
            "Stats - Epoch: 33 AUC-val 0.642  AUC-train 0.987\n",
            "Stats - Epoch: 34 AUC-val 0.628  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.654  AUC-train 0.986\n",
            "Stats - Epoch: 36 AUC-val 0.654  AUC-train 0.989\n",
            "Stats - Epoch: 37 AUC-val 0.645  AUC-train 0.987\n",
            "Stats - Epoch: 38 AUC-val 0.659  AUC-train 0.984\n",
            "Stats - Epoch: 39 AUC-val 0.647  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.644  AUC-train 0.988\n",
            "Stats - Epoch: 41 AUC-val 0.655  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.652  AUC-train 0.986\n",
            "Stats - Epoch: 43 AUC-val 0.644  AUC-train 0.986\n",
            "Stats - Epoch: 44 AUC-val 0.646  AUC-train 0.987\n",
            "Stats - Epoch: 45 AUC-val 0.649  AUC-train 0.988\n",
            "Stats - Epoch: 46 AUC-val 0.675  AUC-train 0.985\n",
            "Stats - Epoch: 47 AUC-val 0.644  AUC-train 0.985\n",
            "Stats - Epoch: 48 AUC-val 0.656  AUC-train 0.987\n",
            "Stats - Epoch: 49 AUC-val 0.649  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.657  AUC-train 0.986\n",
            "Stats - Epoch: 51 AUC-val 0.667  AUC-train 0.987\n",
            "Stats - Epoch: 52 AUC-val 0.663  AUC-train 0.988\n",
            "Stats - Epoch: 53 AUC-val 0.649  AUC-train 0.985\n",
            "Stats - Epoch: 54 AUC-val 0.668  AUC-train 0.987\n",
            "Stats - Epoch: 55 AUC-val 0.654  AUC-train 0.984\n",
            "Stats - Epoch: 56 AUC-val 0.644  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.674  AUC-train 0.986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.655  AUC-train 0.986\n",
            "Stats - Epoch: 59 AUC-val 0.670  AUC-train 0.983\n",
            "Stats - Epoch: 60 AUC-val 0.673  AUC-train 0.986\n",
            "Stats - Epoch: 61 AUC-val 0.674  AUC-train 0.986\n",
            "Stats - Epoch: 62 AUC-val 0.679  AUC-train 0.985\n",
            "Stats - Epoch: 63 AUC-val 0.665  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.668  AUC-train 0.987\n",
            "Stats - Epoch: 65 AUC-val 0.665  AUC-train 0.982\n",
            "Stats - Epoch: 66 AUC-val 0.666  AUC-train 0.987\n",
            "Stats - Epoch: 67 AUC-val 0.666  AUC-train 0.987\n",
            "Stats - Epoch: 68 AUC-val 0.668  AUC-train 0.983\n",
            "Stats - Epoch: 69 AUC-val 0.667  AUC-train 0.986\n",
            "Stats - Epoch: 70 AUC-val 0.682  AUC-train 0.985\n",
            "Stats - Epoch: 71 AUC-val 0.664  AUC-train 0.985\n",
            "Stats - Epoch: 72 AUC-val 0.665  AUC-train 0.984\n",
            "Stats - Epoch: 73 AUC-val 0.666  AUC-train 0.986\n",
            "Stats - Epoch: 74 AUC-val 0.661  AUC-train 0.983\n",
            "Stats - Epoch: 75 AUC-val 0.657  AUC-train 0.983\n",
            "Stats - Epoch: 76 AUC-val 0.658  AUC-train 0.983\n",
            "Stats - Epoch: 77 AUC-val 0.646  AUC-train 0.982\n",
            "Stats - Epoch: 78 AUC-val 0.668  AUC-train 0.981\n",
            "Stats - Epoch: 79 AUC-val 0.674  AUC-train 0.985\n",
            "Stats - Epoch: 80 AUC-val 0.668  AUC-train 0.984\n",
            "Stats - Epoch: 81 AUC-val 0.673  AUC-train 0.982\n",
            "Stats - Epoch: 82 AUC-val 0.666  AUC-train 0.985\n",
            "Stats - Epoch: 83 AUC-val 0.672  AUC-train 0.983\n",
            "Stats - Epoch: 84 AUC-val 0.692  AUC-train 0.984\n",
            "Stats - Epoch: 85 AUC-val 0.669  AUC-train 0.984\n",
            "Stats - Epoch: 86 AUC-val 0.685  AUC-train 0.984\n",
            "Stats - Epoch: 87 AUC-val 0.665  AUC-train 0.984\n",
            "Stats - Epoch: 88 AUC-val 0.668  AUC-train 0.987\n",
            "Stats - Epoch: 89 AUC-val 0.686  AUC-train 0.986\n",
            "Stats - Epoch: 90 AUC-val 0.672  AUC-train 0.986\n",
            "Stats - Epoch: 91 AUC-val 0.685  AUC-train 0.983\n",
            "Stats - Epoch: 92 AUC-val 0.682  AUC-train 0.984\n",
            "Stats - Epoch: 93 AUC-val 0.679  AUC-train 0.983\n",
            "Stats - Epoch: 94 AUC-val 0.690  AUC-train 0.986\n",
            "Stats - Epoch: 95 AUC-val 0.674  AUC-train 0.984\n",
            "Stats - Epoch: 96 AUC-val 0.691  AUC-train 0.985\n",
            "Stats - Epoch: 97 AUC-val 0.687  AUC-train 0.984\n",
            "Stats - Epoch: 98 AUC-val 0.677  AUC-train 0.985\n",
            "Stats - Epoch: 99 AUC-val 0.696  AUC-train 0.984\n",
            "Stats - Epoch: 100 AUC-val 0.690  AUC-train 0.980\n",
            "Results 100 AUC-val 0.361 0.083 0.162 0.477 0.703 AUC-train 0.953\n",
            "Shapley [0.01855444 0.01462774 0.01159515 0.06675603 0.05271363] [0.08422626]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.216294\n",
            "         Iterations 8\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.638  AUC-train 0.462\n",
            "Stats - Epoch: 2 AUC-val 0.612  AUC-train 0.528\n",
            "Stats - Epoch: 3 AUC-val 0.583  AUC-train 0.584\n",
            "Stats - Epoch: 4 AUC-val 0.545  AUC-train 0.653\n",
            "Stats - Epoch: 5 AUC-val 0.515  AUC-train 0.707\n",
            "Stats - Epoch: 6 AUC-val 0.501  AUC-train 0.748\n",
            "Stats - Epoch: 7 AUC-val 0.484  AUC-train 0.779\n",
            "Stats - Epoch: 8 AUC-val 0.458  AUC-train 0.801\n",
            "Stats - Epoch: 9 AUC-val 0.458  AUC-train 0.820\n",
            "Stats - Epoch: 10 AUC-val 0.458  AUC-train 0.836\n",
            "Stats - Epoch: 11 AUC-val 0.445  AUC-train 0.849\n",
            "Stats - Epoch: 12 AUC-val 0.438  AUC-train 0.863\n",
            "Stats - Epoch: 13 AUC-val 0.443  AUC-train 0.871\n",
            "Stats - Epoch: 14 AUC-val 0.453  AUC-train 0.879\n",
            "Stats - Epoch: 15 AUC-val 0.484  AUC-train 0.884\n",
            "Stats - Epoch: 16 AUC-val 0.478  AUC-train 0.889\n",
            "Stats - Epoch: 17 AUC-val 0.489  AUC-train 0.899\n",
            "Stats - Epoch: 18 AUC-val 0.478  AUC-train 0.904\n",
            "Stats - Epoch: 19 AUC-val 0.501  AUC-train 0.911\n",
            "Stats - Epoch: 20 AUC-val 0.471  AUC-train 0.910\n",
            "Stats - Epoch: 21 AUC-val 0.488  AUC-train 0.918\n",
            "Stats - Epoch: 22 AUC-val 0.501  AUC-train 0.911\n",
            "Stats - Epoch: 23 AUC-val 0.591  AUC-train 0.921\n",
            "Stats - Epoch: 24 AUC-val 0.531  AUC-train 0.925\n",
            "Stats - Epoch: 25 AUC-val 0.524  AUC-train 0.926\n",
            "Stats - Epoch: 26 AUC-val 0.552  AUC-train 0.928\n",
            "Stats - Epoch: 27 AUC-val 0.554  AUC-train 0.934\n",
            "Stats - Epoch: 28 AUC-val 0.543  AUC-train 0.936\n",
            "Stats - Epoch: 29 AUC-val 0.561  AUC-train 0.943\n",
            "Stats - Epoch: 30 AUC-val 0.554  AUC-train 0.940\n",
            "Stats - Epoch: 31 AUC-val 0.535  AUC-train 0.941\n",
            "Stats - Epoch: 32 AUC-val 0.558  AUC-train 0.945\n",
            "Stats - Epoch: 33 AUC-val 0.564  AUC-train 0.944\n",
            "Stats - Epoch: 34 AUC-val 0.548  AUC-train 0.944\n",
            "Stats - Epoch: 35 AUC-val 0.564  AUC-train 0.943\n",
            "Stats - Epoch: 36 AUC-val 0.619  AUC-train 0.948\n",
            "Stats - Epoch: 37 AUC-val 0.606  AUC-train 0.943\n",
            "Stats - Epoch: 38 AUC-val 0.586  AUC-train 0.951\n",
            "Stats - Epoch: 39 AUC-val 0.594  AUC-train 0.951\n",
            "Stats - Epoch: 40 AUC-val 0.579  AUC-train 0.952\n",
            "Stats - Epoch: 41 AUC-val 0.631  AUC-train 0.955\n",
            "Stats - Epoch: 42 AUC-val 0.630  AUC-train 0.955\n",
            "Stats - Epoch: 43 AUC-val 0.612  AUC-train 0.958\n",
            "Stats - Epoch: 44 AUC-val 0.614  AUC-train 0.959\n",
            "Stats - Epoch: 45 AUC-val 0.614  AUC-train 0.956\n",
            "Stats - Epoch: 46 AUC-val 0.597  AUC-train 0.958\n",
            "Stats - Epoch: 47 AUC-val 0.641  AUC-train 0.957\n",
            "Stats - Epoch: 48 AUC-val 0.671  AUC-train 0.958\n",
            "Stats - Epoch: 49 AUC-val 0.604  AUC-train 0.962\n",
            "Stats - Epoch: 50 AUC-val 0.646  AUC-train 0.964\n",
            "Stats - Epoch: 51 AUC-val 0.618  AUC-train 0.963\n",
            "Stats - Epoch: 52 AUC-val 0.609  AUC-train 0.966\n",
            "Stats - Epoch: 53 AUC-val 0.593  AUC-train 0.963\n",
            "Stats - Epoch: 54 AUC-val 0.719  AUC-train 0.965\n",
            "Stats - Epoch: 55 AUC-val 0.644  AUC-train 0.966\n",
            "Stats - Epoch: 56 AUC-val 0.697  AUC-train 0.965\n",
            "Stats - Epoch: 57 AUC-val 0.639  AUC-train 0.968\n",
            "Stats - Epoch: 58 AUC-val 0.639  AUC-train 0.966\n",
            "Stats - Epoch: 59 AUC-val 0.630  AUC-train 0.967\n",
            "Stats - Epoch: 60 AUC-val 0.640  AUC-train 0.971\n",
            "Stats - Epoch: 61 AUC-val 0.648  AUC-train 0.971\n",
            "Stats - Epoch: 62 AUC-val 0.663  AUC-train 0.969\n",
            "Stats - Epoch: 63 AUC-val 0.652  AUC-train 0.969\n",
            "Stats - Epoch: 64 AUC-val 0.737  AUC-train 0.973\n",
            "Stats - Epoch: 65 AUC-val 0.658  AUC-train 0.973\n",
            "Stats - Epoch: 66 AUC-val 0.666  AUC-train 0.976\n",
            "Stats - Epoch: 67 AUC-val 0.694  AUC-train 0.976\n",
            "Stats - Epoch: 68 AUC-val 0.674  AUC-train 0.974\n",
            "Stats - Epoch: 69 AUC-val 0.625  AUC-train 0.971\n",
            "Stats - Epoch: 70 AUC-val 0.670  AUC-train 0.970\n",
            "Stats - Epoch: 71 AUC-val 0.644  AUC-train 0.965\n",
            "Stats - Epoch: 72 AUC-val 0.619  AUC-train 0.967\n",
            "Stats - Epoch: 73 AUC-val 0.638  AUC-train 0.966\n",
            "Stats - Epoch: 74 AUC-val 0.651  AUC-train 0.967\n",
            "Stats - Epoch: 75 AUC-val 0.633  AUC-train 0.969\n",
            "Stats - Epoch: 76 AUC-val 0.636  AUC-train 0.966\n",
            "Stats - Epoch: 77 AUC-val 0.670  AUC-train 0.964\n",
            "Stats - Epoch: 78 AUC-val 0.687  AUC-train 0.965\n",
            "Stats - Epoch: 79 AUC-val 0.701  AUC-train 0.972\n",
            "Stats - Epoch: 80 AUC-val 0.676  AUC-train 0.970\n",
            "Stats - Epoch: 81 AUC-val 0.680  AUC-train 0.974\n",
            "Stats - Epoch: 82 AUC-val 0.668  AUC-train 0.976\n",
            "Stats - Epoch: 83 AUC-val 0.696  AUC-train 0.977\n",
            "Stats - Epoch: 84 AUC-val 0.691  AUC-train 0.978\n",
            "Stats - Epoch: 85 AUC-val 0.699  AUC-train 0.978\n",
            "Stats - Epoch: 86 AUC-val 0.696  AUC-train 0.977\n",
            "Stats - Epoch: 87 AUC-val 0.695  AUC-train 0.977\n",
            "Stats - Epoch: 88 AUC-val 0.696  AUC-train 0.981\n",
            "Stats - Epoch: 89 AUC-val 0.690  AUC-train 0.981\n",
            "Stats - Epoch: 90 AUC-val 0.708  AUC-train 0.981\n",
            "Stats - Epoch: 91 AUC-val 0.777  AUC-train 0.979\n",
            "Stats - Epoch: 92 AUC-val 0.708  AUC-train 0.978\n",
            "Stats - Epoch: 93 AUC-val 0.759  AUC-train 0.975\n",
            "Stats - Epoch: 94 AUC-val 0.733  AUC-train 0.980\n",
            "Stats - Epoch: 95 AUC-val 0.728  AUC-train 0.978\n",
            "Stats - Epoch: 96 AUC-val 0.731  AUC-train 0.979\n",
            "Stats - Epoch: 97 AUC-val 0.733  AUC-train 0.980\n",
            "Stats - Epoch: 98 AUC-val 0.750  AUC-train 0.978\n",
            "Stats - Epoch: 99 AUC-val 0.744  AUC-train 0.979\n",
            "Stats - Epoch: 100 AUC-val 0.760  AUC-train 0.976\n",
            "Results 100 AUC-val 0.523 0.548 0.713 0.777 0.777 AUC-train 0.979\n",
            "Shapley [0.00434696 0.00523872 0.00423392 0.01114245 0.00269705] [0.00275477]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.214006\n",
            "         Iterations 8\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.480  AUC-train 0.570\n",
            "Stats - Epoch: 2 AUC-val 0.445  AUC-train 0.694\n",
            "Stats - Epoch: 3 AUC-val 0.405  AUC-train 0.768\n",
            "Stats - Epoch: 4 AUC-val 0.448  AUC-train 0.815\n",
            "Stats - Epoch: 5 AUC-val 0.489  AUC-train 0.848\n",
            "Stats - Epoch: 6 AUC-val 0.546  AUC-train 0.865\n",
            "Stats - Epoch: 7 AUC-val 0.559  AUC-train 0.881\n",
            "Stats - Epoch: 8 AUC-val 0.586  AUC-train 0.896\n",
            "Stats - Epoch: 9 AUC-val 0.602  AUC-train 0.905\n",
            "Stats - Epoch: 10 AUC-val 0.614  AUC-train 0.918\n",
            "Stats - Epoch: 11 AUC-val 0.627  AUC-train 0.926\n",
            "Stats - Epoch: 12 AUC-val 0.631  AUC-train 0.929\n",
            "Stats - Epoch: 13 AUC-val 0.617  AUC-train 0.936\n",
            "Stats - Epoch: 14 AUC-val 0.644  AUC-train 0.937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.657  AUC-train 0.945\n",
            "Stats - Epoch: 16 AUC-val 0.669  AUC-train 0.949\n",
            "Stats - Epoch: 17 AUC-val 0.675  AUC-train 0.953\n",
            "Stats - Epoch: 18 AUC-val 0.664  AUC-train 0.959\n",
            "Stats - Epoch: 19 AUC-val 0.703  AUC-train 0.964\n",
            "Stats - Epoch: 20 AUC-val 0.671  AUC-train 0.963\n",
            "Stats - Epoch: 21 AUC-val 0.697  AUC-train 0.964\n",
            "Stats - Epoch: 22 AUC-val 0.700  AUC-train 0.967\n",
            "Stats - Epoch: 23 AUC-val 0.711  AUC-train 0.970\n",
            "Stats - Epoch: 24 AUC-val 0.726  AUC-train 0.971\n",
            "Stats - Epoch: 25 AUC-val 0.717  AUC-train 0.974\n",
            "Stats - Epoch: 26 AUC-val 0.746  AUC-train 0.975\n",
            "Stats - Epoch: 27 AUC-val 0.738  AUC-train 0.975\n",
            "Stats - Epoch: 28 AUC-val 0.718  AUC-train 0.977\n",
            "Stats - Epoch: 29 AUC-val 0.743  AUC-train 0.978\n",
            "Stats - Epoch: 30 AUC-val 0.715  AUC-train 0.978\n",
            "Stats - Epoch: 31 AUC-val 0.745  AUC-train 0.982\n",
            "Stats - Epoch: 32 AUC-val 0.736  AUC-train 0.981\n",
            "Stats - Epoch: 33 AUC-val 0.749  AUC-train 0.982\n",
            "Stats - Epoch: 34 AUC-val 0.750  AUC-train 0.980\n",
            "Stats - Epoch: 35 AUC-val 0.767  AUC-train 0.980\n",
            "Stats - Epoch: 36 AUC-val 0.747  AUC-train 0.984\n",
            "Stats - Epoch: 37 AUC-val 0.744  AUC-train 0.985\n",
            "Stats - Epoch: 38 AUC-val 0.752  AUC-train 0.985\n",
            "Stats - Epoch: 39 AUC-val 0.760  AUC-train 0.986\n",
            "Stats - Epoch: 40 AUC-val 0.763  AUC-train 0.988\n",
            "Stats - Epoch: 41 AUC-val 0.757  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.767  AUC-train 0.990\n",
            "Stats - Epoch: 43 AUC-val 0.778  AUC-train 0.990\n",
            "Stats - Epoch: 44 AUC-val 0.764  AUC-train 0.990\n",
            "Stats - Epoch: 45 AUC-val 0.765  AUC-train 0.991\n",
            "Stats - Epoch: 46 AUC-val 0.779  AUC-train 0.990\n",
            "Stats - Epoch: 47 AUC-val 0.758  AUC-train 0.990\n",
            "Stats - Epoch: 48 AUC-val 0.776  AUC-train 0.990\n",
            "Stats - Epoch: 49 AUC-val 0.772  AUC-train 0.991\n",
            "Stats - Epoch: 50 AUC-val 0.774  AUC-train 0.993\n",
            "Stats - Epoch: 51 AUC-val 0.805  AUC-train 0.993\n",
            "Stats - Epoch: 52 AUC-val 0.790  AUC-train 0.993\n",
            "Stats - Epoch: 53 AUC-val 0.781  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.781  AUC-train 0.991\n",
            "Stats - Epoch: 55 AUC-val 0.756  AUC-train 0.992\n",
            "Stats - Epoch: 56 AUC-val 0.770  AUC-train 0.993\n",
            "Stats - Epoch: 57 AUC-val 0.774  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.779  AUC-train 0.995\n",
            "Stats - Epoch: 59 AUC-val 0.780  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.757  AUC-train 0.994\n",
            "Stats - Epoch: 61 AUC-val 0.738  AUC-train 0.994\n",
            "Stats - Epoch: 62 AUC-val 0.755  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.762  AUC-train 0.994\n",
            "Stats - Epoch: 64 AUC-val 0.772  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.757  AUC-train 0.994\n",
            "Stats - Epoch: 66 AUC-val 0.791  AUC-train 0.995\n",
            "Stats - Epoch: 67 AUC-val 0.764  AUC-train 0.995\n",
            "Stats - Epoch: 68 AUC-val 0.792  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.772  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.768  AUC-train 0.994\n",
            "Stats - Epoch: 71 AUC-val 0.768  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.788  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.770  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.769  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.785  AUC-train 0.997\n",
            "Stats - Epoch: 76 AUC-val 0.780  AUC-train 0.997\n",
            "Stats - Epoch: 77 AUC-val 0.787  AUC-train 0.993\n",
            "Stats - Epoch: 78 AUC-val 0.785  AUC-train 0.995\n",
            "Stats - Epoch: 79 AUC-val 0.769  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.776  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.794  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.793  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.800  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.796  AUC-train 0.996\n",
            "Stats - Epoch: 85 AUC-val 0.800  AUC-train 0.995\n",
            "Stats - Epoch: 86 AUC-val 0.789  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.817  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.784  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.793  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.800  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.783  AUC-train 0.995\n",
            "Stats - Epoch: 92 AUC-val 0.784  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.797  AUC-train 0.994\n",
            "Stats - Epoch: 94 AUC-val 0.767  AUC-train 0.995\n",
            "Stats - Epoch: 95 AUC-val 0.787  AUC-train 0.992\n",
            "Stats - Epoch: 96 AUC-val 0.784  AUC-train 0.994\n",
            "Stats - Epoch: 97 AUC-val 0.816  AUC-train 0.995\n",
            "Stats - Epoch: 98 AUC-val 0.804  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.805  AUC-train 0.995\n",
            "Stats - Epoch: 100 AUC-val 0.800  AUC-train 0.995\n",
            "Results 100 AUC-val 0.453 0.268 0.363 0.617 0.817 AUC-train 0.998\n",
            "Shapley [0.01312575 0.01785746 0.02446209 0.04515989 0.04103659] [0.0065893]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.148430\n",
            "         Iterations 9\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.377  AUC-train 0.492\n",
            "Stats - Epoch: 2 AUC-val 0.412  AUC-train 0.576\n",
            "Stats - Epoch: 3 AUC-val 0.412  AUC-train 0.666\n",
            "Stats - Epoch: 4 AUC-val 0.442  AUC-train 0.724\n",
            "Stats - Epoch: 5 AUC-val 0.468  AUC-train 0.772\n",
            "Stats - Epoch: 6 AUC-val 0.485  AUC-train 0.803\n",
            "Stats - Epoch: 7 AUC-val 0.531  AUC-train 0.832\n",
            "Stats - Epoch: 8 AUC-val 0.528  AUC-train 0.851\n",
            "Stats - Epoch: 9 AUC-val 0.508  AUC-train 0.868\n",
            "Stats - Epoch: 10 AUC-val 0.545  AUC-train 0.883\n",
            "Stats - Epoch: 11 AUC-val 0.551  AUC-train 0.897\n",
            "Stats - Epoch: 12 AUC-val 0.564  AUC-train 0.909\n",
            "Stats - Epoch: 13 AUC-val 0.566  AUC-train 0.917\n",
            "Stats - Epoch: 14 AUC-val 0.590  AUC-train 0.921\n",
            "Stats - Epoch: 15 AUC-val 0.573  AUC-train 0.930\n",
            "Stats - Epoch: 16 AUC-val 0.581  AUC-train 0.933\n",
            "Stats - Epoch: 17 AUC-val 0.597  AUC-train 0.941\n",
            "Stats - Epoch: 18 AUC-val 0.599  AUC-train 0.946\n",
            "Stats - Epoch: 19 AUC-val 0.588  AUC-train 0.948\n",
            "Stats - Epoch: 20 AUC-val 0.594  AUC-train 0.955\n",
            "Stats - Epoch: 21 AUC-val 0.607  AUC-train 0.956\n",
            "Stats - Epoch: 22 AUC-val 0.614  AUC-train 0.958\n",
            "Stats - Epoch: 23 AUC-val 0.611  AUC-train 0.963\n",
            "Stats - Epoch: 24 AUC-val 0.631  AUC-train 0.966\n",
            "Stats - Epoch: 25 AUC-val 0.628  AUC-train 0.965\n",
            "Stats - Epoch: 26 AUC-val 0.633  AUC-train 0.970\n",
            "Stats - Epoch: 27 AUC-val 0.623  AUC-train 0.974\n",
            "Stats - Epoch: 28 AUC-val 0.634  AUC-train 0.974\n",
            "Stats - Epoch: 29 AUC-val 0.642  AUC-train 0.976\n",
            "Stats - Epoch: 30 AUC-val 0.621  AUC-train 0.977\n",
            "Stats - Epoch: 31 AUC-val 0.626  AUC-train 0.976\n",
            "Stats - Epoch: 32 AUC-val 0.651  AUC-train 0.976\n",
            "Stats - Epoch: 33 AUC-val 0.651  AUC-train 0.976\n",
            "Stats - Epoch: 34 AUC-val 0.655  AUC-train 0.978\n",
            "Stats - Epoch: 35 AUC-val 0.661  AUC-train 0.979\n",
            "Stats - Epoch: 36 AUC-val 0.648  AUC-train 0.982\n",
            "Stats - Epoch: 37 AUC-val 0.660  AUC-train 0.980\n",
            "Stats - Epoch: 38 AUC-val 0.694  AUC-train 0.984\n",
            "Stats - Epoch: 39 AUC-val 0.681  AUC-train 0.986\n",
            "Stats - Epoch: 40 AUC-val 0.682  AUC-train 0.985\n",
            "Stats - Epoch: 41 AUC-val 0.664  AUC-train 0.985\n",
            "Stats - Epoch: 42 AUC-val 0.660  AUC-train 0.987\n",
            "Stats - Epoch: 43 AUC-val 0.685  AUC-train 0.987\n",
            "Stats - Epoch: 44 AUC-val 0.678  AUC-train 0.986\n",
            "Stats - Epoch: 45 AUC-val 0.702  AUC-train 0.987\n",
            "Stats - Epoch: 46 AUC-val 0.706  AUC-train 0.989\n",
            "Stats - Epoch: 47 AUC-val 0.696  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.703  AUC-train 0.988\n",
            "Stats - Epoch: 49 AUC-val 0.696  AUC-train 0.991\n",
            "Stats - Epoch: 50 AUC-val 0.711  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.718  AUC-train 0.992\n",
            "Stats - Epoch: 52 AUC-val 0.690  AUC-train 0.984\n",
            "Stats - Epoch: 53 AUC-val 0.702  AUC-train 0.988\n",
            "Stats - Epoch: 54 AUC-val 0.683  AUC-train 0.990\n",
            "Stats - Epoch: 55 AUC-val 0.689  AUC-train 0.990\n",
            "Stats - Epoch: 56 AUC-val 0.710  AUC-train 0.991\n",
            "Stats - Epoch: 57 AUC-val 0.730  AUC-train 0.992\n",
            "Stats - Epoch: 58 AUC-val 0.732  AUC-train 0.994\n",
            "Stats - Epoch: 59 AUC-val 0.690  AUC-train 0.991\n",
            "Stats - Epoch: 60 AUC-val 0.694  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.703  AUC-train 0.994\n",
            "Stats - Epoch: 62 AUC-val 0.697  AUC-train 0.991\n",
            "Stats - Epoch: 63 AUC-val 0.714  AUC-train 0.989\n",
            "Stats - Epoch: 64 AUC-val 0.683  AUC-train 0.992\n",
            "Stats - Epoch: 65 AUC-val 0.715  AUC-train 0.991\n",
            "Stats - Epoch: 66 AUC-val 0.714  AUC-train 0.993\n",
            "Stats - Epoch: 67 AUC-val 0.716  AUC-train 0.993\n",
            "Stats - Epoch: 68 AUC-val 0.707  AUC-train 0.992\n",
            "Stats - Epoch: 69 AUC-val 0.708  AUC-train 0.993\n",
            "Stats - Epoch: 70 AUC-val 0.721  AUC-train 0.993\n",
            "Stats - Epoch: 71 AUC-val 0.721  AUC-train 0.988\n",
            "Stats - Epoch: 72 AUC-val 0.709  AUC-train 0.990\n",
            "Stats - Epoch: 73 AUC-val 0.720  AUC-train 0.992\n",
            "Stats - Epoch: 74 AUC-val 0.708  AUC-train 0.992\n",
            "Stats - Epoch: 75 AUC-val 0.714  AUC-train 0.989\n",
            "Stats - Epoch: 76 AUC-val 0.721  AUC-train 0.991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.681  AUC-train 0.989\n",
            "Stats - Epoch: 78 AUC-val 0.693  AUC-train 0.990\n",
            "Stats - Epoch: 79 AUC-val 0.700  AUC-train 0.989\n",
            "Stats - Epoch: 80 AUC-val 0.722  AUC-train 0.994\n",
            "Stats - Epoch: 81 AUC-val 0.686  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.708  AUC-train 0.993\n",
            "Stats - Epoch: 83 AUC-val 0.697  AUC-train 0.993\n",
            "Stats - Epoch: 84 AUC-val 0.702  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.725  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.710  AUC-train 0.994\n",
            "Stats - Epoch: 87 AUC-val 0.704  AUC-train 0.996\n",
            "Stats - Epoch: 88 AUC-val 0.718  AUC-train 0.994\n",
            "Stats - Epoch: 89 AUC-val 0.706  AUC-train 0.990\n",
            "Stats - Epoch: 90 AUC-val 0.685  AUC-train 0.989\n",
            "Stats - Epoch: 91 AUC-val 0.686  AUC-train 0.989\n",
            "Stats - Epoch: 92 AUC-val 0.703  AUC-train 0.985\n",
            "Stats - Epoch: 93 AUC-val 0.699  AUC-train 0.989\n",
            "Stats - Epoch: 94 AUC-val 0.698  AUC-train 0.989\n",
            "Stats - Epoch: 95 AUC-val 0.690  AUC-train 0.988\n",
            "Stats - Epoch: 96 AUC-val 0.693  AUC-train 0.992\n",
            "Stats - Epoch: 97 AUC-val 0.723  AUC-train 0.993\n",
            "Stats - Epoch: 98 AUC-val 0.704  AUC-train 0.992\n",
            "Stats - Epoch: 99 AUC-val 0.719  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.706  AUC-train 0.994\n",
            "Results 100 AUC-val 0.525 0.374 0.349 0.493 0.732 AUC-train 0.994\n",
            "Shapley [0.01077043 0.01518366 0.01490122 0.03949399 0.02825605] [0.01288023]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.206685\n",
            "         Iterations 9\n",
            "Crises train:10\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.418  AUC-train 0.606\n",
            "Stats - Epoch: 2 AUC-val 0.317  AUC-train 0.749\n",
            "Stats - Epoch: 3 AUC-val 0.324  AUC-train 0.831\n",
            "Stats - Epoch: 4 AUC-val 0.391  AUC-train 0.879\n",
            "Stats - Epoch: 5 AUC-val 0.443  AUC-train 0.904\n",
            "Stats - Epoch: 6 AUC-val 0.507  AUC-train 0.925\n",
            "Stats - Epoch: 7 AUC-val 0.489  AUC-train 0.938\n",
            "Stats - Epoch: 8 AUC-val 0.580  AUC-train 0.954\n",
            "Stats - Epoch: 9 AUC-val 0.590  AUC-train 0.962\n",
            "Stats - Epoch: 10 AUC-val 0.626  AUC-train 0.973\n",
            "Stats - Epoch: 11 AUC-val 0.613  AUC-train 0.977\n",
            "Stats - Epoch: 12 AUC-val 0.660  AUC-train 0.978\n",
            "Stats - Epoch: 13 AUC-val 0.656  AUC-train 0.986\n",
            "Stats - Epoch: 14 AUC-val 0.669  AUC-train 0.988\n",
            "Stats - Epoch: 15 AUC-val 0.696  AUC-train 0.991\n",
            "Stats - Epoch: 16 AUC-val 0.704  AUC-train 0.992\n",
            "Stats - Epoch: 17 AUC-val 0.694  AUC-train 0.994\n",
            "Stats - Epoch: 18 AUC-val 0.712  AUC-train 0.996\n",
            "Stats - Epoch: 19 AUC-val 0.716  AUC-train 0.996\n",
            "Stats - Epoch: 20 AUC-val 0.728  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.707  AUC-train 0.997\n",
            "Stats - Epoch: 22 AUC-val 0.715  AUC-train 0.997\n",
            "Stats - Epoch: 23 AUC-val 0.732  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.738  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.730  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.745  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.756  AUC-train 0.998\n",
            "Stats - Epoch: 28 AUC-val 0.746  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.743  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.750  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.753  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.734  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.742  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.732  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.733  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.734  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.739  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.745  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.751  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.765  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.758  AUC-train 1.000\n",
            "Stats - Epoch: 42 AUC-val 0.751  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.749  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.741  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.736  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.744  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.738  AUC-train 0.995\n",
            "Stats - Epoch: 48 AUC-val 0.720  AUC-train 0.996\n",
            "Stats - Epoch: 49 AUC-val 0.745  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.718  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.737  AUC-train 0.997\n",
            "Stats - Epoch: 52 AUC-val 0.722  AUC-train 0.997\n",
            "Stats - Epoch: 53 AUC-val 0.736  AUC-train 0.994\n",
            "Stats - Epoch: 54 AUC-val 0.726  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.709  AUC-train 0.995\n",
            "Stats - Epoch: 56 AUC-val 0.741  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.721  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.713  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.747  AUC-train 0.998\n",
            "Stats - Epoch: 60 AUC-val 0.739  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.715  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.725  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.724  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.724  AUC-train 0.999\n",
            "Stats - Epoch: 65 AUC-val 0.748  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.751  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.752  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.749  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.751  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.769  AUC-train 0.998\n",
            "Stats - Epoch: 71 AUC-val 0.769  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.726  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.728  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.726  AUC-train 0.999\n",
            "Stats - Epoch: 75 AUC-val 0.766  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.717  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.747  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.756  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.732  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.751  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.738  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.737  AUC-train 0.999\n",
            "Stats - Epoch: 83 AUC-val 0.774  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.744  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.748  AUC-train 1.000\n",
            "Stats - Epoch: 86 AUC-val 0.749  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.780  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.765  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.770  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.748  AUC-train 0.995\n",
            "Stats - Epoch: 91 AUC-val 0.774  AUC-train 0.993\n",
            "Stats - Epoch: 92 AUC-val 0.753  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.748  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.758  AUC-train 0.993\n",
            "Stats - Epoch: 95 AUC-val 0.775  AUC-train 0.995\n",
            "Stats - Epoch: 96 AUC-val 0.750  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.766  AUC-train 0.998\n",
            "Stats - Epoch: 98 AUC-val 0.770  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.786  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.775  AUC-train 0.999\n",
            "Results 100 AUC-val 0.453 0.306 0.405 0.596 0.786 AUC-train 0.999\n",
            "Shapley [0.01786534 0.01694827 0.03572745 0.05283189 0.04188568] [0.00229381]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.163914\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyFV-eugtapv",
        "outputId": "6cc7f419-d081-4642-931e-b41c96951566"
      },
      "source": [
        "    import os\n",
        "    # Simulation params\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/seq_fc1_reps50_robu.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    epochs = 100;\n",
        "    for dates in [[1970,1999,2000,2016]]: #[1970,2016]\n",
        "    #for dates in [[1974,1999,2000,2016]]: #[1970,2016]\n",
        "        train_end_year=dates[1];\n",
        "        train_start_year=dates[0];\n",
        "        test_start_year=dates[2]; # Define test set\n",
        "        test_end_year=dates[3];\n",
        "        reps=50\n",
        "        print(dates)\n",
        "    \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "\n",
        "        \n",
        "        f.write(sequential_evaluation(reg_weight=[0.0],reps=1,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,nlags=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();     \n",
        "        f.write(sequential_evaluation(reg_weight=[0.0],reps=1,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,nlags=5,df=df3,fcast_horizon=1,plot_reliability=False,epochs=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(reps=reps,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,return_state=True,rnn_mode=2,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,do_shapley=True));       \n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "    \n",
        "f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1970, 1999, 2000, 2016]\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.210  AUC-train 0.610\n",
            "Stats - Epoch: 2 AUC-val 0.186  AUC-train 0.653\n",
            "Stats - Epoch: 3 AUC-val 0.179  AUC-train 0.715\n",
            "Stats - Epoch: 4 AUC-val 0.204  AUC-train 0.767\n",
            "Stats - Epoch: 5 AUC-val 0.254  AUC-train 0.805\n",
            "Stats - Epoch: 6 AUC-val 0.279  AUC-train 0.839\n",
            "Stats - Epoch: 7 AUC-val 0.319  AUC-train 0.857\n",
            "Stats - Epoch: 8 AUC-val 0.317  AUC-train 0.871\n",
            "Stats - Epoch: 9 AUC-val 0.332  AUC-train 0.882\n",
            "Stats - Epoch: 10 AUC-val 0.358  AUC-train 0.891\n",
            "Stats - Epoch: 11 AUC-val 0.423  AUC-train 0.898\n",
            "Stats - Epoch: 12 AUC-val 0.382  AUC-train 0.905\n",
            "Stats - Epoch: 13 AUC-val 0.381  AUC-train 0.906\n",
            "Stats - Epoch: 14 AUC-val 0.418  AUC-train 0.907\n",
            "Stats - Epoch: 15 AUC-val 0.414  AUC-train 0.914\n",
            "Stats - Epoch: 16 AUC-val 0.457  AUC-train 0.917\n",
            "Stats - Epoch: 17 AUC-val 0.408  AUC-train 0.923\n",
            "Stats - Epoch: 18 AUC-val 0.401  AUC-train 0.924\n",
            "Stats - Epoch: 19 AUC-val 0.412  AUC-train 0.931\n",
            "Stats - Epoch: 20 AUC-val 0.451  AUC-train 0.930\n",
            "Stats - Epoch: 21 AUC-val 0.448  AUC-train 0.934\n",
            "Stats - Epoch: 22 AUC-val 0.435  AUC-train 0.935\n",
            "Stats - Epoch: 23 AUC-val 0.467  AUC-train 0.938\n",
            "Stats - Epoch: 24 AUC-val 0.434  AUC-train 0.937\n",
            "Stats - Epoch: 25 AUC-val 0.429  AUC-train 0.934\n",
            "Stats - Epoch: 26 AUC-val 0.444  AUC-train 0.937\n",
            "Stats - Epoch: 27 AUC-val 0.422  AUC-train 0.936\n",
            "Stats - Epoch: 28 AUC-val 0.463  AUC-train 0.938\n",
            "Stats - Epoch: 29 AUC-val 0.486  AUC-train 0.945\n",
            "Stats - Epoch: 30 AUC-val 0.490  AUC-train 0.947\n",
            "Stats - Epoch: 31 AUC-val 0.462  AUC-train 0.943\n",
            "Stats - Epoch: 32 AUC-val 0.473  AUC-train 0.947\n",
            "Stats - Epoch: 33 AUC-val 0.501  AUC-train 0.942\n",
            "Stats - Epoch: 34 AUC-val 0.483  AUC-train 0.949\n",
            "Stats - Epoch: 35 AUC-val 0.498  AUC-train 0.952\n",
            "Stats - Epoch: 36 AUC-val 0.465  AUC-train 0.954\n",
            "Stats - Epoch: 37 AUC-val 0.485  AUC-train 0.949\n",
            "Stats - Epoch: 38 AUC-val 0.525  AUC-train 0.951\n",
            "Stats - Epoch: 39 AUC-val 0.439  AUC-train 0.953\n",
            "Stats - Epoch: 40 AUC-val 0.500  AUC-train 0.952\n",
            "Stats - Epoch: 41 AUC-val 0.468  AUC-train 0.952\n",
            "Stats - Epoch: 42 AUC-val 0.457  AUC-train 0.955\n",
            "Stats - Epoch: 43 AUC-val 0.488  AUC-train 0.954\n",
            "Stats - Epoch: 44 AUC-val 0.474  AUC-train 0.956\n",
            "Stats - Epoch: 45 AUC-val 0.453  AUC-train 0.957\n",
            "Stats - Epoch: 46 AUC-val 0.486  AUC-train 0.957\n",
            "Stats - Epoch: 47 AUC-val 0.490  AUC-train 0.958\n",
            "Stats - Epoch: 48 AUC-val 0.474  AUC-train 0.959\n",
            "Stats - Epoch: 49 AUC-val 0.445  AUC-train 0.956\n",
            "Stats - Epoch: 50 AUC-val 0.459  AUC-train 0.960\n",
            "Stats - Epoch: 51 AUC-val 0.472  AUC-train 0.960\n",
            "Stats - Epoch: 52 AUC-val 0.449  AUC-train 0.963\n",
            "Stats - Epoch: 53 AUC-val 0.486  AUC-train 0.961\n",
            "Stats - Epoch: 54 AUC-val 0.522  AUC-train 0.961\n",
            "Stats - Epoch: 55 AUC-val 0.519  AUC-train 0.961\n",
            "Stats - Epoch: 56 AUC-val 0.491  AUC-train 0.960\n",
            "Stats - Epoch: 57 AUC-val 0.541  AUC-train 0.962\n",
            "Stats - Epoch: 58 AUC-val 0.532  AUC-train 0.962\n",
            "Stats - Epoch: 59 AUC-val 0.543  AUC-train 0.964\n",
            "Stats - Epoch: 60 AUC-val 0.530  AUC-train 0.966\n",
            "Stats - Epoch: 61 AUC-val 0.520  AUC-train 0.966\n",
            "Stats - Epoch: 62 AUC-val 0.500  AUC-train 0.966\n",
            "Stats - Epoch: 63 AUC-val 0.519  AUC-train 0.963\n",
            "Stats - Epoch: 64 AUC-val 0.534  AUC-train 0.965\n",
            "Stats - Epoch: 65 AUC-val 0.548  AUC-train 0.964\n",
            "Stats - Epoch: 66 AUC-val 0.473  AUC-train 0.963\n",
            "Stats - Epoch: 67 AUC-val 0.486  AUC-train 0.966\n",
            "Stats - Epoch: 68 AUC-val 0.455  AUC-train 0.969\n",
            "Stats - Epoch: 69 AUC-val 0.475  AUC-train 0.969\n",
            "Stats - Epoch: 70 AUC-val 0.517  AUC-train 0.964\n",
            "Stats - Epoch: 71 AUC-val 0.532  AUC-train 0.964\n",
            "Stats - Epoch: 72 AUC-val 0.480  AUC-train 0.966\n",
            "Stats - Epoch: 73 AUC-val 0.432  AUC-train 0.968\n",
            "Stats - Epoch: 74 AUC-val 0.461  AUC-train 0.968\n",
            "Stats - Epoch: 75 AUC-val 0.474  AUC-train 0.968\n",
            "Stats - Epoch: 76 AUC-val 0.494  AUC-train 0.970\n",
            "Stats - Epoch: 77 AUC-val 0.483  AUC-train 0.969\n",
            "Stats - Epoch: 78 AUC-val 0.526  AUC-train 0.967\n",
            "Stats - Epoch: 79 AUC-val 0.517  AUC-train 0.970\n",
            "Stats - Epoch: 80 AUC-val 0.533  AUC-train 0.973\n",
            "Stats - Epoch: 81 AUC-val 0.512  AUC-train 0.970\n",
            "Stats - Epoch: 82 AUC-val 0.521  AUC-train 0.968\n",
            "Stats - Epoch: 83 AUC-val 0.500  AUC-train 0.969\n",
            "Stats - Epoch: 84 AUC-val 0.494  AUC-train 0.966\n",
            "Stats - Epoch: 85 AUC-val 0.465  AUC-train 0.968\n",
            "Stats - Epoch: 86 AUC-val 0.476  AUC-train 0.968\n",
            "Stats - Epoch: 87 AUC-val 0.485  AUC-train 0.968\n",
            "Stats - Epoch: 88 AUC-val 0.495  AUC-train 0.968\n",
            "Stats - Epoch: 89 AUC-val 0.487  AUC-train 0.965\n",
            "Stats - Epoch: 90 AUC-val 0.474  AUC-train 0.964\n",
            "Stats - Epoch: 91 AUC-val 0.498  AUC-train 0.969\n",
            "Stats - Epoch: 92 AUC-val 0.463  AUC-train 0.968\n",
            "Stats - Epoch: 93 AUC-val 0.557  AUC-train 0.966\n",
            "Stats - Epoch: 94 AUC-val 0.548  AUC-train 0.968\n",
            "Stats - Epoch: 95 AUC-val 0.509  AUC-train 0.966\n",
            "Stats - Epoch: 96 AUC-val 0.475  AUC-train 0.970\n",
            "Stats - Epoch: 97 AUC-val 0.486  AUC-train 0.970\n",
            "Stats - Epoch: 98 AUC-val 0.516  AUC-train 0.973\n",
            "Stats - Epoch: 99 AUC-val 0.483  AUC-train 0.966\n",
            "Stats - Epoch: 100 AUC-val 0.507  AUC-train 0.964\n",
            "Results 100 AUC-val 0.557 0.521 0.497 0.376 0.681 AUC-train 0.966\n",
            "Shapley [0.01160527 0.00675938 0.00822271 0.01717083 0.00492596] [0.00317493]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.195555\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.183  AUC-train 0.589\n",
            "Stats - Epoch: 2 AUC-val 0.181  AUC-train 0.639\n",
            "Stats - Epoch: 3 AUC-val 0.176  AUC-train 0.695\n",
            "Stats - Epoch: 4 AUC-val 0.220  AUC-train 0.747\n",
            "Stats - Epoch: 5 AUC-val 0.262  AUC-train 0.787\n",
            "Stats - Epoch: 6 AUC-val 0.291  AUC-train 0.811\n",
            "Stats - Epoch: 7 AUC-val 0.355  AUC-train 0.832\n",
            "Stats - Epoch: 8 AUC-val 0.401  AUC-train 0.845\n",
            "Stats - Epoch: 9 AUC-val 0.381  AUC-train 0.859\n",
            "Stats - Epoch: 10 AUC-val 0.422  AUC-train 0.867\n",
            "Stats - Epoch: 11 AUC-val 0.400  AUC-train 0.874\n",
            "Stats - Epoch: 12 AUC-val 0.431  AUC-train 0.877\n",
            "Stats - Epoch: 13 AUC-val 0.453  AUC-train 0.884\n",
            "Stats - Epoch: 14 AUC-val 0.450  AUC-train 0.887\n",
            "Stats - Epoch: 15 AUC-val 0.462  AUC-train 0.888\n",
            "Stats - Epoch: 16 AUC-val 0.481  AUC-train 0.893\n",
            "Stats - Epoch: 17 AUC-val 0.476  AUC-train 0.897\n",
            "Stats - Epoch: 18 AUC-val 0.472  AUC-train 0.902\n",
            "Stats - Epoch: 19 AUC-val 0.468  AUC-train 0.905\n",
            "Stats - Epoch: 20 AUC-val 0.493  AUC-train 0.910\n",
            "Stats - Epoch: 21 AUC-val 0.499  AUC-train 0.909\n",
            "Stats - Epoch: 22 AUC-val 0.499  AUC-train 0.911\n",
            "Stats - Epoch: 23 AUC-val 0.516  AUC-train 0.918\n",
            "Stats - Epoch: 24 AUC-val 0.494  AUC-train 0.922\n",
            "Stats - Epoch: 25 AUC-val 0.481  AUC-train 0.924\n",
            "Stats - Epoch: 26 AUC-val 0.499  AUC-train 0.924\n",
            "Stats - Epoch: 27 AUC-val 0.479  AUC-train 0.926\n",
            "Stats - Epoch: 28 AUC-val 0.507  AUC-train 0.926\n",
            "Stats - Epoch: 29 AUC-val 0.476  AUC-train 0.929\n",
            "Stats - Epoch: 30 AUC-val 0.503  AUC-train 0.929\n",
            "Stats - Epoch: 31 AUC-val 0.482  AUC-train 0.934\n",
            "Stats - Epoch: 32 AUC-val 0.534  AUC-train 0.938\n",
            "Stats - Epoch: 33 AUC-val 0.517  AUC-train 0.940\n",
            "Stats - Epoch: 34 AUC-val 0.553  AUC-train 0.934\n",
            "Stats - Epoch: 35 AUC-val 0.536  AUC-train 0.939\n",
            "Stats - Epoch: 36 AUC-val 0.545  AUC-train 0.939\n",
            "Stats - Epoch: 37 AUC-val 0.528  AUC-train 0.942\n",
            "Stats - Epoch: 38 AUC-val 0.533  AUC-train 0.946\n",
            "Stats - Epoch: 39 AUC-val 0.524  AUC-train 0.946\n",
            "Stats - Epoch: 40 AUC-val 0.556  AUC-train 0.949\n",
            "Stats - Epoch: 41 AUC-val 0.570  AUC-train 0.946\n",
            "Stats - Epoch: 42 AUC-val 0.583  AUC-train 0.950\n",
            "Stats - Epoch: 43 AUC-val 0.559  AUC-train 0.949\n",
            "Stats - Epoch: 44 AUC-val 0.545  AUC-train 0.949\n",
            "Stats - Epoch: 45 AUC-val 0.557  AUC-train 0.949\n",
            "Stats - Epoch: 46 AUC-val 0.540  AUC-train 0.954\n",
            "Stats - Epoch: 47 AUC-val 0.546  AUC-train 0.953\n",
            "Stats - Epoch: 48 AUC-val 0.563  AUC-train 0.951\n",
            "Stats - Epoch: 49 AUC-val 0.543  AUC-train 0.952\n",
            "Stats - Epoch: 50 AUC-val 0.536  AUC-train 0.955\n",
            "Stats - Epoch: 51 AUC-val 0.527  AUC-train 0.955\n",
            "Stats - Epoch: 52 AUC-val 0.552  AUC-train 0.957\n",
            "Stats - Epoch: 53 AUC-val 0.572  AUC-train 0.960\n",
            "Stats - Epoch: 54 AUC-val 0.565  AUC-train 0.958\n",
            "Stats - Epoch: 55 AUC-val 0.584  AUC-train 0.959\n",
            "Stats - Epoch: 56 AUC-val 0.560  AUC-train 0.956\n",
            "Stats - Epoch: 57 AUC-val 0.536  AUC-train 0.959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.551  AUC-train 0.959\n",
            "Stats - Epoch: 59 AUC-val 0.550  AUC-train 0.960\n",
            "Stats - Epoch: 60 AUC-val 0.565  AUC-train 0.959\n",
            "Stats - Epoch: 61 AUC-val 0.556  AUC-train 0.960\n",
            "Stats - Epoch: 62 AUC-val 0.595  AUC-train 0.959\n",
            "Stats - Epoch: 63 AUC-val 0.593  AUC-train 0.956\n",
            "Stats - Epoch: 64 AUC-val 0.546  AUC-train 0.951\n",
            "Stats - Epoch: 65 AUC-val 0.571  AUC-train 0.953\n",
            "Stats - Epoch: 66 AUC-val 0.539  AUC-train 0.959\n",
            "Stats - Epoch: 67 AUC-val 0.529  AUC-train 0.964\n",
            "Stats - Epoch: 68 AUC-val 0.564  AUC-train 0.965\n",
            "Stats - Epoch: 69 AUC-val 0.537  AUC-train 0.966\n",
            "Stats - Epoch: 70 AUC-val 0.557  AUC-train 0.967\n",
            "Stats - Epoch: 71 AUC-val 0.570  AUC-train 0.964\n",
            "Stats - Epoch: 72 AUC-val 0.555  AUC-train 0.964\n",
            "Stats - Epoch: 73 AUC-val 0.550  AUC-train 0.965\n",
            "Stats - Epoch: 74 AUC-val 0.533  AUC-train 0.958\n",
            "Stats - Epoch: 75 AUC-val 0.534  AUC-train 0.963\n",
            "Stats - Epoch: 76 AUC-val 0.547  AUC-train 0.963\n",
            "Stats - Epoch: 77 AUC-val 0.539  AUC-train 0.966\n",
            "Stats - Epoch: 78 AUC-val 0.548  AUC-train 0.965\n",
            "Stats - Epoch: 79 AUC-val 0.602  AUC-train 0.965\n",
            "Stats - Epoch: 80 AUC-val 0.606  AUC-train 0.966\n",
            "Stats - Epoch: 81 AUC-val 0.576  AUC-train 0.970\n",
            "Stats - Epoch: 82 AUC-val 0.558  AUC-train 0.972\n",
            "Stats - Epoch: 83 AUC-val 0.533  AUC-train 0.974\n",
            "Stats - Epoch: 84 AUC-val 0.557  AUC-train 0.975\n",
            "Stats - Epoch: 85 AUC-val 0.610  AUC-train 0.975\n",
            "Stats - Epoch: 86 AUC-val 0.501  AUC-train 0.970\n",
            "Stats - Epoch: 87 AUC-val 0.542  AUC-train 0.972\n",
            "Stats - Epoch: 88 AUC-val 0.559  AUC-train 0.971\n",
            "Stats - Epoch: 89 AUC-val 0.554  AUC-train 0.971\n",
            "Stats - Epoch: 90 AUC-val 0.542  AUC-train 0.965\n",
            "Stats - Epoch: 91 AUC-val 0.547  AUC-train 0.964\n",
            "Stats - Epoch: 92 AUC-val 0.585  AUC-train 0.966\n",
            "Stats - Epoch: 93 AUC-val 0.564  AUC-train 0.971\n",
            "Stats - Epoch: 94 AUC-val 0.563  AUC-train 0.970\n",
            "Stats - Epoch: 95 AUC-val 0.584  AUC-train 0.972\n",
            "Stats - Epoch: 96 AUC-val 0.560  AUC-train 0.975\n",
            "Stats - Epoch: 97 AUC-val 0.620  AUC-train 0.975\n",
            "Stats - Epoch: 98 AUC-val 0.579  AUC-train 0.976\n",
            "Stats - Epoch: 99 AUC-val 0.589  AUC-train 0.974\n",
            "Stats - Epoch: 100 AUC-val 0.645  AUC-train 0.976\n",
            "Results 100 AUC-val 0.645 0.481 0.510 0.486 0.721 AUC-train 0.976\n",
            "Shapley [0.01535025 0.01081764 0.01018904 0.01769754 0.00698119] [0.00259647]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.195300\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.195  AUC-train 0.613\n",
            "Stats - Epoch: 2 AUC-val 0.284  AUC-train 0.846\n",
            "Stats - Epoch: 3 AUC-val 0.448  AUC-train 0.917\n",
            "Stats - Epoch: 4 AUC-val 0.481  AUC-train 0.952\n",
            "Stats - Epoch: 5 AUC-val 0.491  AUC-train 0.971\n",
            "Stats - Epoch: 6 AUC-val 0.496  AUC-train 0.982\n",
            "Stats - Epoch: 7 AUC-val 0.477  AUC-train 0.989\n",
            "Stats - Epoch: 8 AUC-val 0.493  AUC-train 0.993\n",
            "Stats - Epoch: 9 AUC-val 0.442  AUC-train 0.994\n",
            "Stats - Epoch: 10 AUC-val 0.473  AUC-train 0.996\n",
            "Stats - Epoch: 11 AUC-val 0.475  AUC-train 0.997\n",
            "Stats - Epoch: 12 AUC-val 0.419  AUC-train 0.994\n",
            "Stats - Epoch: 13 AUC-val 0.471  AUC-train 0.995\n",
            "Stats - Epoch: 14 AUC-val 0.449  AUC-train 0.997\n",
            "Stats - Epoch: 15 AUC-val 0.460  AUC-train 0.999\n",
            "Stats - Epoch: 16 AUC-val 0.492  AUC-train 0.999\n",
            "Stats - Epoch: 17 AUC-val 0.448  AUC-train 0.998\n",
            "Stats - Epoch: 18 AUC-val 0.484  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.426  AUC-train 0.996\n",
            "Stats - Epoch: 20 AUC-val 0.454  AUC-train 0.996\n",
            "Stats - Epoch: 21 AUC-val 0.438  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.465  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.442  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.462  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.486  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.508  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.452  AUC-train 0.998\n",
            "Stats - Epoch: 28 AUC-val 0.440  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.440  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.456  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.456  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.526  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.416  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.418  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.400  AUC-train 0.996\n",
            "Stats - Epoch: 36 AUC-val 0.448  AUC-train 0.997\n",
            "Stats - Epoch: 37 AUC-val 0.434  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.453  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.483  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.434  AUC-train 0.995\n",
            "Stats - Epoch: 41 AUC-val 0.416  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.427  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.426  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.428  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.449  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.417  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.452  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.515  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.401  AUC-train 0.996\n",
            "Stats - Epoch: 50 AUC-val 0.406  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.456  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.396  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.415  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.422  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.426  AUC-train 0.997\n",
            "Stats - Epoch: 56 AUC-val 0.452  AUC-train 0.994\n",
            "Stats - Epoch: 57 AUC-val 0.460  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.448  AUC-train 0.996\n",
            "Stats - Epoch: 59 AUC-val 0.424  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.470  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.495  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.483  AUC-train 0.993\n",
            "Stats - Epoch: 63 AUC-val 0.496  AUC-train 0.994\n",
            "Stats - Epoch: 64 AUC-val 0.465  AUC-train 0.993\n",
            "Stats - Epoch: 65 AUC-val 0.493  AUC-train 0.991\n",
            "Stats - Epoch: 66 AUC-val 0.466  AUC-train 0.992\n",
            "Stats - Epoch: 67 AUC-val 0.434  AUC-train 0.993\n",
            "Stats - Epoch: 68 AUC-val 0.453  AUC-train 0.992\n",
            "Stats - Epoch: 69 AUC-val 0.502  AUC-train 0.990\n",
            "Stats - Epoch: 70 AUC-val 0.461  AUC-train 0.995\n",
            "Stats - Epoch: 71 AUC-val 0.493  AUC-train 0.994\n",
            "Stats - Epoch: 72 AUC-val 0.445  AUC-train 0.994\n",
            "Stats - Epoch: 73 AUC-val 0.466  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.474  AUC-train 0.996\n",
            "Stats - Epoch: 75 AUC-val 0.477  AUC-train 0.998\n",
            "Stats - Epoch: 76 AUC-val 0.491  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.423  AUC-train 0.997\n",
            "Stats - Epoch: 78 AUC-val 0.448  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.463  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.499  AUC-train 0.993\n",
            "Stats - Epoch: 81 AUC-val 0.489  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.502  AUC-train 0.994\n",
            "Stats - Epoch: 83 AUC-val 0.483  AUC-train 0.992\n",
            "Stats - Epoch: 84 AUC-val 0.444  AUC-train 0.992\n",
            "Stats - Epoch: 85 AUC-val 0.422  AUC-train 0.994\n",
            "Stats - Epoch: 86 AUC-val 0.417  AUC-train 0.993\n",
            "Stats - Epoch: 87 AUC-val 0.490  AUC-train 0.995\n",
            "Stats - Epoch: 88 AUC-val 0.440  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.524  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.485  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.448  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.413  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.427  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.412  AUC-train 0.996\n",
            "Stats - Epoch: 95 AUC-val 0.447  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.526  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.497  AUC-train 0.999\n",
            "Stats - Epoch: 98 AUC-val 0.492  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.450  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.520  AUC-train 0.999\n",
            "Results 100 AUC-val 0.526 0.585 0.366 0.241 0.639 AUC-train 0.998\n",
            "Shapley [0.0080541  0.00575542 0.00441387 0.01524903 0.00327277] [0.00144603]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186059\n",
            "         Iterations 11\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.250  AUC-train 0.607\n",
            "Stats - Epoch: 2 AUC-val 0.373  AUC-train 0.782\n",
            "Stats - Epoch: 3 AUC-val 0.483  AUC-train 0.857\n",
            "Stats - Epoch: 4 AUC-val 0.520  AUC-train 0.895\n",
            "Stats - Epoch: 5 AUC-val 0.527  AUC-train 0.920\n",
            "Stats - Epoch: 6 AUC-val 0.541  AUC-train 0.938\n",
            "Stats - Epoch: 7 AUC-val 0.522  AUC-train 0.954\n",
            "Stats - Epoch: 8 AUC-val 0.530  AUC-train 0.967\n",
            "Stats - Epoch: 9 AUC-val 0.540  AUC-train 0.973\n",
            "Stats - Epoch: 10 AUC-val 0.555  AUC-train 0.980\n",
            "Stats - Epoch: 11 AUC-val 0.571  AUC-train 0.985\n",
            "Stats - Epoch: 12 AUC-val 0.553  AUC-train 0.987\n",
            "Stats - Epoch: 13 AUC-val 0.557  AUC-train 0.990\n",
            "Stats - Epoch: 14 AUC-val 0.571  AUC-train 0.994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.572  AUC-train 0.996\n",
            "Stats - Epoch: 16 AUC-val 0.600  AUC-train 0.996\n",
            "Stats - Epoch: 17 AUC-val 0.575  AUC-train 0.997\n",
            "Stats - Epoch: 18 AUC-val 0.565  AUC-train 0.997\n",
            "Stats - Epoch: 19 AUC-val 0.581  AUC-train 0.998\n",
            "Stats - Epoch: 20 AUC-val 0.569  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.583  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.583  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.634  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.608  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.596  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.605  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.606  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 29 AUC-val 0.624  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.612  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.597  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.606  AUC-train 0.995\n",
            "Stats - Epoch: 33 AUC-val 0.614  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.598  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.608  AUC-train 1.000\n",
            "Stats - Epoch: 36 AUC-val 0.626  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.593  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.609  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.620  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.641  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.626  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.627  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.640  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.627  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.608  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.617  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.603  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.616  AUC-train 1.000\n",
            "Stats - Epoch: 52 AUC-val 0.621  AUC-train 1.000\n",
            "Stats - Epoch: 53 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.656  AUC-train 0.996\n",
            "Stats - Epoch: 56 AUC-val 0.621  AUC-train 0.997\n",
            "Stats - Epoch: 57 AUC-val 0.622  AUC-train 0.997\n",
            "Stats - Epoch: 58 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.647  AUC-train 0.996\n",
            "Stats - Epoch: 60 AUC-val 0.649  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.654  AUC-train 0.996\n",
            "Stats - Epoch: 62 AUC-val 0.635  AUC-train 0.995\n",
            "Stats - Epoch: 63 AUC-val 0.659  AUC-train 0.996\n",
            "Stats - Epoch: 64 AUC-val 0.673  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.676  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.679  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.706  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.676  AUC-train 0.995\n",
            "Stats - Epoch: 69 AUC-val 0.673  AUC-train 0.993\n",
            "Stats - Epoch: 70 AUC-val 0.647  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.672  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.657  AUC-train 0.994\n",
            "Stats - Epoch: 73 AUC-val 0.691  AUC-train 0.996\n",
            "Stats - Epoch: 74 AUC-val 0.680  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.708  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.696  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 80 AUC-val 0.675  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.655  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.653  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.688  AUC-train 0.995\n",
            "Stats - Epoch: 85 AUC-val 0.638  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.637  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.630  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.655  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.661  AUC-train 0.994\n",
            "Stats - Epoch: 91 AUC-val 0.685  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.691  AUC-train 0.994\n",
            "Stats - Epoch: 93 AUC-val 0.674  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.689  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.692  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.630  AUC-train 0.993\n",
            "Stats - Epoch: 98 AUC-val 0.645  AUC-train 0.993\n",
            "Stats - Epoch: 99 AUC-val 0.655  AUC-train 0.994\n",
            "Stats - Epoch: 100 AUC-val 0.683  AUC-train 0.994\n",
            "Results 100 AUC-val 0.708 0.557 0.439 0.403 0.592 AUC-train 0.996\n",
            "Shapley [0.0201094  0.01319633 0.00805918 0.03778169 0.0163284 ] [0.01234162]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187271\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.199  AUC-train 0.669\n",
            "Stats - Epoch: 2 AUC-val 0.264  AUC-train 0.854\n",
            "Stats - Epoch: 3 AUC-val 0.328  AUC-train 0.924\n",
            "Stats - Epoch: 4 AUC-val 0.375  AUC-train 0.958\n",
            "Stats - Epoch: 5 AUC-val 0.395  AUC-train 0.975\n",
            "Stats - Epoch: 6 AUC-val 0.407  AUC-train 0.984\n",
            "Stats - Epoch: 7 AUC-val 0.434  AUC-train 0.989\n",
            "Stats - Epoch: 8 AUC-val 0.422  AUC-train 0.994\n",
            "Stats - Epoch: 9 AUC-val 0.442  AUC-train 0.995\n",
            "Stats - Epoch: 10 AUC-val 0.450  AUC-train 0.997\n",
            "Stats - Epoch: 11 AUC-val 0.443  AUC-train 0.998\n",
            "Stats - Epoch: 12 AUC-val 0.448  AUC-train 0.998\n",
            "Stats - Epoch: 13 AUC-val 0.467  AUC-train 0.999\n",
            "Stats - Epoch: 14 AUC-val 0.465  AUC-train 0.998\n",
            "Stats - Epoch: 15 AUC-val 0.473  AUC-train 0.998\n",
            "Stats - Epoch: 16 AUC-val 0.462  AUC-train 0.998\n",
            "Stats - Epoch: 17 AUC-val 0.490  AUC-train 0.998\n",
            "Stats - Epoch: 18 AUC-val 0.463  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.450  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.421  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.491  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.412  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.428  AUC-train 0.996\n",
            "Stats - Epoch: 24 AUC-val 0.460  AUC-train 0.997\n",
            "Stats - Epoch: 25 AUC-val 0.390  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.381  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.412  AUC-train 0.998\n",
            "Stats - Epoch: 28 AUC-val 0.441  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.443  AUC-train 0.998\n",
            "Stats - Epoch: 30 AUC-val 0.437  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.408  AUC-train 0.995\n",
            "Stats - Epoch: 32 AUC-val 0.468  AUC-train 0.998\n",
            "Stats - Epoch: 33 AUC-val 0.465  AUC-train 0.995\n",
            "Stats - Epoch: 34 AUC-val 0.408  AUC-train 0.995\n",
            "Stats - Epoch: 35 AUC-val 0.408  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.430  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.451  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.436  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.387  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.461  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.421  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.420  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.429  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.426  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.470  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.488  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.464  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.424  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.380  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.449  AUC-train 0.997\n",
            "Stats - Epoch: 51 AUC-val 0.493  AUC-train 0.998\n",
            "Stats - Epoch: 52 AUC-val 0.453  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.448  AUC-train 1.000\n",
            "Stats - Epoch: 54 AUC-val 0.448  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.469  AUC-train 0.996\n",
            "Stats - Epoch: 56 AUC-val 0.436  AUC-train 0.997\n",
            "Stats - Epoch: 57 AUC-val 0.422  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.420  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.418  AUC-train 0.996\n",
            "Stats - Epoch: 60 AUC-val 0.419  AUC-train 0.997\n",
            "Stats - Epoch: 61 AUC-val 0.484  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.447  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.418  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.398  AUC-train 0.999\n",
            "Stats - Epoch: 65 AUC-val 0.433  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.458  AUC-train 0.998\n",
            "Stats - Epoch: 67 AUC-val 0.426  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.459  AUC-train 1.000\n",
            "Stats - Epoch: 69 AUC-val 0.431  AUC-train 0.998\n",
            "Stats - Epoch: 70 AUC-val 0.436  AUC-train 0.998\n",
            "Stats - Epoch: 71 AUC-val 0.404  AUC-train 0.999\n",
            "Stats - Epoch: 72 AUC-val 0.469  AUC-train 0.999\n",
            "Stats - Epoch: 73 AUC-val 0.508  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.492  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.473  AUC-train 0.995\n",
            "Stats - Epoch: 76 AUC-val 0.466  AUC-train 0.995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.503  AUC-train 0.997\n",
            "Stats - Epoch: 78 AUC-val 0.365  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.390  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.348  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.333  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.365  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.371  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.394  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.398  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.403  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.438  AUC-train 0.993\n",
            "Stats - Epoch: 88 AUC-val 0.432  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.426  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.435  AUC-train 0.994\n",
            "Stats - Epoch: 91 AUC-val 0.394  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.400  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.437  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.394  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.425  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.417  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.417  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.431  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.474  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.429  AUC-train 0.998\n",
            "Results 100 AUC-val 0.508 0.606 0.436 0.281 0.558 AUC-train 0.999\n",
            "Shapley [0.0086136  0.00540703 0.00466027 0.01381378 0.00232359] [0.00162354]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.189928\n",
            "         Iterations 11\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.324  AUC-train 0.621\n",
            "Stats - Epoch: 2 AUC-val 0.388  AUC-train 0.771\n",
            "Stats - Epoch: 3 AUC-val 0.409  AUC-train 0.848\n",
            "Stats - Epoch: 4 AUC-val 0.417  AUC-train 0.888\n",
            "Stats - Epoch: 5 AUC-val 0.454  AUC-train 0.915\n",
            "Stats - Epoch: 6 AUC-val 0.454  AUC-train 0.934\n",
            "Stats - Epoch: 7 AUC-val 0.462  AUC-train 0.950\n",
            "Stats - Epoch: 8 AUC-val 0.443  AUC-train 0.965\n",
            "Stats - Epoch: 9 AUC-val 0.441  AUC-train 0.972\n",
            "Stats - Epoch: 10 AUC-val 0.473  AUC-train 0.980\n",
            "Stats - Epoch: 11 AUC-val 0.464  AUC-train 0.983\n",
            "Stats - Epoch: 12 AUC-val 0.464  AUC-train 0.988\n",
            "Stats - Epoch: 13 AUC-val 0.500  AUC-train 0.990\n",
            "Stats - Epoch: 14 AUC-val 0.499  AUC-train 0.993\n",
            "Stats - Epoch: 15 AUC-val 0.468  AUC-train 0.994\n",
            "Stats - Epoch: 16 AUC-val 0.517  AUC-train 0.994\n",
            "Stats - Epoch: 17 AUC-val 0.536  AUC-train 0.995\n",
            "Stats - Epoch: 18 AUC-val 0.526  AUC-train 0.997\n",
            "Stats - Epoch: 19 AUC-val 0.598  AUC-train 0.998\n",
            "Stats - Epoch: 20 AUC-val 0.579  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.544  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.607  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.574  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.585  AUC-train 0.997\n",
            "Stats - Epoch: 25 AUC-val 0.578  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.578  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.616  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.604  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.605  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.628  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.640  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.634  AUC-train 1.000\n",
            "Stats - Epoch: 33 AUC-val 0.624  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.621  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.628  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.600  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.638  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.588  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.584  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.622  AUC-train 0.997\n",
            "Stats - Epoch: 42 AUC-val 0.614  AUC-train 0.996\n",
            "Stats - Epoch: 43 AUC-val 0.609  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.644  AUC-train 0.996\n",
            "Stats - Epoch: 45 AUC-val 0.629  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.638  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.624  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.607  AUC-train 0.997\n",
            "Stats - Epoch: 49 AUC-val 0.656  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.647  AUC-train 0.997\n",
            "Stats - Epoch: 51 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.623  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.658  AUC-train 1.000\n",
            "Stats - Epoch: 57 AUC-val 0.634  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.650  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.677  AUC-train 0.992\n",
            "Stats - Epoch: 61 AUC-val 0.640  AUC-train 0.993\n",
            "Stats - Epoch: 62 AUC-val 0.661  AUC-train 0.995\n",
            "Stats - Epoch: 63 AUC-val 0.623  AUC-train 0.994\n",
            "Stats - Epoch: 64 AUC-val 0.681  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.673  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 67 AUC-val 0.658  AUC-train 0.993\n",
            "Stats - Epoch: 68 AUC-val 0.658  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.642  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.621  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.669  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.631  AUC-train 0.993\n",
            "Stats - Epoch: 73 AUC-val 0.672  AUC-train 0.990\n",
            "Stats - Epoch: 74 AUC-val 0.683  AUC-train 0.994\n",
            "Stats - Epoch: 75 AUC-val 0.671  AUC-train 0.994\n",
            "Stats - Epoch: 76 AUC-val 0.666  AUC-train 0.995\n",
            "Stats - Epoch: 77 AUC-val 0.640  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.664  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.674  AUC-train 0.996\n",
            "Stats - Epoch: 80 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.663  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.668  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.659  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 86 AUC-val 0.705  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.625  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.683  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.630  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.646  AUC-train 0.994\n",
            "Stats - Epoch: 92 AUC-val 0.639  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.642  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.672  AUC-train 0.994\n",
            "Stats - Epoch: 95 AUC-val 0.658  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.643  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.678  AUC-train 0.994\n",
            "Stats - Epoch: 98 AUC-val 0.634  AUC-train 0.992\n",
            "Stats - Epoch: 99 AUC-val 0.631  AUC-train 0.994\n",
            "Stats - Epoch: 100 AUC-val 0.642  AUC-train 0.997\n",
            "Results 100 AUC-val 0.705 0.608 0.413 0.491 0.678 AUC-train 0.999\n",
            "Shapley [0.0176166  0.01286423 0.00988943 0.02659679 0.01030149] [0.00382944]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188142\n",
            "         Iterations 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD2tG2Pytapv"
      },
      "source": [
        "# Robustness seq time steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QliBI7NNtapw",
        "outputId": "5098ae72-b20d-46a8-a110-543f7491ec10"
      },
      "source": [
        "    # Seq\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/seq_timestep_control_obs_rep50_epochs50.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=50;\n",
        "    epochs = 50;\n",
        "    fcast_horizon=1;\n",
        "    for timestep in [1,2,3,4,5,6,7,8,9,10]: #\n",
        "        dates =[1970,1999,2000,2016] #[1970,2016]\n",
        "        train_end_year=dates[1];\n",
        "        train_start_year=dates[0];\n",
        "        test_start_year=dates[2]; # Define test set\n",
        "        test_end_year=dates[3];\n",
        "        \n",
        "    \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "        \n",
        "        \n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,reg_weight=[0.0],nlags=timestep,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=1,reps=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();     \n",
        "        f.write(sequential_evaluation(timestep=timestep,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=2,nlags=timestep,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(timestep=timestep,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(timestep=timestep,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(timestep=timestep,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();        \n",
        "\n",
        "\n",
        "        #f.write(cross_validation2(timestep=timestep,reps=reps,mm=3,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(timestep=timestep,reps=reps,mm=4,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(timestep=timestep,reps=reps,mm=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Stats - Epoch: 1 AUC-val 0.319  AUC-train 0.489\n",
            "Stats - Epoch: 2 AUC-val 0.350  AUC-train 0.546\n",
            "Stats - Epoch: 3 AUC-val 0.372  AUC-train 0.598\n",
            "Stats - Epoch: 4 AUC-val 0.376  AUC-train 0.637\n",
            "Stats - Epoch: 5 AUC-val 0.380  AUC-train 0.661\n",
            "Stats - Epoch: 6 AUC-val 0.377  AUC-train 0.681\n",
            "Stats - Epoch: 7 AUC-val 0.386  AUC-train 0.693\n",
            "Stats - Epoch: 8 AUC-val 0.390  AUC-train 0.714\n",
            "Stats - Epoch: 9 AUC-val 0.400  AUC-train 0.718\n",
            "Stats - Epoch: 10 AUC-val 0.395  AUC-train 0.738\n",
            "Stats - Epoch: 11 AUC-val 0.411  AUC-train 0.741\n",
            "Stats - Epoch: 12 AUC-val 0.414  AUC-train 0.753\n",
            "Stats - Epoch: 13 AUC-val 0.410  AUC-train 0.767\n",
            "Stats - Epoch: 14 AUC-val 0.428  AUC-train 0.762\n",
            "Stats - Epoch: 15 AUC-val 0.425  AUC-train 0.780\n",
            "Stats - Epoch: 16 AUC-val 0.437  AUC-train 0.775\n",
            "Stats - Epoch: 17 AUC-val 0.434  AUC-train 0.784\n",
            "Stats - Epoch: 18 AUC-val 0.442  AUC-train 0.788\n",
            "Stats - Epoch: 19 AUC-val 0.443  AUC-train 0.787\n",
            "Stats - Epoch: 20 AUC-val 0.450  AUC-train 0.793\n",
            "Stats - Epoch: 21 AUC-val 0.455  AUC-train 0.794\n",
            "Stats - Epoch: 22 AUC-val 0.456  AUC-train 0.802\n",
            "Stats - Epoch: 23 AUC-val 0.469  AUC-train 0.799\n",
            "Stats - Epoch: 24 AUC-val 0.458  AUC-train 0.806\n",
            "Stats - Epoch: 25 AUC-val 0.461  AUC-train 0.804\n",
            "Stats - Epoch: 26 AUC-val 0.473  AUC-train 0.803\n",
            "Stats - Epoch: 27 AUC-val 0.469  AUC-train 0.810\n",
            "Stats - Epoch: 28 AUC-val 0.467  AUC-train 0.809\n",
            "Stats - Epoch: 29 AUC-val 0.479  AUC-train 0.810\n",
            "Stats - Epoch: 30 AUC-val 0.481  AUC-train 0.809\n",
            "Stats - Epoch: 31 AUC-val 0.488  AUC-train 0.810\n",
            "Stats - Epoch: 32 AUC-val 0.477  AUC-train 0.812\n",
            "Stats - Epoch: 33 AUC-val 0.486  AUC-train 0.814\n",
            "Stats - Epoch: 34 AUC-val 0.488  AUC-train 0.811\n",
            "Stats - Epoch: 35 AUC-val 0.490  AUC-train 0.812\n",
            "Stats - Epoch: 36 AUC-val 0.493  AUC-train 0.813\n",
            "Stats - Epoch: 37 AUC-val 0.493  AUC-train 0.813\n",
            "Stats - Epoch: 38 AUC-val 0.491  AUC-train 0.812\n",
            "Stats - Epoch: 39 AUC-val 0.496  AUC-train 0.811\n",
            "Stats - Epoch: 40 AUC-val 0.495  AUC-train 0.811\n",
            "Stats - Epoch: 41 AUC-val 0.496  AUC-train 0.812\n",
            "Stats - Epoch: 42 AUC-val 0.499  AUC-train 0.811\n",
            "Stats - Epoch: 43 AUC-val 0.493  AUC-train 0.809\n",
            "Stats - Epoch: 44 AUC-val 0.494  AUC-train 0.810\n",
            "Stats - Epoch: 45 AUC-val 0.499  AUC-train 0.810\n",
            "Stats - Epoch: 46 AUC-val 0.497  AUC-train 0.809\n",
            "Stats - Epoch: 47 AUC-val 0.501  AUC-train 0.808\n",
            "Stats - Epoch: 48 AUC-val 0.506  AUC-train 0.809\n",
            "Stats - Epoch: 49 AUC-val 0.501  AUC-train 0.809\n",
            "Stats - Epoch: 50 AUC-val 0.491  AUC-train 0.809\n",
            "Results 50 AUC-val 0.506 0.467 0.545 0.407 0.631 AUC-train 0.809\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.255  AUC-train 0.585\n",
            "Stats - Epoch: 2 AUC-val 0.216  AUC-train 0.603\n",
            "Stats - Epoch: 3 AUC-val 0.187  AUC-train 0.646\n",
            "Stats - Epoch: 4 AUC-val 0.199  AUC-train 0.689\n",
            "Stats - Epoch: 5 AUC-val 0.229  AUC-train 0.712\n",
            "Stats - Epoch: 6 AUC-val 0.245  AUC-train 0.742\n",
            "Stats - Epoch: 7 AUC-val 0.284  AUC-train 0.758\n",
            "Stats - Epoch: 8 AUC-val 0.314  AUC-train 0.786\n",
            "Stats - Epoch: 9 AUC-val 0.328  AUC-train 0.793\n",
            "Stats - Epoch: 10 AUC-val 0.342  AUC-train 0.806\n",
            "Stats - Epoch: 11 AUC-val 0.362  AUC-train 0.811\n",
            "Stats - Epoch: 12 AUC-val 0.365  AUC-train 0.815\n",
            "Stats - Epoch: 13 AUC-val 0.360  AUC-train 0.821\n",
            "Stats - Epoch: 14 AUC-val 0.372  AUC-train 0.823\n",
            "Stats - Epoch: 15 AUC-val 0.381  AUC-train 0.821\n",
            "Stats - Epoch: 16 AUC-val 0.378  AUC-train 0.827\n",
            "Stats - Epoch: 17 AUC-val 0.389  AUC-train 0.827\n",
            "Stats - Epoch: 18 AUC-val 0.393  AUC-train 0.831\n",
            "Stats - Epoch: 19 AUC-val 0.397  AUC-train 0.831\n",
            "Stats - Epoch: 20 AUC-val 0.405  AUC-train 0.833\n",
            "Stats - Epoch: 21 AUC-val 0.408  AUC-train 0.835\n",
            "Stats - Epoch: 22 AUC-val 0.413  AUC-train 0.836\n",
            "Stats - Epoch: 23 AUC-val 0.409  AUC-train 0.838\n",
            "Stats - Epoch: 24 AUC-val 0.407  AUC-train 0.836\n",
            "Stats - Epoch: 25 AUC-val 0.410  AUC-train 0.840\n",
            "Stats - Epoch: 26 AUC-val 0.414  AUC-train 0.841\n",
            "Stats - Epoch: 27 AUC-val 0.421  AUC-train 0.843\n",
            "Stats - Epoch: 28 AUC-val 0.424  AUC-train 0.843\n",
            "Stats - Epoch: 29 AUC-val 0.433  AUC-train 0.844\n",
            "Stats - Epoch: 30 AUC-val 0.445  AUC-train 0.844\n",
            "Stats - Epoch: 31 AUC-val 0.441  AUC-train 0.845\n",
            "Stats - Epoch: 32 AUC-val 0.448  AUC-train 0.847\n",
            "Stats - Epoch: 33 AUC-val 0.444  AUC-train 0.849\n",
            "Stats - Epoch: 34 AUC-val 0.452  AUC-train 0.850\n",
            "Stats - Epoch: 35 AUC-val 0.465  AUC-train 0.852\n",
            "Stats - Epoch: 36 AUC-val 0.456  AUC-train 0.852\n",
            "Stats - Epoch: 37 AUC-val 0.469  AUC-train 0.853\n",
            "Stats - Epoch: 38 AUC-val 0.472  AUC-train 0.852\n",
            "Stats - Epoch: 39 AUC-val 0.459  AUC-train 0.855\n",
            "Stats - Epoch: 40 AUC-val 0.475  AUC-train 0.854\n",
            "Stats - Epoch: 41 AUC-val 0.469  AUC-train 0.856\n",
            "Stats - Epoch: 42 AUC-val 0.472  AUC-train 0.856\n",
            "Stats - Epoch: 43 AUC-val 0.472  AUC-train 0.858\n",
            "Stats - Epoch: 44 AUC-val 0.478  AUC-train 0.858\n",
            "Stats - Epoch: 45 AUC-val 0.485  AUC-train 0.858\n",
            "Stats - Epoch: 46 AUC-val 0.493  AUC-train 0.857\n",
            "Stats - Epoch: 47 AUC-val 0.485  AUC-train 0.860\n",
            "Stats - Epoch: 48 AUC-val 0.496  AUC-train 0.862\n",
            "Stats - Epoch: 49 AUC-val 0.494  AUC-train 0.862\n",
            "Stats - Epoch: 50 AUC-val 0.498  AUC-train 0.863\n",
            "Results 50 AUC-val 0.498 0.484 0.539 0.416 0.647 AUC-train 0.863\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.266  AUC-train 0.527\n",
            "Stats - Epoch: 2 AUC-val 0.222  AUC-train 0.615\n",
            "Stats - Epoch: 3 AUC-val 0.254  AUC-train 0.731\n",
            "Stats - Epoch: 4 AUC-val 0.300  AUC-train 0.788\n",
            "Stats - Epoch: 5 AUC-val 0.325  AUC-train 0.809\n",
            "Stats - Epoch: 6 AUC-val 0.356  AUC-train 0.824\n",
            "Stats - Epoch: 7 AUC-val 0.366  AUC-train 0.833\n",
            "Stats - Epoch: 8 AUC-val 0.382  AUC-train 0.841\n",
            "Stats - Epoch: 9 AUC-val 0.393  AUC-train 0.847\n",
            "Stats - Epoch: 10 AUC-val 0.407  AUC-train 0.851\n",
            "Stats - Epoch: 11 AUC-val 0.411  AUC-train 0.855\n",
            "Stats - Epoch: 12 AUC-val 0.418  AUC-train 0.858\n",
            "Stats - Epoch: 13 AUC-val 0.425  AUC-train 0.861\n",
            "Stats - Epoch: 14 AUC-val 0.437  AUC-train 0.864\n",
            "Stats - Epoch: 15 AUC-val 0.428  AUC-train 0.869\n",
            "Stats - Epoch: 16 AUC-val 0.442  AUC-train 0.872\n",
            "Stats - Epoch: 17 AUC-val 0.432  AUC-train 0.876\n",
            "Stats - Epoch: 18 AUC-val 0.450  AUC-train 0.877\n",
            "Stats - Epoch: 19 AUC-val 0.441  AUC-train 0.881\n",
            "Stats - Epoch: 20 AUC-val 0.456  AUC-train 0.881\n",
            "Stats - Epoch: 21 AUC-val 0.453  AUC-train 0.882\n",
            "Stats - Epoch: 22 AUC-val 0.446  AUC-train 0.886\n",
            "Stats - Epoch: 23 AUC-val 0.457  AUC-train 0.886\n",
            "Stats - Epoch: 24 AUC-val 0.457  AUC-train 0.889\n",
            "Stats - Epoch: 25 AUC-val 0.467  AUC-train 0.888\n",
            "Stats - Epoch: 26 AUC-val 0.457  AUC-train 0.890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 27 AUC-val 0.454  AUC-train 0.892\n",
            "Stats - Epoch: 28 AUC-val 0.459  AUC-train 0.893\n",
            "Stats - Epoch: 29 AUC-val 0.468  AUC-train 0.894\n",
            "Stats - Epoch: 30 AUC-val 0.464  AUC-train 0.896\n",
            "Stats - Epoch: 31 AUC-val 0.460  AUC-train 0.897\n",
            "Stats - Epoch: 32 AUC-val 0.467  AUC-train 0.897\n",
            "Stats - Epoch: 33 AUC-val 0.462  AUC-train 0.900\n",
            "Stats - Epoch: 34 AUC-val 0.474  AUC-train 0.899\n",
            "Stats - Epoch: 35 AUC-val 0.483  AUC-train 0.901\n",
            "Stats - Epoch: 36 AUC-val 0.481  AUC-train 0.900\n",
            "Stats - Epoch: 37 AUC-val 0.476  AUC-train 0.903\n",
            "Stats - Epoch: 38 AUC-val 0.487  AUC-train 0.902\n",
            "Stats - Epoch: 39 AUC-val 0.484  AUC-train 0.904\n",
            "Stats - Epoch: 40 AUC-val 0.486  AUC-train 0.905\n",
            "Stats - Epoch: 41 AUC-val 0.486  AUC-train 0.905\n",
            "Stats - Epoch: 42 AUC-val 0.489  AUC-train 0.906\n",
            "Stats - Epoch: 43 AUC-val 0.488  AUC-train 0.907\n",
            "Stats - Epoch: 44 AUC-val 0.502  AUC-train 0.909\n",
            "Stats - Epoch: 45 AUC-val 0.498  AUC-train 0.909\n",
            "Stats - Epoch: 46 AUC-val 0.507  AUC-train 0.910\n",
            "Stats - Epoch: 47 AUC-val 0.503  AUC-train 0.912\n",
            "Stats - Epoch: 48 AUC-val 0.508  AUC-train 0.910\n",
            "Stats - Epoch: 49 AUC-val 0.498  AUC-train 0.912\n",
            "Stats - Epoch: 50 AUC-val 0.497  AUC-train 0.914\n",
            "Results 50 AUC-val 0.508 0.555 0.560 0.445 0.650 AUC-train 0.910\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.244  AUC-train 0.533\n",
            "Stats - Epoch: 2 AUC-val 0.241  AUC-train 0.638\n",
            "Stats - Epoch: 3 AUC-val 0.266  AUC-train 0.726\n",
            "Stats - Epoch: 4 AUC-val 0.297  AUC-train 0.780\n",
            "Stats - Epoch: 5 AUC-val 0.300  AUC-train 0.808\n",
            "Stats - Epoch: 6 AUC-val 0.320  AUC-train 0.825\n",
            "Stats - Epoch: 7 AUC-val 0.340  AUC-train 0.835\n",
            "Stats - Epoch: 8 AUC-val 0.352  AUC-train 0.845\n",
            "Stats - Epoch: 9 AUC-val 0.353  AUC-train 0.851\n",
            "Stats - Epoch: 10 AUC-val 0.377  AUC-train 0.858\n",
            "Stats - Epoch: 11 AUC-val 0.380  AUC-train 0.865\n",
            "Stats - Epoch: 12 AUC-val 0.399  AUC-train 0.867\n",
            "Stats - Epoch: 13 AUC-val 0.398  AUC-train 0.873\n",
            "Stats - Epoch: 14 AUC-val 0.414  AUC-train 0.878\n",
            "Stats - Epoch: 15 AUC-val 0.412  AUC-train 0.881\n",
            "Stats - Epoch: 16 AUC-val 0.413  AUC-train 0.885\n",
            "Stats - Epoch: 17 AUC-val 0.421  AUC-train 0.893\n",
            "Stats - Epoch: 18 AUC-val 0.430  AUC-train 0.892\n",
            "Stats - Epoch: 19 AUC-val 0.426  AUC-train 0.898\n",
            "Stats - Epoch: 20 AUC-val 0.442  AUC-train 0.898\n",
            "Stats - Epoch: 21 AUC-val 0.436  AUC-train 0.902\n",
            "Stats - Epoch: 22 AUC-val 0.438  AUC-train 0.902\n",
            "Stats - Epoch: 23 AUC-val 0.445  AUC-train 0.907\n",
            "Stats - Epoch: 24 AUC-val 0.453  AUC-train 0.911\n",
            "Stats - Epoch: 25 AUC-val 0.438  AUC-train 0.912\n",
            "Stats - Epoch: 26 AUC-val 0.440  AUC-train 0.913\n",
            "Stats - Epoch: 27 AUC-val 0.456  AUC-train 0.915\n",
            "Stats - Epoch: 28 AUC-val 0.461  AUC-train 0.918\n",
            "Stats - Epoch: 29 AUC-val 0.457  AUC-train 0.918\n",
            "Stats - Epoch: 30 AUC-val 0.465  AUC-train 0.919\n",
            "Stats - Epoch: 31 AUC-val 0.458  AUC-train 0.920\n",
            "Stats - Epoch: 32 AUC-val 0.463  AUC-train 0.922\n",
            "Stats - Epoch: 33 AUC-val 0.466  AUC-train 0.924\n",
            "Stats - Epoch: 34 AUC-val 0.467  AUC-train 0.924\n",
            "Stats - Epoch: 35 AUC-val 0.470  AUC-train 0.927\n",
            "Stats - Epoch: 36 AUC-val 0.469  AUC-train 0.929\n",
            "Stats - Epoch: 37 AUC-val 0.472  AUC-train 0.929\n",
            "Stats - Epoch: 38 AUC-val 0.477  AUC-train 0.930\n",
            "Stats - Epoch: 39 AUC-val 0.473  AUC-train 0.931\n",
            "Stats - Epoch: 40 AUC-val 0.486  AUC-train 0.932\n",
            "Stats - Epoch: 41 AUC-val 0.484  AUC-train 0.934\n",
            "Stats - Epoch: 42 AUC-val 0.474  AUC-train 0.934\n",
            "Stats - Epoch: 43 AUC-val 0.485  AUC-train 0.936\n",
            "Stats - Epoch: 44 AUC-val 0.485  AUC-train 0.937\n",
            "Stats - Epoch: 45 AUC-val 0.507  AUC-train 0.935\n",
            "Stats - Epoch: 46 AUC-val 0.491  AUC-train 0.939\n",
            "Stats - Epoch: 47 AUC-val 0.499  AUC-train 0.939\n",
            "Stats - Epoch: 48 AUC-val 0.501  AUC-train 0.940\n",
            "Stats - Epoch: 49 AUC-val 0.505  AUC-train 0.940\n",
            "Stats - Epoch: 50 AUC-val 0.502  AUC-train 0.941\n",
            "Results 50 AUC-val 0.507 0.524 0.515 0.409 0.619 AUC-train 0.935\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.523  AUC-train 0.828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.523 0.555 0.485 0.518 0.686 AUC-train 0.828\n",
            "Shapley [0.01376499 0.00632486 0.02010741 0.01061047 0.00809987] [0.0109057]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184464\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.319  AUC-train 0.547\n",
            "Stats - Epoch: 2 AUC-val 0.374  AUC-train 0.680\n",
            "Stats - Epoch: 3 AUC-val 0.416  AUC-train 0.755\n",
            "Stats - Epoch: 4 AUC-val 0.419  AUC-train 0.793\n",
            "Stats - Epoch: 5 AUC-val 0.417  AUC-train 0.816\n",
            "Stats - Epoch: 6 AUC-val 0.426  AUC-train 0.835\n",
            "Stats - Epoch: 7 AUC-val 0.430  AUC-train 0.848\n",
            "Stats - Epoch: 8 AUC-val 0.443  AUC-train 0.856\n",
            "Stats - Epoch: 9 AUC-val 0.440  AUC-train 0.868\n",
            "Stats - Epoch: 10 AUC-val 0.446  AUC-train 0.873\n",
            "Stats - Epoch: 11 AUC-val 0.447  AUC-train 0.879\n",
            "Stats - Epoch: 12 AUC-val 0.461  AUC-train 0.882\n",
            "Stats - Epoch: 13 AUC-val 0.453  AUC-train 0.884\n",
            "Stats - Epoch: 14 AUC-val 0.457  AUC-train 0.887\n",
            "Stats - Epoch: 15 AUC-val 0.460  AUC-train 0.889\n",
            "Stats - Epoch: 16 AUC-val 0.464  AUC-train 0.890\n",
            "Stats - Epoch: 17 AUC-val 0.480  AUC-train 0.892\n",
            "Stats - Epoch: 18 AUC-val 0.480  AUC-train 0.891\n",
            "Stats - Epoch: 19 AUC-val 0.490  AUC-train 0.895\n",
            "Stats - Epoch: 20 AUC-val 0.476  AUC-train 0.895\n",
            "Stats - Epoch: 21 AUC-val 0.489  AUC-train 0.895\n",
            "Stats - Epoch: 22 AUC-val 0.492  AUC-train 0.898\n",
            "Stats - Epoch: 23 AUC-val 0.493  AUC-train 0.899\n",
            "Stats - Epoch: 24 AUC-val 0.491  AUC-train 0.899\n",
            "Stats - Epoch: 25 AUC-val 0.495  AUC-train 0.898\n",
            "Stats - Epoch: 26 AUC-val 0.497  AUC-train 0.898\n",
            "Stats - Epoch: 27 AUC-val 0.497  AUC-train 0.896\n",
            "Stats - Epoch: 28 AUC-val 0.502  AUC-train 0.898\n",
            "Stats - Epoch: 29 AUC-val 0.499  AUC-train 0.897\n",
            "Stats - Epoch: 30 AUC-val 0.503  AUC-train 0.897\n",
            "Stats - Epoch: 31 AUC-val 0.498  AUC-train 0.897\n",
            "Stats - Epoch: 32 AUC-val 0.500  AUC-train 0.898\n",
            "Stats - Epoch: 33 AUC-val 0.509  AUC-train 0.895\n",
            "Stats - Epoch: 34 AUC-val 0.503  AUC-train 0.896\n",
            "Stats - Epoch: 35 AUC-val 0.508  AUC-train 0.895\n",
            "Stats - Epoch: 36 AUC-val 0.518  AUC-train 0.895\n",
            "Stats - Epoch: 37 AUC-val 0.507  AUC-train 0.894\n",
            "Stats - Epoch: 38 AUC-val 0.507  AUC-train 0.895\n",
            "Stats - Epoch: 39 AUC-val 0.512  AUC-train 0.892\n",
            "Stats - Epoch: 40 AUC-val 0.512  AUC-train 0.893\n",
            "Stats - Epoch: 41 AUC-val 0.516  AUC-train 0.896\n",
            "Stats - Epoch: 42 AUC-val 0.510  AUC-train 0.893\n",
            "Stats - Epoch: 43 AUC-val 0.506  AUC-train 0.894\n",
            "Stats - Epoch: 44 AUC-val 0.511  AUC-train 0.894\n",
            "Stats - Epoch: 45 AUC-val 0.509  AUC-train 0.892\n",
            "Stats - Epoch: 46 AUC-val 0.511  AUC-train 0.892\n",
            "Stats - Epoch: 47 AUC-val 0.516  AUC-train 0.891\n",
            "Stats - Epoch: 48 AUC-val 0.516  AUC-train 0.890\n",
            "Stats - Epoch: 49 AUC-val 0.510  AUC-train 0.892\n",
            "Stats - Epoch: 50 AUC-val 0.521  AUC-train 0.890\n",
            "Results 50 AUC-val 0.521 0.553 0.480 0.468 0.544 AUC-train 0.890\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.219  AUC-train 0.591\n",
            "Stats - Epoch: 2 AUC-val 0.209  AUC-train 0.630\n",
            "Stats - Epoch: 3 AUC-val 0.193  AUC-train 0.686\n",
            "Stats - Epoch: 4 AUC-val 0.218  AUC-train 0.732\n",
            "Stats - Epoch: 5 AUC-val 0.245  AUC-train 0.767\n",
            "Stats - Epoch: 6 AUC-val 0.262  AUC-train 0.792\n",
            "Stats - Epoch: 7 AUC-val 0.302  AUC-train 0.812\n",
            "Stats - Epoch: 8 AUC-val 0.331  AUC-train 0.828\n",
            "Stats - Epoch: 9 AUC-val 0.347  AUC-train 0.838\n",
            "Stats - Epoch: 10 AUC-val 0.373  AUC-train 0.848\n",
            "Stats - Epoch: 11 AUC-val 0.383  AUC-train 0.854\n",
            "Stats - Epoch: 12 AUC-val 0.401  AUC-train 0.861\n",
            "Stats - Epoch: 13 AUC-val 0.412  AUC-train 0.869\n",
            "Stats - Epoch: 14 AUC-val 0.401  AUC-train 0.874\n",
            "Stats - Epoch: 15 AUC-val 0.443  AUC-train 0.878\n",
            "Stats - Epoch: 16 AUC-val 0.433  AUC-train 0.879\n",
            "Stats - Epoch: 17 AUC-val 0.441  AUC-train 0.882\n",
            "Stats - Epoch: 18 AUC-val 0.446  AUC-train 0.887\n",
            "Stats - Epoch: 19 AUC-val 0.451  AUC-train 0.891\n",
            "Stats - Epoch: 20 AUC-val 0.464  AUC-train 0.891\n",
            "Stats - Epoch: 21 AUC-val 0.476  AUC-train 0.896\n",
            "Stats - Epoch: 22 AUC-val 0.461  AUC-train 0.901\n",
            "Stats - Epoch: 23 AUC-val 0.469  AUC-train 0.900\n",
            "Stats - Epoch: 24 AUC-val 0.493  AUC-train 0.904\n",
            "Stats - Epoch: 25 AUC-val 0.454  AUC-train 0.907\n",
            "Stats - Epoch: 26 AUC-val 0.487  AUC-train 0.910\n",
            "Stats - Epoch: 27 AUC-val 0.465  AUC-train 0.911\n",
            "Stats - Epoch: 28 AUC-val 0.471  AUC-train 0.912\n",
            "Stats - Epoch: 29 AUC-val 0.463  AUC-train 0.916\n",
            "Stats - Epoch: 30 AUC-val 0.487  AUC-train 0.918\n",
            "Stats - Epoch: 31 AUC-val 0.492  AUC-train 0.919\n",
            "Stats - Epoch: 32 AUC-val 0.496  AUC-train 0.921\n",
            "Stats - Epoch: 33 AUC-val 0.471  AUC-train 0.922\n",
            "Stats - Epoch: 34 AUC-val 0.482  AUC-train 0.923\n",
            "Stats - Epoch: 35 AUC-val 0.490  AUC-train 0.927\n",
            "Stats - Epoch: 36 AUC-val 0.482  AUC-train 0.928\n",
            "Stats - Epoch: 37 AUC-val 0.496  AUC-train 0.930\n",
            "Stats - Epoch: 38 AUC-val 0.486  AUC-train 0.932\n",
            "Stats - Epoch: 39 AUC-val 0.501  AUC-train 0.934\n",
            "Stats - Epoch: 40 AUC-val 0.509  AUC-train 0.938\n",
            "Stats - Epoch: 41 AUC-val 0.489  AUC-train 0.939\n",
            "Stats - Epoch: 42 AUC-val 0.491  AUC-train 0.939\n",
            "Stats - Epoch: 43 AUC-val 0.509  AUC-train 0.938\n",
            "Stats - Epoch: 44 AUC-val 0.505  AUC-train 0.939\n",
            "Stats - Epoch: 45 AUC-val 0.507  AUC-train 0.943\n",
            "Stats - Epoch: 46 AUC-val 0.509  AUC-train 0.943\n",
            "Stats - Epoch: 47 AUC-val 0.533  AUC-train 0.944\n",
            "Stats - Epoch: 48 AUC-val 0.491  AUC-train 0.946\n",
            "Stats - Epoch: 49 AUC-val 0.505  AUC-train 0.946\n",
            "Stats - Epoch: 50 AUC-val 0.489  AUC-train 0.948\n",
            "Results 50 AUC-val 0.533 0.659 0.541 0.518 0.691 AUC-train 0.944\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.297  AUC-train 0.553\n",
            "Stats - Epoch: 2 AUC-val 0.285  AUC-train 0.711\n",
            "Stats - Epoch: 3 AUC-val 0.372  AUC-train 0.819\n",
            "Stats - Epoch: 4 AUC-val 0.439  AUC-train 0.861\n",
            "Stats - Epoch: 5 AUC-val 0.488  AUC-train 0.882\n",
            "Stats - Epoch: 6 AUC-val 0.511  AUC-train 0.898\n",
            "Stats - Epoch: 7 AUC-val 0.514  AUC-train 0.911\n",
            "Stats - Epoch: 8 AUC-val 0.531  AUC-train 0.926\n",
            "Stats - Epoch: 9 AUC-val 0.514  AUC-train 0.935\n",
            "Stats - Epoch: 10 AUC-val 0.516  AUC-train 0.942\n",
            "Stats - Epoch: 11 AUC-val 0.492  AUC-train 0.948\n",
            "Stats - Epoch: 12 AUC-val 0.509  AUC-train 0.952\n",
            "Stats - Epoch: 13 AUC-val 0.481  AUC-train 0.962\n",
            "Stats - Epoch: 14 AUC-val 0.507  AUC-train 0.965\n",
            "Stats - Epoch: 15 AUC-val 0.495  AUC-train 0.969\n",
            "Stats - Epoch: 16 AUC-val 0.505  AUC-train 0.970\n",
            "Stats - Epoch: 17 AUC-val 0.495  AUC-train 0.975\n",
            "Stats - Epoch: 18 AUC-val 0.519  AUC-train 0.975\n",
            "Stats - Epoch: 19 AUC-val 0.514  AUC-train 0.979\n",
            "Stats - Epoch: 20 AUC-val 0.509  AUC-train 0.980\n",
            "Stats - Epoch: 21 AUC-val 0.482  AUC-train 0.984\n",
            "Stats - Epoch: 22 AUC-val 0.499  AUC-train 0.986\n",
            "Stats - Epoch: 23 AUC-val 0.491  AUC-train 0.987\n",
            "Stats - Epoch: 24 AUC-val 0.476  AUC-train 0.989\n",
            "Stats - Epoch: 25 AUC-val 0.494  AUC-train 0.989\n",
            "Stats - Epoch: 26 AUC-val 0.481  AUC-train 0.990\n",
            "Stats - Epoch: 27 AUC-val 0.471  AUC-train 0.991\n",
            "Stats - Epoch: 28 AUC-val 0.471  AUC-train 0.992\n",
            "Stats - Epoch: 29 AUC-val 0.481  AUC-train 0.993\n",
            "Stats - Epoch: 30 AUC-val 0.465  AUC-train 0.994\n",
            "Stats - Epoch: 31 AUC-val 0.487  AUC-train 0.994\n",
            "Stats - Epoch: 32 AUC-val 0.457  AUC-train 0.995\n",
            "Stats - Epoch: 33 AUC-val 0.465  AUC-train 0.995\n",
            "Stats - Epoch: 34 AUC-val 0.458  AUC-train 0.996\n",
            "Stats - Epoch: 35 AUC-val 0.474  AUC-train 0.994\n",
            "Stats - Epoch: 36 AUC-val 0.466  AUC-train 0.995\n",
            "Stats - Epoch: 37 AUC-val 0.473  AUC-train 0.996\n",
            "Stats - Epoch: 38 AUC-val 0.471  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.467  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.456  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.476  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.463  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.469  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.478  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.462  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.475  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.470  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.467  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.477  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.455  AUC-train 0.998\n",
            "Results 50 AUC-val 0.531 0.653 0.590 0.511 0.656 AUC-train 0.926\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.493  AUC-train 0.459\n",
            "Stats - Epoch: 2 AUC-val 0.486  AUC-train 0.576\n",
            "Stats - Epoch: 3 AUC-val 0.512  AUC-train 0.691\n",
            "Stats - Epoch: 4 AUC-val 0.525  AUC-train 0.774\n",
            "Stats - Epoch: 5 AUC-val 0.547  AUC-train 0.822\n",
            "Stats - Epoch: 6 AUC-val 0.559  AUC-train 0.857\n",
            "Stats - Epoch: 7 AUC-val 0.556  AUC-train 0.877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.571  AUC-train 0.890\n",
            "Stats - Epoch: 9 AUC-val 0.566  AUC-train 0.904\n",
            "Stats - Epoch: 10 AUC-val 0.576  AUC-train 0.911\n",
            "Stats - Epoch: 11 AUC-val 0.564  AUC-train 0.920\n",
            "Stats - Epoch: 12 AUC-val 0.563  AUC-train 0.927\n",
            "Stats - Epoch: 13 AUC-val 0.536  AUC-train 0.936\n",
            "Stats - Epoch: 14 AUC-val 0.567  AUC-train 0.943\n",
            "Stats - Epoch: 15 AUC-val 0.552  AUC-train 0.949\n",
            "Stats - Epoch: 16 AUC-val 0.550  AUC-train 0.954\n",
            "Stats - Epoch: 17 AUC-val 0.553  AUC-train 0.958\n",
            "Stats - Epoch: 18 AUC-val 0.533  AUC-train 0.963\n",
            "Stats - Epoch: 19 AUC-val 0.552  AUC-train 0.965\n",
            "Stats - Epoch: 20 AUC-val 0.533  AUC-train 0.970\n",
            "Stats - Epoch: 21 AUC-val 0.548  AUC-train 0.973\n",
            "Stats - Epoch: 22 AUC-val 0.519  AUC-train 0.976\n",
            "Stats - Epoch: 23 AUC-val 0.535  AUC-train 0.979\n",
            "Stats - Epoch: 24 AUC-val 0.556  AUC-train 0.981\n",
            "Stats - Epoch: 25 AUC-val 0.536  AUC-train 0.981\n",
            "Stats - Epoch: 26 AUC-val 0.551  AUC-train 0.986\n",
            "Stats - Epoch: 27 AUC-val 0.520  AUC-train 0.988\n",
            "Stats - Epoch: 28 AUC-val 0.524  AUC-train 0.987\n",
            "Stats - Epoch: 29 AUC-val 0.531  AUC-train 0.989\n",
            "Stats - Epoch: 30 AUC-val 0.547  AUC-train 0.988\n",
            "Stats - Epoch: 31 AUC-val 0.520  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.538  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.557  AUC-train 0.992\n",
            "Stats - Epoch: 34 AUC-val 0.523  AUC-train 0.993\n",
            "Stats - Epoch: 35 AUC-val 0.523  AUC-train 0.994\n",
            "Stats - Epoch: 36 AUC-val 0.529  AUC-train 0.994\n",
            "Stats - Epoch: 37 AUC-val 0.533  AUC-train 0.994\n",
            "Stats - Epoch: 38 AUC-val 0.526  AUC-train 0.995\n",
            "Stats - Epoch: 39 AUC-val 0.536  AUC-train 0.996\n",
            "Stats - Epoch: 40 AUC-val 0.535  AUC-train 0.995\n",
            "Stats - Epoch: 41 AUC-val 0.518  AUC-train 0.996\n",
            "Stats - Epoch: 42 AUC-val 0.530  AUC-train 0.996\n",
            "Stats - Epoch: 43 AUC-val 0.536  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.517  AUC-train 0.997\n",
            "Stats - Epoch: 45 AUC-val 0.524  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.526  AUC-train 0.996\n",
            "Stats - Epoch: 47 AUC-val 0.505  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.524  AUC-train 0.997\n",
            "Stats - Epoch: 49 AUC-val 0.534  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.523  AUC-train 0.998\n",
            "Results 50 AUC-val 0.576 0.714 0.658 0.356 0.638 AUC-train 0.911\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.548  AUC-train 0.842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.548 0.556 0.523 0.548 0.712 AUC-train 0.842\n",
            "Shapley [0.01298441 0.00792295 0.01453058 0.00910832 0.00694712] [0.00862639]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188086\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.306  AUC-train 0.585\n",
            "Stats - Epoch: 2 AUC-val 0.518  AUC-train 0.730\n",
            "Stats - Epoch: 3 AUC-val 0.520  AUC-train 0.804\n",
            "Stats - Epoch: 4 AUC-val 0.539  AUC-train 0.847\n",
            "Stats - Epoch: 5 AUC-val 0.514  AUC-train 0.879\n",
            "Stats - Epoch: 6 AUC-val 0.512  AUC-train 0.898\n",
            "Stats - Epoch: 7 AUC-val 0.510  AUC-train 0.912\n",
            "Stats - Epoch: 8 AUC-val 0.490  AUC-train 0.920\n",
            "Stats - Epoch: 9 AUC-val 0.478  AUC-train 0.927\n",
            "Stats - Epoch: 10 AUC-val 0.474  AUC-train 0.934\n",
            "Stats - Epoch: 11 AUC-val 0.485  AUC-train 0.937\n",
            "Stats - Epoch: 12 AUC-val 0.484  AUC-train 0.939\n",
            "Stats - Epoch: 13 AUC-val 0.480  AUC-train 0.942\n",
            "Stats - Epoch: 14 AUC-val 0.472  AUC-train 0.946\n",
            "Stats - Epoch: 15 AUC-val 0.486  AUC-train 0.943\n",
            "Stats - Epoch: 16 AUC-val 0.454  AUC-train 0.947\n",
            "Stats - Epoch: 17 AUC-val 0.483  AUC-train 0.949\n",
            "Stats - Epoch: 18 AUC-val 0.486  AUC-train 0.945\n",
            "Stats - Epoch: 19 AUC-val 0.467  AUC-train 0.951\n",
            "Stats - Epoch: 20 AUC-val 0.466  AUC-train 0.950\n",
            "Stats - Epoch: 21 AUC-val 0.485  AUC-train 0.950\n",
            "Stats - Epoch: 22 AUC-val 0.470  AUC-train 0.949\n",
            "Stats - Epoch: 23 AUC-val 0.493  AUC-train 0.952\n",
            "Stats - Epoch: 24 AUC-val 0.478  AUC-train 0.950\n",
            "Stats - Epoch: 25 AUC-val 0.479  AUC-train 0.950\n",
            "Stats - Epoch: 26 AUC-val 0.485  AUC-train 0.949\n",
            "Stats - Epoch: 27 AUC-val 0.476  AUC-train 0.950\n",
            "Stats - Epoch: 28 AUC-val 0.472  AUC-train 0.948\n",
            "Stats - Epoch: 29 AUC-val 0.483  AUC-train 0.948\n",
            "Stats - Epoch: 30 AUC-val 0.484  AUC-train 0.945\n",
            "Stats - Epoch: 31 AUC-val 0.482  AUC-train 0.948\n",
            "Stats - Epoch: 32 AUC-val 0.487  AUC-train 0.950\n",
            "Stats - Epoch: 33 AUC-val 0.484  AUC-train 0.950\n",
            "Stats - Epoch: 34 AUC-val 0.490  AUC-train 0.948\n",
            "Stats - Epoch: 35 AUC-val 0.493  AUC-train 0.948\n",
            "Stats - Epoch: 36 AUC-val 0.483  AUC-train 0.947\n",
            "Stats - Epoch: 37 AUC-val 0.475  AUC-train 0.949\n",
            "Stats - Epoch: 38 AUC-val 0.502  AUC-train 0.945\n",
            "Stats - Epoch: 39 AUC-val 0.495  AUC-train 0.945\n",
            "Stats - Epoch: 40 AUC-val 0.498  AUC-train 0.943\n",
            "Stats - Epoch: 41 AUC-val 0.498  AUC-train 0.945\n",
            "Stats - Epoch: 42 AUC-val 0.494  AUC-train 0.947\n",
            "Stats - Epoch: 43 AUC-val 0.490  AUC-train 0.948\n",
            "Stats - Epoch: 44 AUC-val 0.481  AUC-train 0.947\n",
            "Stats - Epoch: 45 AUC-val 0.481  AUC-train 0.944\n",
            "Stats - Epoch: 46 AUC-val 0.501  AUC-train 0.944\n",
            "Stats - Epoch: 47 AUC-val 0.481  AUC-train 0.942\n",
            "Stats - Epoch: 48 AUC-val 0.498  AUC-train 0.942\n",
            "Stats - Epoch: 49 AUC-val 0.490  AUC-train 0.945\n",
            "Stats - Epoch: 50 AUC-val 0.478  AUC-train 0.946\n",
            "Results 50 AUC-val 0.539 0.468 0.500 0.381 0.412 AUC-train 0.847\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.208  AUC-train 0.584\n",
            "Stats - Epoch: 2 AUC-val 0.195  AUC-train 0.618\n",
            "Stats - Epoch: 3 AUC-val 0.191  AUC-train 0.681\n",
            "Stats - Epoch: 4 AUC-val 0.234  AUC-train 0.726\n",
            "Stats - Epoch: 5 AUC-val 0.275  AUC-train 0.765\n",
            "Stats - Epoch: 6 AUC-val 0.329  AUC-train 0.793\n",
            "Stats - Epoch: 7 AUC-val 0.359  AUC-train 0.814\n",
            "Stats - Epoch: 8 AUC-val 0.395  AUC-train 0.829\n",
            "Stats - Epoch: 9 AUC-val 0.448  AUC-train 0.838\n",
            "Stats - Epoch: 10 AUC-val 0.463  AUC-train 0.847\n",
            "Stats - Epoch: 11 AUC-val 0.459  AUC-train 0.855\n",
            "Stats - Epoch: 12 AUC-val 0.523  AUC-train 0.860\n",
            "Stats - Epoch: 13 AUC-val 0.495  AUC-train 0.866\n",
            "Stats - Epoch: 14 AUC-val 0.516  AUC-train 0.872\n",
            "Stats - Epoch: 15 AUC-val 0.516  AUC-train 0.874\n",
            "Stats - Epoch: 16 AUC-val 0.505  AUC-train 0.877\n",
            "Stats - Epoch: 17 AUC-val 0.530  AUC-train 0.881\n",
            "Stats - Epoch: 18 AUC-val 0.524  AUC-train 0.887\n",
            "Stats - Epoch: 19 AUC-val 0.529  AUC-train 0.887\n",
            "Stats - Epoch: 20 AUC-val 0.522  AUC-train 0.889\n",
            "Stats - Epoch: 21 AUC-val 0.531  AUC-train 0.893\n",
            "Stats - Epoch: 22 AUC-val 0.558  AUC-train 0.894\n",
            "Stats - Epoch: 23 AUC-val 0.550  AUC-train 0.895\n",
            "Stats - Epoch: 24 AUC-val 0.571  AUC-train 0.897\n",
            "Stats - Epoch: 25 AUC-val 0.583  AUC-train 0.899\n",
            "Stats - Epoch: 26 AUC-val 0.541  AUC-train 0.900\n",
            "Stats - Epoch: 27 AUC-val 0.605  AUC-train 0.903\n",
            "Stats - Epoch: 28 AUC-val 0.561  AUC-train 0.906\n",
            "Stats - Epoch: 29 AUC-val 0.604  AUC-train 0.906\n",
            "Stats - Epoch: 30 AUC-val 0.576  AUC-train 0.909\n",
            "Stats - Epoch: 31 AUC-val 0.595  AUC-train 0.909\n",
            "Stats - Epoch: 32 AUC-val 0.574  AUC-train 0.912\n",
            "Stats - Epoch: 33 AUC-val 0.583  AUC-train 0.915\n",
            "Stats - Epoch: 34 AUC-val 0.579  AUC-train 0.916\n",
            "Stats - Epoch: 35 AUC-val 0.584  AUC-train 0.916\n",
            "Stats - Epoch: 36 AUC-val 0.575  AUC-train 0.916\n",
            "Stats - Epoch: 37 AUC-val 0.591  AUC-train 0.918\n",
            "Stats - Epoch: 38 AUC-val 0.602  AUC-train 0.918\n",
            "Stats - Epoch: 39 AUC-val 0.634  AUC-train 0.922\n",
            "Stats - Epoch: 40 AUC-val 0.603  AUC-train 0.922\n",
            "Stats - Epoch: 41 AUC-val 0.618  AUC-train 0.920\n",
            "Stats - Epoch: 42 AUC-val 0.619  AUC-train 0.920\n",
            "Stats - Epoch: 43 AUC-val 0.596  AUC-train 0.926\n",
            "Stats - Epoch: 44 AUC-val 0.614  AUC-train 0.925\n",
            "Stats - Epoch: 45 AUC-val 0.627  AUC-train 0.926\n",
            "Stats - Epoch: 46 AUC-val 0.623  AUC-train 0.926\n",
            "Stats - Epoch: 47 AUC-val 0.636  AUC-train 0.927\n",
            "Stats - Epoch: 48 AUC-val 0.641  AUC-train 0.930\n",
            "Stats - Epoch: 49 AUC-val 0.587  AUC-train 0.930\n",
            "Stats - Epoch: 50 AUC-val 0.602  AUC-train 0.929\n",
            "Results 50 AUC-val 0.641 0.613 0.624 0.587 0.712 AUC-train 0.930\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.540\n",
            "Stats - Epoch: 2 AUC-val 0.506  AUC-train 0.721\n",
            "Stats - Epoch: 3 AUC-val 0.588  AUC-train 0.810\n",
            "Stats - Epoch: 4 AUC-val 0.617  AUC-train 0.848\n",
            "Stats - Epoch: 5 AUC-val 0.634  AUC-train 0.877\n",
            "Stats - Epoch: 6 AUC-val 0.646  AUC-train 0.900\n",
            "Stats - Epoch: 7 AUC-val 0.645  AUC-train 0.918\n",
            "Stats - Epoch: 8 AUC-val 0.650  AUC-train 0.933\n",
            "Stats - Epoch: 9 AUC-val 0.664  AUC-train 0.945\n",
            "Stats - Epoch: 10 AUC-val 0.666  AUC-train 0.953\n",
            "Stats - Epoch: 11 AUC-val 0.667  AUC-train 0.962\n",
            "Stats - Epoch: 12 AUC-val 0.666  AUC-train 0.967\n",
            "Stats - Epoch: 13 AUC-val 0.645  AUC-train 0.972\n",
            "Stats - Epoch: 14 AUC-val 0.640  AUC-train 0.976\n",
            "Stats - Epoch: 15 AUC-val 0.652  AUC-train 0.981\n",
            "Stats - Epoch: 16 AUC-val 0.634  AUC-train 0.982\n",
            "Stats - Epoch: 17 AUC-val 0.649  AUC-train 0.984\n",
            "Stats - Epoch: 18 AUC-val 0.628  AUC-train 0.988\n",
            "Stats - Epoch: 19 AUC-val 0.632  AUC-train 0.989\n",
            "Stats - Epoch: 20 AUC-val 0.628  AUC-train 0.990\n",
            "Stats - Epoch: 21 AUC-val 0.633  AUC-train 0.989\n",
            "Stats - Epoch: 22 AUC-val 0.624  AUC-train 0.991\n",
            "Stats - Epoch: 23 AUC-val 0.610  AUC-train 0.993\n",
            "Stats - Epoch: 24 AUC-val 0.621  AUC-train 0.992\n",
            "Stats - Epoch: 25 AUC-val 0.619  AUC-train 0.995\n",
            "Stats - Epoch: 26 AUC-val 0.636  AUC-train 0.995\n",
            "Stats - Epoch: 27 AUC-val 0.622  AUC-train 0.995\n",
            "Stats - Epoch: 28 AUC-val 0.631  AUC-train 0.995\n",
            "Stats - Epoch: 29 AUC-val 0.628  AUC-train 0.996\n",
            "Stats - Epoch: 30 AUC-val 0.626  AUC-train 0.996\n",
            "Stats - Epoch: 31 AUC-val 0.651  AUC-train 0.996\n",
            "Stats - Epoch: 32 AUC-val 0.619  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.652  AUC-train 0.997\n",
            "Stats - Epoch: 34 AUC-val 0.623  AUC-train 0.997\n",
            "Stats - Epoch: 35 AUC-val 0.630  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.639  AUC-train 0.997\n",
            "Stats - Epoch: 37 AUC-val 0.641  AUC-train 0.997\n",
            "Stats - Epoch: 38 AUC-val 0.646  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.640  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.650  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.634  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.642  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.668  AUC-train 0.999\n",
            "Results 50 AUC-val 0.685 0.586 0.562 0.567 0.730 AUC-train 0.999\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.646  AUC-train 0.436\n",
            "Stats - Epoch: 2 AUC-val 0.693  AUC-train 0.577\n",
            "Stats - Epoch: 3 AUC-val 0.701  AUC-train 0.688\n",
            "Stats - Epoch: 4 AUC-val 0.696  AUC-train 0.759\n",
            "Stats - Epoch: 5 AUC-val 0.696  AUC-train 0.809\n",
            "Stats - Epoch: 6 AUC-val 0.693  AUC-train 0.843\n",
            "Stats - Epoch: 7 AUC-val 0.679  AUC-train 0.867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.676  AUC-train 0.885\n",
            "Stats - Epoch: 9 AUC-val 0.659  AUC-train 0.904\n",
            "Stats - Epoch: 10 AUC-val 0.657  AUC-train 0.915\n",
            "Stats - Epoch: 11 AUC-val 0.645  AUC-train 0.930\n",
            "Stats - Epoch: 12 AUC-val 0.636  AUC-train 0.938\n",
            "Stats - Epoch: 13 AUC-val 0.629  AUC-train 0.948\n",
            "Stats - Epoch: 14 AUC-val 0.618  AUC-train 0.955\n",
            "Stats - Epoch: 15 AUC-val 0.620  AUC-train 0.963\n",
            "Stats - Epoch: 16 AUC-val 0.624  AUC-train 0.967\n",
            "Stats - Epoch: 17 AUC-val 0.627  AUC-train 0.968\n",
            "Stats - Epoch: 18 AUC-val 0.605  AUC-train 0.974\n",
            "Stats - Epoch: 19 AUC-val 0.603  AUC-train 0.977\n",
            "Stats - Epoch: 20 AUC-val 0.613  AUC-train 0.979\n",
            "Stats - Epoch: 21 AUC-val 0.622  AUC-train 0.982\n",
            "Stats - Epoch: 22 AUC-val 0.627  AUC-train 0.982\n",
            "Stats - Epoch: 23 AUC-val 0.623  AUC-train 0.984\n",
            "Stats - Epoch: 24 AUC-val 0.614  AUC-train 0.987\n",
            "Stats - Epoch: 25 AUC-val 0.615  AUC-train 0.988\n",
            "Stats - Epoch: 26 AUC-val 0.626  AUC-train 0.988\n",
            "Stats - Epoch: 27 AUC-val 0.612  AUC-train 0.989\n",
            "Stats - Epoch: 28 AUC-val 0.627  AUC-train 0.991\n",
            "Stats - Epoch: 29 AUC-val 0.617  AUC-train 0.992\n",
            "Stats - Epoch: 30 AUC-val 0.629  AUC-train 0.992\n",
            "Stats - Epoch: 31 AUC-val 0.618  AUC-train 0.993\n",
            "Stats - Epoch: 32 AUC-val 0.614  AUC-train 0.992\n",
            "Stats - Epoch: 33 AUC-val 0.641  AUC-train 0.992\n",
            "Stats - Epoch: 34 AUC-val 0.640  AUC-train 0.994\n",
            "Stats - Epoch: 35 AUC-val 0.620  AUC-train 0.994\n",
            "Stats - Epoch: 36 AUC-val 0.626  AUC-train 0.994\n",
            "Stats - Epoch: 37 AUC-val 0.614  AUC-train 0.995\n",
            "Stats - Epoch: 38 AUC-val 0.638  AUC-train 0.995\n",
            "Stats - Epoch: 39 AUC-val 0.643  AUC-train 0.994\n",
            "Stats - Epoch: 40 AUC-val 0.624  AUC-train 0.995\n",
            "Stats - Epoch: 41 AUC-val 0.630  AUC-train 0.995\n",
            "Stats - Epoch: 42 AUC-val 0.645  AUC-train 0.996\n",
            "Stats - Epoch: 43 AUC-val 0.649  AUC-train 0.996\n",
            "Stats - Epoch: 44 AUC-val 0.691  AUC-train 0.996\n",
            "Stats - Epoch: 45 AUC-val 0.640  AUC-train 0.994\n",
            "Stats - Epoch: 46 AUC-val 0.642  AUC-train 0.996\n",
            "Stats - Epoch: 47 AUC-val 0.663  AUC-train 0.995\n",
            "Stats - Epoch: 48 AUC-val 0.679  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.643  AUC-train 0.996\n",
            "Stats - Epoch: 50 AUC-val 0.620  AUC-train 0.996\n",
            "Results 50 AUC-val 0.701 0.798 0.524 0.200 0.768 AUC-train 0.688\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.530  AUC-train 0.903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.530 0.425 0.403 0.426 0.734 AUC-train 0.903\n",
            "Shapley [0.02416692 0.00575758 0.01119229 0.02020464 0.01016532] [0.00384114]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.190877\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.363  AUC-train 0.553\n",
            "Stats - Epoch: 2 AUC-val 0.440  AUC-train 0.728\n",
            "Stats - Epoch: 3 AUC-val 0.534  AUC-train 0.815\n",
            "Stats - Epoch: 4 AUC-val 0.496  AUC-train 0.872\n",
            "Stats - Epoch: 5 AUC-val 0.503  AUC-train 0.905\n",
            "Stats - Epoch: 6 AUC-val 0.474  AUC-train 0.930\n",
            "Stats - Epoch: 7 AUC-val 0.489  AUC-train 0.943\n",
            "Stats - Epoch: 8 AUC-val 0.491  AUC-train 0.956\n",
            "Stats - Epoch: 9 AUC-val 0.486  AUC-train 0.961\n",
            "Stats - Epoch: 10 AUC-val 0.512  AUC-train 0.967\n",
            "Stats - Epoch: 11 AUC-val 0.529  AUC-train 0.971\n",
            "Stats - Epoch: 12 AUC-val 0.523  AUC-train 0.972\n",
            "Stats - Epoch: 13 AUC-val 0.510  AUC-train 0.975\n",
            "Stats - Epoch: 14 AUC-val 0.529  AUC-train 0.978\n",
            "Stats - Epoch: 15 AUC-val 0.527  AUC-train 0.979\n",
            "Stats - Epoch: 16 AUC-val 0.534  AUC-train 0.979\n",
            "Stats - Epoch: 17 AUC-val 0.523  AUC-train 0.981\n",
            "Stats - Epoch: 18 AUC-val 0.517  AUC-train 0.983\n",
            "Stats - Epoch: 19 AUC-val 0.513  AUC-train 0.982\n",
            "Stats - Epoch: 20 AUC-val 0.528  AUC-train 0.984\n",
            "Stats - Epoch: 21 AUC-val 0.528  AUC-train 0.982\n",
            "Stats - Epoch: 22 AUC-val 0.512  AUC-train 0.984\n",
            "Stats - Epoch: 23 AUC-val 0.549  AUC-train 0.981\n",
            "Stats - Epoch: 24 AUC-val 0.507  AUC-train 0.985\n",
            "Stats - Epoch: 25 AUC-val 0.514  AUC-train 0.983\n",
            "Stats - Epoch: 26 AUC-val 0.543  AUC-train 0.980\n",
            "Stats - Epoch: 27 AUC-val 0.559  AUC-train 0.981\n",
            "Stats - Epoch: 28 AUC-val 0.532  AUC-train 0.982\n",
            "Stats - Epoch: 29 AUC-val 0.548  AUC-train 0.984\n",
            "Stats - Epoch: 30 AUC-val 0.541  AUC-train 0.983\n",
            "Stats - Epoch: 31 AUC-val 0.535  AUC-train 0.984\n",
            "Stats - Epoch: 32 AUC-val 0.551  AUC-train 0.986\n",
            "Stats - Epoch: 33 AUC-val 0.530  AUC-train 0.984\n",
            "Stats - Epoch: 34 AUC-val 0.549  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.526  AUC-train 0.984\n",
            "Stats - Epoch: 36 AUC-val 0.537  AUC-train 0.983\n",
            "Stats - Epoch: 37 AUC-val 0.550  AUC-train 0.984\n",
            "Stats - Epoch: 38 AUC-val 0.540  AUC-train 0.985\n",
            "Stats - Epoch: 39 AUC-val 0.538  AUC-train 0.985\n",
            "Stats - Epoch: 40 AUC-val 0.539  AUC-train 0.984\n",
            "Stats - Epoch: 41 AUC-val 0.538  AUC-train 0.981\n",
            "Stats - Epoch: 42 AUC-val 0.543  AUC-train 0.984\n",
            "Stats - Epoch: 43 AUC-val 0.543  AUC-train 0.984\n",
            "Stats - Epoch: 44 AUC-val 0.539  AUC-train 0.982\n",
            "Stats - Epoch: 45 AUC-val 0.532  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.548  AUC-train 0.984\n",
            "Stats - Epoch: 47 AUC-val 0.540  AUC-train 0.985\n",
            "Stats - Epoch: 48 AUC-val 0.523  AUC-train 0.984\n",
            "Stats - Epoch: 49 AUC-val 0.549  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.541  AUC-train 0.985\n",
            "Results 50 AUC-val 0.559 0.509 0.453 0.169 0.520 AUC-train 0.981\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.233  AUC-train 0.580\n",
            "Stats - Epoch: 2 AUC-val 0.202  AUC-train 0.621\n",
            "Stats - Epoch: 3 AUC-val 0.198  AUC-train 0.675\n",
            "Stats - Epoch: 4 AUC-val 0.221  AUC-train 0.720\n",
            "Stats - Epoch: 5 AUC-val 0.302  AUC-train 0.758\n",
            "Stats - Epoch: 6 AUC-val 0.326  AUC-train 0.788\n",
            "Stats - Epoch: 7 AUC-val 0.370  AUC-train 0.806\n",
            "Stats - Epoch: 8 AUC-val 0.481  AUC-train 0.825\n",
            "Stats - Epoch: 9 AUC-val 0.438  AUC-train 0.838\n",
            "Stats - Epoch: 10 AUC-val 0.531  AUC-train 0.842\n",
            "Stats - Epoch: 11 AUC-val 0.614  AUC-train 0.850\n",
            "Stats - Epoch: 12 AUC-val 0.552  AUC-train 0.854\n",
            "Stats - Epoch: 13 AUC-val 0.572  AUC-train 0.854\n",
            "Stats - Epoch: 14 AUC-val 0.601  AUC-train 0.862\n",
            "Stats - Epoch: 15 AUC-val 0.580  AUC-train 0.863\n",
            "Stats - Epoch: 16 AUC-val 0.569  AUC-train 0.868\n",
            "Stats - Epoch: 17 AUC-val 0.568  AUC-train 0.875\n",
            "Stats - Epoch: 18 AUC-val 0.612  AUC-train 0.879\n",
            "Stats - Epoch: 19 AUC-val 0.592  AUC-train 0.881\n",
            "Stats - Epoch: 20 AUC-val 0.579  AUC-train 0.885\n",
            "Stats - Epoch: 21 AUC-val 0.558  AUC-train 0.884\n",
            "Stats - Epoch: 22 AUC-val 0.572  AUC-train 0.885\n",
            "Stats - Epoch: 23 AUC-val 0.624  AUC-train 0.888\n",
            "Stats - Epoch: 24 AUC-val 0.571  AUC-train 0.888\n",
            "Stats - Epoch: 25 AUC-val 0.600  AUC-train 0.893\n",
            "Stats - Epoch: 26 AUC-val 0.586  AUC-train 0.897\n",
            "Stats - Epoch: 27 AUC-val 0.593  AUC-train 0.898\n",
            "Stats - Epoch: 28 AUC-val 0.577  AUC-train 0.895\n",
            "Stats - Epoch: 29 AUC-val 0.580  AUC-train 0.901\n",
            "Stats - Epoch: 30 AUC-val 0.633  AUC-train 0.903\n",
            "Stats - Epoch: 31 AUC-val 0.597  AUC-train 0.903\n",
            "Stats - Epoch: 32 AUC-val 0.592  AUC-train 0.902\n",
            "Stats - Epoch: 33 AUC-val 0.611  AUC-train 0.907\n",
            "Stats - Epoch: 34 AUC-val 0.557  AUC-train 0.908\n",
            "Stats - Epoch: 35 AUC-val 0.605  AUC-train 0.907\n",
            "Stats - Epoch: 36 AUC-val 0.586  AUC-train 0.911\n",
            "Stats - Epoch: 37 AUC-val 0.591  AUC-train 0.915\n",
            "Stats - Epoch: 38 AUC-val 0.582  AUC-train 0.912\n",
            "Stats - Epoch: 39 AUC-val 0.603  AUC-train 0.912\n",
            "Stats - Epoch: 40 AUC-val 0.629  AUC-train 0.915\n",
            "Stats - Epoch: 41 AUC-val 0.582  AUC-train 0.917\n",
            "Stats - Epoch: 42 AUC-val 0.593  AUC-train 0.916\n",
            "Stats - Epoch: 43 AUC-val 0.626  AUC-train 0.920\n",
            "Stats - Epoch: 44 AUC-val 0.578  AUC-train 0.919\n",
            "Stats - Epoch: 45 AUC-val 0.616  AUC-train 0.918\n",
            "Stats - Epoch: 46 AUC-val 0.595  AUC-train 0.919\n",
            "Stats - Epoch: 47 AUC-val 0.637  AUC-train 0.921\n",
            "Stats - Epoch: 48 AUC-val 0.630  AUC-train 0.924\n",
            "Stats - Epoch: 49 AUC-val 0.592  AUC-train 0.923\n",
            "Stats - Epoch: 50 AUC-val 0.616  AUC-train 0.923\n",
            "Results 50 AUC-val 0.637 0.643 0.612 0.531 0.678 AUC-train 0.921\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.631  AUC-train 0.533\n",
            "Stats - Epoch: 2 AUC-val 0.769  AUC-train 0.719\n",
            "Stats - Epoch: 3 AUC-val 0.754  AUC-train 0.805\n",
            "Stats - Epoch: 4 AUC-val 0.747  AUC-train 0.845\n",
            "Stats - Epoch: 5 AUC-val 0.736  AUC-train 0.873\n",
            "Stats - Epoch: 6 AUC-val 0.752  AUC-train 0.899\n",
            "Stats - Epoch: 7 AUC-val 0.741  AUC-train 0.916\n",
            "Stats - Epoch: 8 AUC-val 0.740  AUC-train 0.933\n",
            "Stats - Epoch: 9 AUC-val 0.748  AUC-train 0.946\n",
            "Stats - Epoch: 10 AUC-val 0.739  AUC-train 0.955\n",
            "Stats - Epoch: 11 AUC-val 0.746  AUC-train 0.961\n",
            "Stats - Epoch: 12 AUC-val 0.712  AUC-train 0.967\n",
            "Stats - Epoch: 13 AUC-val 0.731  AUC-train 0.975\n",
            "Stats - Epoch: 14 AUC-val 0.689  AUC-train 0.977\n",
            "Stats - Epoch: 15 AUC-val 0.683  AUC-train 0.984\n",
            "Stats - Epoch: 16 AUC-val 0.658  AUC-train 0.987\n",
            "Stats - Epoch: 17 AUC-val 0.654  AUC-train 0.989\n",
            "Stats - Epoch: 18 AUC-val 0.664  AUC-train 0.992\n",
            "Stats - Epoch: 19 AUC-val 0.645  AUC-train 0.992\n",
            "Stats - Epoch: 20 AUC-val 0.648  AUC-train 0.993\n",
            "Stats - Epoch: 21 AUC-val 0.654  AUC-train 0.994\n",
            "Stats - Epoch: 22 AUC-val 0.650  AUC-train 0.995\n",
            "Stats - Epoch: 23 AUC-val 0.656  AUC-train 0.995\n",
            "Stats - Epoch: 24 AUC-val 0.642  AUC-train 0.997\n",
            "Stats - Epoch: 25 AUC-val 0.645  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.617  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.631  AUC-train 0.998\n",
            "Stats - Epoch: 28 AUC-val 0.611  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.619  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.640  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.627  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.597  AUC-train 0.998\n",
            "Stats - Epoch: 33 AUC-val 0.638  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.611  AUC-train 0.997\n",
            "Stats - Epoch: 35 AUC-val 0.648  AUC-train 0.997\n",
            "Stats - Epoch: 36 AUC-val 0.640  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.612  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.614  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.609  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.625  AUC-train 1.000\n",
            "Stats - Epoch: 41 AUC-val 0.612  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.627  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.558  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.545  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.597  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.593  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.583  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.636  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.625  AUC-train 0.998\n",
            "Results 50 AUC-val 0.769 0.493 0.276 0.378 0.589 AUC-train 0.719\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.779  AUC-train 0.456\n",
            "Stats - Epoch: 2 AUC-val 0.870  AUC-train 0.613\n",
            "Stats - Epoch: 3 AUC-val 0.851  AUC-train 0.736\n",
            "Stats - Epoch: 4 AUC-val 0.819  AUC-train 0.800\n",
            "Stats - Epoch: 5 AUC-val 0.788  AUC-train 0.831\n",
            "Stats - Epoch: 6 AUC-val 0.771  AUC-train 0.855\n",
            "Stats - Epoch: 7 AUC-val 0.751  AUC-train 0.873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.732  AUC-train 0.889\n",
            "Stats - Epoch: 9 AUC-val 0.714  AUC-train 0.904\n",
            "Stats - Epoch: 10 AUC-val 0.708  AUC-train 0.920\n",
            "Stats - Epoch: 11 AUC-val 0.681  AUC-train 0.930\n",
            "Stats - Epoch: 12 AUC-val 0.684  AUC-train 0.936\n",
            "Stats - Epoch: 13 AUC-val 0.691  AUC-train 0.948\n",
            "Stats - Epoch: 14 AUC-val 0.663  AUC-train 0.956\n",
            "Stats - Epoch: 15 AUC-val 0.642  AUC-train 0.961\n",
            "Stats - Epoch: 16 AUC-val 0.656  AUC-train 0.968\n",
            "Stats - Epoch: 17 AUC-val 0.650  AUC-train 0.973\n",
            "Stats - Epoch: 18 AUC-val 0.609  AUC-train 0.974\n",
            "Stats - Epoch: 19 AUC-val 0.625  AUC-train 0.979\n",
            "Stats - Epoch: 20 AUC-val 0.610  AUC-train 0.981\n",
            "Stats - Epoch: 21 AUC-val 0.563  AUC-train 0.984\n",
            "Stats - Epoch: 22 AUC-val 0.580  AUC-train 0.987\n",
            "Stats - Epoch: 23 AUC-val 0.588  AUC-train 0.989\n",
            "Stats - Epoch: 24 AUC-val 0.593  AUC-train 0.989\n",
            "Stats - Epoch: 25 AUC-val 0.605  AUC-train 0.988\n",
            "Stats - Epoch: 26 AUC-val 0.603  AUC-train 0.989\n",
            "Stats - Epoch: 27 AUC-val 0.595  AUC-train 0.991\n",
            "Stats - Epoch: 28 AUC-val 0.580  AUC-train 0.993\n",
            "Stats - Epoch: 29 AUC-val 0.553  AUC-train 0.993\n",
            "Stats - Epoch: 30 AUC-val 0.555  AUC-train 0.996\n",
            "Stats - Epoch: 31 AUC-val 0.568  AUC-train 0.995\n",
            "Stats - Epoch: 32 AUC-val 0.542  AUC-train 0.995\n",
            "Stats - Epoch: 33 AUC-val 0.553  AUC-train 0.996\n",
            "Stats - Epoch: 34 AUC-val 0.555  AUC-train 0.996\n",
            "Stats - Epoch: 35 AUC-val 0.571  AUC-train 0.995\n",
            "Stats - Epoch: 36 AUC-val 0.565  AUC-train 0.996\n",
            "Stats - Epoch: 37 AUC-val 0.573  AUC-train 0.997\n",
            "Stats - Epoch: 38 AUC-val 0.553  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.547  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.572  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.588  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.582  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.591  AUC-train 0.994\n",
            "Stats - Epoch: 44 AUC-val 0.571  AUC-train 0.996\n",
            "Stats - Epoch: 45 AUC-val 0.561  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.578  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.581  AUC-train 0.997\n",
            "Stats - Epoch: 48 AUC-val 0.558  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.598  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.588  AUC-train 0.997\n",
            "Results 50 AUC-val 0.870 0.573 0.301 0.278 0.450 AUC-train 0.613\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.214  AUC-train 0.565\n",
            "Stats - Epoch: 2 AUC-val 0.275  AUC-train 0.752\n",
            "Stats - Epoch: 3 AUC-val 0.275  AUC-train 0.837\n",
            "Stats - Epoch: 4 AUC-val 0.309  AUC-train 0.885\n",
            "Stats - Epoch: 5 AUC-val 0.322  AUC-train 0.917\n",
            "Stats - Epoch: 6 AUC-val 0.322  AUC-train 0.941\n",
            "Stats - Epoch: 7 AUC-val 0.320  AUC-train 0.950\n",
            "Stats - Epoch: 8 AUC-val 0.349  AUC-train 0.952\n",
            "Stats - Epoch: 9 AUC-val 0.351  AUC-train 0.964\n",
            "Stats - Epoch: 10 AUC-val 0.359  AUC-train 0.970\n",
            "Stats - Epoch: 11 AUC-val 0.376  AUC-train 0.974\n",
            "Stats - Epoch: 12 AUC-val 0.372  AUC-train 0.981\n",
            "Stats - Epoch: 13 AUC-val 0.376  AUC-train 0.980\n",
            "Stats - Epoch: 14 AUC-val 0.397  AUC-train 0.982\n",
            "Stats - Epoch: 15 AUC-val 0.371  AUC-train 0.985\n",
            "Stats - Epoch: 16 AUC-val 0.401  AUC-train 0.986\n",
            "Stats - Epoch: 17 AUC-val 0.402  AUC-train 0.980\n",
            "Stats - Epoch: 18 AUC-val 0.400  AUC-train 0.984\n",
            "Stats - Epoch: 19 AUC-val 0.399  AUC-train 0.987\n",
            "Stats - Epoch: 20 AUC-val 0.387  AUC-train 0.984\n",
            "Stats - Epoch: 21 AUC-val 0.388  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.409  AUC-train 0.982\n",
            "Stats - Epoch: 23 AUC-val 0.389  AUC-train 0.982\n",
            "Stats - Epoch: 24 AUC-val 0.413  AUC-train 0.987\n",
            "Stats - Epoch: 25 AUC-val 0.398  AUC-train 0.985\n",
            "Stats - Epoch: 26 AUC-val 0.440  AUC-train 0.985\n",
            "Stats - Epoch: 27 AUC-val 0.431  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.409  AUC-train 0.984\n",
            "Stats - Epoch: 29 AUC-val 0.407  AUC-train 0.986\n",
            "Stats - Epoch: 30 AUC-val 0.429  AUC-train 0.987\n",
            "Stats - Epoch: 31 AUC-val 0.427  AUC-train 0.991\n",
            "Stats - Epoch: 32 AUC-val 0.421  AUC-train 0.988\n",
            "Stats - Epoch: 33 AUC-val 0.395  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.422  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.445  AUC-train 0.985\n",
            "Stats - Epoch: 36 AUC-val 0.419  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.433  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.452  AUC-train 0.986\n",
            "Stats - Epoch: 39 AUC-val 0.432  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 41 AUC-val 0.422  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.438  AUC-train 0.981\n",
            "Stats - Epoch: 43 AUC-val 0.415  AUC-train 0.977\n",
            "Stats - Epoch: 44 AUC-val 0.416  AUC-train 0.985\n",
            "Stats - Epoch: 45 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.414  AUC-train 0.986\n",
            "Stats - Epoch: 47 AUC-val 0.436  AUC-train 0.983\n",
            "Stats - Epoch: 48 AUC-val 0.462  AUC-train 0.982\n",
            "Stats - Epoch: 49 AUC-val 0.443  AUC-train 0.981\n",
            "Stats - Epoch: 50 AUC-val 0.426  AUC-train 0.981\n",
            "Results 50 AUC-val 0.462 0.423 0.372 0.178 0.523 AUC-train 0.982\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.210  AUC-train 0.592\n",
            "Stats - Epoch: 2 AUC-val 0.188  AUC-train 0.618\n",
            "Stats - Epoch: 3 AUC-val 0.217  AUC-train 0.680\n",
            "Stats - Epoch: 4 AUC-val 0.245  AUC-train 0.729\n",
            "Stats - Epoch: 5 AUC-val 0.322  AUC-train 0.764\n",
            "Stats - Epoch: 6 AUC-val 0.319  AUC-train 0.788\n",
            "Stats - Epoch: 7 AUC-val 0.410  AUC-train 0.806\n",
            "Stats - Epoch: 8 AUC-val 0.452  AUC-train 0.815\n",
            "Stats - Epoch: 9 AUC-val 0.480  AUC-train 0.826\n",
            "Stats - Epoch: 10 AUC-val 0.467  AUC-train 0.838\n",
            "Stats - Epoch: 11 AUC-val 0.565  AUC-train 0.843\n",
            "Stats - Epoch: 12 AUC-val 0.505  AUC-train 0.850\n",
            "Stats - Epoch: 13 AUC-val 0.550  AUC-train 0.853\n",
            "Stats - Epoch: 14 AUC-val 0.555  AUC-train 0.858\n",
            "Stats - Epoch: 15 AUC-val 0.549  AUC-train 0.857\n",
            "Stats - Epoch: 16 AUC-val 0.568  AUC-train 0.860\n",
            "Stats - Epoch: 17 AUC-val 0.552  AUC-train 0.865\n",
            "Stats - Epoch: 18 AUC-val 0.539  AUC-train 0.868\n",
            "Stats - Epoch: 19 AUC-val 0.552  AUC-train 0.867\n",
            "Stats - Epoch: 20 AUC-val 0.571  AUC-train 0.874\n",
            "Stats - Epoch: 21 AUC-val 0.574  AUC-train 0.874\n",
            "Stats - Epoch: 22 AUC-val 0.566  AUC-train 0.876\n",
            "Stats - Epoch: 23 AUC-val 0.557  AUC-train 0.881\n",
            "Stats - Epoch: 24 AUC-val 0.564  AUC-train 0.879\n",
            "Stats - Epoch: 25 AUC-val 0.589  AUC-train 0.881\n",
            "Stats - Epoch: 26 AUC-val 0.597  AUC-train 0.884\n",
            "Stats - Epoch: 27 AUC-val 0.579  AUC-train 0.885\n",
            "Stats - Epoch: 28 AUC-val 0.593  AUC-train 0.885\n",
            "Stats - Epoch: 29 AUC-val 0.562  AUC-train 0.889\n",
            "Stats - Epoch: 30 AUC-val 0.590  AUC-train 0.887\n",
            "Stats - Epoch: 31 AUC-val 0.591  AUC-train 0.892\n",
            "Stats - Epoch: 32 AUC-val 0.582  AUC-train 0.896\n",
            "Stats - Epoch: 33 AUC-val 0.575  AUC-train 0.897\n",
            "Stats - Epoch: 34 AUC-val 0.599  AUC-train 0.897\n",
            "Stats - Epoch: 35 AUC-val 0.589  AUC-train 0.898\n",
            "Stats - Epoch: 36 AUC-val 0.582  AUC-train 0.899\n",
            "Stats - Epoch: 37 AUC-val 0.588  AUC-train 0.897\n",
            "Stats - Epoch: 38 AUC-val 0.603  AUC-train 0.901\n",
            "Stats - Epoch: 39 AUC-val 0.599  AUC-train 0.898\n",
            "Stats - Epoch: 40 AUC-val 0.606  AUC-train 0.903\n",
            "Stats - Epoch: 41 AUC-val 0.621  AUC-train 0.902\n",
            "Stats - Epoch: 42 AUC-val 0.598  AUC-train 0.906\n",
            "Stats - Epoch: 43 AUC-val 0.602  AUC-train 0.906\n",
            "Stats - Epoch: 44 AUC-val 0.600  AUC-train 0.909\n",
            "Stats - Epoch: 45 AUC-val 0.604  AUC-train 0.912\n",
            "Stats - Epoch: 46 AUC-val 0.603  AUC-train 0.913\n",
            "Stats - Epoch: 47 AUC-val 0.603  AUC-train 0.913\n",
            "Stats - Epoch: 48 AUC-val 0.598  AUC-train 0.916\n",
            "Stats - Epoch: 49 AUC-val 0.631  AUC-train 0.916\n",
            "Stats - Epoch: 50 AUC-val 0.588  AUC-train 0.916\n",
            "Results 50 AUC-val 0.631 0.621 0.599 0.527 0.619 AUC-train 0.916\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.376  AUC-train 0.574\n",
            "Stats - Epoch: 2 AUC-val 0.488  AUC-train 0.736\n",
            "Stats - Epoch: 3 AUC-val 0.603  AUC-train 0.808\n",
            "Stats - Epoch: 4 AUC-val 0.639  AUC-train 0.844\n",
            "Stats - Epoch: 5 AUC-val 0.653  AUC-train 0.867\n",
            "Stats - Epoch: 6 AUC-val 0.678  AUC-train 0.887\n",
            "Stats - Epoch: 7 AUC-val 0.690  AUC-train 0.903\n",
            "Stats - Epoch: 8 AUC-val 0.683  AUC-train 0.919\n",
            "Stats - Epoch: 9 AUC-val 0.702  AUC-train 0.930\n",
            "Stats - Epoch: 10 AUC-val 0.716  AUC-train 0.939\n",
            "Stats - Epoch: 11 AUC-val 0.719  AUC-train 0.949\n",
            "Stats - Epoch: 12 AUC-val 0.721  AUC-train 0.956\n",
            "Stats - Epoch: 13 AUC-val 0.723  AUC-train 0.964\n",
            "Stats - Epoch: 14 AUC-val 0.733  AUC-train 0.967\n",
            "Stats - Epoch: 15 AUC-val 0.721  AUC-train 0.974\n",
            "Stats - Epoch: 16 AUC-val 0.716  AUC-train 0.979\n",
            "Stats - Epoch: 17 AUC-val 0.710  AUC-train 0.982\n",
            "Stats - Epoch: 18 AUC-val 0.709  AUC-train 0.982\n",
            "Stats - Epoch: 19 AUC-val 0.680  AUC-train 0.985\n",
            "Stats - Epoch: 20 AUC-val 0.720  AUC-train 0.985\n",
            "Stats - Epoch: 21 AUC-val 0.737  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.716  AUC-train 0.990\n",
            "Stats - Epoch: 23 AUC-val 0.748  AUC-train 0.992\n",
            "Stats - Epoch: 24 AUC-val 0.730  AUC-train 0.993\n",
            "Stats - Epoch: 25 AUC-val 0.707  AUC-train 0.992\n",
            "Stats - Epoch: 26 AUC-val 0.742  AUC-train 0.994\n",
            "Stats - Epoch: 27 AUC-val 0.717  AUC-train 0.996\n",
            "Stats - Epoch: 28 AUC-val 0.722  AUC-train 0.996\n",
            "Stats - Epoch: 29 AUC-val 0.704  AUC-train 0.995\n",
            "Stats - Epoch: 30 AUC-val 0.715  AUC-train 0.996\n",
            "Stats - Epoch: 31 AUC-val 0.708  AUC-train 0.996\n",
            "Stats - Epoch: 32 AUC-val 0.714  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.701  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.709  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.718  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.736  AUC-train 0.997\n",
            "Stats - Epoch: 37 AUC-val 0.696  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.702  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.717  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.695  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.697  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.722  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.701  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.704  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.694  AUC-train 0.996\n",
            "Stats - Epoch: 47 AUC-val 0.684  AUC-train 0.997\n",
            "Stats - Epoch: 48 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 49 AUC-val 0.686  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.701  AUC-train 0.998\n",
            "Results 50 AUC-val 0.748 0.626 0.499 0.446 0.578 AUC-train 0.992\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.488  AUC-train 0.494\n",
            "Stats - Epoch: 2 AUC-val 0.547  AUC-train 0.666\n",
            "Stats - Epoch: 3 AUC-val 0.600  AUC-train 0.753\n",
            "Stats - Epoch: 4 AUC-val 0.603  AUC-train 0.796\n",
            "Stats - Epoch: 5 AUC-val 0.613  AUC-train 0.829\n",
            "Stats - Epoch: 6 AUC-val 0.610  AUC-train 0.848\n",
            "Stats - Epoch: 7 AUC-val 0.622  AUC-train 0.865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.594  AUC-train 0.878\n",
            "Stats - Epoch: 9 AUC-val 0.607  AUC-train 0.888\n",
            "Stats - Epoch: 10 AUC-val 0.606  AUC-train 0.900\n",
            "Stats - Epoch: 11 AUC-val 0.605  AUC-train 0.909\n",
            "Stats - Epoch: 12 AUC-val 0.600  AUC-train 0.918\n",
            "Stats - Epoch: 13 AUC-val 0.614  AUC-train 0.923\n",
            "Stats - Epoch: 14 AUC-val 0.602  AUC-train 0.930\n",
            "Stats - Epoch: 15 AUC-val 0.614  AUC-train 0.938\n",
            "Stats - Epoch: 16 AUC-val 0.598  AUC-train 0.946\n",
            "Stats - Epoch: 17 AUC-val 0.648  AUC-train 0.953\n",
            "Stats - Epoch: 18 AUC-val 0.663  AUC-train 0.954\n",
            "Stats - Epoch: 19 AUC-val 0.609  AUC-train 0.960\n",
            "Stats - Epoch: 20 AUC-val 0.634  AUC-train 0.967\n",
            "Stats - Epoch: 21 AUC-val 0.626  AUC-train 0.968\n",
            "Stats - Epoch: 22 AUC-val 0.613  AUC-train 0.972\n",
            "Stats - Epoch: 23 AUC-val 0.621  AUC-train 0.977\n",
            "Stats - Epoch: 24 AUC-val 0.606  AUC-train 0.979\n",
            "Stats - Epoch: 25 AUC-val 0.616  AUC-train 0.981\n",
            "Stats - Epoch: 26 AUC-val 0.622  AUC-train 0.982\n",
            "Stats - Epoch: 27 AUC-val 0.633  AUC-train 0.984\n",
            "Stats - Epoch: 28 AUC-val 0.643  AUC-train 0.980\n",
            "Stats - Epoch: 29 AUC-val 0.616  AUC-train 0.985\n",
            "Stats - Epoch: 30 AUC-val 0.674  AUC-train 0.987\n",
            "Stats - Epoch: 31 AUC-val 0.632  AUC-train 0.988\n",
            "Stats - Epoch: 32 AUC-val 0.659  AUC-train 0.990\n",
            "Stats - Epoch: 33 AUC-val 0.659  AUC-train 0.991\n",
            "Stats - Epoch: 34 AUC-val 0.659  AUC-train 0.991\n",
            "Stats - Epoch: 35 AUC-val 0.661  AUC-train 0.989\n",
            "Stats - Epoch: 36 AUC-val 0.665  AUC-train 0.991\n",
            "Stats - Epoch: 37 AUC-val 0.673  AUC-train 0.991\n",
            "Stats - Epoch: 38 AUC-val 0.674  AUC-train 0.990\n",
            "Stats - Epoch: 39 AUC-val 0.675  AUC-train 0.992\n",
            "Stats - Epoch: 40 AUC-val 0.658  AUC-train 0.993\n",
            "Stats - Epoch: 41 AUC-val 0.686  AUC-train 0.994\n",
            "Stats - Epoch: 42 AUC-val 0.671  AUC-train 0.992\n",
            "Stats - Epoch: 43 AUC-val 0.655  AUC-train 0.992\n",
            "Stats - Epoch: 44 AUC-val 0.695  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.643  AUC-train 0.992\n",
            "Stats - Epoch: 46 AUC-val 0.657  AUC-train 0.994\n",
            "Stats - Epoch: 47 AUC-val 0.626  AUC-train 0.993\n",
            "Stats - Epoch: 48 AUC-val 0.642  AUC-train 0.994\n",
            "Stats - Epoch: 49 AUC-val 0.678  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.690  AUC-train 0.995\n",
            "Results 50 AUC-val 0.695 0.769 0.730 0.513 0.572 AUC-train 0.991\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.229  AUC-train 0.560\n",
            "Stats - Epoch: 2 AUC-val 0.266  AUC-train 0.765\n",
            "Stats - Epoch: 3 AUC-val 0.327  AUC-train 0.856\n",
            "Stats - Epoch: 4 AUC-val 0.330  AUC-train 0.916\n",
            "Stats - Epoch: 5 AUC-val 0.350  AUC-train 0.946\n",
            "Stats - Epoch: 6 AUC-val 0.317  AUC-train 0.960\n",
            "Stats - Epoch: 7 AUC-val 0.318  AUC-train 0.974\n",
            "Stats - Epoch: 8 AUC-val 0.304  AUC-train 0.982\n",
            "Stats - Epoch: 9 AUC-val 0.300  AUC-train 0.985\n",
            "Stats - Epoch: 10 AUC-val 0.322  AUC-train 0.988\n",
            "Stats - Epoch: 11 AUC-val 0.303  AUC-train 0.989\n",
            "Stats - Epoch: 12 AUC-val 0.328  AUC-train 0.991\n",
            "Stats - Epoch: 13 AUC-val 0.297  AUC-train 0.993\n",
            "Stats - Epoch: 14 AUC-val 0.319  AUC-train 0.993\n",
            "Stats - Epoch: 15 AUC-val 0.308  AUC-train 0.993\n",
            "Stats - Epoch: 16 AUC-val 0.326  AUC-train 0.994\n",
            "Stats - Epoch: 17 AUC-val 0.317  AUC-train 0.995\n",
            "Stats - Epoch: 18 AUC-val 0.327  AUC-train 0.994\n",
            "Stats - Epoch: 19 AUC-val 0.336  AUC-train 0.993\n",
            "Stats - Epoch: 20 AUC-val 0.337  AUC-train 0.995\n",
            "Stats - Epoch: 21 AUC-val 0.333  AUC-train 0.992\n",
            "Stats - Epoch: 22 AUC-val 0.333  AUC-train 0.994\n",
            "Stats - Epoch: 23 AUC-val 0.391  AUC-train 0.994\n",
            "Stats - Epoch: 24 AUC-val 0.366  AUC-train 0.994\n",
            "Stats - Epoch: 25 AUC-val 0.351  AUC-train 0.993\n",
            "Stats - Epoch: 26 AUC-val 0.356  AUC-train 0.994\n",
            "Stats - Epoch: 27 AUC-val 0.381  AUC-train 0.993\n",
            "Stats - Epoch: 28 AUC-val 0.366  AUC-train 0.993\n",
            "Stats - Epoch: 29 AUC-val 0.385  AUC-train 0.992\n",
            "Stats - Epoch: 30 AUC-val 0.377  AUC-train 0.994\n",
            "Stats - Epoch: 31 AUC-val 0.387  AUC-train 0.994\n",
            "Stats - Epoch: 32 AUC-val 0.392  AUC-train 0.994\n",
            "Stats - Epoch: 33 AUC-val 0.387  AUC-train 0.994\n",
            "Stats - Epoch: 34 AUC-val 0.403  AUC-train 0.993\n",
            "Stats - Epoch: 35 AUC-val 0.387  AUC-train 0.994\n",
            "Stats - Epoch: 36 AUC-val 0.404  AUC-train 0.994\n",
            "Stats - Epoch: 37 AUC-val 0.402  AUC-train 0.993\n",
            "Stats - Epoch: 38 AUC-val 0.403  AUC-train 0.993\n",
            "Stats - Epoch: 39 AUC-val 0.404  AUC-train 0.995\n",
            "Stats - Epoch: 40 AUC-val 0.393  AUC-train 0.994\n",
            "Stats - Epoch: 41 AUC-val 0.386  AUC-train 0.994\n",
            "Stats - Epoch: 42 AUC-val 0.403  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.404  AUC-train 0.994\n",
            "Stats - Epoch: 44 AUC-val 0.409  AUC-train 0.993\n",
            "Stats - Epoch: 45 AUC-val 0.401  AUC-train 0.994\n",
            "Stats - Epoch: 46 AUC-val 0.400  AUC-train 0.994\n",
            "Stats - Epoch: 47 AUC-val 0.397  AUC-train 0.995\n",
            "Stats - Epoch: 48 AUC-val 0.401  AUC-train 0.992\n",
            "Stats - Epoch: 49 AUC-val 0.399  AUC-train 0.993\n",
            "Stats - Epoch: 50 AUC-val 0.396  AUC-train 0.994\n",
            "Results 50 AUC-val 0.409 0.300 0.514 0.221 0.265 AUC-train 0.993\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.218  AUC-train 0.562\n",
            "Stats - Epoch: 2 AUC-val 0.196  AUC-train 0.605\n",
            "Stats - Epoch: 3 AUC-val 0.198  AUC-train 0.667\n",
            "Stats - Epoch: 4 AUC-val 0.230  AUC-train 0.715\n",
            "Stats - Epoch: 5 AUC-val 0.269  AUC-train 0.759\n",
            "Stats - Epoch: 6 AUC-val 0.326  AUC-train 0.788\n",
            "Stats - Epoch: 7 AUC-val 0.491  AUC-train 0.810\n",
            "Stats - Epoch: 8 AUC-val 0.474  AUC-train 0.829\n",
            "Stats - Epoch: 9 AUC-val 0.493  AUC-train 0.839\n",
            "Stats - Epoch: 10 AUC-val 0.522  AUC-train 0.845\n",
            "Stats - Epoch: 11 AUC-val 0.553  AUC-train 0.854\n",
            "Stats - Epoch: 12 AUC-val 0.562  AUC-train 0.857\n",
            "Stats - Epoch: 13 AUC-val 0.535  AUC-train 0.865\n",
            "Stats - Epoch: 14 AUC-val 0.569  AUC-train 0.868\n",
            "Stats - Epoch: 15 AUC-val 0.555  AUC-train 0.873\n",
            "Stats - Epoch: 16 AUC-val 0.569  AUC-train 0.877\n",
            "Stats - Epoch: 17 AUC-val 0.569  AUC-train 0.878\n",
            "Stats - Epoch: 18 AUC-val 0.600  AUC-train 0.882\n",
            "Stats - Epoch: 19 AUC-val 0.622  AUC-train 0.880\n",
            "Stats - Epoch: 20 AUC-val 0.615  AUC-train 0.887\n",
            "Stats - Epoch: 21 AUC-val 0.628  AUC-train 0.885\n",
            "Stats - Epoch: 22 AUC-val 0.610  AUC-train 0.893\n",
            "Stats - Epoch: 23 AUC-val 0.611  AUC-train 0.894\n",
            "Stats - Epoch: 24 AUC-val 0.623  AUC-train 0.895\n",
            "Stats - Epoch: 25 AUC-val 0.614  AUC-train 0.895\n",
            "Stats - Epoch: 26 AUC-val 0.654  AUC-train 0.900\n",
            "Stats - Epoch: 27 AUC-val 0.616  AUC-train 0.904\n",
            "Stats - Epoch: 28 AUC-val 0.631  AUC-train 0.908\n",
            "Stats - Epoch: 29 AUC-val 0.634  AUC-train 0.906\n",
            "Stats - Epoch: 30 AUC-val 0.616  AUC-train 0.908\n",
            "Stats - Epoch: 31 AUC-val 0.615  AUC-train 0.907\n",
            "Stats - Epoch: 32 AUC-val 0.593  AUC-train 0.913\n",
            "Stats - Epoch: 33 AUC-val 0.616  AUC-train 0.914\n",
            "Stats - Epoch: 34 AUC-val 0.619  AUC-train 0.914\n",
            "Stats - Epoch: 35 AUC-val 0.591  AUC-train 0.918\n",
            "Stats - Epoch: 36 AUC-val 0.602  AUC-train 0.917\n",
            "Stats - Epoch: 37 AUC-val 0.590  AUC-train 0.914\n",
            "Stats - Epoch: 38 AUC-val 0.622  AUC-train 0.917\n",
            "Stats - Epoch: 39 AUC-val 0.627  AUC-train 0.920\n",
            "Stats - Epoch: 40 AUC-val 0.620  AUC-train 0.921\n",
            "Stats - Epoch: 41 AUC-val 0.685  AUC-train 0.920\n",
            "Stats - Epoch: 42 AUC-val 0.624  AUC-train 0.919\n",
            "Stats - Epoch: 43 AUC-val 0.598  AUC-train 0.922\n",
            "Stats - Epoch: 44 AUC-val 0.589  AUC-train 0.923\n",
            "Stats - Epoch: 45 AUC-val 0.612  AUC-train 0.928\n",
            "Stats - Epoch: 46 AUC-val 0.618  AUC-train 0.928\n",
            "Stats - Epoch: 47 AUC-val 0.604  AUC-train 0.926\n",
            "Stats - Epoch: 48 AUC-val 0.628  AUC-train 0.928\n",
            "Stats - Epoch: 49 AUC-val 0.612  AUC-train 0.934\n",
            "Stats - Epoch: 50 AUC-val 0.617  AUC-train 0.935\n",
            "Results 50 AUC-val 0.685 0.655 0.621 0.456 0.543 AUC-train 0.920\n",
            "Crises train:11\n",
            "Crises test:12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 1 AUC-val 0.264  AUC-train 0.538\n",
            "Stats - Epoch: 2 AUC-val 0.364  AUC-train 0.710\n",
            "Stats - Epoch: 3 AUC-val 0.553  AUC-train 0.797\n",
            "Stats - Epoch: 4 AUC-val 0.591  AUC-train 0.829\n",
            "Stats - Epoch: 5 AUC-val 0.605  AUC-train 0.855\n",
            "Stats - Epoch: 6 AUC-val 0.616  AUC-train 0.874\n",
            "Stats - Epoch: 7 AUC-val 0.641  AUC-train 0.891\n",
            "Stats - Epoch: 8 AUC-val 0.651  AUC-train 0.906\n",
            "Stats - Epoch: 9 AUC-val 0.651  AUC-train 0.912\n",
            "Stats - Epoch: 10 AUC-val 0.652  AUC-train 0.922\n",
            "Stats - Epoch: 11 AUC-val 0.666  AUC-train 0.934\n",
            "Stats - Epoch: 12 AUC-val 0.664  AUC-train 0.938\n",
            "Stats - Epoch: 13 AUC-val 0.669  AUC-train 0.945\n",
            "Stats - Epoch: 14 AUC-val 0.683  AUC-train 0.944\n",
            "Stats - Epoch: 15 AUC-val 0.671  AUC-train 0.955\n",
            "Stats - Epoch: 16 AUC-val 0.666  AUC-train 0.962\n",
            "Stats - Epoch: 17 AUC-val 0.669  AUC-train 0.965\n",
            "Stats - Epoch: 18 AUC-val 0.684  AUC-train 0.967\n",
            "Stats - Epoch: 19 AUC-val 0.686  AUC-train 0.970\n",
            "Stats - Epoch: 20 AUC-val 0.667  AUC-train 0.973\n",
            "Stats - Epoch: 21 AUC-val 0.663  AUC-train 0.971\n",
            "Stats - Epoch: 22 AUC-val 0.635  AUC-train 0.972\n",
            "Stats - Epoch: 23 AUC-val 0.667  AUC-train 0.978\n",
            "Stats - Epoch: 24 AUC-val 0.640  AUC-train 0.977\n",
            "Stats - Epoch: 25 AUC-val 0.650  AUC-train 0.977\n",
            "Stats - Epoch: 26 AUC-val 0.644  AUC-train 0.981\n",
            "Stats - Epoch: 27 AUC-val 0.661  AUC-train 0.980\n",
            "Stats - Epoch: 28 AUC-val 0.644  AUC-train 0.984\n",
            "Stats - Epoch: 29 AUC-val 0.635  AUC-train 0.984\n",
            "Stats - Epoch: 30 AUC-val 0.648  AUC-train 0.984\n",
            "Stats - Epoch: 31 AUC-val 0.647  AUC-train 0.986\n",
            "Stats - Epoch: 32 AUC-val 0.669  AUC-train 0.987\n",
            "Stats - Epoch: 33 AUC-val 0.645  AUC-train 0.987\n",
            "Stats - Epoch: 34 AUC-val 0.639  AUC-train 0.986\n",
            "Stats - Epoch: 35 AUC-val 0.643  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.657  AUC-train 0.988\n",
            "Stats - Epoch: 37 AUC-val 0.665  AUC-train 0.988\n",
            "Stats - Epoch: 38 AUC-val 0.634  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.642  AUC-train 0.989\n",
            "Stats - Epoch: 40 AUC-val 0.626  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.621  AUC-train 0.989\n",
            "Stats - Epoch: 42 AUC-val 0.638  AUC-train 0.990\n",
            "Stats - Epoch: 43 AUC-val 0.619  AUC-train 0.990\n",
            "Stats - Epoch: 44 AUC-val 0.625  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.655  AUC-train 0.991\n",
            "Stats - Epoch: 46 AUC-val 0.647  AUC-train 0.991\n",
            "Stats - Epoch: 47 AUC-val 0.645  AUC-train 0.992\n",
            "Stats - Epoch: 48 AUC-val 0.622  AUC-train 0.989\n",
            "Stats - Epoch: 49 AUC-val 0.652  AUC-train 0.988\n",
            "Stats - Epoch: 50 AUC-val 0.620  AUC-train 0.989\n",
            "Results 50 AUC-val 0.686 0.601 0.600 0.545 0.626 AUC-train 0.970\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.310  AUC-train 0.489\n",
            "Stats - Epoch: 2 AUC-val 0.375  AUC-train 0.643\n",
            "Stats - Epoch: 3 AUC-val 0.464  AUC-train 0.730\n",
            "Stats - Epoch: 4 AUC-val 0.509  AUC-train 0.785\n",
            "Stats - Epoch: 5 AUC-val 0.545  AUC-train 0.821\n",
            "Stats - Epoch: 6 AUC-val 0.555  AUC-train 0.841\n",
            "Stats - Epoch: 7 AUC-val 0.570  AUC-train 0.855\n",
            "Stats - Epoch: 8 AUC-val 0.571  AUC-train 0.876\n",
            "Stats - Epoch: 9 AUC-val 0.564  AUC-train 0.883\n",
            "Stats - Epoch: 10 AUC-val 0.592  AUC-train 0.893\n",
            "Stats - Epoch: 11 AUC-val 0.600  AUC-train 0.904\n",
            "Stats - Epoch: 12 AUC-val 0.604  AUC-train 0.911\n",
            "Stats - Epoch: 13 AUC-val 0.612  AUC-train 0.924\n",
            "Stats - Epoch: 14 AUC-val 0.630  AUC-train 0.929\n",
            "Stats - Epoch: 15 AUC-val 0.622  AUC-train 0.934\n",
            "Stats - Epoch: 16 AUC-val 0.616  AUC-train 0.941\n",
            "Stats - Epoch: 17 AUC-val 0.628  AUC-train 0.942\n",
            "Stats - Epoch: 18 AUC-val 0.637  AUC-train 0.950\n",
            "Stats - Epoch: 19 AUC-val 0.629  AUC-train 0.953\n",
            "Stats - Epoch: 20 AUC-val 0.648  AUC-train 0.957\n",
            "Stats - Epoch: 21 AUC-val 0.649  AUC-train 0.959\n",
            "Stats - Epoch: 22 AUC-val 0.664  AUC-train 0.964\n",
            "Stats - Epoch: 23 AUC-val 0.675  AUC-train 0.964\n",
            "Stats - Epoch: 24 AUC-val 0.670  AUC-train 0.969\n",
            "Stats - Epoch: 25 AUC-val 0.673  AUC-train 0.972\n",
            "Stats - Epoch: 26 AUC-val 0.643  AUC-train 0.975\n",
            "Stats - Epoch: 27 AUC-val 0.629  AUC-train 0.976\n",
            "Stats - Epoch: 28 AUC-val 0.684  AUC-train 0.978\n",
            "Stats - Epoch: 29 AUC-val 0.708  AUC-train 0.980\n",
            "Stats - Epoch: 30 AUC-val 0.664  AUC-train 0.983\n",
            "Stats - Epoch: 31 AUC-val 0.673  AUC-train 0.983\n",
            "Stats - Epoch: 32 AUC-val 0.659  AUC-train 0.984\n",
            "Stats - Epoch: 33 AUC-val 0.690  AUC-train 0.984\n",
            "Stats - Epoch: 34 AUC-val 0.683  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.705  AUC-train 0.985\n",
            "Stats - Epoch: 36 AUC-val 0.691  AUC-train 0.986\n",
            "Stats - Epoch: 37 AUC-val 0.728  AUC-train 0.987\n",
            "Stats - Epoch: 38 AUC-val 0.708  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.701  AUC-train 0.990\n",
            "Stats - Epoch: 40 AUC-val 0.687  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.693  AUC-train 0.991\n",
            "Stats - Epoch: 42 AUC-val 0.667  AUC-train 0.990\n",
            "Stats - Epoch: 43 AUC-val 0.695  AUC-train 0.990\n",
            "Stats - Epoch: 44 AUC-val 0.663  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.720  AUC-train 0.992\n",
            "Stats - Epoch: 46 AUC-val 0.726  AUC-train 0.991\n",
            "Stats - Epoch: 47 AUC-val 0.692  AUC-train 0.991\n",
            "Stats - Epoch: 48 AUC-val 0.678  AUC-train 0.991\n",
            "Stats - Epoch: 49 AUC-val 0.682  AUC-train 0.993\n",
            "Stats - Epoch: 50 AUC-val 0.666  AUC-train 0.993\n",
            "Results 50 AUC-val 0.728 0.709 0.627 0.550 0.503 AUC-train 0.987\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.523  AUC-train 0.828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.523 0.555 0.485 0.518 0.686 AUC-train 0.828\n",
            "Shapley [0.01376499 0.00632486 0.02010741 0.01061047 0.00809987] [0.0109057]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184464\n",
            "         Iterations 9\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.160  AUC-train 0.611\n",
            "Stats - Epoch: 2 AUC-val 0.255  AUC-train 0.805\n",
            "Stats - Epoch: 3 AUC-val 0.290  AUC-train 0.892\n",
            "Stats - Epoch: 4 AUC-val 0.304  AUC-train 0.940\n",
            "Stats - Epoch: 5 AUC-val 0.313  AUC-train 0.964\n",
            "Stats - Epoch: 6 AUC-val 0.350  AUC-train 0.979\n",
            "Stats - Epoch: 7 AUC-val 0.373  AUC-train 0.984\n",
            "Stats - Epoch: 8 AUC-val 0.398  AUC-train 0.992\n",
            "Stats - Epoch: 9 AUC-val 0.400  AUC-train 0.993\n",
            "Stats - Epoch: 10 AUC-val 0.375  AUC-train 0.992\n",
            "Stats - Epoch: 11 AUC-val 0.440  AUC-train 0.995\n",
            "Stats - Epoch: 12 AUC-val 0.422  AUC-train 0.995\n",
            "Stats - Epoch: 13 AUC-val 0.436  AUC-train 0.996\n",
            "Stats - Epoch: 14 AUC-val 0.434  AUC-train 0.996\n",
            "Stats - Epoch: 15 AUC-val 0.421  AUC-train 0.995\n",
            "Stats - Epoch: 16 AUC-val 0.439  AUC-train 0.996\n",
            "Stats - Epoch: 17 AUC-val 0.430  AUC-train 0.996\n",
            "Stats - Epoch: 18 AUC-val 0.448  AUC-train 0.996\n",
            "Stats - Epoch: 19 AUC-val 0.428  AUC-train 0.995\n",
            "Stats - Epoch: 20 AUC-val 0.471  AUC-train 0.997\n",
            "Stats - Epoch: 21 AUC-val 0.433  AUC-train 0.997\n",
            "Stats - Epoch: 22 AUC-val 0.471  AUC-train 0.995\n",
            "Stats - Epoch: 23 AUC-val 0.455  AUC-train 0.995\n",
            "Stats - Epoch: 24 AUC-val 0.454  AUC-train 0.995\n",
            "Stats - Epoch: 25 AUC-val 0.478  AUC-train 0.995\n",
            "Stats - Epoch: 26 AUC-val 0.471  AUC-train 0.996\n",
            "Stats - Epoch: 27 AUC-val 0.461  AUC-train 0.995\n",
            "Stats - Epoch: 28 AUC-val 0.457  AUC-train 0.996\n",
            "Stats - Epoch: 29 AUC-val 0.479  AUC-train 0.995\n",
            "Stats - Epoch: 30 AUC-val 0.472  AUC-train 0.995\n",
            "Stats - Epoch: 31 AUC-val 0.474  AUC-train 0.997\n",
            "Stats - Epoch: 32 AUC-val 0.476  AUC-train 0.996\n",
            "Stats - Epoch: 33 AUC-val 0.475  AUC-train 0.996\n",
            "Stats - Epoch: 34 AUC-val 0.481  AUC-train 0.997\n",
            "Stats - Epoch: 35 AUC-val 0.480  AUC-train 0.997\n",
            "Stats - Epoch: 36 AUC-val 0.482  AUC-train 0.995\n",
            "Stats - Epoch: 37 AUC-val 0.460  AUC-train 0.995\n",
            "Stats - Epoch: 38 AUC-val 0.487  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.482  AUC-train 0.996\n",
            "Stats - Epoch: 40 AUC-val 0.478  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.497  AUC-train 0.995\n",
            "Stats - Epoch: 42 AUC-val 0.465  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.472  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.496  AUC-train 0.996\n",
            "Stats - Epoch: 45 AUC-val 0.493  AUC-train 0.995\n",
            "Stats - Epoch: 46 AUC-val 0.475  AUC-train 0.994\n",
            "Stats - Epoch: 47 AUC-val 0.498  AUC-train 0.995\n",
            "Stats - Epoch: 48 AUC-val 0.473  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.497  AUC-train 0.996\n",
            "Stats - Epoch: 50 AUC-val 0.515  AUC-train 0.993\n",
            "Results 50 AUC-val 0.515 0.284 0.522 0.213 0.281 AUC-train 0.993\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.235  AUC-train 0.562\n",
            "Stats - Epoch: 2 AUC-val 0.208  AUC-train 0.607\n",
            "Stats - Epoch: 3 AUC-val 0.214  AUC-train 0.679\n",
            "Stats - Epoch: 4 AUC-val 0.252  AUC-train 0.734\n",
            "Stats - Epoch: 5 AUC-val 0.325  AUC-train 0.770\n",
            "Stats - Epoch: 6 AUC-val 0.369  AUC-train 0.796\n",
            "Stats - Epoch: 7 AUC-val 0.449  AUC-train 0.815\n",
            "Stats - Epoch: 8 AUC-val 0.509  AUC-train 0.831\n",
            "Stats - Epoch: 9 AUC-val 0.519  AUC-train 0.839\n",
            "Stats - Epoch: 10 AUC-val 0.527  AUC-train 0.846\n",
            "Stats - Epoch: 11 AUC-val 0.589  AUC-train 0.849\n",
            "Stats - Epoch: 12 AUC-val 0.562  AUC-train 0.857\n",
            "Stats - Epoch: 13 AUC-val 0.585  AUC-train 0.862\n",
            "Stats - Epoch: 14 AUC-val 0.569  AUC-train 0.862\n",
            "Stats - Epoch: 15 AUC-val 0.562  AUC-train 0.872\n",
            "Stats - Epoch: 16 AUC-val 0.582  AUC-train 0.875\n",
            "Stats - Epoch: 17 AUC-val 0.571  AUC-train 0.878\n",
            "Stats - Epoch: 18 AUC-val 0.617  AUC-train 0.879\n",
            "Stats - Epoch: 19 AUC-val 0.614  AUC-train 0.878\n",
            "Stats - Epoch: 20 AUC-val 0.609  AUC-train 0.883\n",
            "Stats - Epoch: 21 AUC-val 0.633  AUC-train 0.879\n",
            "Stats - Epoch: 22 AUC-val 0.607  AUC-train 0.888\n",
            "Stats - Epoch: 23 AUC-val 0.636  AUC-train 0.894\n",
            "Stats - Epoch: 24 AUC-val 0.692  AUC-train 0.895\n",
            "Stats - Epoch: 25 AUC-val 0.647  AUC-train 0.901\n",
            "Stats - Epoch: 26 AUC-val 0.634  AUC-train 0.902\n",
            "Stats - Epoch: 27 AUC-val 0.619  AUC-train 0.906\n",
            "Stats - Epoch: 28 AUC-val 0.619  AUC-train 0.907\n",
            "Stats - Epoch: 29 AUC-val 0.638  AUC-train 0.906\n",
            "Stats - Epoch: 30 AUC-val 0.636  AUC-train 0.910\n",
            "Stats - Epoch: 31 AUC-val 0.614  AUC-train 0.914\n",
            "Stats - Epoch: 32 AUC-val 0.617  AUC-train 0.916\n",
            "Stats - Epoch: 33 AUC-val 0.633  AUC-train 0.918\n",
            "Stats - Epoch: 34 AUC-val 0.630  AUC-train 0.919\n",
            "Stats - Epoch: 35 AUC-val 0.638  AUC-train 0.918\n",
            "Stats - Epoch: 36 AUC-val 0.646  AUC-train 0.915\n",
            "Stats - Epoch: 37 AUC-val 0.661  AUC-train 0.916\n",
            "Stats - Epoch: 38 AUC-val 0.652  AUC-train 0.920\n",
            "Stats - Epoch: 39 AUC-val 0.651  AUC-train 0.923\n",
            "Stats - Epoch: 40 AUC-val 0.633  AUC-train 0.923\n",
            "Stats - Epoch: 41 AUC-val 0.643  AUC-train 0.925\n",
            "Stats - Epoch: 42 AUC-val 0.693  AUC-train 0.924\n",
            "Stats - Epoch: 43 AUC-val 0.668  AUC-train 0.923\n",
            "Stats - Epoch: 44 AUC-val 0.685  AUC-train 0.926\n",
            "Stats - Epoch: 45 AUC-val 0.679  AUC-train 0.929\n",
            "Stats - Epoch: 46 AUC-val 0.652  AUC-train 0.931\n",
            "Stats - Epoch: 47 AUC-val 0.660  AUC-train 0.925\n",
            "Stats - Epoch: 48 AUC-val 0.657  AUC-train 0.932\n",
            "Stats - Epoch: 49 AUC-val 0.669  AUC-train 0.930\n",
            "Stats - Epoch: 50 AUC-val 0.653  AUC-train 0.931\n",
            "Results 50 AUC-val 0.693 0.716 0.652 0.485 0.554 AUC-train 0.924\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.243  AUC-train 0.563\n",
            "Stats - Epoch: 2 AUC-val 0.380  AUC-train 0.715\n",
            "Stats - Epoch: 3 AUC-val 0.527  AUC-train 0.793\n",
            "Stats - Epoch: 4 AUC-val 0.572  AUC-train 0.825\n",
            "Stats - Epoch: 5 AUC-val 0.597  AUC-train 0.844\n",
            "Stats - Epoch: 6 AUC-val 0.602  AUC-train 0.863\n",
            "Stats - Epoch: 7 AUC-val 0.643  AUC-train 0.878\n",
            "Stats - Epoch: 8 AUC-val 0.654  AUC-train 0.888\n",
            "Stats - Epoch: 9 AUC-val 0.660  AUC-train 0.897\n",
            "Stats - Epoch: 10 AUC-val 0.674  AUC-train 0.901\n",
            "Stats - Epoch: 11 AUC-val 0.671  AUC-train 0.917\n",
            "Stats - Epoch: 12 AUC-val 0.679  AUC-train 0.921\n",
            "Stats - Epoch: 13 AUC-val 0.681  AUC-train 0.929\n",
            "Stats - Epoch: 14 AUC-val 0.688  AUC-train 0.936\n",
            "Stats - Epoch: 15 AUC-val 0.665  AUC-train 0.942\n",
            "Stats - Epoch: 16 AUC-val 0.678  AUC-train 0.944\n",
            "Stats - Epoch: 17 AUC-val 0.666  AUC-train 0.948\n",
            "Stats - Epoch: 18 AUC-val 0.683  AUC-train 0.951\n",
            "Stats - Epoch: 19 AUC-val 0.685  AUC-train 0.957\n",
            "Stats - Epoch: 20 AUC-val 0.662  AUC-train 0.961\n",
            "Stats - Epoch: 21 AUC-val 0.685  AUC-train 0.962\n",
            "Stats - Epoch: 22 AUC-val 0.697  AUC-train 0.966\n",
            "Stats - Epoch: 23 AUC-val 0.672  AUC-train 0.972\n",
            "Stats - Epoch: 24 AUC-val 0.672  AUC-train 0.972\n",
            "Stats - Epoch: 25 AUC-val 0.669  AUC-train 0.974\n",
            "Stats - Epoch: 26 AUC-val 0.686  AUC-train 0.977\n",
            "Stats - Epoch: 27 AUC-val 0.676  AUC-train 0.977\n",
            "Stats - Epoch: 28 AUC-val 0.688  AUC-train 0.978\n",
            "Stats - Epoch: 29 AUC-val 0.692  AUC-train 0.982\n",
            "Stats - Epoch: 30 AUC-val 0.700  AUC-train 0.982\n",
            "Stats - Epoch: 31 AUC-val 0.686  AUC-train 0.982\n",
            "Stats - Epoch: 32 AUC-val 0.703  AUC-train 0.982\n",
            "Stats - Epoch: 33 AUC-val 0.674  AUC-train 0.985\n",
            "Stats - Epoch: 34 AUC-val 0.681  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.671  AUC-train 0.985\n",
            "Stats - Epoch: 36 AUC-val 0.679  AUC-train 0.984\n",
            "Stats - Epoch: 37 AUC-val 0.704  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.676  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.702  AUC-train 0.988\n",
            "Stats - Epoch: 40 AUC-val 0.680  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.695  AUC-train 0.989\n",
            "Stats - Epoch: 42 AUC-val 0.698  AUC-train 0.988\n",
            "Stats - Epoch: 43 AUC-val 0.693  AUC-train 0.990\n",
            "Stats - Epoch: 44 AUC-val 0.706  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.702  AUC-train 0.989\n",
            "Stats - Epoch: 46 AUC-val 0.676  AUC-train 0.990\n",
            "Stats - Epoch: 47 AUC-val 0.688  AUC-train 0.992\n",
            "Stats - Epoch: 48 AUC-val 0.697  AUC-train 0.990\n",
            "Stats - Epoch: 49 AUC-val 0.693  AUC-train 0.990\n",
            "Stats - Epoch: 50 AUC-val 0.710  AUC-train 0.988\n",
            "Results 50 AUC-val 0.710 0.623 0.639 0.538 0.600 AUC-train 0.988\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.404  AUC-train 0.507\n",
            "Stats - Epoch: 2 AUC-val 0.480  AUC-train 0.662\n",
            "Stats - Epoch: 3 AUC-val 0.548  AUC-train 0.754\n",
            "Stats - Epoch: 4 AUC-val 0.566  AUC-train 0.806\n",
            "Stats - Epoch: 5 AUC-val 0.597  AUC-train 0.834\n",
            "Stats - Epoch: 6 AUC-val 0.598  AUC-train 0.857\n",
            "Stats - Epoch: 7 AUC-val 0.610  AUC-train 0.874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.629  AUC-train 0.890\n",
            "Stats - Epoch: 9 AUC-val 0.631  AUC-train 0.897\n",
            "Stats - Epoch: 10 AUC-val 0.637  AUC-train 0.911\n",
            "Stats - Epoch: 11 AUC-val 0.653  AUC-train 0.923\n",
            "Stats - Epoch: 12 AUC-val 0.650  AUC-train 0.926\n",
            "Stats - Epoch: 13 AUC-val 0.653  AUC-train 0.937\n",
            "Stats - Epoch: 14 AUC-val 0.666  AUC-train 0.944\n",
            "Stats - Epoch: 15 AUC-val 0.679  AUC-train 0.952\n",
            "Stats - Epoch: 16 AUC-val 0.674  AUC-train 0.954\n",
            "Stats - Epoch: 17 AUC-val 0.683  AUC-train 0.958\n",
            "Stats - Epoch: 18 AUC-val 0.688  AUC-train 0.963\n",
            "Stats - Epoch: 19 AUC-val 0.699  AUC-train 0.966\n",
            "Stats - Epoch: 20 AUC-val 0.721  AUC-train 0.970\n",
            "Stats - Epoch: 21 AUC-val 0.726  AUC-train 0.974\n",
            "Stats - Epoch: 22 AUC-val 0.710  AUC-train 0.976\n",
            "Stats - Epoch: 23 AUC-val 0.709  AUC-train 0.979\n",
            "Stats - Epoch: 24 AUC-val 0.695  AUC-train 0.979\n",
            "Stats - Epoch: 25 AUC-val 0.687  AUC-train 0.981\n",
            "Stats - Epoch: 26 AUC-val 0.719  AUC-train 0.981\n",
            "Stats - Epoch: 27 AUC-val 0.728  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.705  AUC-train 0.987\n",
            "Stats - Epoch: 29 AUC-val 0.737  AUC-train 0.987\n",
            "Stats - Epoch: 30 AUC-val 0.748  AUC-train 0.988\n",
            "Stats - Epoch: 31 AUC-val 0.726  AUC-train 0.988\n",
            "Stats - Epoch: 32 AUC-val 0.715  AUC-train 0.990\n",
            "Stats - Epoch: 33 AUC-val 0.738  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.728  AUC-train 0.992\n",
            "Stats - Epoch: 35 AUC-val 0.779  AUC-train 0.993\n",
            "Stats - Epoch: 36 AUC-val 0.767  AUC-train 0.991\n",
            "Stats - Epoch: 37 AUC-val 0.746  AUC-train 0.992\n",
            "Stats - Epoch: 38 AUC-val 0.759  AUC-train 0.993\n",
            "Stats - Epoch: 39 AUC-val 0.761  AUC-train 0.994\n",
            "Stats - Epoch: 40 AUC-val 0.745  AUC-train 0.994\n",
            "Stats - Epoch: 41 AUC-val 0.730  AUC-train 0.995\n",
            "Stats - Epoch: 42 AUC-val 0.748  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.709  AUC-train 0.994\n",
            "Stats - Epoch: 44 AUC-val 0.727  AUC-train 0.994\n",
            "Stats - Epoch: 45 AUC-val 0.753  AUC-train 0.995\n",
            "Stats - Epoch: 46 AUC-val 0.729  AUC-train 0.997\n",
            "Stats - Epoch: 47 AUC-val 0.760  AUC-train 0.995\n",
            "Stats - Epoch: 48 AUC-val 0.746  AUC-train 0.996\n",
            "Stats - Epoch: 49 AUC-val 0.737  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.748  AUC-train 0.996\n",
            "Results 50 AUC-val 0.779 0.757 0.705 0.550 0.572 AUC-train 0.993\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.548  AUC-train 0.842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.548 0.556 0.523 0.548 0.712 AUC-train 0.842\n",
            "Shapley [0.01298441 0.00792295 0.01453058 0.00910832 0.00694712] [0.00862639]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188086\n",
            "         Iterations 10\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.217  AUC-train 0.600\n",
            "Stats - Epoch: 2 AUC-val 0.336  AUC-train 0.807\n",
            "Stats - Epoch: 3 AUC-val 0.355  AUC-train 0.889\n",
            "Stats - Epoch: 4 AUC-val 0.336  AUC-train 0.935\n",
            "Stats - Epoch: 5 AUC-val 0.365  AUC-train 0.969\n",
            "Stats - Epoch: 6 AUC-val 0.371  AUC-train 0.980\n",
            "Stats - Epoch: 7 AUC-val 0.349  AUC-train 0.987\n",
            "Stats - Epoch: 8 AUC-val 0.370  AUC-train 0.992\n",
            "Stats - Epoch: 9 AUC-val 0.381  AUC-train 0.994\n",
            "Stats - Epoch: 10 AUC-val 0.430  AUC-train 0.995\n",
            "Stats - Epoch: 11 AUC-val 0.465  AUC-train 0.996\n",
            "Stats - Epoch: 12 AUC-val 0.425  AUC-train 0.996\n",
            "Stats - Epoch: 13 AUC-val 0.452  AUC-train 0.997\n",
            "Stats - Epoch: 14 AUC-val 0.487  AUC-train 0.997\n",
            "Stats - Epoch: 15 AUC-val 0.443  AUC-train 0.994\n",
            "Stats - Epoch: 16 AUC-val 0.494  AUC-train 0.997\n",
            "Stats - Epoch: 17 AUC-val 0.491  AUC-train 0.997\n",
            "Stats - Epoch: 18 AUC-val 0.504  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.500  AUC-train 0.997\n",
            "Stats - Epoch: 20 AUC-val 0.489  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.503  AUC-train 0.997\n",
            "Stats - Epoch: 22 AUC-val 0.515  AUC-train 0.997\n",
            "Stats - Epoch: 23 AUC-val 0.505  AUC-train 0.996\n",
            "Stats - Epoch: 24 AUC-val 0.509  AUC-train 0.998\n",
            "Stats - Epoch: 25 AUC-val 0.528  AUC-train 0.997\n",
            "Stats - Epoch: 26 AUC-val 0.526  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.506  AUC-train 0.996\n",
            "Stats - Epoch: 28 AUC-val 0.502  AUC-train 0.997\n",
            "Stats - Epoch: 29 AUC-val 0.507  AUC-train 0.998\n",
            "Stats - Epoch: 30 AUC-val 0.537  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.488  AUC-train 0.998\n",
            "Stats - Epoch: 32 AUC-val 0.518  AUC-train 0.998\n",
            "Stats - Epoch: 33 AUC-val 0.508  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.531  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.515  AUC-train 0.997\n",
            "Stats - Epoch: 36 AUC-val 0.533  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.511  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.520  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.523  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.528  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.517  AUC-train 0.995\n",
            "Stats - Epoch: 42 AUC-val 0.508  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.530  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.513  AUC-train 0.997\n",
            "Stats - Epoch: 45 AUC-val 0.541  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.543  AUC-train 0.996\n",
            "Stats - Epoch: 47 AUC-val 0.537  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.513  AUC-train 0.997\n",
            "Stats - Epoch: 49 AUC-val 0.540  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.538  AUC-train 0.997\n",
            "Results 50 AUC-val 0.543 0.392 0.616 0.233 0.271 AUC-train 0.996\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.221  AUC-train 0.576\n",
            "Stats - Epoch: 2 AUC-val 0.205  AUC-train 0.611\n",
            "Stats - Epoch: 3 AUC-val 0.197  AUC-train 0.676\n",
            "Stats - Epoch: 4 AUC-val 0.247  AUC-train 0.724\n",
            "Stats - Epoch: 5 AUC-val 0.314  AUC-train 0.768\n",
            "Stats - Epoch: 6 AUC-val 0.376  AUC-train 0.793\n",
            "Stats - Epoch: 7 AUC-val 0.414  AUC-train 0.813\n",
            "Stats - Epoch: 8 AUC-val 0.467  AUC-train 0.826\n",
            "Stats - Epoch: 9 AUC-val 0.499  AUC-train 0.836\n",
            "Stats - Epoch: 10 AUC-val 0.531  AUC-train 0.845\n",
            "Stats - Epoch: 11 AUC-val 0.547  AUC-train 0.846\n",
            "Stats - Epoch: 12 AUC-val 0.525  AUC-train 0.854\n",
            "Stats - Epoch: 13 AUC-val 0.551  AUC-train 0.858\n",
            "Stats - Epoch: 14 AUC-val 0.566  AUC-train 0.863\n",
            "Stats - Epoch: 15 AUC-val 0.543  AUC-train 0.862\n",
            "Stats - Epoch: 16 AUC-val 0.547  AUC-train 0.872\n",
            "Stats - Epoch: 17 AUC-val 0.565  AUC-train 0.877\n",
            "Stats - Epoch: 18 AUC-val 0.563  AUC-train 0.878\n",
            "Stats - Epoch: 19 AUC-val 0.591  AUC-train 0.876\n",
            "Stats - Epoch: 20 AUC-val 0.579  AUC-train 0.883\n",
            "Stats - Epoch: 21 AUC-val 0.593  AUC-train 0.887\n",
            "Stats - Epoch: 22 AUC-val 0.617  AUC-train 0.889\n",
            "Stats - Epoch: 23 AUC-val 0.624  AUC-train 0.890\n",
            "Stats - Epoch: 24 AUC-val 0.593  AUC-train 0.892\n",
            "Stats - Epoch: 25 AUC-val 0.611  AUC-train 0.894\n",
            "Stats - Epoch: 26 AUC-val 0.601  AUC-train 0.896\n",
            "Stats - Epoch: 27 AUC-val 0.608  AUC-train 0.901\n",
            "Stats - Epoch: 28 AUC-val 0.596  AUC-train 0.902\n",
            "Stats - Epoch: 29 AUC-val 0.631  AUC-train 0.904\n",
            "Stats - Epoch: 30 AUC-val 0.671  AUC-train 0.904\n",
            "Stats - Epoch: 31 AUC-val 0.608  AUC-train 0.906\n",
            "Stats - Epoch: 32 AUC-val 0.627  AUC-train 0.908\n",
            "Stats - Epoch: 33 AUC-val 0.619  AUC-train 0.913\n",
            "Stats - Epoch: 34 AUC-val 0.619  AUC-train 0.913\n",
            "Stats - Epoch: 35 AUC-val 0.637  AUC-train 0.914\n",
            "Stats - Epoch: 36 AUC-val 0.656  AUC-train 0.917\n",
            "Stats - Epoch: 37 AUC-val 0.617  AUC-train 0.919\n",
            "Stats - Epoch: 38 AUC-val 0.607  AUC-train 0.920\n",
            "Stats - Epoch: 39 AUC-val 0.655  AUC-train 0.923\n",
            "Stats - Epoch: 40 AUC-val 0.609  AUC-train 0.925\n",
            "Stats - Epoch: 41 AUC-val 0.617  AUC-train 0.927\n",
            "Stats - Epoch: 42 AUC-val 0.592  AUC-train 0.925\n",
            "Stats - Epoch: 43 AUC-val 0.614  AUC-train 0.925\n",
            "Stats - Epoch: 44 AUC-val 0.624  AUC-train 0.926\n",
            "Stats - Epoch: 45 AUC-val 0.609  AUC-train 0.929\n",
            "Stats - Epoch: 46 AUC-val 0.634  AUC-train 0.930\n",
            "Stats - Epoch: 47 AUC-val 0.604  AUC-train 0.928\n",
            "Stats - Epoch: 48 AUC-val 0.629  AUC-train 0.933\n",
            "Stats - Epoch: 49 AUC-val 0.619  AUC-train 0.935\n",
            "Stats - Epoch: 50 AUC-val 0.647  AUC-train 0.931\n",
            "Results 50 AUC-val 0.671 0.683 0.603 0.426 0.580 AUC-train 0.904\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.273  AUC-train 0.559\n",
            "Stats - Epoch: 2 AUC-val 0.388  AUC-train 0.720\n",
            "Stats - Epoch: 3 AUC-val 0.526  AUC-train 0.796\n",
            "Stats - Epoch: 4 AUC-val 0.566  AUC-train 0.821\n",
            "Stats - Epoch: 5 AUC-val 0.590  AUC-train 0.841\n",
            "Stats - Epoch: 6 AUC-val 0.603  AUC-train 0.859\n",
            "Stats - Epoch: 7 AUC-val 0.611  AUC-train 0.874\n",
            "Stats - Epoch: 8 AUC-val 0.636  AUC-train 0.881\n",
            "Stats - Epoch: 9 AUC-val 0.618  AUC-train 0.889\n",
            "Stats - Epoch: 10 AUC-val 0.634  AUC-train 0.899\n",
            "Stats - Epoch: 11 AUC-val 0.638  AUC-train 0.912\n",
            "Stats - Epoch: 12 AUC-val 0.651  AUC-train 0.918\n",
            "Stats - Epoch: 13 AUC-val 0.654  AUC-train 0.928\n",
            "Stats - Epoch: 14 AUC-val 0.643  AUC-train 0.931\n",
            "Stats - Epoch: 15 AUC-val 0.658  AUC-train 0.935\n",
            "Stats - Epoch: 16 AUC-val 0.638  AUC-train 0.940\n",
            "Stats - Epoch: 17 AUC-val 0.647  AUC-train 0.943\n",
            "Stats - Epoch: 18 AUC-val 0.641  AUC-train 0.950\n",
            "Stats - Epoch: 19 AUC-val 0.656  AUC-train 0.953\n",
            "Stats - Epoch: 20 AUC-val 0.635  AUC-train 0.956\n",
            "Stats - Epoch: 21 AUC-val 0.632  AUC-train 0.959\n",
            "Stats - Epoch: 22 AUC-val 0.652  AUC-train 0.961\n",
            "Stats - Epoch: 23 AUC-val 0.658  AUC-train 0.963\n",
            "Stats - Epoch: 24 AUC-val 0.622  AUC-train 0.965\n",
            "Stats - Epoch: 25 AUC-val 0.637  AUC-train 0.963\n",
            "Stats - Epoch: 26 AUC-val 0.624  AUC-train 0.966\n",
            "Stats - Epoch: 27 AUC-val 0.646  AUC-train 0.968\n",
            "Stats - Epoch: 28 AUC-val 0.664  AUC-train 0.971\n",
            "Stats - Epoch: 29 AUC-val 0.643  AUC-train 0.970\n",
            "Stats - Epoch: 30 AUC-val 0.642  AUC-train 0.974\n",
            "Stats - Epoch: 31 AUC-val 0.619  AUC-train 0.974\n",
            "Stats - Epoch: 32 AUC-val 0.622  AUC-train 0.974\n",
            "Stats - Epoch: 33 AUC-val 0.643  AUC-train 0.975\n",
            "Stats - Epoch: 34 AUC-val 0.628  AUC-train 0.975\n",
            "Stats - Epoch: 35 AUC-val 0.614  AUC-train 0.976\n",
            "Stats - Epoch: 36 AUC-val 0.650  AUC-train 0.977\n",
            "Stats - Epoch: 37 AUC-val 0.624  AUC-train 0.979\n",
            "Stats - Epoch: 38 AUC-val 0.647  AUC-train 0.980\n",
            "Stats - Epoch: 39 AUC-val 0.636  AUC-train 0.979\n",
            "Stats - Epoch: 40 AUC-val 0.656  AUC-train 0.980\n",
            "Stats - Epoch: 41 AUC-val 0.628  AUC-train 0.980\n",
            "Stats - Epoch: 42 AUC-val 0.624  AUC-train 0.981\n",
            "Stats - Epoch: 43 AUC-val 0.622  AUC-train 0.981\n",
            "Stats - Epoch: 44 AUC-val 0.624  AUC-train 0.983\n",
            "Stats - Epoch: 45 AUC-val 0.620  AUC-train 0.982\n",
            "Stats - Epoch: 46 AUC-val 0.600  AUC-train 0.983\n",
            "Stats - Epoch: 47 AUC-val 0.617  AUC-train 0.985\n",
            "Stats - Epoch: 48 AUC-val 0.641  AUC-train 0.985\n",
            "Stats - Epoch: 49 AUC-val 0.597  AUC-train 0.986\n",
            "Stats - Epoch: 50 AUC-val 0.615  AUC-train 0.984\n",
            "Results 50 AUC-val 0.664 0.635 0.623 0.570 0.671 AUC-train 0.971\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.370  AUC-train 0.514\n",
            "Stats - Epoch: 2 AUC-val 0.465  AUC-train 0.675\n",
            "Stats - Epoch: 3 AUC-val 0.554  AUC-train 0.762\n",
            "Stats - Epoch: 4 AUC-val 0.573  AUC-train 0.816\n",
            "Stats - Epoch: 5 AUC-val 0.586  AUC-train 0.840\n",
            "Stats - Epoch: 6 AUC-val 0.604  AUC-train 0.857\n",
            "Stats - Epoch: 7 AUC-val 0.611  AUC-train 0.869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.605  AUC-train 0.884\n",
            "Stats - Epoch: 9 AUC-val 0.606  AUC-train 0.896\n",
            "Stats - Epoch: 10 AUC-val 0.616  AUC-train 0.905\n",
            "Stats - Epoch: 11 AUC-val 0.613  AUC-train 0.916\n",
            "Stats - Epoch: 12 AUC-val 0.617  AUC-train 0.922\n",
            "Stats - Epoch: 13 AUC-val 0.603  AUC-train 0.932\n",
            "Stats - Epoch: 14 AUC-val 0.601  AUC-train 0.940\n",
            "Stats - Epoch: 15 AUC-val 0.610  AUC-train 0.944\n",
            "Stats - Epoch: 16 AUC-val 0.618  AUC-train 0.950\n",
            "Stats - Epoch: 17 AUC-val 0.617  AUC-train 0.957\n",
            "Stats - Epoch: 18 AUC-val 0.617  AUC-train 0.958\n",
            "Stats - Epoch: 19 AUC-val 0.608  AUC-train 0.965\n",
            "Stats - Epoch: 20 AUC-val 0.607  AUC-train 0.968\n",
            "Stats - Epoch: 21 AUC-val 0.624  AUC-train 0.973\n",
            "Stats - Epoch: 22 AUC-val 0.630  AUC-train 0.973\n",
            "Stats - Epoch: 23 AUC-val 0.633  AUC-train 0.976\n",
            "Stats - Epoch: 24 AUC-val 0.650  AUC-train 0.980\n",
            "Stats - Epoch: 25 AUC-val 0.639  AUC-train 0.982\n",
            "Stats - Epoch: 26 AUC-val 0.648  AUC-train 0.986\n",
            "Stats - Epoch: 27 AUC-val 0.669  AUC-train 0.986\n",
            "Stats - Epoch: 28 AUC-val 0.671  AUC-train 0.985\n",
            "Stats - Epoch: 29 AUC-val 0.658  AUC-train 0.987\n",
            "Stats - Epoch: 30 AUC-val 0.630  AUC-train 0.989\n",
            "Stats - Epoch: 31 AUC-val 0.644  AUC-train 0.990\n",
            "Stats - Epoch: 32 AUC-val 0.680  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.696  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.656  AUC-train 0.990\n",
            "Stats - Epoch: 35 AUC-val 0.661  AUC-train 0.992\n",
            "Stats - Epoch: 36 AUC-val 0.654  AUC-train 0.993\n",
            "Stats - Epoch: 37 AUC-val 0.679  AUC-train 0.992\n",
            "Stats - Epoch: 38 AUC-val 0.694  AUC-train 0.994\n",
            "Stats - Epoch: 39 AUC-val 0.655  AUC-train 0.991\n",
            "Stats - Epoch: 40 AUC-val 0.663  AUC-train 0.993\n",
            "Stats - Epoch: 41 AUC-val 0.664  AUC-train 0.994\n",
            "Stats - Epoch: 42 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.646  AUC-train 0.994\n",
            "Stats - Epoch: 44 AUC-val 0.648  AUC-train 0.995\n",
            "Stats - Epoch: 45 AUC-val 0.693  AUC-train 0.996\n",
            "Stats - Epoch: 46 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 47 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.665  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.651  AUC-train 0.997\n",
            "Results 50 AUC-val 0.696 0.698 0.673 0.578 0.621 AUC-train 0.990\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.530  AUC-train 0.903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.530 0.425 0.403 0.426 0.734 AUC-train 0.903\n",
            "Shapley [0.02416692 0.00575758 0.01119229 0.02020464 0.01016532] [0.00384114]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.190877\n",
            "         Iterations 10\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.297  AUC-train 0.605\n",
            "Stats - Epoch: 2 AUC-val 0.338  AUC-train 0.810\n",
            "Stats - Epoch: 3 AUC-val 0.354  AUC-train 0.910\n",
            "Stats - Epoch: 4 AUC-val 0.386  AUC-train 0.954\n",
            "Stats - Epoch: 5 AUC-val 0.400  AUC-train 0.976\n",
            "Stats - Epoch: 6 AUC-val 0.402  AUC-train 0.988\n",
            "Stats - Epoch: 7 AUC-val 0.450  AUC-train 0.994\n",
            "Stats - Epoch: 8 AUC-val 0.447  AUC-train 0.995\n",
            "Stats - Epoch: 9 AUC-val 0.440  AUC-train 0.998\n",
            "Stats - Epoch: 10 AUC-val 0.482  AUC-train 0.999\n",
            "Stats - Epoch: 11 AUC-val 0.463  AUC-train 0.998\n",
            "Stats - Epoch: 12 AUC-val 0.468  AUC-train 0.999\n",
            "Stats - Epoch: 13 AUC-val 0.476  AUC-train 0.999\n",
            "Stats - Epoch: 14 AUC-val 0.464  AUC-train 0.997\n",
            "Stats - Epoch: 15 AUC-val 0.502  AUC-train 0.996\n",
            "Stats - Epoch: 16 AUC-val 0.469  AUC-train 0.998\n",
            "Stats - Epoch: 17 AUC-val 0.487  AUC-train 0.999\n",
            "Stats - Epoch: 18 AUC-val 0.503  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.504  AUC-train 1.000\n",
            "Stats - Epoch: 20 AUC-val 0.502  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.524  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.512  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.533  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.510  AUC-train 0.998\n",
            "Stats - Epoch: 25 AUC-val 0.512  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.516  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.545  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.516  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.519  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.528  AUC-train 0.997\n",
            "Stats - Epoch: 31 AUC-val 0.541  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.552  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.537  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.519  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.548  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.534  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.518  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.547  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.498  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.522  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.540  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.501  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.524  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.506  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.510  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.529  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.516  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.536  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.525  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.535  AUC-train 0.998\n",
            "Results 50 AUC-val 0.552 0.423 0.636 0.315 0.328 AUC-train 0.997\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.210  AUC-train 0.565\n",
            "Stats - Epoch: 2 AUC-val 0.191  AUC-train 0.604\n",
            "Stats - Epoch: 3 AUC-val 0.188  AUC-train 0.661\n",
            "Stats - Epoch: 4 AUC-val 0.228  AUC-train 0.706\n",
            "Stats - Epoch: 5 AUC-val 0.307  AUC-train 0.753\n",
            "Stats - Epoch: 6 AUC-val 0.437  AUC-train 0.781\n",
            "Stats - Epoch: 7 AUC-val 0.408  AUC-train 0.804\n",
            "Stats - Epoch: 8 AUC-val 0.489  AUC-train 0.813\n",
            "Stats - Epoch: 9 AUC-val 0.503  AUC-train 0.823\n",
            "Stats - Epoch: 10 AUC-val 0.514  AUC-train 0.834\n",
            "Stats - Epoch: 11 AUC-val 0.568  AUC-train 0.840\n",
            "Stats - Epoch: 12 AUC-val 0.553  AUC-train 0.849\n",
            "Stats - Epoch: 13 AUC-val 0.606  AUC-train 0.849\n",
            "Stats - Epoch: 14 AUC-val 0.596  AUC-train 0.850\n",
            "Stats - Epoch: 15 AUC-val 0.583  AUC-train 0.858\n",
            "Stats - Epoch: 16 AUC-val 0.582  AUC-train 0.861\n",
            "Stats - Epoch: 17 AUC-val 0.587  AUC-train 0.861\n",
            "Stats - Epoch: 18 AUC-val 0.603  AUC-train 0.868\n",
            "Stats - Epoch: 19 AUC-val 0.581  AUC-train 0.867\n",
            "Stats - Epoch: 20 AUC-val 0.579  AUC-train 0.871\n",
            "Stats - Epoch: 21 AUC-val 0.612  AUC-train 0.874\n",
            "Stats - Epoch: 22 AUC-val 0.613  AUC-train 0.875\n",
            "Stats - Epoch: 23 AUC-val 0.621  AUC-train 0.880\n",
            "Stats - Epoch: 24 AUC-val 0.627  AUC-train 0.879\n",
            "Stats - Epoch: 25 AUC-val 0.636  AUC-train 0.881\n",
            "Stats - Epoch: 26 AUC-val 0.646  AUC-train 0.883\n",
            "Stats - Epoch: 27 AUC-val 0.628  AUC-train 0.883\n",
            "Stats - Epoch: 28 AUC-val 0.605  AUC-train 0.885\n",
            "Stats - Epoch: 29 AUC-val 0.595  AUC-train 0.887\n",
            "Stats - Epoch: 30 AUC-val 0.633  AUC-train 0.891\n",
            "Stats - Epoch: 31 AUC-val 0.652  AUC-train 0.890\n",
            "Stats - Epoch: 32 AUC-val 0.622  AUC-train 0.897\n",
            "Stats - Epoch: 33 AUC-val 0.629  AUC-train 0.900\n",
            "Stats - Epoch: 34 AUC-val 0.651  AUC-train 0.901\n",
            "Stats - Epoch: 35 AUC-val 0.610  AUC-train 0.906\n",
            "Stats - Epoch: 36 AUC-val 0.653  AUC-train 0.908\n",
            "Stats - Epoch: 37 AUC-val 0.650  AUC-train 0.906\n",
            "Stats - Epoch: 38 AUC-val 0.619  AUC-train 0.909\n",
            "Stats - Epoch: 39 AUC-val 0.629  AUC-train 0.911\n",
            "Stats - Epoch: 40 AUC-val 0.681  AUC-train 0.910\n",
            "Stats - Epoch: 41 AUC-val 0.622  AUC-train 0.910\n",
            "Stats - Epoch: 42 AUC-val 0.625  AUC-train 0.913\n",
            "Stats - Epoch: 43 AUC-val 0.623  AUC-train 0.915\n",
            "Stats - Epoch: 44 AUC-val 0.627  AUC-train 0.919\n",
            "Stats - Epoch: 45 AUC-val 0.652  AUC-train 0.920\n",
            "Stats - Epoch: 46 AUC-val 0.621  AUC-train 0.918\n",
            "Stats - Epoch: 47 AUC-val 0.608  AUC-train 0.921\n",
            "Stats - Epoch: 48 AUC-val 0.636  AUC-train 0.920\n",
            "Stats - Epoch: 49 AUC-val 0.607  AUC-train 0.923\n",
            "Stats - Epoch: 50 AUC-val 0.628  AUC-train 0.922\n",
            "Results 50 AUC-val 0.681 0.668 0.565 0.432 0.550 AUC-train 0.910\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.259  AUC-train 0.575\n",
            "Stats - Epoch: 2 AUC-val 0.363  AUC-train 0.738\n",
            "Stats - Epoch: 3 AUC-val 0.508  AUC-train 0.804\n",
            "Stats - Epoch: 4 AUC-val 0.561  AUC-train 0.831\n",
            "Stats - Epoch: 5 AUC-val 0.598  AUC-train 0.850\n",
            "Stats - Epoch: 6 AUC-val 0.605  AUC-train 0.863\n",
            "Stats - Epoch: 7 AUC-val 0.609  AUC-train 0.877\n",
            "Stats - Epoch: 8 AUC-val 0.623  AUC-train 0.886\n",
            "Stats - Epoch: 9 AUC-val 0.633  AUC-train 0.898\n",
            "Stats - Epoch: 10 AUC-val 0.622  AUC-train 0.901\n",
            "Stats - Epoch: 11 AUC-val 0.619  AUC-train 0.909\n",
            "Stats - Epoch: 12 AUC-val 0.629  AUC-train 0.916\n",
            "Stats - Epoch: 13 AUC-val 0.618  AUC-train 0.920\n",
            "Stats - Epoch: 14 AUC-val 0.621  AUC-train 0.931\n",
            "Stats - Epoch: 15 AUC-val 0.623  AUC-train 0.931\n",
            "Stats - Epoch: 16 AUC-val 0.617  AUC-train 0.935\n",
            "Stats - Epoch: 17 AUC-val 0.612  AUC-train 0.942\n",
            "Stats - Epoch: 18 AUC-val 0.609  AUC-train 0.945\n",
            "Stats - Epoch: 19 AUC-val 0.610  AUC-train 0.945\n",
            "Stats - Epoch: 20 AUC-val 0.611  AUC-train 0.949\n",
            "Stats - Epoch: 21 AUC-val 0.598  AUC-train 0.954\n",
            "Stats - Epoch: 22 AUC-val 0.622  AUC-train 0.956\n",
            "Stats - Epoch: 23 AUC-val 0.617  AUC-train 0.957\n",
            "Stats - Epoch: 24 AUC-val 0.616  AUC-train 0.957\n",
            "Stats - Epoch: 25 AUC-val 0.612  AUC-train 0.961\n",
            "Stats - Epoch: 26 AUC-val 0.616  AUC-train 0.964\n",
            "Stats - Epoch: 27 AUC-val 0.611  AUC-train 0.966\n",
            "Stats - Epoch: 28 AUC-val 0.597  AUC-train 0.965\n",
            "Stats - Epoch: 29 AUC-val 0.597  AUC-train 0.966\n",
            "Stats - Epoch: 30 AUC-val 0.609  AUC-train 0.966\n",
            "Stats - Epoch: 31 AUC-val 0.598  AUC-train 0.967\n",
            "Stats - Epoch: 32 AUC-val 0.598  AUC-train 0.970\n",
            "Stats - Epoch: 33 AUC-val 0.603  AUC-train 0.971\n",
            "Stats - Epoch: 34 AUC-val 0.610  AUC-train 0.972\n",
            "Stats - Epoch: 35 AUC-val 0.595  AUC-train 0.972\n",
            "Stats - Epoch: 36 AUC-val 0.599  AUC-train 0.974\n",
            "Stats - Epoch: 37 AUC-val 0.585  AUC-train 0.975\n",
            "Stats - Epoch: 38 AUC-val 0.591  AUC-train 0.973\n",
            "Stats - Epoch: 39 AUC-val 0.590  AUC-train 0.977\n",
            "Stats - Epoch: 40 AUC-val 0.608  AUC-train 0.976\n",
            "Stats - Epoch: 41 AUC-val 0.599  AUC-train 0.977\n",
            "Stats - Epoch: 42 AUC-val 0.607  AUC-train 0.978\n",
            "Stats - Epoch: 43 AUC-val 0.564  AUC-train 0.979\n",
            "Stats - Epoch: 44 AUC-val 0.602  AUC-train 0.980\n",
            "Stats - Epoch: 45 AUC-val 0.607  AUC-train 0.980\n",
            "Stats - Epoch: 46 AUC-val 0.614  AUC-train 0.977\n",
            "Stats - Epoch: 47 AUC-val 0.599  AUC-train 0.979\n",
            "Stats - Epoch: 48 AUC-val 0.626  AUC-train 0.982\n",
            "Stats - Epoch: 49 AUC-val 0.618  AUC-train 0.982\n",
            "Stats - Epoch: 50 AUC-val 0.599  AUC-train 0.985\n",
            "Results 50 AUC-val 0.633 0.653 0.645 0.571 0.657 AUC-train 0.898\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.390  AUC-train 0.529\n",
            "Stats - Epoch: 2 AUC-val 0.474  AUC-train 0.706\n",
            "Stats - Epoch: 3 AUC-val 0.531  AUC-train 0.778\n",
            "Stats - Epoch: 4 AUC-val 0.548  AUC-train 0.816\n",
            "Stats - Epoch: 5 AUC-val 0.575  AUC-train 0.837\n",
            "Stats - Epoch: 6 AUC-val 0.572  AUC-train 0.854\n",
            "Stats - Epoch: 7 AUC-val 0.590  AUC-train 0.868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.582  AUC-train 0.883\n",
            "Stats - Epoch: 9 AUC-val 0.585  AUC-train 0.894\n",
            "Stats - Epoch: 10 AUC-val 0.597  AUC-train 0.900\n",
            "Stats - Epoch: 11 AUC-val 0.622  AUC-train 0.910\n",
            "Stats - Epoch: 12 AUC-val 0.614  AUC-train 0.919\n",
            "Stats - Epoch: 13 AUC-val 0.593  AUC-train 0.924\n",
            "Stats - Epoch: 14 AUC-val 0.615  AUC-train 0.933\n",
            "Stats - Epoch: 15 AUC-val 0.605  AUC-train 0.938\n",
            "Stats - Epoch: 16 AUC-val 0.632  AUC-train 0.945\n",
            "Stats - Epoch: 17 AUC-val 0.608  AUC-train 0.950\n",
            "Stats - Epoch: 18 AUC-val 0.641  AUC-train 0.952\n",
            "Stats - Epoch: 19 AUC-val 0.636  AUC-train 0.956\n",
            "Stats - Epoch: 20 AUC-val 0.646  AUC-train 0.961\n",
            "Stats - Epoch: 21 AUC-val 0.653  AUC-train 0.962\n",
            "Stats - Epoch: 22 AUC-val 0.650  AUC-train 0.965\n",
            "Stats - Epoch: 23 AUC-val 0.653  AUC-train 0.970\n",
            "Stats - Epoch: 24 AUC-val 0.666  AUC-train 0.969\n",
            "Stats - Epoch: 25 AUC-val 0.631  AUC-train 0.972\n",
            "Stats - Epoch: 26 AUC-val 0.640  AUC-train 0.974\n",
            "Stats - Epoch: 27 AUC-val 0.655  AUC-train 0.977\n",
            "Stats - Epoch: 28 AUC-val 0.656  AUC-train 0.979\n",
            "Stats - Epoch: 29 AUC-val 0.654  AUC-train 0.982\n",
            "Stats - Epoch: 30 AUC-val 0.646  AUC-train 0.983\n",
            "Stats - Epoch: 31 AUC-val 0.598  AUC-train 0.985\n",
            "Stats - Epoch: 32 AUC-val 0.623  AUC-train 0.984\n",
            "Stats - Epoch: 33 AUC-val 0.645  AUC-train 0.987\n",
            "Stats - Epoch: 34 AUC-val 0.635  AUC-train 0.986\n",
            "Stats - Epoch: 35 AUC-val 0.660  AUC-train 0.989\n",
            "Stats - Epoch: 36 AUC-val 0.632  AUC-train 0.990\n",
            "Stats - Epoch: 37 AUC-val 0.657  AUC-train 0.991\n",
            "Stats - Epoch: 38 AUC-val 0.638  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.652  AUC-train 0.990\n",
            "Stats - Epoch: 40 AUC-val 0.667  AUC-train 0.992\n",
            "Stats - Epoch: 41 AUC-val 0.660  AUC-train 0.992\n",
            "Stats - Epoch: 42 AUC-val 0.698  AUC-train 0.993\n",
            "Stats - Epoch: 43 AUC-val 0.688  AUC-train 0.991\n",
            "Stats - Epoch: 44 AUC-val 0.698  AUC-train 0.994\n",
            "Stats - Epoch: 45 AUC-val 0.676  AUC-train 0.993\n",
            "Stats - Epoch: 46 AUC-val 0.684  AUC-train 0.993\n",
            "Stats - Epoch: 47 AUC-val 0.674  AUC-train 0.994\n",
            "Stats - Epoch: 48 AUC-val 0.686  AUC-train 0.993\n",
            "Stats - Epoch: 49 AUC-val 0.679  AUC-train 0.994\n",
            "Stats - Epoch: 50 AUC-val 0.689  AUC-train 0.996\n",
            "Results 50 AUC-val 0.698 0.703 0.690 0.573 0.550 AUC-train 0.993\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.283  AUC-train 0.645\n",
            "Stats - Epoch: 2 AUC-val 0.444  AUC-train 0.831\n",
            "Stats - Epoch: 3 AUC-val 0.468  AUC-train 0.918\n",
            "Stats - Epoch: 4 AUC-val 0.433  AUC-train 0.958\n",
            "Stats - Epoch: 5 AUC-val 0.465  AUC-train 0.979\n",
            "Stats - Epoch: 6 AUC-val 0.490  AUC-train 0.989\n",
            "Stats - Epoch: 7 AUC-val 0.499  AUC-train 0.994\n",
            "Stats - Epoch: 8 AUC-val 0.509  AUC-train 0.996\n",
            "Stats - Epoch: 9 AUC-val 0.476  AUC-train 0.998\n",
            "Stats - Epoch: 10 AUC-val 0.492  AUC-train 0.999\n",
            "Stats - Epoch: 11 AUC-val 0.534  AUC-train 0.998\n",
            "Stats - Epoch: 12 AUC-val 0.533  AUC-train 0.997\n",
            "Stats - Epoch: 13 AUC-val 0.529  AUC-train 0.998\n",
            "Stats - Epoch: 14 AUC-val 0.535  AUC-train 0.999\n",
            "Stats - Epoch: 15 AUC-val 0.502  AUC-train 0.999\n",
            "Stats - Epoch: 16 AUC-val 0.546  AUC-train 0.999\n",
            "Stats - Epoch: 17 AUC-val 0.549  AUC-train 0.999\n",
            "Stats - Epoch: 18 AUC-val 0.562  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.571  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.573  AUC-train 0.996\n",
            "Stats - Epoch: 21 AUC-val 0.534  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.555  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.526  AUC-train 0.996\n",
            "Stats - Epoch: 24 AUC-val 0.559  AUC-train 0.998\n",
            "Stats - Epoch: 25 AUC-val 0.600  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.593  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.578  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.584  AUC-train 0.998\n",
            "Stats - Epoch: 29 AUC-val 0.589  AUC-train 0.997\n",
            "Stats - Epoch: 30 AUC-val 0.568  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.572  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.562  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.597  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.568  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.598  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.611  AUC-train 0.997\n",
            "Stats - Epoch: 37 AUC-val 0.610  AUC-train 0.997\n",
            "Stats - Epoch: 38 AUC-val 0.605  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.590  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.562  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.640  AUC-train 1.000\n",
            "Stats - Epoch: 42 AUC-val 0.608  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.601  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.623  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.597  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.577  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.629  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.634  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.605  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.610  AUC-train 0.998\n",
            "Results 50 AUC-val 0.640 0.430 0.577 0.305 0.378 AUC-train 1.000\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.222  AUC-train 0.557\n",
            "Stats - Epoch: 2 AUC-val 0.209  AUC-train 0.596\n",
            "Stats - Epoch: 3 AUC-val 0.221  AUC-train 0.657\n",
            "Stats - Epoch: 4 AUC-val 0.242  AUC-train 0.708\n",
            "Stats - Epoch: 5 AUC-val 0.282  AUC-train 0.751\n",
            "Stats - Epoch: 6 AUC-val 0.327  AUC-train 0.781\n",
            "Stats - Epoch: 7 AUC-val 0.386  AUC-train 0.804\n",
            "Stats - Epoch: 8 AUC-val 0.453  AUC-train 0.818\n",
            "Stats - Epoch: 9 AUC-val 0.525  AUC-train 0.827\n",
            "Stats - Epoch: 10 AUC-val 0.511  AUC-train 0.840\n",
            "Stats - Epoch: 11 AUC-val 0.516  AUC-train 0.847\n",
            "Stats - Epoch: 12 AUC-val 0.601  AUC-train 0.853\n",
            "Stats - Epoch: 13 AUC-val 0.550  AUC-train 0.858\n",
            "Stats - Epoch: 14 AUC-val 0.527  AUC-train 0.865\n",
            "Stats - Epoch: 15 AUC-val 0.533  AUC-train 0.864\n",
            "Stats - Epoch: 16 AUC-val 0.564  AUC-train 0.865\n",
            "Stats - Epoch: 17 AUC-val 0.543  AUC-train 0.872\n",
            "Stats - Epoch: 18 AUC-val 0.490  AUC-train 0.874\n",
            "Stats - Epoch: 19 AUC-val 0.555  AUC-train 0.878\n",
            "Stats - Epoch: 20 AUC-val 0.592  AUC-train 0.875\n",
            "Stats - Epoch: 21 AUC-val 0.564  AUC-train 0.880\n",
            "Stats - Epoch: 22 AUC-val 0.545  AUC-train 0.886\n",
            "Stats - Epoch: 23 AUC-val 0.578  AUC-train 0.890\n",
            "Stats - Epoch: 24 AUC-val 0.550  AUC-train 0.887\n",
            "Stats - Epoch: 25 AUC-val 0.614  AUC-train 0.889\n",
            "Stats - Epoch: 26 AUC-val 0.558  AUC-train 0.891\n",
            "Stats - Epoch: 27 AUC-val 0.562  AUC-train 0.893\n",
            "Stats - Epoch: 28 AUC-val 0.643  AUC-train 0.893\n",
            "Stats - Epoch: 29 AUC-val 0.581  AUC-train 0.889\n",
            "Stats - Epoch: 30 AUC-val 0.580  AUC-train 0.891\n",
            "Stats - Epoch: 31 AUC-val 0.571  AUC-train 0.895\n",
            "Stats - Epoch: 32 AUC-val 0.602  AUC-train 0.897\n",
            "Stats - Epoch: 33 AUC-val 0.616  AUC-train 0.904\n",
            "Stats - Epoch: 34 AUC-val 0.617  AUC-train 0.906\n",
            "Stats - Epoch: 35 AUC-val 0.632  AUC-train 0.907\n",
            "Stats - Epoch: 36 AUC-val 0.614  AUC-train 0.905\n",
            "Stats - Epoch: 37 AUC-val 0.584  AUC-train 0.908\n",
            "Stats - Epoch: 38 AUC-val 0.631  AUC-train 0.906\n",
            "Stats - Epoch: 39 AUC-val 0.640  AUC-train 0.906\n",
            "Stats - Epoch: 40 AUC-val 0.634  AUC-train 0.910\n",
            "Stats - Epoch: 41 AUC-val 0.714  AUC-train 0.914\n",
            "Stats - Epoch: 42 AUC-val 0.647  AUC-train 0.914\n",
            "Stats - Epoch: 43 AUC-val 0.619  AUC-train 0.916\n",
            "Stats - Epoch: 44 AUC-val 0.673  AUC-train 0.915\n",
            "Stats - Epoch: 45 AUC-val 0.655  AUC-train 0.918\n",
            "Stats - Epoch: 46 AUC-val 0.669  AUC-train 0.915\n",
            "Stats - Epoch: 47 AUC-val 0.658  AUC-train 0.917\n",
            "Stats - Epoch: 48 AUC-val 0.650  AUC-train 0.920\n",
            "Stats - Epoch: 49 AUC-val 0.621  AUC-train 0.915\n",
            "Stats - Epoch: 50 AUC-val 0.635  AUC-train 0.915\n",
            "Results 50 AUC-val 0.714 0.688 0.589 0.507 0.576 AUC-train 0.914\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.276  AUC-train 0.572\n",
            "Stats - Epoch: 2 AUC-val 0.414  AUC-train 0.727\n",
            "Stats - Epoch: 3 AUC-val 0.542  AUC-train 0.800\n",
            "Stats - Epoch: 4 AUC-val 0.592  AUC-train 0.824\n",
            "Stats - Epoch: 5 AUC-val 0.626  AUC-train 0.844\n",
            "Stats - Epoch: 6 AUC-val 0.644  AUC-train 0.861\n",
            "Stats - Epoch: 7 AUC-val 0.652  AUC-train 0.871\n",
            "Stats - Epoch: 8 AUC-val 0.655  AUC-train 0.888\n",
            "Stats - Epoch: 9 AUC-val 0.667  AUC-train 0.898\n",
            "Stats - Epoch: 10 AUC-val 0.667  AUC-train 0.907\n",
            "Stats - Epoch: 11 AUC-val 0.693  AUC-train 0.914\n",
            "Stats - Epoch: 12 AUC-val 0.690  AUC-train 0.919\n",
            "Stats - Epoch: 13 AUC-val 0.686  AUC-train 0.927\n",
            "Stats - Epoch: 14 AUC-val 0.698  AUC-train 0.930\n",
            "Stats - Epoch: 15 AUC-val 0.681  AUC-train 0.935\n",
            "Stats - Epoch: 16 AUC-val 0.672  AUC-train 0.934\n",
            "Stats - Epoch: 17 AUC-val 0.687  AUC-train 0.943\n",
            "Stats - Epoch: 18 AUC-val 0.683  AUC-train 0.946\n",
            "Stats - Epoch: 19 AUC-val 0.683  AUC-train 0.951\n",
            "Stats - Epoch: 20 AUC-val 0.669  AUC-train 0.956\n",
            "Stats - Epoch: 21 AUC-val 0.681  AUC-train 0.961\n",
            "Stats - Epoch: 22 AUC-val 0.684  AUC-train 0.959\n",
            "Stats - Epoch: 23 AUC-val 0.690  AUC-train 0.965\n",
            "Stats - Epoch: 24 AUC-val 0.667  AUC-train 0.964\n",
            "Stats - Epoch: 25 AUC-val 0.675  AUC-train 0.966\n",
            "Stats - Epoch: 26 AUC-val 0.673  AUC-train 0.968\n",
            "Stats - Epoch: 27 AUC-val 0.677  AUC-train 0.971\n",
            "Stats - Epoch: 28 AUC-val 0.677  AUC-train 0.973\n",
            "Stats - Epoch: 29 AUC-val 0.682  AUC-train 0.973\n",
            "Stats - Epoch: 30 AUC-val 0.672  AUC-train 0.974\n",
            "Stats - Epoch: 31 AUC-val 0.685  AUC-train 0.975\n",
            "Stats - Epoch: 32 AUC-val 0.675  AUC-train 0.976\n",
            "Stats - Epoch: 33 AUC-val 0.669  AUC-train 0.978\n",
            "Stats - Epoch: 34 AUC-val 0.677  AUC-train 0.979\n",
            "Stats - Epoch: 35 AUC-val 0.675  AUC-train 0.976\n",
            "Stats - Epoch: 36 AUC-val 0.662  AUC-train 0.976\n",
            "Stats - Epoch: 37 AUC-val 0.671  AUC-train 0.978\n",
            "Stats - Epoch: 38 AUC-val 0.667  AUC-train 0.981\n",
            "Stats - Epoch: 39 AUC-val 0.657  AUC-train 0.980\n",
            "Stats - Epoch: 40 AUC-val 0.666  AUC-train 0.982\n",
            "Stats - Epoch: 41 AUC-val 0.685  AUC-train 0.981\n",
            "Stats - Epoch: 42 AUC-val 0.669  AUC-train 0.982\n",
            "Stats - Epoch: 43 AUC-val 0.667  AUC-train 0.982\n",
            "Stats - Epoch: 44 AUC-val 0.660  AUC-train 0.984\n",
            "Stats - Epoch: 45 AUC-val 0.682  AUC-train 0.983\n",
            "Stats - Epoch: 46 AUC-val 0.678  AUC-train 0.986\n",
            "Stats - Epoch: 47 AUC-val 0.659  AUC-train 0.983\n",
            "Stats - Epoch: 48 AUC-val 0.671  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.676  AUC-train 0.983\n",
            "Stats - Epoch: 50 AUC-val 0.660  AUC-train 0.983\n",
            "Results 50 AUC-val 0.698 0.677 0.687 0.586 0.637 AUC-train 0.930\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.347  AUC-train 0.557\n",
            "Stats - Epoch: 2 AUC-val 0.450  AUC-train 0.708\n",
            "Stats - Epoch: 3 AUC-val 0.534  AUC-train 0.788\n",
            "Stats - Epoch: 4 AUC-val 0.557  AUC-train 0.824\n",
            "Stats - Epoch: 5 AUC-val 0.573  AUC-train 0.838\n",
            "Stats - Epoch: 6 AUC-val 0.583  AUC-train 0.850\n",
            "Stats - Epoch: 7 AUC-val 0.609  AUC-train 0.867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 8 AUC-val 0.603  AUC-train 0.882\n",
            "Stats - Epoch: 9 AUC-val 0.636  AUC-train 0.891\n",
            "Stats - Epoch: 10 AUC-val 0.632  AUC-train 0.902\n",
            "Stats - Epoch: 11 AUC-val 0.632  AUC-train 0.912\n",
            "Stats - Epoch: 12 AUC-val 0.636  AUC-train 0.917\n",
            "Stats - Epoch: 13 AUC-val 0.622  AUC-train 0.926\n",
            "Stats - Epoch: 14 AUC-val 0.634  AUC-train 0.932\n",
            "Stats - Epoch: 15 AUC-val 0.630  AUC-train 0.938\n",
            "Stats - Epoch: 16 AUC-val 0.627  AUC-train 0.944\n",
            "Stats - Epoch: 17 AUC-val 0.648  AUC-train 0.948\n",
            "Stats - Epoch: 18 AUC-val 0.645  AUC-train 0.949\n",
            "Stats - Epoch: 19 AUC-val 0.655  AUC-train 0.954\n",
            "Stats - Epoch: 20 AUC-val 0.635  AUC-train 0.960\n",
            "Stats - Epoch: 21 AUC-val 0.641  AUC-train 0.963\n",
            "Stats - Epoch: 22 AUC-val 0.645  AUC-train 0.968\n",
            "Stats - Epoch: 23 AUC-val 0.650  AUC-train 0.970\n",
            "Stats - Epoch: 24 AUC-val 0.654  AUC-train 0.972\n",
            "Stats - Epoch: 25 AUC-val 0.657  AUC-train 0.975\n",
            "Stats - Epoch: 26 AUC-val 0.666  AUC-train 0.978\n",
            "Stats - Epoch: 27 AUC-val 0.651  AUC-train 0.979\n",
            "Stats - Epoch: 28 AUC-val 0.660  AUC-train 0.983\n",
            "Stats - Epoch: 29 AUC-val 0.645  AUC-train 0.984\n",
            "Stats - Epoch: 30 AUC-val 0.646  AUC-train 0.984\n",
            "Stats - Epoch: 31 AUC-val 0.662  AUC-train 0.987\n",
            "Stats - Epoch: 32 AUC-val 0.624  AUC-train 0.987\n",
            "Stats - Epoch: 33 AUC-val 0.647  AUC-train 0.988\n",
            "Stats - Epoch: 34 AUC-val 0.638  AUC-train 0.990\n",
            "Stats - Epoch: 35 AUC-val 0.672  AUC-train 0.990\n",
            "Stats - Epoch: 36 AUC-val 0.653  AUC-train 0.989\n",
            "Stats - Epoch: 37 AUC-val 0.628  AUC-train 0.993\n",
            "Stats - Epoch: 38 AUC-val 0.640  AUC-train 0.991\n",
            "Stats - Epoch: 39 AUC-val 0.650  AUC-train 0.992\n",
            "Stats - Epoch: 40 AUC-val 0.638  AUC-train 0.992\n",
            "Stats - Epoch: 41 AUC-val 0.648  AUC-train 0.994\n",
            "Stats - Epoch: 42 AUC-val 0.645  AUC-train 0.993\n",
            "Stats - Epoch: 43 AUC-val 0.665  AUC-train 0.995\n",
            "Stats - Epoch: 44 AUC-val 0.632  AUC-train 0.995\n",
            "Stats - Epoch: 45 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 46 AUC-val 0.645  AUC-train 0.993\n",
            "Stats - Epoch: 47 AUC-val 0.643  AUC-train 0.994\n",
            "Stats - Epoch: 48 AUC-val 0.678  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 50 AUC-val 0.650  AUC-train 0.994\n",
            "Results 50 AUC-val 0.678 0.726 0.719 0.519 0.504 AUC-train 0.995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVJZ5JAVtapw",
        "outputId": "b1d73f8d-c5fe-4b4e-84ae-355f4e6fb75a"
      },
      "source": [
        "   # Seq\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/seq_robu_units_rep50_epochs100.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    reps=50;\n",
        "    epochs = 100;\n",
        "    fcast_horizon=1;\n",
        "    for units in range(1,21): #\n",
        "        dates =[1970,1999,2000,2016] #[1970,2016]\n",
        "        train_end_year=dates[1];\n",
        "        train_start_year=dates[0];\n",
        "        test_start_year=dates[2]; # Define test set\n",
        "        test_end_year=dates[3];\n",
        "        \n",
        "    \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "        \n",
        "        f.write(sequential_evaluation(units=units,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,reg_weight=[0.0],nlags=1,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=1,reps=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();     \n",
        "        f.write(sequential_evaluation(units=units,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=0,reg_weight=[0.0],nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=1,reps=1,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();     \n",
        "        f.write(sequential_evaluation(units=units,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=2,nlags=1,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(units=units,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=2,nlags=5,reg_weight=[0.01,0,0,0.01],df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(units=units,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=3,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(units=units,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=4,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "        f.write(sequential_evaluation(units=units,test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=5,df=df3,fcast_horizon=fcast_horizon,epochs=epochs,reps=reps,do_shapley=True));\n",
        "        f.write(\"\\n\");f.flush();        \n",
        "\n",
        "\n",
        "        #f.write(cross_validation2(timestep=timestep,reps=reps,mm=3,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(timestep=timestep,reps=reps,mm=4,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        #f.write(cross_validation2(timestep=timestep,reps=reps,mm=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True));\n",
        "        #f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "\n",
        "    \n",
        "    f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.284  AUC-train 0.520\n",
            "Stats - Epoch: 2 AUC-val 0.291  AUC-train 0.513\n",
            "Stats - Epoch: 3 AUC-val 0.311  AUC-train 0.530\n",
            "Stats - Epoch: 4 AUC-val 0.318  AUC-train 0.543\n",
            "Stats - Epoch: 5 AUC-val 0.342  AUC-train 0.557\n",
            "Stats - Epoch: 6 AUC-val 0.343  AUC-train 0.567\n",
            "Stats - Epoch: 7 AUC-val 0.352  AUC-train 0.575\n",
            "Stats - Epoch: 8 AUC-val 0.372  AUC-train 0.587\n",
            "Stats - Epoch: 9 AUC-val 0.377  AUC-train 0.595\n",
            "Stats - Epoch: 10 AUC-val 0.378  AUC-train 0.602\n",
            "Stats - Epoch: 11 AUC-val 0.395  AUC-train 0.609\n",
            "Stats - Epoch: 12 AUC-val 0.400  AUC-train 0.618\n",
            "Stats - Epoch: 13 AUC-val 0.403  AUC-train 0.626\n",
            "Stats - Epoch: 14 AUC-val 0.403  AUC-train 0.633\n",
            "Stats - Epoch: 15 AUC-val 0.416  AUC-train 0.641\n",
            "Stats - Epoch: 16 AUC-val 0.421  AUC-train 0.646\n",
            "Stats - Epoch: 17 AUC-val 0.429  AUC-train 0.650\n",
            "Stats - Epoch: 18 AUC-val 0.433  AUC-train 0.654\n",
            "Stats - Epoch: 19 AUC-val 0.439  AUC-train 0.656\n",
            "Stats - Epoch: 20 AUC-val 0.434  AUC-train 0.657\n",
            "Stats - Epoch: 21 AUC-val 0.439  AUC-train 0.660\n",
            "Stats - Epoch: 22 AUC-val 0.442  AUC-train 0.663\n",
            "Stats - Epoch: 23 AUC-val 0.448  AUC-train 0.664\n",
            "Stats - Epoch: 24 AUC-val 0.448  AUC-train 0.667\n",
            "Stats - Epoch: 25 AUC-val 0.450  AUC-train 0.668\n",
            "Stats - Epoch: 26 AUC-val 0.453  AUC-train 0.669\n",
            "Stats - Epoch: 27 AUC-val 0.459  AUC-train 0.675\n",
            "Stats - Epoch: 28 AUC-val 0.456  AUC-train 0.683\n",
            "Stats - Epoch: 29 AUC-val 0.455  AUC-train 0.692\n",
            "Stats - Epoch: 30 AUC-val 0.454  AUC-train 0.693\n",
            "Stats - Epoch: 31 AUC-val 0.459  AUC-train 0.689\n",
            "Stats - Epoch: 32 AUC-val 0.460  AUC-train 0.695\n",
            "Stats - Epoch: 33 AUC-val 0.460  AUC-train 0.692\n",
            "Stats - Epoch: 34 AUC-val 0.460  AUC-train 0.697\n",
            "Stats - Epoch: 35 AUC-val 0.464  AUC-train 0.698\n",
            "Stats - Epoch: 36 AUC-val 0.472  AUC-train 0.697\n",
            "Stats - Epoch: 37 AUC-val 0.473  AUC-train 0.699\n",
            "Stats - Epoch: 38 AUC-val 0.469  AUC-train 0.703\n",
            "Stats - Epoch: 39 AUC-val 0.469  AUC-train 0.705\n",
            "Stats - Epoch: 40 AUC-val 0.469  AUC-train 0.705\n",
            "Stats - Epoch: 41 AUC-val 0.472  AUC-train 0.707\n",
            "Stats - Epoch: 42 AUC-val 0.476  AUC-train 0.711\n",
            "Stats - Epoch: 43 AUC-val 0.471  AUC-train 0.712\n",
            "Stats - Epoch: 44 AUC-val 0.473  AUC-train 0.714\n",
            "Stats - Epoch: 45 AUC-val 0.474  AUC-train 0.718\n",
            "Stats - Epoch: 46 AUC-val 0.471  AUC-train 0.722\n",
            "Stats - Epoch: 47 AUC-val 0.477  AUC-train 0.724\n",
            "Stats - Epoch: 48 AUC-val 0.475  AUC-train 0.725\n",
            "Stats - Epoch: 49 AUC-val 0.475  AUC-train 0.727\n",
            "Stats - Epoch: 50 AUC-val 0.476  AUC-train 0.731\n",
            "Stats - Epoch: 51 AUC-val 0.479  AUC-train 0.733\n",
            "Stats - Epoch: 52 AUC-val 0.481  AUC-train 0.736\n",
            "Stats - Epoch: 53 AUC-val 0.481  AUC-train 0.735\n",
            "Stats - Epoch: 54 AUC-val 0.485  AUC-train 0.737\n",
            "Stats - Epoch: 55 AUC-val 0.484  AUC-train 0.738\n",
            "Stats - Epoch: 56 AUC-val 0.485  AUC-train 0.741\n",
            "Stats - Epoch: 57 AUC-val 0.486  AUC-train 0.741\n",
            "Stats - Epoch: 58 AUC-val 0.485  AUC-train 0.742\n",
            "Stats - Epoch: 59 AUC-val 0.488  AUC-train 0.738\n",
            "Stats - Epoch: 60 AUC-val 0.487  AUC-train 0.740\n",
            "Stats - Epoch: 61 AUC-val 0.484  AUC-train 0.739\n",
            "Stats - Epoch: 62 AUC-val 0.483  AUC-train 0.739\n",
            "Stats - Epoch: 63 AUC-val 0.488  AUC-train 0.742\n",
            "Stats - Epoch: 64 AUC-val 0.482  AUC-train 0.739\n",
            "Stats - Epoch: 65 AUC-val 0.486  AUC-train 0.740\n",
            "Stats - Epoch: 66 AUC-val 0.484  AUC-train 0.742\n",
            "Stats - Epoch: 67 AUC-val 0.487  AUC-train 0.740\n",
            "Stats - Epoch: 68 AUC-val 0.488  AUC-train 0.740\n",
            "Stats - Epoch: 69 AUC-val 0.486  AUC-train 0.742\n",
            "Stats - Epoch: 70 AUC-val 0.488  AUC-train 0.742\n",
            "Stats - Epoch: 71 AUC-val 0.486  AUC-train 0.742\n",
            "Stats - Epoch: 72 AUC-val 0.492  AUC-train 0.743\n",
            "Stats - Epoch: 73 AUC-val 0.493  AUC-train 0.740\n",
            "Stats - Epoch: 74 AUC-val 0.495  AUC-train 0.742\n",
            "Stats - Epoch: 75 AUC-val 0.487  AUC-train 0.742\n",
            "Stats - Epoch: 76 AUC-val 0.495  AUC-train 0.744\n",
            "Stats - Epoch: 77 AUC-val 0.494  AUC-train 0.744\n",
            "Stats - Epoch: 78 AUC-val 0.497  AUC-train 0.744\n",
            "Stats - Epoch: 79 AUC-val 0.493  AUC-train 0.745\n",
            "Stats - Epoch: 80 AUC-val 0.492  AUC-train 0.745\n",
            "Stats - Epoch: 81 AUC-val 0.493  AUC-train 0.745\n",
            "Stats - Epoch: 82 AUC-val 0.491  AUC-train 0.747\n",
            "Stats - Epoch: 83 AUC-val 0.494  AUC-train 0.748\n",
            "Stats - Epoch: 84 AUC-val 0.494  AUC-train 0.745\n",
            "Stats - Epoch: 85 AUC-val 0.491  AUC-train 0.747\n",
            "Stats - Epoch: 86 AUC-val 0.496  AUC-train 0.747\n",
            "Stats - Epoch: 87 AUC-val 0.492  AUC-train 0.749\n",
            "Stats - Epoch: 88 AUC-val 0.492  AUC-train 0.748\n",
            "Stats - Epoch: 89 AUC-val 0.491  AUC-train 0.749\n",
            "Stats - Epoch: 90 AUC-val 0.495  AUC-train 0.750\n",
            "Stats - Epoch: 91 AUC-val 0.500  AUC-train 0.749\n",
            "Stats - Epoch: 92 AUC-val 0.500  AUC-train 0.747\n",
            "Stats - Epoch: 93 AUC-val 0.502  AUC-train 0.749\n",
            "Stats - Epoch: 94 AUC-val 0.498  AUC-train 0.751\n",
            "Stats - Epoch: 95 AUC-val 0.500  AUC-train 0.748\n",
            "Stats - Epoch: 96 AUC-val 0.497  AUC-train 0.749\n",
            "Stats - Epoch: 97 AUC-val 0.500  AUC-train 0.750\n",
            "Stats - Epoch: 98 AUC-val 0.501  AUC-train 0.750\n",
            "Stats - Epoch: 99 AUC-val 0.504  AUC-train 0.750\n",
            "Stats - Epoch: 100 AUC-val 0.501  AUC-train 0.751\n",
            "Results 100 AUC-val 0.504 0.474 0.533 0.441 0.626 AUC-train 0.750\n",
            "Shapley [0.00305695 0.00339688 0.01560943 0.00703684 0.00360404] [0.01764532]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.189359\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.135  AUC-train 0.503\n",
            "Stats - Epoch: 2 AUC-val 0.183  AUC-train 0.546\n",
            "Stats - Epoch: 3 AUC-val 0.203  AUC-train 0.585\n",
            "Stats - Epoch: 4 AUC-val 0.203  AUC-train 0.607\n",
            "Stats - Epoch: 5 AUC-val 0.225  AUC-train 0.632\n",
            "Stats - Epoch: 6 AUC-val 0.248  AUC-train 0.649\n",
            "Stats - Epoch: 7 AUC-val 0.265  AUC-train 0.654\n",
            "Stats - Epoch: 8 AUC-val 0.265  AUC-train 0.662\n",
            "Stats - Epoch: 9 AUC-val 0.272  AUC-train 0.673\n",
            "Stats - Epoch: 10 AUC-val 0.272  AUC-train 0.678\n",
            "Stats - Epoch: 11 AUC-val 0.277  AUC-train 0.682\n",
            "Stats - Epoch: 12 AUC-val 0.271  AUC-train 0.693\n",
            "Stats - Epoch: 13 AUC-val 0.275  AUC-train 0.700\n",
            "Stats - Epoch: 14 AUC-val 0.273  AUC-train 0.705\n",
            "Stats - Epoch: 15 AUC-val 0.274  AUC-train 0.714\n",
            "Stats - Epoch: 16 AUC-val 0.300  AUC-train 0.715\n",
            "Stats - Epoch: 17 AUC-val 0.312  AUC-train 0.713\n",
            "Stats - Epoch: 18 AUC-val 0.308  AUC-train 0.720\n",
            "Stats - Epoch: 19 AUC-val 0.298  AUC-train 0.723\n",
            "Stats - Epoch: 20 AUC-val 0.307  AUC-train 0.722\n",
            "Stats - Epoch: 21 AUC-val 0.292  AUC-train 0.731\n",
            "Stats - Epoch: 22 AUC-val 0.320  AUC-train 0.737\n",
            "Stats - Epoch: 23 AUC-val 0.303  AUC-train 0.739\n",
            "Stats - Epoch: 24 AUC-val 0.316  AUC-train 0.742\n",
            "Stats - Epoch: 25 AUC-val 0.325  AUC-train 0.740\n",
            "Stats - Epoch: 26 AUC-val 0.295  AUC-train 0.750\n",
            "Stats - Epoch: 27 AUC-val 0.355  AUC-train 0.749\n",
            "Stats - Epoch: 28 AUC-val 0.348  AUC-train 0.751\n",
            "Stats - Epoch: 29 AUC-val 0.339  AUC-train 0.754\n",
            "Stats - Epoch: 30 AUC-val 0.340  AUC-train 0.757\n",
            "Stats - Epoch: 31 AUC-val 0.323  AUC-train 0.758\n",
            "Stats - Epoch: 32 AUC-val 0.328  AUC-train 0.760\n",
            "Stats - Epoch: 33 AUC-val 0.327  AUC-train 0.762\n",
            "Stats - Epoch: 34 AUC-val 0.360  AUC-train 0.757\n",
            "Stats - Epoch: 35 AUC-val 0.352  AUC-train 0.761\n",
            "Stats - Epoch: 36 AUC-val 0.357  AUC-train 0.755\n",
            "Stats - Epoch: 37 AUC-val 0.352  AUC-train 0.762\n",
            "Stats - Epoch: 38 AUC-val 0.351  AUC-train 0.760\n",
            "Stats - Epoch: 39 AUC-val 0.352  AUC-train 0.760\n",
            "Stats - Epoch: 40 AUC-val 0.350  AUC-train 0.762\n",
            "Stats - Epoch: 41 AUC-val 0.385  AUC-train 0.758\n",
            "Stats - Epoch: 42 AUC-val 0.374  AUC-train 0.765\n",
            "Stats - Epoch: 43 AUC-val 0.352  AUC-train 0.763\n",
            "Stats - Epoch: 44 AUC-val 0.348  AUC-train 0.765\n",
            "Stats - Epoch: 45 AUC-val 0.357  AUC-train 0.764\n",
            "Stats - Epoch: 46 AUC-val 0.352  AUC-train 0.767\n",
            "Stats - Epoch: 47 AUC-val 0.397  AUC-train 0.761\n",
            "Stats - Epoch: 48 AUC-val 0.383  AUC-train 0.759\n",
            "Stats - Epoch: 49 AUC-val 0.389  AUC-train 0.761\n",
            "Stats - Epoch: 50 AUC-val 0.386  AUC-train 0.761\n",
            "Stats - Epoch: 51 AUC-val 0.375  AUC-train 0.765\n",
            "Stats - Epoch: 52 AUC-val 0.376  AUC-train 0.766\n",
            "Stats - Epoch: 53 AUC-val 0.375  AUC-train 0.769\n",
            "Stats - Epoch: 54 AUC-val 0.390  AUC-train 0.766\n",
            "Stats - Epoch: 55 AUC-val 0.391  AUC-train 0.769\n",
            "Stats - Epoch: 56 AUC-val 0.392  AUC-train 0.766\n",
            "Stats - Epoch: 57 AUC-val 0.383  AUC-train 0.768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.369  AUC-train 0.771\n",
            "Stats - Epoch: 59 AUC-val 0.370  AUC-train 0.771\n",
            "Stats - Epoch: 60 AUC-val 0.371  AUC-train 0.772\n",
            "Stats - Epoch: 61 AUC-val 0.364  AUC-train 0.772\n",
            "Stats - Epoch: 62 AUC-val 0.378  AUC-train 0.769\n",
            "Stats - Epoch: 63 AUC-val 0.380  AUC-train 0.771\n",
            "Stats - Epoch: 64 AUC-val 0.369  AUC-train 0.771\n",
            "Stats - Epoch: 65 AUC-val 0.381  AUC-train 0.771\n",
            "Stats - Epoch: 66 AUC-val 0.358  AUC-train 0.773\n",
            "Stats - Epoch: 67 AUC-val 0.389  AUC-train 0.772\n",
            "Stats - Epoch: 68 AUC-val 0.409  AUC-train 0.761\n",
            "Stats - Epoch: 69 AUC-val 0.392  AUC-train 0.768\n",
            "Stats - Epoch: 70 AUC-val 0.377  AUC-train 0.765\n",
            "Stats - Epoch: 71 AUC-val 0.403  AUC-train 0.764\n",
            "Stats - Epoch: 72 AUC-val 0.382  AUC-train 0.766\n",
            "Stats - Epoch: 73 AUC-val 0.410  AUC-train 0.766\n",
            "Stats - Epoch: 74 AUC-val 0.417  AUC-train 0.775\n",
            "Stats - Epoch: 75 AUC-val 0.417  AUC-train 0.773\n",
            "Stats - Epoch: 76 AUC-val 0.373  AUC-train 0.776\n",
            "Stats - Epoch: 77 AUC-val 0.428  AUC-train 0.777\n",
            "Stats - Epoch: 78 AUC-val 0.438  AUC-train 0.775\n",
            "Stats - Epoch: 79 AUC-val 0.397  AUC-train 0.781\n",
            "Stats - Epoch: 80 AUC-val 0.401  AUC-train 0.784\n",
            "Stats - Epoch: 81 AUC-val 0.378  AUC-train 0.789\n",
            "Stats - Epoch: 82 AUC-val 0.388  AUC-train 0.790\n",
            "Stats - Epoch: 83 AUC-val 0.388  AUC-train 0.787\n",
            "Stats - Epoch: 84 AUC-val 0.419  AUC-train 0.786\n",
            "Stats - Epoch: 85 AUC-val 0.397  AUC-train 0.785\n",
            "Stats - Epoch: 86 AUC-val 0.406  AUC-train 0.786\n",
            "Stats - Epoch: 87 AUC-val 0.412  AUC-train 0.786\n",
            "Stats - Epoch: 88 AUC-val 0.384  AUC-train 0.788\n",
            "Stats - Epoch: 89 AUC-val 0.398  AUC-train 0.787\n",
            "Stats - Epoch: 90 AUC-val 0.390  AUC-train 0.787\n",
            "Stats - Epoch: 91 AUC-val 0.375  AUC-train 0.789\n",
            "Stats - Epoch: 92 AUC-val 0.388  AUC-train 0.787\n",
            "Stats - Epoch: 93 AUC-val 0.397  AUC-train 0.790\n",
            "Stats - Epoch: 94 AUC-val 0.400  AUC-train 0.786\n",
            "Stats - Epoch: 95 AUC-val 0.396  AUC-train 0.784\n",
            "Stats - Epoch: 96 AUC-val 0.425  AUC-train 0.779\n",
            "Stats - Epoch: 97 AUC-val 0.386  AUC-train 0.784\n",
            "Stats - Epoch: 98 AUC-val 0.390  AUC-train 0.783\n",
            "Stats - Epoch: 99 AUC-val 0.420  AUC-train 0.779\n",
            "Stats - Epoch: 100 AUC-val 0.397  AUC-train 0.784\n",
            "Results 100 AUC-val 0.438 0.331 0.411 0.582 0.791 AUC-train 0.775\n",
            "Shapley [0.01067589 0.00633362 0.00220989 0.01481922 0.00574994] [0.02243363]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.175441\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.294  AUC-train 0.541\n",
            "Stats - Epoch: 2 AUC-val 0.255  AUC-train 0.547\n",
            "Stats - Epoch: 3 AUC-val 0.224  AUC-train 0.547\n",
            "Stats - Epoch: 4 AUC-val 0.212  AUC-train 0.547\n",
            "Stats - Epoch: 5 AUC-val 0.221  AUC-train 0.555\n",
            "Stats - Epoch: 6 AUC-val 0.234  AUC-train 0.544\n",
            "Stats - Epoch: 7 AUC-val 0.234  AUC-train 0.551\n",
            "Stats - Epoch: 8 AUC-val 0.226  AUC-train 0.552\n",
            "Stats - Epoch: 9 AUC-val 0.218  AUC-train 0.557\n",
            "Stats - Epoch: 10 AUC-val 0.249  AUC-train 0.563\n",
            "Stats - Epoch: 11 AUC-val 0.249  AUC-train 0.569\n",
            "Stats - Epoch: 12 AUC-val 0.278  AUC-train 0.569\n",
            "Stats - Epoch: 13 AUC-val 0.303  AUC-train 0.577\n",
            "Stats - Epoch: 14 AUC-val 0.282  AUC-train 0.589\n",
            "Stats - Epoch: 15 AUC-val 0.282  AUC-train 0.599\n",
            "Stats - Epoch: 16 AUC-val 0.313  AUC-train 0.599\n",
            "Stats - Epoch: 17 AUC-val 0.310  AUC-train 0.613\n",
            "Stats - Epoch: 18 AUC-val 0.328  AUC-train 0.628\n",
            "Stats - Epoch: 19 AUC-val 0.314  AUC-train 0.633\n",
            "Stats - Epoch: 20 AUC-val 0.326  AUC-train 0.642\n",
            "Stats - Epoch: 21 AUC-val 0.358  AUC-train 0.647\n",
            "Stats - Epoch: 22 AUC-val 0.367  AUC-train 0.656\n",
            "Stats - Epoch: 23 AUC-val 0.407  AUC-train 0.664\n",
            "Stats - Epoch: 24 AUC-val 0.424  AUC-train 0.673\n",
            "Stats - Epoch: 25 AUC-val 0.417  AUC-train 0.673\n",
            "Stats - Epoch: 26 AUC-val 0.448  AUC-train 0.680\n",
            "Stats - Epoch: 27 AUC-val 0.413  AUC-train 0.689\n",
            "Stats - Epoch: 28 AUC-val 0.446  AUC-train 0.691\n",
            "Stats - Epoch: 29 AUC-val 0.469  AUC-train 0.692\n",
            "Stats - Epoch: 30 AUC-val 0.443  AUC-train 0.693\n",
            "Stats - Epoch: 31 AUC-val 0.447  AUC-train 0.697\n",
            "Stats - Epoch: 32 AUC-val 0.428  AUC-train 0.698\n",
            "Stats - Epoch: 33 AUC-val 0.491  AUC-train 0.704\n",
            "Stats - Epoch: 34 AUC-val 0.438  AUC-train 0.707\n",
            "Stats - Epoch: 35 AUC-val 0.481  AUC-train 0.709\n",
            "Stats - Epoch: 36 AUC-val 0.463  AUC-train 0.706\n",
            "Stats - Epoch: 37 AUC-val 0.454  AUC-train 0.712\n",
            "Stats - Epoch: 38 AUC-val 0.465  AUC-train 0.716\n",
            "Stats - Epoch: 39 AUC-val 0.451  AUC-train 0.722\n",
            "Stats - Epoch: 40 AUC-val 0.454  AUC-train 0.720\n",
            "Stats - Epoch: 41 AUC-val 0.473  AUC-train 0.722\n",
            "Stats - Epoch: 42 AUC-val 0.472  AUC-train 0.722\n",
            "Stats - Epoch: 43 AUC-val 0.467  AUC-train 0.721\n",
            "Stats - Epoch: 44 AUC-val 0.515  AUC-train 0.726\n",
            "Stats - Epoch: 45 AUC-val 0.478  AUC-train 0.727\n",
            "Stats - Epoch: 46 AUC-val 0.536  AUC-train 0.732\n",
            "Stats - Epoch: 47 AUC-val 0.466  AUC-train 0.736\n",
            "Stats - Epoch: 48 AUC-val 0.564  AUC-train 0.734\n",
            "Stats - Epoch: 49 AUC-val 0.541  AUC-train 0.737\n",
            "Stats - Epoch: 50 AUC-val 0.513  AUC-train 0.736\n",
            "Stats - Epoch: 51 AUC-val 0.472  AUC-train 0.737\n",
            "Stats - Epoch: 52 AUC-val 0.464  AUC-train 0.740\n",
            "Stats - Epoch: 53 AUC-val 0.486  AUC-train 0.738\n",
            "Stats - Epoch: 54 AUC-val 0.463  AUC-train 0.741\n",
            "Stats - Epoch: 55 AUC-val 0.469  AUC-train 0.740\n",
            "Stats - Epoch: 56 AUC-val 0.447  AUC-train 0.745\n",
            "Stats - Epoch: 57 AUC-val 0.450  AUC-train 0.745\n",
            "Stats - Epoch: 58 AUC-val 0.458  AUC-train 0.746\n",
            "Stats - Epoch: 59 AUC-val 0.452  AUC-train 0.743\n",
            "Stats - Epoch: 60 AUC-val 0.520  AUC-train 0.748\n",
            "Stats - Epoch: 61 AUC-val 0.491  AUC-train 0.750\n",
            "Stats - Epoch: 62 AUC-val 0.514  AUC-train 0.748\n",
            "Stats - Epoch: 63 AUC-val 0.483  AUC-train 0.752\n",
            "Stats - Epoch: 64 AUC-val 0.542  AUC-train 0.750\n",
            "Stats - Epoch: 65 AUC-val 0.498  AUC-train 0.749\n",
            "Stats - Epoch: 66 AUC-val 0.502  AUC-train 0.754\n",
            "Stats - Epoch: 67 AUC-val 0.478  AUC-train 0.750\n",
            "Stats - Epoch: 68 AUC-val 0.480  AUC-train 0.748\n",
            "Stats - Epoch: 69 AUC-val 0.494  AUC-train 0.752\n",
            "Stats - Epoch: 70 AUC-val 0.502  AUC-train 0.750\n",
            "Stats - Epoch: 71 AUC-val 0.499  AUC-train 0.750\n",
            "Stats - Epoch: 72 AUC-val 0.502  AUC-train 0.750\n",
            "Stats - Epoch: 73 AUC-val 0.509  AUC-train 0.752\n",
            "Stats - Epoch: 74 AUC-val 0.495  AUC-train 0.748\n",
            "Stats - Epoch: 75 AUC-val 0.495  AUC-train 0.749\n",
            "Stats - Epoch: 76 AUC-val 0.499  AUC-train 0.752\n",
            "Stats - Epoch: 77 AUC-val 0.504  AUC-train 0.752\n",
            "Stats - Epoch: 78 AUC-val 0.515  AUC-train 0.750\n",
            "Stats - Epoch: 79 AUC-val 0.523  AUC-train 0.752\n",
            "Stats - Epoch: 80 AUC-val 0.526  AUC-train 0.751\n",
            "Stats - Epoch: 81 AUC-val 0.500  AUC-train 0.750\n",
            "Stats - Epoch: 82 AUC-val 0.510  AUC-train 0.753\n",
            "Stats - Epoch: 83 AUC-val 0.489  AUC-train 0.753\n",
            "Stats - Epoch: 84 AUC-val 0.515  AUC-train 0.751\n",
            "Stats - Epoch: 85 AUC-val 0.500  AUC-train 0.754\n",
            "Stats - Epoch: 86 AUC-val 0.488  AUC-train 0.752\n",
            "Stats - Epoch: 87 AUC-val 0.510  AUC-train 0.751\n",
            "Stats - Epoch: 88 AUC-val 0.508  AUC-train 0.752\n",
            "Stats - Epoch: 89 AUC-val 0.497  AUC-train 0.753\n",
            "Stats - Epoch: 90 AUC-val 0.508  AUC-train 0.753\n",
            "Stats - Epoch: 91 AUC-val 0.501  AUC-train 0.754\n",
            "Stats - Epoch: 92 AUC-val 0.516  AUC-train 0.752\n",
            "Stats - Epoch: 93 AUC-val 0.517  AUC-train 0.750\n",
            "Stats - Epoch: 94 AUC-val 0.527  AUC-train 0.754\n",
            "Stats - Epoch: 95 AUC-val 0.524  AUC-train 0.754\n",
            "Stats - Epoch: 96 AUC-val 0.523  AUC-train 0.758\n",
            "Stats - Epoch: 97 AUC-val 0.514  AUC-train 0.756\n",
            "Stats - Epoch: 98 AUC-val 0.516  AUC-train 0.758\n",
            "Stats - Epoch: 99 AUC-val 0.533  AUC-train 0.758\n",
            "Stats - Epoch: 100 AUC-val 0.542  AUC-train 0.759\n",
            "Results 100 AUC-val 0.564 0.587 0.603 0.544 0.688 AUC-train 0.734\n",
            "Shapley [0.00270676 0.00395379 0.00865444 0.00504538 0.00251904] [0.0200891]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.183839\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.437  AUC-train 0.506\n",
            "Stats - Epoch: 2 AUC-val 0.331  AUC-train 0.515\n",
            "Stats - Epoch: 3 AUC-val 0.392  AUC-train 0.522\n",
            "Stats - Epoch: 4 AUC-val 0.450  AUC-train 0.546\n",
            "Stats - Epoch: 5 AUC-val 0.508  AUC-train 0.552\n",
            "Stats - Epoch: 6 AUC-val 0.579  AUC-train 0.562\n",
            "Stats - Epoch: 7 AUC-val 0.596  AUC-train 0.600\n",
            "Stats - Epoch: 8 AUC-val 0.618  AUC-train 0.636\n",
            "Stats - Epoch: 9 AUC-val 0.674  AUC-train 0.670\n",
            "Stats - Epoch: 10 AUC-val 0.624  AUC-train 0.703\n",
            "Stats - Epoch: 11 AUC-val 0.630  AUC-train 0.735\n",
            "Stats - Epoch: 12 AUC-val 0.645  AUC-train 0.750\n",
            "Stats - Epoch: 13 AUC-val 0.650  AUC-train 0.761\n",
            "Stats - Epoch: 14 AUC-val 0.655  AUC-train 0.768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.655  AUC-train 0.771\n",
            "Stats - Epoch: 16 AUC-val 0.607  AUC-train 0.774\n",
            "Stats - Epoch: 17 AUC-val 0.610  AUC-train 0.779\n",
            "Stats - Epoch: 18 AUC-val 0.625  AUC-train 0.781\n",
            "Stats - Epoch: 19 AUC-val 0.620  AUC-train 0.781\n",
            "Stats - Epoch: 20 AUC-val 0.605  AUC-train 0.783\n",
            "Stats - Epoch: 21 AUC-val 0.583  AUC-train 0.784\n",
            "Stats - Epoch: 22 AUC-val 0.746  AUC-train 0.784\n",
            "Stats - Epoch: 23 AUC-val 0.646  AUC-train 0.784\n",
            "Stats - Epoch: 24 AUC-val 0.635  AUC-train 0.783\n",
            "Stats - Epoch: 25 AUC-val 0.651  AUC-train 0.785\n",
            "Stats - Epoch: 26 AUC-val 0.640  AUC-train 0.786\n",
            "Stats - Epoch: 27 AUC-val 0.648  AUC-train 0.785\n",
            "Stats - Epoch: 28 AUC-val 0.642  AUC-train 0.783\n",
            "Stats - Epoch: 29 AUC-val 0.648  AUC-train 0.782\n",
            "Stats - Epoch: 30 AUC-val 0.620  AUC-train 0.783\n",
            "Stats - Epoch: 31 AUC-val 0.647  AUC-train 0.782\n",
            "Stats - Epoch: 32 AUC-val 0.628  AUC-train 0.783\n",
            "Stats - Epoch: 33 AUC-val 0.640  AUC-train 0.782\n",
            "Stats - Epoch: 34 AUC-val 0.638  AUC-train 0.781\n",
            "Stats - Epoch: 35 AUC-val 0.619  AUC-train 0.779\n",
            "Stats - Epoch: 36 AUC-val 0.628  AUC-train 0.783\n",
            "Stats - Epoch: 37 AUC-val 0.616  AUC-train 0.782\n",
            "Stats - Epoch: 38 AUC-val 0.641  AUC-train 0.782\n",
            "Stats - Epoch: 39 AUC-val 0.641  AUC-train 0.782\n",
            "Stats - Epoch: 40 AUC-val 0.642  AUC-train 0.782\n",
            "Stats - Epoch: 41 AUC-val 0.632  AUC-train 0.782\n",
            "Stats - Epoch: 42 AUC-val 0.619  AUC-train 0.782\n",
            "Stats - Epoch: 43 AUC-val 0.605  AUC-train 0.779\n",
            "Stats - Epoch: 44 AUC-val 0.653  AUC-train 0.782\n",
            "Stats - Epoch: 45 AUC-val 0.653  AUC-train 0.783\n",
            "Stats - Epoch: 46 AUC-val 0.665  AUC-train 0.784\n",
            "Stats - Epoch: 47 AUC-val 0.687  AUC-train 0.782\n",
            "Stats - Epoch: 48 AUC-val 0.720  AUC-train 0.780\n",
            "Stats - Epoch: 49 AUC-val 0.691  AUC-train 0.782\n",
            "Stats - Epoch: 50 AUC-val 0.657  AUC-train 0.780\n",
            "Stats - Epoch: 51 AUC-val 0.663  AUC-train 0.781\n",
            "Stats - Epoch: 52 AUC-val 0.667  AUC-train 0.783\n",
            "Stats - Epoch: 53 AUC-val 0.678  AUC-train 0.777\n",
            "Stats - Epoch: 54 AUC-val 0.675  AUC-train 0.778\n",
            "Stats - Epoch: 55 AUC-val 0.655  AUC-train 0.779\n",
            "Stats - Epoch: 56 AUC-val 0.676  AUC-train 0.780\n",
            "Stats - Epoch: 57 AUC-val 0.676  AUC-train 0.780\n",
            "Stats - Epoch: 58 AUC-val 0.680  AUC-train 0.781\n",
            "Stats - Epoch: 59 AUC-val 0.664  AUC-train 0.780\n",
            "Stats - Epoch: 60 AUC-val 0.683  AUC-train 0.783\n",
            "Stats - Epoch: 61 AUC-val 0.688  AUC-train 0.781\n",
            "Stats - Epoch: 62 AUC-val 0.657  AUC-train 0.782\n",
            "Stats - Epoch: 63 AUC-val 0.652  AUC-train 0.782\n",
            "Stats - Epoch: 64 AUC-val 0.650  AUC-train 0.780\n",
            "Stats - Epoch: 65 AUC-val 0.650  AUC-train 0.781\n",
            "Stats - Epoch: 66 AUC-val 0.636  AUC-train 0.780\n",
            "Stats - Epoch: 67 AUC-val 0.630  AUC-train 0.780\n",
            "Stats - Epoch: 68 AUC-val 0.610  AUC-train 0.776\n",
            "Stats - Epoch: 69 AUC-val 0.680  AUC-train 0.776\n",
            "Stats - Epoch: 70 AUC-val 0.716  AUC-train 0.776\n",
            "Stats - Epoch: 71 AUC-val 0.683  AUC-train 0.779\n",
            "Stats - Epoch: 72 AUC-val 0.655  AUC-train 0.776\n",
            "Stats - Epoch: 73 AUC-val 0.630  AUC-train 0.779\n",
            "Stats - Epoch: 74 AUC-val 0.616  AUC-train 0.778\n",
            "Stats - Epoch: 75 AUC-val 0.616  AUC-train 0.779\n",
            "Stats - Epoch: 76 AUC-val 0.623  AUC-train 0.779\n",
            "Stats - Epoch: 77 AUC-val 0.612  AUC-train 0.778\n",
            "Stats - Epoch: 78 AUC-val 0.632  AUC-train 0.777\n",
            "Stats - Epoch: 79 AUC-val 0.641  AUC-train 0.777\n",
            "Stats - Epoch: 80 AUC-val 0.672  AUC-train 0.776\n",
            "Stats - Epoch: 81 AUC-val 0.646  AUC-train 0.779\n",
            "Stats - Epoch: 82 AUC-val 0.662  AUC-train 0.778\n",
            "Stats - Epoch: 83 AUC-val 0.642  AUC-train 0.779\n",
            "Stats - Epoch: 84 AUC-val 0.634  AUC-train 0.778\n",
            "Stats - Epoch: 85 AUC-val 0.607  AUC-train 0.779\n",
            "Stats - Epoch: 86 AUC-val 0.593  AUC-train 0.779\n",
            "Stats - Epoch: 87 AUC-val 0.615  AUC-train 0.779\n",
            "Stats - Epoch: 88 AUC-val 0.638  AUC-train 0.780\n",
            "Stats - Epoch: 89 AUC-val 0.638  AUC-train 0.780\n",
            "Stats - Epoch: 90 AUC-val 0.641  AUC-train 0.779\n",
            "Stats - Epoch: 91 AUC-val 0.650  AUC-train 0.780\n",
            "Stats - Epoch: 92 AUC-val 0.663  AUC-train 0.780\n",
            "Stats - Epoch: 93 AUC-val 0.645  AUC-train 0.778\n",
            "Stats - Epoch: 94 AUC-val 0.629  AUC-train 0.779\n",
            "Stats - Epoch: 95 AUC-val 0.650  AUC-train 0.777\n",
            "Stats - Epoch: 96 AUC-val 0.660  AUC-train 0.776\n",
            "Stats - Epoch: 97 AUC-val 0.667  AUC-train 0.778\n",
            "Stats - Epoch: 98 AUC-val 0.679  AUC-train 0.778\n",
            "Stats - Epoch: 99 AUC-val 0.662  AUC-train 0.777\n",
            "Stats - Epoch: 100 AUC-val 0.619  AUC-train 0.776\n",
            "Results 100 AUC-val 0.746 0.681 0.617 0.512 0.625 AUC-train 0.784\n",
            "Shapley [0.00530714 0.00667934 0.01627864 0.00528975 0.00308812] [0.02201782]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.189266\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.430  AUC-train 0.459\n",
            "Stats - Epoch: 2 AUC-val 0.476  AUC-train 0.457\n",
            "Stats - Epoch: 3 AUC-val 0.509  AUC-train 0.472\n",
            "Stats - Epoch: 4 AUC-val 0.577  AUC-train 0.478\n",
            "Stats - Epoch: 5 AUC-val 0.597  AUC-train 0.482\n",
            "Stats - Epoch: 6 AUC-val 0.586  AUC-train 0.490\n",
            "Stats - Epoch: 7 AUC-val 0.630  AUC-train 0.493\n",
            "Stats - Epoch: 8 AUC-val 0.613  AUC-train 0.497\n",
            "Stats - Epoch: 9 AUC-val 0.651  AUC-train 0.509\n",
            "Stats - Epoch: 10 AUC-val 0.635  AUC-train 0.513\n",
            "Stats - Epoch: 11 AUC-val 0.615  AUC-train 0.515\n",
            "Stats - Epoch: 12 AUC-val 0.622  AUC-train 0.523\n",
            "Stats - Epoch: 13 AUC-val 0.621  AUC-train 0.523\n",
            "Stats - Epoch: 14 AUC-val 0.621  AUC-train 0.529\n",
            "Stats - Epoch: 15 AUC-val 0.609  AUC-train 0.533\n",
            "Stats - Epoch: 16 AUC-val 0.614  AUC-train 0.539\n",
            "Stats - Epoch: 17 AUC-val 0.592  AUC-train 0.538\n",
            "Stats - Epoch: 18 AUC-val 0.603  AUC-train 0.546\n",
            "Stats - Epoch: 19 AUC-val 0.617  AUC-train 0.542\n",
            "Stats - Epoch: 20 AUC-val 0.589  AUC-train 0.548\n",
            "Stats - Epoch: 21 AUC-val 0.621  AUC-train 0.554\n",
            "Stats - Epoch: 22 AUC-val 0.595  AUC-train 0.564\n",
            "Stats - Epoch: 23 AUC-val 0.605  AUC-train 0.570\n",
            "Stats - Epoch: 24 AUC-val 0.608  AUC-train 0.569\n",
            "Stats - Epoch: 25 AUC-val 0.564  AUC-train 0.571\n",
            "Stats - Epoch: 26 AUC-val 0.618  AUC-train 0.578\n",
            "Stats - Epoch: 27 AUC-val 0.621  AUC-train 0.579\n",
            "Stats - Epoch: 28 AUC-val 0.590  AUC-train 0.580\n",
            "Stats - Epoch: 29 AUC-val 0.636  AUC-train 0.577\n",
            "Stats - Epoch: 30 AUC-val 0.612  AUC-train 0.580\n",
            "Stats - Epoch: 31 AUC-val 0.603  AUC-train 0.583\n",
            "Stats - Epoch: 32 AUC-val 0.628  AUC-train 0.590\n",
            "Stats - Epoch: 33 AUC-val 0.629  AUC-train 0.597\n",
            "Stats - Epoch: 34 AUC-val 0.642  AUC-train 0.606\n",
            "Stats - Epoch: 35 AUC-val 0.632  AUC-train 0.613\n",
            "Stats - Epoch: 36 AUC-val 0.663  AUC-train 0.610\n",
            "Stats - Epoch: 37 AUC-val 0.652  AUC-train 0.619\n",
            "Stats - Epoch: 38 AUC-val 0.673  AUC-train 0.612\n",
            "Stats - Epoch: 39 AUC-val 0.674  AUC-train 0.618\n",
            "Stats - Epoch: 40 AUC-val 0.686  AUC-train 0.622\n",
            "Stats - Epoch: 41 AUC-val 0.685  AUC-train 0.624\n",
            "Stats - Epoch: 42 AUC-val 0.670  AUC-train 0.625\n",
            "Stats - Epoch: 43 AUC-val 0.698  AUC-train 0.627\n",
            "Stats - Epoch: 44 AUC-val 0.646  AUC-train 0.627\n",
            "Stats - Epoch: 45 AUC-val 0.680  AUC-train 0.627\n",
            "Stats - Epoch: 46 AUC-val 0.690  AUC-train 0.630\n",
            "Stats - Epoch: 47 AUC-val 0.718  AUC-train 0.634\n",
            "Stats - Epoch: 48 AUC-val 0.673  AUC-train 0.632\n",
            "Stats - Epoch: 49 AUC-val 0.707  AUC-train 0.632\n",
            "Stats - Epoch: 50 AUC-val 0.695  AUC-train 0.636\n",
            "Stats - Epoch: 51 AUC-val 0.682  AUC-train 0.630\n",
            "Stats - Epoch: 52 AUC-val 0.686  AUC-train 0.634\n",
            "Stats - Epoch: 53 AUC-val 0.683  AUC-train 0.637\n",
            "Stats - Epoch: 54 AUC-val 0.698  AUC-train 0.636\n",
            "Stats - Epoch: 55 AUC-val 0.684  AUC-train 0.634\n",
            "Stats - Epoch: 56 AUC-val 0.668  AUC-train 0.641\n",
            "Stats - Epoch: 57 AUC-val 0.678  AUC-train 0.643\n",
            "Stats - Epoch: 58 AUC-val 0.697  AUC-train 0.645\n",
            "Stats - Epoch: 59 AUC-val 0.685  AUC-train 0.641\n",
            "Stats - Epoch: 60 AUC-val 0.678  AUC-train 0.644\n",
            "Stats - Epoch: 61 AUC-val 0.686  AUC-train 0.645\n",
            "Stats - Epoch: 62 AUC-val 0.637  AUC-train 0.649\n",
            "Stats - Epoch: 63 AUC-val 0.659  AUC-train 0.651\n",
            "Stats - Epoch: 64 AUC-val 0.657  AUC-train 0.655\n",
            "Stats - Epoch: 65 AUC-val 0.681  AUC-train 0.654\n",
            "Stats - Epoch: 66 AUC-val 0.681  AUC-train 0.657\n",
            "Stats - Epoch: 67 AUC-val 0.693  AUC-train 0.664\n",
            "Stats - Epoch: 68 AUC-val 0.671  AUC-train 0.662\n",
            "Stats - Epoch: 69 AUC-val 0.674  AUC-train 0.664\n",
            "Stats - Epoch: 70 AUC-val 0.685  AUC-train 0.671\n",
            "Stats - Epoch: 71 AUC-val 0.648  AUC-train 0.675\n",
            "Stats - Epoch: 72 AUC-val 0.643  AUC-train 0.676\n",
            "Stats - Epoch: 73 AUC-val 0.624  AUC-train 0.680\n",
            "Stats - Epoch: 74 AUC-val 0.619  AUC-train 0.683\n",
            "Stats - Epoch: 75 AUC-val 0.598  AUC-train 0.684\n",
            "Stats - Epoch: 76 AUC-val 0.611  AUC-train 0.687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.633  AUC-train 0.688\n",
            "Stats - Epoch: 78 AUC-val 0.627  AUC-train 0.695\n",
            "Stats - Epoch: 79 AUC-val 0.641  AUC-train 0.696\n",
            "Stats - Epoch: 80 AUC-val 0.612  AUC-train 0.691\n",
            "Stats - Epoch: 81 AUC-val 0.596  AUC-train 0.691\n",
            "Stats - Epoch: 82 AUC-val 0.641  AUC-train 0.686\n",
            "Stats - Epoch: 83 AUC-val 0.650  AUC-train 0.682\n",
            "Stats - Epoch: 84 AUC-val 0.637  AUC-train 0.688\n",
            "Stats - Epoch: 85 AUC-val 0.634  AUC-train 0.687\n",
            "Stats - Epoch: 86 AUC-val 0.645  AUC-train 0.691\n",
            "Stats - Epoch: 87 AUC-val 0.652  AUC-train 0.692\n",
            "Stats - Epoch: 88 AUC-val 0.652  AUC-train 0.690\n",
            "Stats - Epoch: 89 AUC-val 0.660  AUC-train 0.691\n",
            "Stats - Epoch: 90 AUC-val 0.679  AUC-train 0.692\n",
            "Stats - Epoch: 91 AUC-val 0.658  AUC-train 0.694\n",
            "Stats - Epoch: 92 AUC-val 0.654  AUC-train 0.695\n",
            "Stats - Epoch: 93 AUC-val 0.664  AUC-train 0.697\n",
            "Stats - Epoch: 94 AUC-val 0.669  AUC-train 0.699\n",
            "Stats - Epoch: 95 AUC-val 0.640  AUC-train 0.700\n",
            "Stats - Epoch: 96 AUC-val 0.657  AUC-train 0.709\n",
            "Stats - Epoch: 97 AUC-val 0.658  AUC-train 0.712\n",
            "Stats - Epoch: 98 AUC-val 0.661  AUC-train 0.717\n",
            "Stats - Epoch: 99 AUC-val 0.665  AUC-train 0.719\n",
            "Stats - Epoch: 100 AUC-val 0.649  AUC-train 0.724\n",
            "Results 100 AUC-val 0.718 0.650 0.672 0.481 0.547 AUC-train 0.634\n",
            "Shapley [0.00279205 0.00426508 0.00897106 0.00477185 0.00187475] [0.02677333]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.201793\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.309  AUC-train 0.526\n",
            "Stats - Epoch: 2 AUC-val 0.312  AUC-train 0.532\n",
            "Stats - Epoch: 3 AUC-val 0.336  AUC-train 0.541\n",
            "Stats - Epoch: 4 AUC-val 0.332  AUC-train 0.547\n",
            "Stats - Epoch: 5 AUC-val 0.338  AUC-train 0.572\n",
            "Stats - Epoch: 6 AUC-val 0.354  AUC-train 0.592\n",
            "Stats - Epoch: 7 AUC-val 0.362  AUC-train 0.602\n",
            "Stats - Epoch: 8 AUC-val 0.371  AUC-train 0.614\n",
            "Stats - Epoch: 9 AUC-val 0.380  AUC-train 0.627\n",
            "Stats - Epoch: 10 AUC-val 0.379  AUC-train 0.637\n",
            "Stats - Epoch: 11 AUC-val 0.387  AUC-train 0.651\n",
            "Stats - Epoch: 12 AUC-val 0.393  AUC-train 0.666\n",
            "Stats - Epoch: 13 AUC-val 0.400  AUC-train 0.675\n",
            "Stats - Epoch: 14 AUC-val 0.405  AUC-train 0.683\n",
            "Stats - Epoch: 15 AUC-val 0.416  AUC-train 0.694\n",
            "Stats - Epoch: 16 AUC-val 0.428  AUC-train 0.699\n",
            "Stats - Epoch: 17 AUC-val 0.423  AUC-train 0.708\n",
            "Stats - Epoch: 18 AUC-val 0.423  AUC-train 0.714\n",
            "Stats - Epoch: 19 AUC-val 0.429  AUC-train 0.723\n",
            "Stats - Epoch: 20 AUC-val 0.428  AUC-train 0.728\n",
            "Stats - Epoch: 21 AUC-val 0.431  AUC-train 0.734\n",
            "Stats - Epoch: 22 AUC-val 0.433  AUC-train 0.738\n",
            "Stats - Epoch: 23 AUC-val 0.439  AUC-train 0.743\n",
            "Stats - Epoch: 24 AUC-val 0.439  AUC-train 0.747\n",
            "Stats - Epoch: 25 AUC-val 0.443  AUC-train 0.747\n",
            "Stats - Epoch: 26 AUC-val 0.444  AUC-train 0.754\n",
            "Stats - Epoch: 27 AUC-val 0.450  AUC-train 0.754\n",
            "Stats - Epoch: 28 AUC-val 0.453  AUC-train 0.759\n",
            "Stats - Epoch: 29 AUC-val 0.450  AUC-train 0.761\n",
            "Stats - Epoch: 30 AUC-val 0.454  AUC-train 0.763\n",
            "Stats - Epoch: 31 AUC-val 0.455  AUC-train 0.768\n",
            "Stats - Epoch: 32 AUC-val 0.455  AUC-train 0.767\n",
            "Stats - Epoch: 33 AUC-val 0.456  AUC-train 0.773\n",
            "Stats - Epoch: 34 AUC-val 0.458  AUC-train 0.772\n",
            "Stats - Epoch: 35 AUC-val 0.460  AUC-train 0.774\n",
            "Stats - Epoch: 36 AUC-val 0.463  AUC-train 0.773\n",
            "Stats - Epoch: 37 AUC-val 0.463  AUC-train 0.775\n",
            "Stats - Epoch: 38 AUC-val 0.464  AUC-train 0.776\n",
            "Stats - Epoch: 39 AUC-val 0.465  AUC-train 0.778\n",
            "Stats - Epoch: 40 AUC-val 0.470  AUC-train 0.778\n",
            "Stats - Epoch: 41 AUC-val 0.467  AUC-train 0.779\n",
            "Stats - Epoch: 42 AUC-val 0.469  AUC-train 0.782\n",
            "Stats - Epoch: 43 AUC-val 0.471  AUC-train 0.778\n",
            "Stats - Epoch: 44 AUC-val 0.473  AUC-train 0.780\n",
            "Stats - Epoch: 45 AUC-val 0.472  AUC-train 0.783\n",
            "Stats - Epoch: 46 AUC-val 0.469  AUC-train 0.785\n",
            "Stats - Epoch: 47 AUC-val 0.475  AUC-train 0.785\n",
            "Stats - Epoch: 48 AUC-val 0.471  AUC-train 0.786\n",
            "Stats - Epoch: 49 AUC-val 0.472  AUC-train 0.786\n",
            "Stats - Epoch: 50 AUC-val 0.474  AUC-train 0.788\n",
            "Stats - Epoch: 51 AUC-val 0.471  AUC-train 0.789\n",
            "Stats - Epoch: 52 AUC-val 0.472  AUC-train 0.792\n",
            "Stats - Epoch: 53 AUC-val 0.472  AUC-train 0.792\n",
            "Stats - Epoch: 54 AUC-val 0.471  AUC-train 0.792\n",
            "Stats - Epoch: 55 AUC-val 0.469  AUC-train 0.793\n",
            "Stats - Epoch: 56 AUC-val 0.477  AUC-train 0.795\n",
            "Stats - Epoch: 57 AUC-val 0.476  AUC-train 0.794\n",
            "Stats - Epoch: 58 AUC-val 0.474  AUC-train 0.795\n",
            "Stats - Epoch: 59 AUC-val 0.476  AUC-train 0.794\n",
            "Stats - Epoch: 60 AUC-val 0.473  AUC-train 0.796\n",
            "Stats - Epoch: 61 AUC-val 0.472  AUC-train 0.795\n",
            "Stats - Epoch: 62 AUC-val 0.473  AUC-train 0.798\n",
            "Stats - Epoch: 63 AUC-val 0.483  AUC-train 0.796\n",
            "Stats - Epoch: 64 AUC-val 0.473  AUC-train 0.795\n",
            "Stats - Epoch: 65 AUC-val 0.477  AUC-train 0.798\n",
            "Stats - Epoch: 66 AUC-val 0.475  AUC-train 0.797\n",
            "Stats - Epoch: 67 AUC-val 0.475  AUC-train 0.797\n",
            "Stats - Epoch: 68 AUC-val 0.479  AUC-train 0.796\n",
            "Stats - Epoch: 69 AUC-val 0.478  AUC-train 0.799\n",
            "Stats - Epoch: 70 AUC-val 0.476  AUC-train 0.797\n",
            "Stats - Epoch: 71 AUC-val 0.478  AUC-train 0.797\n",
            "Stats - Epoch: 72 AUC-val 0.482  AUC-train 0.798\n",
            "Stats - Epoch: 73 AUC-val 0.482  AUC-train 0.797\n",
            "Stats - Epoch: 74 AUC-val 0.486  AUC-train 0.797\n",
            "Stats - Epoch: 75 AUC-val 0.478  AUC-train 0.800\n",
            "Stats - Epoch: 76 AUC-val 0.484  AUC-train 0.799\n",
            "Stats - Epoch: 77 AUC-val 0.484  AUC-train 0.800\n",
            "Stats - Epoch: 78 AUC-val 0.481  AUC-train 0.798\n",
            "Stats - Epoch: 79 AUC-val 0.481  AUC-train 0.800\n",
            "Stats - Epoch: 80 AUC-val 0.479  AUC-train 0.800\n",
            "Stats - Epoch: 81 AUC-val 0.484  AUC-train 0.800\n",
            "Stats - Epoch: 82 AUC-val 0.482  AUC-train 0.799\n",
            "Stats - Epoch: 83 AUC-val 0.483  AUC-train 0.801\n",
            "Stats - Epoch: 84 AUC-val 0.485  AUC-train 0.800\n",
            "Stats - Epoch: 85 AUC-val 0.485  AUC-train 0.800\n",
            "Stats - Epoch: 86 AUC-val 0.486  AUC-train 0.799\n",
            "Stats - Epoch: 87 AUC-val 0.481  AUC-train 0.798\n",
            "Stats - Epoch: 88 AUC-val 0.482  AUC-train 0.801\n",
            "Stats - Epoch: 89 AUC-val 0.485  AUC-train 0.801\n",
            "Stats - Epoch: 90 AUC-val 0.482  AUC-train 0.800\n",
            "Stats - Epoch: 91 AUC-val 0.484  AUC-train 0.801\n",
            "Stats - Epoch: 92 AUC-val 0.487  AUC-train 0.800\n",
            "Stats - Epoch: 93 AUC-val 0.485  AUC-train 0.800\n",
            "Stats - Epoch: 94 AUC-val 0.481  AUC-train 0.801\n",
            "Stats - Epoch: 95 AUC-val 0.488  AUC-train 0.798\n",
            "Stats - Epoch: 96 AUC-val 0.487  AUC-train 0.798\n",
            "Stats - Epoch: 97 AUC-val 0.487  AUC-train 0.799\n",
            "Stats - Epoch: 98 AUC-val 0.487  AUC-train 0.801\n",
            "Stats - Epoch: 99 AUC-val 0.492  AUC-train 0.798\n",
            "Stats - Epoch: 100 AUC-val 0.488  AUC-train 0.799\n",
            "Results 100 AUC-val 0.492 0.467 0.519 0.438 0.634 AUC-train 0.798\n",
            "Shapley [0.00360107 0.00520086 0.0196736  0.01004084 0.00477527] [0.0173198]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187659\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.247  AUC-train 0.493\n",
            "Stats - Epoch: 2 AUC-val 0.272  AUC-train 0.581\n",
            "Stats - Epoch: 3 AUC-val 0.287  AUC-train 0.644\n",
            "Stats - Epoch: 4 AUC-val 0.317  AUC-train 0.684\n",
            "Stats - Epoch: 5 AUC-val 0.340  AUC-train 0.718\n",
            "Stats - Epoch: 6 AUC-val 0.341  AUC-train 0.745\n",
            "Stats - Epoch: 7 AUC-val 0.343  AUC-train 0.762\n",
            "Stats - Epoch: 8 AUC-val 0.322  AUC-train 0.775\n",
            "Stats - Epoch: 9 AUC-val 0.328  AUC-train 0.787\n",
            "Stats - Epoch: 10 AUC-val 0.337  AUC-train 0.799\n",
            "Stats - Epoch: 11 AUC-val 0.316  AUC-train 0.806\n",
            "Stats - Epoch: 12 AUC-val 0.320  AUC-train 0.815\n",
            "Stats - Epoch: 13 AUC-val 0.314  AUC-train 0.822\n",
            "Stats - Epoch: 14 AUC-val 0.328  AUC-train 0.828\n",
            "Stats - Epoch: 15 AUC-val 0.331  AUC-train 0.832\n",
            "Stats - Epoch: 16 AUC-val 0.311  AUC-train 0.837\n",
            "Stats - Epoch: 17 AUC-val 0.344  AUC-train 0.841\n",
            "Stats - Epoch: 18 AUC-val 0.359  AUC-train 0.845\n",
            "Stats - Epoch: 19 AUC-val 0.352  AUC-train 0.857\n",
            "Stats - Epoch: 20 AUC-val 0.348  AUC-train 0.856\n",
            "Stats - Epoch: 21 AUC-val 0.336  AUC-train 0.868\n",
            "Stats - Epoch: 22 AUC-val 0.369  AUC-train 0.869\n",
            "Stats - Epoch: 23 AUC-val 0.332  AUC-train 0.876\n",
            "Stats - Epoch: 24 AUC-val 0.348  AUC-train 0.883\n",
            "Stats - Epoch: 25 AUC-val 0.352  AUC-train 0.876\n",
            "Stats - Epoch: 26 AUC-val 0.380  AUC-train 0.883\n",
            "Stats - Epoch: 27 AUC-val 0.366  AUC-train 0.880\n",
            "Stats - Epoch: 28 AUC-val 0.360  AUC-train 0.883\n",
            "Stats - Epoch: 29 AUC-val 0.360  AUC-train 0.889\n",
            "Stats - Epoch: 30 AUC-val 0.361  AUC-train 0.890\n",
            "Stats - Epoch: 31 AUC-val 0.388  AUC-train 0.890\n",
            "Stats - Epoch: 32 AUC-val 0.380  AUC-train 0.893\n",
            "Stats - Epoch: 33 AUC-val 0.379  AUC-train 0.896\n",
            "Stats - Epoch: 34 AUC-val 0.415  AUC-train 0.891\n",
            "Stats - Epoch: 35 AUC-val 0.393  AUC-train 0.893\n",
            "Stats - Epoch: 36 AUC-val 0.405  AUC-train 0.893\n",
            "Stats - Epoch: 37 AUC-val 0.402  AUC-train 0.892\n",
            "Stats - Epoch: 38 AUC-val 0.379  AUC-train 0.896\n",
            "Stats - Epoch: 39 AUC-val 0.428  AUC-train 0.893\n",
            "Stats - Epoch: 40 AUC-val 0.429  AUC-train 0.894\n",
            "Stats - Epoch: 41 AUC-val 0.434  AUC-train 0.896\n",
            "Stats - Epoch: 42 AUC-val 0.404  AUC-train 0.893\n",
            "Stats - Epoch: 43 AUC-val 0.421  AUC-train 0.892\n",
            "Stats - Epoch: 44 AUC-val 0.398  AUC-train 0.895\n",
            "Stats - Epoch: 45 AUC-val 0.422  AUC-train 0.895\n",
            "Stats - Epoch: 46 AUC-val 0.425  AUC-train 0.899\n",
            "Stats - Epoch: 47 AUC-val 0.423  AUC-train 0.894\n",
            "Stats - Epoch: 48 AUC-val 0.430  AUC-train 0.890\n",
            "Stats - Epoch: 49 AUC-val 0.418  AUC-train 0.891\n",
            "Stats - Epoch: 50 AUC-val 0.445  AUC-train 0.887\n",
            "Stats - Epoch: 51 AUC-val 0.413  AUC-train 0.894\n",
            "Stats - Epoch: 52 AUC-val 0.420  AUC-train 0.896\n",
            "Stats - Epoch: 53 AUC-val 0.429  AUC-train 0.896\n",
            "Stats - Epoch: 54 AUC-val 0.426  AUC-train 0.897\n",
            "Stats - Epoch: 55 AUC-val 0.413  AUC-train 0.897\n",
            "Stats - Epoch: 56 AUC-val 0.438  AUC-train 0.896\n",
            "Stats - Epoch: 57 AUC-val 0.399  AUC-train 0.893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.419  AUC-train 0.898\n",
            "Stats - Epoch: 59 AUC-val 0.405  AUC-train 0.892\n",
            "Stats - Epoch: 60 AUC-val 0.415  AUC-train 0.898\n",
            "Stats - Epoch: 61 AUC-val 0.414  AUC-train 0.897\n",
            "Stats - Epoch: 62 AUC-val 0.414  AUC-train 0.896\n",
            "Stats - Epoch: 63 AUC-val 0.438  AUC-train 0.899\n",
            "Stats - Epoch: 64 AUC-val 0.439  AUC-train 0.895\n",
            "Stats - Epoch: 65 AUC-val 0.394  AUC-train 0.900\n",
            "Stats - Epoch: 66 AUC-val 0.419  AUC-train 0.901\n",
            "Stats - Epoch: 67 AUC-val 0.405  AUC-train 0.900\n",
            "Stats - Epoch: 68 AUC-val 0.423  AUC-train 0.898\n",
            "Stats - Epoch: 69 AUC-val 0.431  AUC-train 0.901\n",
            "Stats - Epoch: 70 AUC-val 0.411  AUC-train 0.898\n",
            "Stats - Epoch: 71 AUC-val 0.402  AUC-train 0.905\n",
            "Stats - Epoch: 72 AUC-val 0.428  AUC-train 0.893\n",
            "Stats - Epoch: 73 AUC-val 0.440  AUC-train 0.894\n",
            "Stats - Epoch: 74 AUC-val 0.456  AUC-train 0.892\n",
            "Stats - Epoch: 75 AUC-val 0.432  AUC-train 0.894\n",
            "Stats - Epoch: 76 AUC-val 0.422  AUC-train 0.899\n",
            "Stats - Epoch: 77 AUC-val 0.457  AUC-train 0.898\n",
            "Stats - Epoch: 78 AUC-val 0.457  AUC-train 0.893\n",
            "Stats - Epoch: 79 AUC-val 0.442  AUC-train 0.899\n",
            "Stats - Epoch: 80 AUC-val 0.444  AUC-train 0.901\n",
            "Stats - Epoch: 81 AUC-val 0.427  AUC-train 0.900\n",
            "Stats - Epoch: 82 AUC-val 0.421  AUC-train 0.904\n",
            "Stats - Epoch: 83 AUC-val 0.435  AUC-train 0.896\n",
            "Stats - Epoch: 84 AUC-val 0.443  AUC-train 0.900\n",
            "Stats - Epoch: 85 AUC-val 0.444  AUC-train 0.900\n",
            "Stats - Epoch: 86 AUC-val 0.447  AUC-train 0.902\n",
            "Stats - Epoch: 87 AUC-val 0.434  AUC-train 0.904\n",
            "Stats - Epoch: 88 AUC-val 0.433  AUC-train 0.906\n",
            "Stats - Epoch: 89 AUC-val 0.451  AUC-train 0.900\n",
            "Stats - Epoch: 90 AUC-val 0.438  AUC-train 0.903\n",
            "Stats - Epoch: 91 AUC-val 0.453  AUC-train 0.905\n",
            "Stats - Epoch: 92 AUC-val 0.448  AUC-train 0.904\n",
            "Stats - Epoch: 93 AUC-val 0.431  AUC-train 0.903\n",
            "Stats - Epoch: 94 AUC-val 0.434  AUC-train 0.902\n",
            "Stats - Epoch: 95 AUC-val 0.403  AUC-train 0.894\n",
            "Stats - Epoch: 96 AUC-val 0.446  AUC-train 0.892\n",
            "Stats - Epoch: 97 AUC-val 0.411  AUC-train 0.898\n",
            "Stats - Epoch: 98 AUC-val 0.421  AUC-train 0.900\n",
            "Stats - Epoch: 99 AUC-val 0.464  AUC-train 0.889\n",
            "Stats - Epoch: 100 AUC-val 0.423  AUC-train 0.902\n",
            "Results 100 AUC-val 0.464 0.337 0.314 0.423 0.736 AUC-train 0.889\n",
            "Shapley [0.01915673 0.00741129 0.00436446 0.02742466 0.00768644] [0.02396826]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.181847\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.217  AUC-train 0.531\n",
            "Stats - Epoch: 2 AUC-val 0.221  AUC-train 0.544\n",
            "Stats - Epoch: 3 AUC-val 0.208  AUC-train 0.555\n",
            "Stats - Epoch: 4 AUC-val 0.217  AUC-train 0.562\n",
            "Stats - Epoch: 5 AUC-val 0.219  AUC-train 0.576\n",
            "Stats - Epoch: 6 AUC-val 0.224  AUC-train 0.584\n",
            "Stats - Epoch: 7 AUC-val 0.223  AUC-train 0.596\n",
            "Stats - Epoch: 8 AUC-val 0.218  AUC-train 0.615\n",
            "Stats - Epoch: 9 AUC-val 0.229  AUC-train 0.624\n",
            "Stats - Epoch: 10 AUC-val 0.285  AUC-train 0.641\n",
            "Stats - Epoch: 11 AUC-val 0.261  AUC-train 0.642\n",
            "Stats - Epoch: 12 AUC-val 0.297  AUC-train 0.656\n",
            "Stats - Epoch: 13 AUC-val 0.255  AUC-train 0.669\n",
            "Stats - Epoch: 14 AUC-val 0.394  AUC-train 0.681\n",
            "Stats - Epoch: 15 AUC-val 0.347  AUC-train 0.682\n",
            "Stats - Epoch: 16 AUC-val 0.450  AUC-train 0.696\n",
            "Stats - Epoch: 17 AUC-val 0.375  AUC-train 0.697\n",
            "Stats - Epoch: 18 AUC-val 0.393  AUC-train 0.698\n",
            "Stats - Epoch: 19 AUC-val 0.367  AUC-train 0.705\n",
            "Stats - Epoch: 20 AUC-val 0.450  AUC-train 0.712\n",
            "Stats - Epoch: 21 AUC-val 0.446  AUC-train 0.722\n",
            "Stats - Epoch: 22 AUC-val 0.445  AUC-train 0.727\n",
            "Stats - Epoch: 23 AUC-val 0.439  AUC-train 0.726\n",
            "Stats - Epoch: 24 AUC-val 0.481  AUC-train 0.727\n",
            "Stats - Epoch: 25 AUC-val 0.448  AUC-train 0.730\n",
            "Stats - Epoch: 26 AUC-val 0.458  AUC-train 0.735\n",
            "Stats - Epoch: 27 AUC-val 0.497  AUC-train 0.736\n",
            "Stats - Epoch: 28 AUC-val 0.510  AUC-train 0.744\n",
            "Stats - Epoch: 29 AUC-val 0.516  AUC-train 0.746\n",
            "Stats - Epoch: 30 AUC-val 0.553  AUC-train 0.748\n",
            "Stats - Epoch: 31 AUC-val 0.487  AUC-train 0.749\n",
            "Stats - Epoch: 32 AUC-val 0.558  AUC-train 0.754\n",
            "Stats - Epoch: 33 AUC-val 0.524  AUC-train 0.756\n",
            "Stats - Epoch: 34 AUC-val 0.461  AUC-train 0.758\n",
            "Stats - Epoch: 35 AUC-val 0.521  AUC-train 0.759\n",
            "Stats - Epoch: 36 AUC-val 0.506  AUC-train 0.759\n",
            "Stats - Epoch: 37 AUC-val 0.542  AUC-train 0.758\n",
            "Stats - Epoch: 38 AUC-val 0.519  AUC-train 0.761\n",
            "Stats - Epoch: 39 AUC-val 0.495  AUC-train 0.763\n",
            "Stats - Epoch: 40 AUC-val 0.514  AUC-train 0.764\n",
            "Stats - Epoch: 41 AUC-val 0.555  AUC-train 0.763\n",
            "Stats - Epoch: 42 AUC-val 0.539  AUC-train 0.763\n",
            "Stats - Epoch: 43 AUC-val 0.512  AUC-train 0.768\n",
            "Stats - Epoch: 44 AUC-val 0.531  AUC-train 0.768\n",
            "Stats - Epoch: 45 AUC-val 0.538  AUC-train 0.769\n",
            "Stats - Epoch: 46 AUC-val 0.514  AUC-train 0.772\n",
            "Stats - Epoch: 47 AUC-val 0.512  AUC-train 0.771\n",
            "Stats - Epoch: 48 AUC-val 0.498  AUC-train 0.772\n",
            "Stats - Epoch: 49 AUC-val 0.546  AUC-train 0.770\n",
            "Stats - Epoch: 50 AUC-val 0.568  AUC-train 0.770\n",
            "Stats - Epoch: 51 AUC-val 0.527  AUC-train 0.773\n",
            "Stats - Epoch: 52 AUC-val 0.544  AUC-train 0.773\n",
            "Stats - Epoch: 53 AUC-val 0.531  AUC-train 0.771\n",
            "Stats - Epoch: 54 AUC-val 0.531  AUC-train 0.772\n",
            "Stats - Epoch: 55 AUC-val 0.545  AUC-train 0.770\n",
            "Stats - Epoch: 56 AUC-val 0.560  AUC-train 0.770\n",
            "Stats - Epoch: 57 AUC-val 0.528  AUC-train 0.770\n",
            "Stats - Epoch: 58 AUC-val 0.570  AUC-train 0.768\n",
            "Stats - Epoch: 59 AUC-val 0.587  AUC-train 0.766\n",
            "Stats - Epoch: 60 AUC-val 0.553  AUC-train 0.771\n",
            "Stats - Epoch: 61 AUC-val 0.550  AUC-train 0.771\n",
            "Stats - Epoch: 62 AUC-val 0.548  AUC-train 0.768\n",
            "Stats - Epoch: 63 AUC-val 0.543  AUC-train 0.769\n",
            "Stats - Epoch: 64 AUC-val 0.554  AUC-train 0.766\n",
            "Stats - Epoch: 65 AUC-val 0.540  AUC-train 0.765\n",
            "Stats - Epoch: 66 AUC-val 0.544  AUC-train 0.767\n",
            "Stats - Epoch: 67 AUC-val 0.540  AUC-train 0.767\n",
            "Stats - Epoch: 68 AUC-val 0.521  AUC-train 0.769\n",
            "Stats - Epoch: 69 AUC-val 0.517  AUC-train 0.770\n",
            "Stats - Epoch: 70 AUC-val 0.514  AUC-train 0.773\n",
            "Stats - Epoch: 71 AUC-val 0.549  AUC-train 0.771\n",
            "Stats - Epoch: 72 AUC-val 0.559  AUC-train 0.770\n",
            "Stats - Epoch: 73 AUC-val 0.538  AUC-train 0.772\n",
            "Stats - Epoch: 74 AUC-val 0.529  AUC-train 0.773\n",
            "Stats - Epoch: 75 AUC-val 0.540  AUC-train 0.768\n",
            "Stats - Epoch: 76 AUC-val 0.527  AUC-train 0.772\n",
            "Stats - Epoch: 77 AUC-val 0.508  AUC-train 0.775\n",
            "Stats - Epoch: 78 AUC-val 0.510  AUC-train 0.775\n",
            "Stats - Epoch: 79 AUC-val 0.513  AUC-train 0.777\n",
            "Stats - Epoch: 80 AUC-val 0.537  AUC-train 0.774\n",
            "Stats - Epoch: 81 AUC-val 0.557  AUC-train 0.775\n",
            "Stats - Epoch: 82 AUC-val 0.523  AUC-train 0.779\n",
            "Stats - Epoch: 83 AUC-val 0.541  AUC-train 0.776\n",
            "Stats - Epoch: 84 AUC-val 0.533  AUC-train 0.777\n",
            "Stats - Epoch: 85 AUC-val 0.529  AUC-train 0.779\n",
            "Stats - Epoch: 86 AUC-val 0.548  AUC-train 0.774\n",
            "Stats - Epoch: 87 AUC-val 0.538  AUC-train 0.778\n",
            "Stats - Epoch: 88 AUC-val 0.527  AUC-train 0.777\n",
            "Stats - Epoch: 89 AUC-val 0.541  AUC-train 0.777\n",
            "Stats - Epoch: 90 AUC-val 0.556  AUC-train 0.776\n",
            "Stats - Epoch: 91 AUC-val 0.547  AUC-train 0.775\n",
            "Stats - Epoch: 92 AUC-val 0.556  AUC-train 0.774\n",
            "Stats - Epoch: 93 AUC-val 0.556  AUC-train 0.774\n",
            "Stats - Epoch: 94 AUC-val 0.530  AUC-train 0.777\n",
            "Stats - Epoch: 95 AUC-val 0.543  AUC-train 0.777\n",
            "Stats - Epoch: 96 AUC-val 0.559  AUC-train 0.771\n",
            "Stats - Epoch: 97 AUC-val 0.529  AUC-train 0.777\n",
            "Stats - Epoch: 98 AUC-val 0.529  AUC-train 0.776\n",
            "Stats - Epoch: 99 AUC-val 0.536  AUC-train 0.775\n",
            "Stats - Epoch: 100 AUC-val 0.533  AUC-train 0.775\n",
            "Results 100 AUC-val 0.587 0.572 0.583 0.514 0.680 AUC-train 0.766\n",
            "Shapley [0.00578791 0.0068223  0.00956863 0.00753799 0.00317473] [0.01321723]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188772\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.407  AUC-train 0.476\n",
            "Stats - Epoch: 2 AUC-val 0.391  AUC-train 0.531\n",
            "Stats - Epoch: 3 AUC-val 0.450  AUC-train 0.567\n",
            "Stats - Epoch: 4 AUC-val 0.548  AUC-train 0.611\n",
            "Stats - Epoch: 5 AUC-val 0.593  AUC-train 0.666\n",
            "Stats - Epoch: 6 AUC-val 0.603  AUC-train 0.709\n",
            "Stats - Epoch: 7 AUC-val 0.615  AUC-train 0.741\n",
            "Stats - Epoch: 8 AUC-val 0.638  AUC-train 0.762\n",
            "Stats - Epoch: 9 AUC-val 0.611  AUC-train 0.776\n",
            "Stats - Epoch: 10 AUC-val 0.646  AUC-train 0.783\n",
            "Stats - Epoch: 11 AUC-val 0.629  AUC-train 0.787\n",
            "Stats - Epoch: 12 AUC-val 0.637  AUC-train 0.790\n",
            "Stats - Epoch: 13 AUC-val 0.649  AUC-train 0.789\n",
            "Stats - Epoch: 14 AUC-val 0.646  AUC-train 0.794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.671  AUC-train 0.794\n",
            "Stats - Epoch: 16 AUC-val 0.660  AUC-train 0.795\n",
            "Stats - Epoch: 17 AUC-val 0.664  AUC-train 0.795\n",
            "Stats - Epoch: 18 AUC-val 0.675  AUC-train 0.794\n",
            "Stats - Epoch: 19 AUC-val 0.671  AUC-train 0.798\n",
            "Stats - Epoch: 20 AUC-val 0.670  AUC-train 0.796\n",
            "Stats - Epoch: 21 AUC-val 0.683  AUC-train 0.796\n",
            "Stats - Epoch: 22 AUC-val 0.690  AUC-train 0.794\n",
            "Stats - Epoch: 23 AUC-val 0.704  AUC-train 0.798\n",
            "Stats - Epoch: 24 AUC-val 0.686  AUC-train 0.795\n",
            "Stats - Epoch: 25 AUC-val 0.693  AUC-train 0.795\n",
            "Stats - Epoch: 26 AUC-val 0.684  AUC-train 0.794\n",
            "Stats - Epoch: 27 AUC-val 0.686  AUC-train 0.795\n",
            "Stats - Epoch: 28 AUC-val 0.681  AUC-train 0.795\n",
            "Stats - Epoch: 29 AUC-val 0.679  AUC-train 0.795\n",
            "Stats - Epoch: 30 AUC-val 0.684  AUC-train 0.794\n",
            "Stats - Epoch: 31 AUC-val 0.679  AUC-train 0.793\n",
            "Stats - Epoch: 32 AUC-val 0.686  AUC-train 0.793\n",
            "Stats - Epoch: 33 AUC-val 0.679  AUC-train 0.796\n",
            "Stats - Epoch: 34 AUC-val 0.682  AUC-train 0.793\n",
            "Stats - Epoch: 35 AUC-val 0.685  AUC-train 0.794\n",
            "Stats - Epoch: 36 AUC-val 0.694  AUC-train 0.792\n",
            "Stats - Epoch: 37 AUC-val 0.677  AUC-train 0.793\n",
            "Stats - Epoch: 38 AUC-val 0.674  AUC-train 0.794\n",
            "Stats - Epoch: 39 AUC-val 0.682  AUC-train 0.794\n",
            "Stats - Epoch: 40 AUC-val 0.675  AUC-train 0.796\n",
            "Stats - Epoch: 41 AUC-val 0.674  AUC-train 0.794\n",
            "Stats - Epoch: 42 AUC-val 0.671  AUC-train 0.793\n",
            "Stats - Epoch: 43 AUC-val 0.680  AUC-train 0.795\n",
            "Stats - Epoch: 44 AUC-val 0.681  AUC-train 0.794\n",
            "Stats - Epoch: 45 AUC-val 0.684  AUC-train 0.794\n",
            "Stats - Epoch: 46 AUC-val 0.681  AUC-train 0.794\n",
            "Stats - Epoch: 47 AUC-val 0.689  AUC-train 0.794\n",
            "Stats - Epoch: 48 AUC-val 0.672  AUC-train 0.795\n",
            "Stats - Epoch: 49 AUC-val 0.671  AUC-train 0.794\n",
            "Stats - Epoch: 50 AUC-val 0.693  AUC-train 0.791\n",
            "Stats - Epoch: 51 AUC-val 0.684  AUC-train 0.796\n",
            "Stats - Epoch: 52 AUC-val 0.691  AUC-train 0.799\n",
            "Stats - Epoch: 53 AUC-val 0.691  AUC-train 0.799\n",
            "Stats - Epoch: 54 AUC-val 0.683  AUC-train 0.799\n",
            "Stats - Epoch: 55 AUC-val 0.681  AUC-train 0.799\n",
            "Stats - Epoch: 56 AUC-val 0.701  AUC-train 0.800\n",
            "Stats - Epoch: 57 AUC-val 0.688  AUC-train 0.800\n",
            "Stats - Epoch: 58 AUC-val 0.690  AUC-train 0.803\n",
            "Stats - Epoch: 59 AUC-val 0.690  AUC-train 0.801\n",
            "Stats - Epoch: 60 AUC-val 0.686  AUC-train 0.802\n",
            "Stats - Epoch: 61 AUC-val 0.701  AUC-train 0.801\n",
            "Stats - Epoch: 62 AUC-val 0.708  AUC-train 0.802\n",
            "Stats - Epoch: 63 AUC-val 0.688  AUC-train 0.802\n",
            "Stats - Epoch: 64 AUC-val 0.691  AUC-train 0.798\n",
            "Stats - Epoch: 65 AUC-val 0.686  AUC-train 0.801\n",
            "Stats - Epoch: 66 AUC-val 0.671  AUC-train 0.801\n",
            "Stats - Epoch: 67 AUC-val 0.678  AUC-train 0.800\n",
            "Stats - Epoch: 68 AUC-val 0.680  AUC-train 0.801\n",
            "Stats - Epoch: 69 AUC-val 0.694  AUC-train 0.802\n",
            "Stats - Epoch: 70 AUC-val 0.684  AUC-train 0.802\n",
            "Stats - Epoch: 71 AUC-val 0.684  AUC-train 0.802\n",
            "Stats - Epoch: 72 AUC-val 0.673  AUC-train 0.801\n",
            "Stats - Epoch: 73 AUC-val 0.673  AUC-train 0.802\n",
            "Stats - Epoch: 74 AUC-val 0.690  AUC-train 0.803\n",
            "Stats - Epoch: 75 AUC-val 0.726  AUC-train 0.805\n",
            "Stats - Epoch: 76 AUC-val 0.728  AUC-train 0.805\n",
            "Stats - Epoch: 77 AUC-val 0.712  AUC-train 0.801\n",
            "Stats - Epoch: 78 AUC-val 0.722  AUC-train 0.803\n",
            "Stats - Epoch: 79 AUC-val 0.697  AUC-train 0.806\n",
            "Stats - Epoch: 80 AUC-val 0.694  AUC-train 0.805\n",
            "Stats - Epoch: 81 AUC-val 0.727  AUC-train 0.805\n",
            "Stats - Epoch: 82 AUC-val 0.728  AUC-train 0.807\n",
            "Stats - Epoch: 83 AUC-val 0.730  AUC-train 0.807\n",
            "Stats - Epoch: 84 AUC-val 0.731  AUC-train 0.808\n",
            "Stats - Epoch: 85 AUC-val 0.736  AUC-train 0.807\n",
            "Stats - Epoch: 86 AUC-val 0.734  AUC-train 0.810\n",
            "Stats - Epoch: 87 AUC-val 0.691  AUC-train 0.809\n",
            "Stats - Epoch: 88 AUC-val 0.708  AUC-train 0.810\n",
            "Stats - Epoch: 89 AUC-val 0.736  AUC-train 0.811\n",
            "Stats - Epoch: 90 AUC-val 0.732  AUC-train 0.812\n",
            "Stats - Epoch: 91 AUC-val 0.720  AUC-train 0.812\n",
            "Stats - Epoch: 92 AUC-val 0.713  AUC-train 0.813\n",
            "Stats - Epoch: 93 AUC-val 0.739  AUC-train 0.813\n",
            "Stats - Epoch: 94 AUC-val 0.746  AUC-train 0.812\n",
            "Stats - Epoch: 95 AUC-val 0.726  AUC-train 0.813\n",
            "Stats - Epoch: 96 AUC-val 0.740  AUC-train 0.815\n",
            "Stats - Epoch: 97 AUC-val 0.748  AUC-train 0.812\n",
            "Stats - Epoch: 98 AUC-val 0.722  AUC-train 0.811\n",
            "Stats - Epoch: 99 AUC-val 0.725  AUC-train 0.812\n",
            "Stats - Epoch: 100 AUC-val 0.724  AUC-train 0.813\n",
            "Results 100 AUC-val 0.748 0.623 0.563 0.522 0.636 AUC-train 0.812\n",
            "Shapley [0.00982278 0.011092   0.01808583 0.0100016  0.00241984] [0.01159394]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198502\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.595  AUC-train 0.452\n",
            "Stats - Epoch: 2 AUC-val 0.542  AUC-train 0.445\n",
            "Stats - Epoch: 3 AUC-val 0.614  AUC-train 0.467\n",
            "Stats - Epoch: 4 AUC-val 0.653  AUC-train 0.494\n",
            "Stats - Epoch: 5 AUC-val 0.662  AUC-train 0.518\n",
            "Stats - Epoch: 6 AUC-val 0.661  AUC-train 0.540\n",
            "Stats - Epoch: 7 AUC-val 0.669  AUC-train 0.552\n",
            "Stats - Epoch: 8 AUC-val 0.647  AUC-train 0.563\n",
            "Stats - Epoch: 9 AUC-val 0.658  AUC-train 0.577\n",
            "Stats - Epoch: 10 AUC-val 0.661  AUC-train 0.587\n",
            "Stats - Epoch: 11 AUC-val 0.673  AUC-train 0.595\n",
            "Stats - Epoch: 12 AUC-val 0.678  AUC-train 0.607\n",
            "Stats - Epoch: 13 AUC-val 0.655  AUC-train 0.621\n",
            "Stats - Epoch: 14 AUC-val 0.654  AUC-train 0.626\n",
            "Stats - Epoch: 15 AUC-val 0.649  AUC-train 0.642\n",
            "Stats - Epoch: 16 AUC-val 0.652  AUC-train 0.653\n",
            "Stats - Epoch: 17 AUC-val 0.637  AUC-train 0.651\n",
            "Stats - Epoch: 18 AUC-val 0.655  AUC-train 0.659\n",
            "Stats - Epoch: 19 AUC-val 0.639  AUC-train 0.662\n",
            "Stats - Epoch: 20 AUC-val 0.653  AUC-train 0.667\n",
            "Stats - Epoch: 21 AUC-val 0.636  AUC-train 0.677\n",
            "Stats - Epoch: 22 AUC-val 0.641  AUC-train 0.673\n",
            "Stats - Epoch: 23 AUC-val 0.650  AUC-train 0.684\n",
            "Stats - Epoch: 24 AUC-val 0.623  AUC-train 0.682\n",
            "Stats - Epoch: 25 AUC-val 0.630  AUC-train 0.692\n",
            "Stats - Epoch: 26 AUC-val 0.638  AUC-train 0.700\n",
            "Stats - Epoch: 27 AUC-val 0.612  AUC-train 0.700\n",
            "Stats - Epoch: 28 AUC-val 0.631  AUC-train 0.706\n",
            "Stats - Epoch: 29 AUC-val 0.630  AUC-train 0.713\n",
            "Stats - Epoch: 30 AUC-val 0.649  AUC-train 0.715\n",
            "Stats - Epoch: 31 AUC-val 0.612  AUC-train 0.715\n",
            "Stats - Epoch: 32 AUC-val 0.628  AUC-train 0.722\n",
            "Stats - Epoch: 33 AUC-val 0.633  AUC-train 0.722\n",
            "Stats - Epoch: 34 AUC-val 0.623  AUC-train 0.725\n",
            "Stats - Epoch: 35 AUC-val 0.616  AUC-train 0.730\n",
            "Stats - Epoch: 36 AUC-val 0.614  AUC-train 0.736\n",
            "Stats - Epoch: 37 AUC-val 0.627  AUC-train 0.742\n",
            "Stats - Epoch: 38 AUC-val 0.640  AUC-train 0.744\n",
            "Stats - Epoch: 39 AUC-val 0.627  AUC-train 0.738\n",
            "Stats - Epoch: 40 AUC-val 0.633  AUC-train 0.743\n",
            "Stats - Epoch: 41 AUC-val 0.650  AUC-train 0.744\n",
            "Stats - Epoch: 42 AUC-val 0.631  AUC-train 0.747\n",
            "Stats - Epoch: 43 AUC-val 0.636  AUC-train 0.747\n",
            "Stats - Epoch: 44 AUC-val 0.627  AUC-train 0.759\n",
            "Stats - Epoch: 45 AUC-val 0.634  AUC-train 0.757\n",
            "Stats - Epoch: 46 AUC-val 0.622  AUC-train 0.757\n",
            "Stats - Epoch: 47 AUC-val 0.636  AUC-train 0.757\n",
            "Stats - Epoch: 48 AUC-val 0.640  AUC-train 0.761\n",
            "Stats - Epoch: 49 AUC-val 0.652  AUC-train 0.763\n",
            "Stats - Epoch: 50 AUC-val 0.664  AUC-train 0.766\n",
            "Stats - Epoch: 51 AUC-val 0.640  AUC-train 0.765\n",
            "Stats - Epoch: 52 AUC-val 0.643  AUC-train 0.767\n",
            "Stats - Epoch: 53 AUC-val 0.622  AUC-train 0.769\n",
            "Stats - Epoch: 54 AUC-val 0.622  AUC-train 0.774\n",
            "Stats - Epoch: 55 AUC-val 0.601  AUC-train 0.769\n",
            "Stats - Epoch: 56 AUC-val 0.628  AUC-train 0.767\n",
            "Stats - Epoch: 57 AUC-val 0.621  AUC-train 0.771\n",
            "Stats - Epoch: 58 AUC-val 0.644  AUC-train 0.770\n",
            "Stats - Epoch: 59 AUC-val 0.614  AUC-train 0.772\n",
            "Stats - Epoch: 60 AUC-val 0.638  AUC-train 0.775\n",
            "Stats - Epoch: 61 AUC-val 0.633  AUC-train 0.776\n",
            "Stats - Epoch: 62 AUC-val 0.625  AUC-train 0.781\n",
            "Stats - Epoch: 63 AUC-val 0.630  AUC-train 0.779\n",
            "Stats - Epoch: 64 AUC-val 0.645  AUC-train 0.785\n",
            "Stats - Epoch: 65 AUC-val 0.641  AUC-train 0.792\n",
            "Stats - Epoch: 66 AUC-val 0.630  AUC-train 0.792\n",
            "Stats - Epoch: 67 AUC-val 0.604  AUC-train 0.789\n",
            "Stats - Epoch: 68 AUC-val 0.592  AUC-train 0.791\n",
            "Stats - Epoch: 69 AUC-val 0.604  AUC-train 0.796\n",
            "Stats - Epoch: 70 AUC-val 0.638  AUC-train 0.795\n",
            "Stats - Epoch: 71 AUC-val 0.621  AUC-train 0.797\n",
            "Stats - Epoch: 72 AUC-val 0.633  AUC-train 0.796\n",
            "Stats - Epoch: 73 AUC-val 0.616  AUC-train 0.801\n",
            "Stats - Epoch: 74 AUC-val 0.654  AUC-train 0.799\n",
            "Stats - Epoch: 75 AUC-val 0.626  AUC-train 0.799\n",
            "Stats - Epoch: 76 AUC-val 0.607  AUC-train 0.798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.611  AUC-train 0.804\n",
            "Stats - Epoch: 78 AUC-val 0.624  AUC-train 0.806\n",
            "Stats - Epoch: 79 AUC-val 0.650  AUC-train 0.810\n",
            "Stats - Epoch: 80 AUC-val 0.624  AUC-train 0.810\n",
            "Stats - Epoch: 81 AUC-val 0.626  AUC-train 0.811\n",
            "Stats - Epoch: 82 AUC-val 0.650  AUC-train 0.810\n",
            "Stats - Epoch: 83 AUC-val 0.629  AUC-train 0.812\n",
            "Stats - Epoch: 84 AUC-val 0.651  AUC-train 0.811\n",
            "Stats - Epoch: 85 AUC-val 0.625  AUC-train 0.811\n",
            "Stats - Epoch: 86 AUC-val 0.640  AUC-train 0.815\n",
            "Stats - Epoch: 87 AUC-val 0.635  AUC-train 0.816\n",
            "Stats - Epoch: 88 AUC-val 0.634  AUC-train 0.811\n",
            "Stats - Epoch: 89 AUC-val 0.618  AUC-train 0.813\n",
            "Stats - Epoch: 90 AUC-val 0.640  AUC-train 0.813\n",
            "Stats - Epoch: 91 AUC-val 0.655  AUC-train 0.813\n",
            "Stats - Epoch: 92 AUC-val 0.665  AUC-train 0.814\n",
            "Stats - Epoch: 93 AUC-val 0.630  AUC-train 0.812\n",
            "Stats - Epoch: 94 AUC-val 0.631  AUC-train 0.813\n",
            "Stats - Epoch: 95 AUC-val 0.651  AUC-train 0.816\n",
            "Stats - Epoch: 96 AUC-val 0.617  AUC-train 0.813\n",
            "Stats - Epoch: 97 AUC-val 0.650  AUC-train 0.816\n",
            "Stats - Epoch: 98 AUC-val 0.654  AUC-train 0.817\n",
            "Stats - Epoch: 99 AUC-val 0.622  AUC-train 0.820\n",
            "Stats - Epoch: 100 AUC-val 0.622  AUC-train 0.820\n",
            "Results 100 AUC-val 0.678 0.565 0.541 0.424 0.588 AUC-train 0.607\n",
            "Shapley [0.00296419 0.00791418 0.01040715 0.02391122 0.00581824] [0.04618684]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.194440\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.342  AUC-train 0.481\n",
            "Stats - Epoch: 2 AUC-val 0.389  AUC-train 0.504\n",
            "Stats - Epoch: 3 AUC-val 0.391  AUC-train 0.534\n",
            "Stats - Epoch: 4 AUC-val 0.412  AUC-train 0.561\n",
            "Stats - Epoch: 5 AUC-val 0.418  AUC-train 0.585\n",
            "Stats - Epoch: 6 AUC-val 0.414  AUC-train 0.605\n",
            "Stats - Epoch: 7 AUC-val 0.407  AUC-train 0.626\n",
            "Stats - Epoch: 8 AUC-val 0.423  AUC-train 0.636\n",
            "Stats - Epoch: 9 AUC-val 0.399  AUC-train 0.652\n",
            "Stats - Epoch: 10 AUC-val 0.411  AUC-train 0.667\n",
            "Stats - Epoch: 11 AUC-val 0.414  AUC-train 0.671\n",
            "Stats - Epoch: 12 AUC-val 0.417  AUC-train 0.688\n",
            "Stats - Epoch: 13 AUC-val 0.425  AUC-train 0.694\n",
            "Stats - Epoch: 14 AUC-val 0.432  AUC-train 0.700\n",
            "Stats - Epoch: 15 AUC-val 0.431  AUC-train 0.718\n",
            "Stats - Epoch: 16 AUC-val 0.424  AUC-train 0.714\n",
            "Stats - Epoch: 17 AUC-val 0.429  AUC-train 0.724\n",
            "Stats - Epoch: 18 AUC-val 0.433  AUC-train 0.729\n",
            "Stats - Epoch: 19 AUC-val 0.441  AUC-train 0.737\n",
            "Stats - Epoch: 20 AUC-val 0.439  AUC-train 0.745\n",
            "Stats - Epoch: 21 AUC-val 0.447  AUC-train 0.742\n",
            "Stats - Epoch: 22 AUC-val 0.454  AUC-train 0.746\n",
            "Stats - Epoch: 23 AUC-val 0.459  AUC-train 0.754\n",
            "Stats - Epoch: 24 AUC-val 0.452  AUC-train 0.760\n",
            "Stats - Epoch: 25 AUC-val 0.444  AUC-train 0.769\n",
            "Stats - Epoch: 26 AUC-val 0.448  AUC-train 0.770\n",
            "Stats - Epoch: 27 AUC-val 0.452  AUC-train 0.768\n",
            "Stats - Epoch: 28 AUC-val 0.465  AUC-train 0.768\n",
            "Stats - Epoch: 29 AUC-val 0.462  AUC-train 0.777\n",
            "Stats - Epoch: 30 AUC-val 0.471  AUC-train 0.781\n",
            "Stats - Epoch: 31 AUC-val 0.471  AUC-train 0.781\n",
            "Stats - Epoch: 32 AUC-val 0.471  AUC-train 0.783\n",
            "Stats - Epoch: 33 AUC-val 0.475  AUC-train 0.788\n",
            "Stats - Epoch: 34 AUC-val 0.476  AUC-train 0.789\n",
            "Stats - Epoch: 35 AUC-val 0.477  AUC-train 0.786\n",
            "Stats - Epoch: 36 AUC-val 0.481  AUC-train 0.785\n",
            "Stats - Epoch: 37 AUC-val 0.478  AUC-train 0.793\n",
            "Stats - Epoch: 38 AUC-val 0.483  AUC-train 0.789\n",
            "Stats - Epoch: 39 AUC-val 0.486  AUC-train 0.795\n",
            "Stats - Epoch: 40 AUC-val 0.488  AUC-train 0.799\n",
            "Stats - Epoch: 41 AUC-val 0.485  AUC-train 0.802\n",
            "Stats - Epoch: 42 AUC-val 0.485  AUC-train 0.802\n",
            "Stats - Epoch: 43 AUC-val 0.484  AUC-train 0.798\n",
            "Stats - Epoch: 44 AUC-val 0.491  AUC-train 0.796\n",
            "Stats - Epoch: 45 AUC-val 0.490  AUC-train 0.801\n",
            "Stats - Epoch: 46 AUC-val 0.489  AUC-train 0.806\n",
            "Stats - Epoch: 47 AUC-val 0.489  AUC-train 0.805\n",
            "Stats - Epoch: 48 AUC-val 0.489  AUC-train 0.802\n",
            "Stats - Epoch: 49 AUC-val 0.497  AUC-train 0.804\n",
            "Stats - Epoch: 50 AUC-val 0.493  AUC-train 0.807\n",
            "Stats - Epoch: 51 AUC-val 0.490  AUC-train 0.803\n",
            "Stats - Epoch: 52 AUC-val 0.493  AUC-train 0.808\n",
            "Stats - Epoch: 53 AUC-val 0.494  AUC-train 0.807\n",
            "Stats - Epoch: 54 AUC-val 0.491  AUC-train 0.806\n",
            "Stats - Epoch: 55 AUC-val 0.496  AUC-train 0.808\n",
            "Stats - Epoch: 56 AUC-val 0.496  AUC-train 0.804\n",
            "Stats - Epoch: 57 AUC-val 0.498  AUC-train 0.807\n",
            "Stats - Epoch: 58 AUC-val 0.497  AUC-train 0.806\n",
            "Stats - Epoch: 59 AUC-val 0.490  AUC-train 0.804\n",
            "Stats - Epoch: 60 AUC-val 0.495  AUC-train 0.809\n",
            "Stats - Epoch: 61 AUC-val 0.495  AUC-train 0.810\n",
            "Stats - Epoch: 62 AUC-val 0.495  AUC-train 0.810\n",
            "Stats - Epoch: 63 AUC-val 0.497  AUC-train 0.809\n",
            "Stats - Epoch: 64 AUC-val 0.492  AUC-train 0.808\n",
            "Stats - Epoch: 65 AUC-val 0.501  AUC-train 0.810\n",
            "Stats - Epoch: 66 AUC-val 0.499  AUC-train 0.809\n",
            "Stats - Epoch: 67 AUC-val 0.500  AUC-train 0.809\n",
            "Stats - Epoch: 68 AUC-val 0.501  AUC-train 0.811\n",
            "Stats - Epoch: 69 AUC-val 0.499  AUC-train 0.809\n",
            "Stats - Epoch: 70 AUC-val 0.495  AUC-train 0.811\n",
            "Stats - Epoch: 71 AUC-val 0.495  AUC-train 0.810\n",
            "Stats - Epoch: 72 AUC-val 0.500  AUC-train 0.807\n",
            "Stats - Epoch: 73 AUC-val 0.497  AUC-train 0.808\n",
            "Stats - Epoch: 74 AUC-val 0.500  AUC-train 0.810\n",
            "Stats - Epoch: 75 AUC-val 0.502  AUC-train 0.809\n",
            "Stats - Epoch: 76 AUC-val 0.502  AUC-train 0.811\n",
            "Stats - Epoch: 77 AUC-val 0.497  AUC-train 0.810\n",
            "Stats - Epoch: 78 AUC-val 0.497  AUC-train 0.810\n",
            "Stats - Epoch: 79 AUC-val 0.498  AUC-train 0.811\n",
            "Stats - Epoch: 80 AUC-val 0.495  AUC-train 0.809\n",
            "Stats - Epoch: 81 AUC-val 0.496  AUC-train 0.811\n",
            "Stats - Epoch: 82 AUC-val 0.495  AUC-train 0.812\n",
            "Stats - Epoch: 83 AUC-val 0.493  AUC-train 0.814\n",
            "Stats - Epoch: 84 AUC-val 0.491  AUC-train 0.811\n",
            "Stats - Epoch: 85 AUC-val 0.497  AUC-train 0.812\n",
            "Stats - Epoch: 86 AUC-val 0.499  AUC-train 0.812\n",
            "Stats - Epoch: 87 AUC-val 0.495  AUC-train 0.809\n",
            "Stats - Epoch: 88 AUC-val 0.495  AUC-train 0.812\n",
            "Stats - Epoch: 89 AUC-val 0.497  AUC-train 0.811\n",
            "Stats - Epoch: 90 AUC-val 0.497  AUC-train 0.814\n",
            "Stats - Epoch: 91 AUC-val 0.499  AUC-train 0.813\n",
            "Stats - Epoch: 92 AUC-val 0.495  AUC-train 0.811\n",
            "Stats - Epoch: 93 AUC-val 0.497  AUC-train 0.815\n",
            "Stats - Epoch: 94 AUC-val 0.498  AUC-train 0.814\n",
            "Stats - Epoch: 95 AUC-val 0.493  AUC-train 0.811\n",
            "Stats - Epoch: 96 AUC-val 0.497  AUC-train 0.815\n",
            "Stats - Epoch: 97 AUC-val 0.496  AUC-train 0.815\n",
            "Stats - Epoch: 98 AUC-val 0.496  AUC-train 0.816\n",
            "Stats - Epoch: 99 AUC-val 0.502  AUC-train 0.813\n",
            "Stats - Epoch: 100 AUC-val 0.499  AUC-train 0.815\n",
            "Results 100 AUC-val 0.502 0.488 0.538 0.456 0.632 AUC-train 0.809\n",
            "Shapley [0.00413252 0.005702   0.02007649 0.00935139 0.00500732] [0.01772536]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.185002\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.194  AUC-train 0.531\n",
            "Stats - Epoch: 2 AUC-val 0.259  AUC-train 0.624\n",
            "Stats - Epoch: 3 AUC-val 0.279  AUC-train 0.688\n",
            "Stats - Epoch: 4 AUC-val 0.306  AUC-train 0.739\n",
            "Stats - Epoch: 5 AUC-val 0.310  AUC-train 0.775\n",
            "Stats - Epoch: 6 AUC-val 0.323  AUC-train 0.802\n",
            "Stats - Epoch: 7 AUC-val 0.321  AUC-train 0.823\n",
            "Stats - Epoch: 8 AUC-val 0.310  AUC-train 0.839\n",
            "Stats - Epoch: 9 AUC-val 0.316  AUC-train 0.852\n",
            "Stats - Epoch: 10 AUC-val 0.310  AUC-train 0.860\n",
            "Stats - Epoch: 11 AUC-val 0.326  AUC-train 0.868\n",
            "Stats - Epoch: 12 AUC-val 0.321  AUC-train 0.878\n",
            "Stats - Epoch: 13 AUC-val 0.330  AUC-train 0.885\n",
            "Stats - Epoch: 14 AUC-val 0.319  AUC-train 0.895\n",
            "Stats - Epoch: 15 AUC-val 0.314  AUC-train 0.896\n",
            "Stats - Epoch: 16 AUC-val 0.339  AUC-train 0.898\n",
            "Stats - Epoch: 17 AUC-val 0.307  AUC-train 0.893\n",
            "Stats - Epoch: 18 AUC-val 0.348  AUC-train 0.902\n",
            "Stats - Epoch: 19 AUC-val 0.326  AUC-train 0.908\n",
            "Stats - Epoch: 20 AUC-val 0.325  AUC-train 0.908\n",
            "Stats - Epoch: 21 AUC-val 0.336  AUC-train 0.914\n",
            "Stats - Epoch: 22 AUC-val 0.355  AUC-train 0.912\n",
            "Stats - Epoch: 23 AUC-val 0.338  AUC-train 0.917\n",
            "Stats - Epoch: 24 AUC-val 0.344  AUC-train 0.919\n",
            "Stats - Epoch: 25 AUC-val 0.331  AUC-train 0.913\n",
            "Stats - Epoch: 26 AUC-val 0.341  AUC-train 0.917\n",
            "Stats - Epoch: 27 AUC-val 0.348  AUC-train 0.919\n",
            "Stats - Epoch: 28 AUC-val 0.337  AUC-train 0.916\n",
            "Stats - Epoch: 29 AUC-val 0.368  AUC-train 0.919\n",
            "Stats - Epoch: 30 AUC-val 0.366  AUC-train 0.925\n",
            "Stats - Epoch: 31 AUC-val 0.374  AUC-train 0.925\n",
            "Stats - Epoch: 32 AUC-val 0.360  AUC-train 0.929\n",
            "Stats - Epoch: 33 AUC-val 0.347  AUC-train 0.930\n",
            "Stats - Epoch: 34 AUC-val 0.371  AUC-train 0.924\n",
            "Stats - Epoch: 35 AUC-val 0.360  AUC-train 0.928\n",
            "Stats - Epoch: 36 AUC-val 0.379  AUC-train 0.928\n",
            "Stats - Epoch: 37 AUC-val 0.381  AUC-train 0.928\n",
            "Stats - Epoch: 38 AUC-val 0.369  AUC-train 0.934\n",
            "Stats - Epoch: 39 AUC-val 0.372  AUC-train 0.930\n",
            "Stats - Epoch: 40 AUC-val 0.372  AUC-train 0.931\n",
            "Stats - Epoch: 41 AUC-val 0.367  AUC-train 0.930\n",
            "Stats - Epoch: 42 AUC-val 0.390  AUC-train 0.931\n",
            "Stats - Epoch: 43 AUC-val 0.375  AUC-train 0.925\n",
            "Stats - Epoch: 44 AUC-val 0.395  AUC-train 0.932\n",
            "Stats - Epoch: 45 AUC-val 0.400  AUC-train 0.936\n",
            "Stats - Epoch: 46 AUC-val 0.380  AUC-train 0.937\n",
            "Stats - Epoch: 47 AUC-val 0.426  AUC-train 0.936\n",
            "Stats - Epoch: 48 AUC-val 0.395  AUC-train 0.936\n",
            "Stats - Epoch: 49 AUC-val 0.401  AUC-train 0.933\n",
            "Stats - Epoch: 50 AUC-val 0.431  AUC-train 0.930\n",
            "Stats - Epoch: 51 AUC-val 0.412  AUC-train 0.933\n",
            "Stats - Epoch: 52 AUC-val 0.394  AUC-train 0.934\n",
            "Stats - Epoch: 53 AUC-val 0.395  AUC-train 0.934\n",
            "Stats - Epoch: 54 AUC-val 0.398  AUC-train 0.935\n",
            "Stats - Epoch: 55 AUC-val 0.402  AUC-train 0.929\n",
            "Stats - Epoch: 56 AUC-val 0.390  AUC-train 0.934\n",
            "Stats - Epoch: 57 AUC-val 0.386  AUC-train 0.931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.409  AUC-train 0.935\n",
            "Stats - Epoch: 59 AUC-val 0.390  AUC-train 0.935\n",
            "Stats - Epoch: 60 AUC-val 0.403  AUC-train 0.937\n",
            "Stats - Epoch: 61 AUC-val 0.403  AUC-train 0.936\n",
            "Stats - Epoch: 62 AUC-val 0.408  AUC-train 0.936\n",
            "Stats - Epoch: 63 AUC-val 0.422  AUC-train 0.935\n",
            "Stats - Epoch: 64 AUC-val 0.429  AUC-train 0.928\n",
            "Stats - Epoch: 65 AUC-val 0.415  AUC-train 0.932\n",
            "Stats - Epoch: 66 AUC-val 0.413  AUC-train 0.937\n",
            "Stats - Epoch: 67 AUC-val 0.395  AUC-train 0.934\n",
            "Stats - Epoch: 68 AUC-val 0.395  AUC-train 0.933\n",
            "Stats - Epoch: 69 AUC-val 0.407  AUC-train 0.938\n",
            "Stats - Epoch: 70 AUC-val 0.393  AUC-train 0.936\n",
            "Stats - Epoch: 71 AUC-val 0.404  AUC-train 0.937\n",
            "Stats - Epoch: 72 AUC-val 0.428  AUC-train 0.931\n",
            "Stats - Epoch: 73 AUC-val 0.415  AUC-train 0.931\n",
            "Stats - Epoch: 74 AUC-val 0.441  AUC-train 0.929\n",
            "Stats - Epoch: 75 AUC-val 0.416  AUC-train 0.931\n",
            "Stats - Epoch: 76 AUC-val 0.464  AUC-train 0.928\n",
            "Stats - Epoch: 77 AUC-val 0.447  AUC-train 0.930\n",
            "Stats - Epoch: 78 AUC-val 0.447  AUC-train 0.925\n",
            "Stats - Epoch: 79 AUC-val 0.417  AUC-train 0.931\n",
            "Stats - Epoch: 80 AUC-val 0.421  AUC-train 0.931\n",
            "Stats - Epoch: 81 AUC-val 0.409  AUC-train 0.937\n",
            "Stats - Epoch: 82 AUC-val 0.400  AUC-train 0.940\n",
            "Stats - Epoch: 83 AUC-val 0.424  AUC-train 0.935\n",
            "Stats - Epoch: 84 AUC-val 0.418  AUC-train 0.935\n",
            "Stats - Epoch: 85 AUC-val 0.429  AUC-train 0.935\n",
            "Stats - Epoch: 86 AUC-val 0.429  AUC-train 0.935\n",
            "Stats - Epoch: 87 AUC-val 0.398  AUC-train 0.935\n",
            "Stats - Epoch: 88 AUC-val 0.418  AUC-train 0.940\n",
            "Stats - Epoch: 89 AUC-val 0.409  AUC-train 0.939\n",
            "Stats - Epoch: 90 AUC-val 0.398  AUC-train 0.940\n",
            "Stats - Epoch: 91 AUC-val 0.434  AUC-train 0.942\n",
            "Stats - Epoch: 92 AUC-val 0.407  AUC-train 0.938\n",
            "Stats - Epoch: 93 AUC-val 0.417  AUC-train 0.937\n",
            "Stats - Epoch: 94 AUC-val 0.412  AUC-train 0.935\n",
            "Stats - Epoch: 95 AUC-val 0.391  AUC-train 0.929\n",
            "Stats - Epoch: 96 AUC-val 0.424  AUC-train 0.932\n",
            "Stats - Epoch: 97 AUC-val 0.424  AUC-train 0.935\n",
            "Stats - Epoch: 98 AUC-val 0.407  AUC-train 0.936\n",
            "Stats - Epoch: 99 AUC-val 0.429  AUC-train 0.931\n",
            "Stats - Epoch: 100 AUC-val 0.414  AUC-train 0.932\n",
            "Results 100 AUC-val 0.464 0.359 0.384 0.356 0.641 AUC-train 0.928\n",
            "Shapley [0.02252821 0.00942584 0.00639042 0.02917142 0.00984874] [0.03626315]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.179273\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.240  AUC-train 0.538\n",
            "Stats - Epoch: 2 AUC-val 0.203  AUC-train 0.544\n",
            "Stats - Epoch: 3 AUC-val 0.189  AUC-train 0.553\n",
            "Stats - Epoch: 4 AUC-val 0.169  AUC-train 0.564\n",
            "Stats - Epoch: 5 AUC-val 0.176  AUC-train 0.592\n",
            "Stats - Epoch: 6 AUC-val 0.176  AUC-train 0.619\n",
            "Stats - Epoch: 7 AUC-val 0.184  AUC-train 0.642\n",
            "Stats - Epoch: 8 AUC-val 0.225  AUC-train 0.664\n",
            "Stats - Epoch: 9 AUC-val 0.236  AUC-train 0.673\n",
            "Stats - Epoch: 10 AUC-val 0.314  AUC-train 0.696\n",
            "Stats - Epoch: 11 AUC-val 0.326  AUC-train 0.704\n",
            "Stats - Epoch: 12 AUC-val 0.326  AUC-train 0.720\n",
            "Stats - Epoch: 13 AUC-val 0.327  AUC-train 0.729\n",
            "Stats - Epoch: 14 AUC-val 0.374  AUC-train 0.737\n",
            "Stats - Epoch: 15 AUC-val 0.409  AUC-train 0.743\n",
            "Stats - Epoch: 16 AUC-val 0.450  AUC-train 0.757\n",
            "Stats - Epoch: 17 AUC-val 0.485  AUC-train 0.767\n",
            "Stats - Epoch: 18 AUC-val 0.485  AUC-train 0.770\n",
            "Stats - Epoch: 19 AUC-val 0.486  AUC-train 0.771\n",
            "Stats - Epoch: 20 AUC-val 0.490  AUC-train 0.776\n",
            "Stats - Epoch: 21 AUC-val 0.486  AUC-train 0.777\n",
            "Stats - Epoch: 22 AUC-val 0.490  AUC-train 0.779\n",
            "Stats - Epoch: 23 AUC-val 0.557  AUC-train 0.781\n",
            "Stats - Epoch: 24 AUC-val 0.540  AUC-train 0.781\n",
            "Stats - Epoch: 25 AUC-val 0.461  AUC-train 0.783\n",
            "Stats - Epoch: 26 AUC-val 0.486  AUC-train 0.783\n",
            "Stats - Epoch: 27 AUC-val 0.515  AUC-train 0.784\n",
            "Stats - Epoch: 28 AUC-val 0.498  AUC-train 0.786\n",
            "Stats - Epoch: 29 AUC-val 0.512  AUC-train 0.787\n",
            "Stats - Epoch: 30 AUC-val 0.530  AUC-train 0.791\n",
            "Stats - Epoch: 31 AUC-val 0.530  AUC-train 0.792\n",
            "Stats - Epoch: 32 AUC-val 0.524  AUC-train 0.792\n",
            "Stats - Epoch: 33 AUC-val 0.524  AUC-train 0.792\n",
            "Stats - Epoch: 34 AUC-val 0.554  AUC-train 0.795\n",
            "Stats - Epoch: 35 AUC-val 0.511  AUC-train 0.796\n",
            "Stats - Epoch: 36 AUC-val 0.510  AUC-train 0.798\n",
            "Stats - Epoch: 37 AUC-val 0.534  AUC-train 0.797\n",
            "Stats - Epoch: 38 AUC-val 0.520  AUC-train 0.796\n",
            "Stats - Epoch: 39 AUC-val 0.521  AUC-train 0.802\n",
            "Stats - Epoch: 40 AUC-val 0.546  AUC-train 0.798\n",
            "Stats - Epoch: 41 AUC-val 0.543  AUC-train 0.802\n",
            "Stats - Epoch: 42 AUC-val 0.531  AUC-train 0.801\n",
            "Stats - Epoch: 43 AUC-val 0.569  AUC-train 0.795\n",
            "Stats - Epoch: 44 AUC-val 0.554  AUC-train 0.799\n",
            "Stats - Epoch: 45 AUC-val 0.550  AUC-train 0.801\n",
            "Stats - Epoch: 46 AUC-val 0.562  AUC-train 0.799\n",
            "Stats - Epoch: 47 AUC-val 0.563  AUC-train 0.800\n",
            "Stats - Epoch: 48 AUC-val 0.527  AUC-train 0.803\n",
            "Stats - Epoch: 49 AUC-val 0.539  AUC-train 0.805\n",
            "Stats - Epoch: 50 AUC-val 0.522  AUC-train 0.805\n",
            "Stats - Epoch: 51 AUC-val 0.529  AUC-train 0.799\n",
            "Stats - Epoch: 52 AUC-val 0.531  AUC-train 0.801\n",
            "Stats - Epoch: 53 AUC-val 0.566  AUC-train 0.801\n",
            "Stats - Epoch: 54 AUC-val 0.564  AUC-train 0.802\n",
            "Stats - Epoch: 55 AUC-val 0.552  AUC-train 0.802\n",
            "Stats - Epoch: 56 AUC-val 0.550  AUC-train 0.802\n",
            "Stats - Epoch: 57 AUC-val 0.567  AUC-train 0.801\n",
            "Stats - Epoch: 58 AUC-val 0.569  AUC-train 0.803\n",
            "Stats - Epoch: 59 AUC-val 0.557  AUC-train 0.801\n",
            "Stats - Epoch: 60 AUC-val 0.553  AUC-train 0.804\n",
            "Stats - Epoch: 61 AUC-val 0.562  AUC-train 0.798\n",
            "Stats - Epoch: 62 AUC-val 0.561  AUC-train 0.799\n",
            "Stats - Epoch: 63 AUC-val 0.569  AUC-train 0.799\n",
            "Stats - Epoch: 64 AUC-val 0.560  AUC-train 0.802\n",
            "Stats - Epoch: 65 AUC-val 0.590  AUC-train 0.803\n",
            "Stats - Epoch: 66 AUC-val 0.559  AUC-train 0.804\n",
            "Stats - Epoch: 67 AUC-val 0.555  AUC-train 0.806\n",
            "Stats - Epoch: 68 AUC-val 0.553  AUC-train 0.805\n",
            "Stats - Epoch: 69 AUC-val 0.542  AUC-train 0.807\n",
            "Stats - Epoch: 70 AUC-val 0.548  AUC-train 0.810\n",
            "Stats - Epoch: 71 AUC-val 0.548  AUC-train 0.807\n",
            "Stats - Epoch: 72 AUC-val 0.581  AUC-train 0.803\n",
            "Stats - Epoch: 73 AUC-val 0.576  AUC-train 0.807\n",
            "Stats - Epoch: 74 AUC-val 0.552  AUC-train 0.809\n",
            "Stats - Epoch: 75 AUC-val 0.578  AUC-train 0.807\n",
            "Stats - Epoch: 76 AUC-val 0.554  AUC-train 0.806\n",
            "Stats - Epoch: 77 AUC-val 0.560  AUC-train 0.810\n",
            "Stats - Epoch: 78 AUC-val 0.606  AUC-train 0.806\n",
            "Stats - Epoch: 79 AUC-val 0.583  AUC-train 0.808\n",
            "Stats - Epoch: 80 AUC-val 0.546  AUC-train 0.807\n",
            "Stats - Epoch: 81 AUC-val 0.559  AUC-train 0.806\n",
            "Stats - Epoch: 82 AUC-val 0.541  AUC-train 0.805\n",
            "Stats - Epoch: 83 AUC-val 0.573  AUC-train 0.801\n",
            "Stats - Epoch: 84 AUC-val 0.564  AUC-train 0.800\n",
            "Stats - Epoch: 85 AUC-val 0.587  AUC-train 0.801\n",
            "Stats - Epoch: 86 AUC-val 0.558  AUC-train 0.802\n",
            "Stats - Epoch: 87 AUC-val 0.574  AUC-train 0.800\n",
            "Stats - Epoch: 88 AUC-val 0.571  AUC-train 0.806\n",
            "Stats - Epoch: 89 AUC-val 0.559  AUC-train 0.801\n",
            "Stats - Epoch: 90 AUC-val 0.573  AUC-train 0.804\n",
            "Stats - Epoch: 91 AUC-val 0.577  AUC-train 0.805\n",
            "Stats - Epoch: 92 AUC-val 0.577  AUC-train 0.803\n",
            "Stats - Epoch: 93 AUC-val 0.564  AUC-train 0.804\n",
            "Stats - Epoch: 94 AUC-val 0.579  AUC-train 0.805\n",
            "Stats - Epoch: 95 AUC-val 0.598  AUC-train 0.806\n",
            "Stats - Epoch: 96 AUC-val 0.575  AUC-train 0.803\n",
            "Stats - Epoch: 97 AUC-val 0.574  AUC-train 0.804\n",
            "Stats - Epoch: 98 AUC-val 0.583  AUC-train 0.802\n",
            "Stats - Epoch: 99 AUC-val 0.564  AUC-train 0.805\n",
            "Stats - Epoch: 100 AUC-val 0.576  AUC-train 0.805\n",
            "Results 100 AUC-val 0.606 0.639 0.609 0.538 0.633 AUC-train 0.806\n",
            "Shapley [0.00661583 0.00850366 0.01317715 0.0077722  0.00303256] [0.01038154]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196129\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.307  AUC-train 0.530\n",
            "Stats - Epoch: 2 AUC-val 0.382  AUC-train 0.574\n",
            "Stats - Epoch: 3 AUC-val 0.436  AUC-train 0.622\n",
            "Stats - Epoch: 4 AUC-val 0.517  AUC-train 0.700\n",
            "Stats - Epoch: 5 AUC-val 0.559  AUC-train 0.757\n",
            "Stats - Epoch: 6 AUC-val 0.597  AUC-train 0.786\n",
            "Stats - Epoch: 7 AUC-val 0.631  AUC-train 0.799\n",
            "Stats - Epoch: 8 AUC-val 0.643  AUC-train 0.812\n",
            "Stats - Epoch: 9 AUC-val 0.659  AUC-train 0.816\n",
            "Stats - Epoch: 10 AUC-val 0.685  AUC-train 0.826\n",
            "Stats - Epoch: 11 AUC-val 0.676  AUC-train 0.829\n",
            "Stats - Epoch: 12 AUC-val 0.686  AUC-train 0.828\n",
            "Stats - Epoch: 13 AUC-val 0.676  AUC-train 0.832\n",
            "Stats - Epoch: 14 AUC-val 0.691  AUC-train 0.836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.698  AUC-train 0.836\n",
            "Stats - Epoch: 16 AUC-val 0.704  AUC-train 0.836\n",
            "Stats - Epoch: 17 AUC-val 0.702  AUC-train 0.842\n",
            "Stats - Epoch: 18 AUC-val 0.725  AUC-train 0.845\n",
            "Stats - Epoch: 19 AUC-val 0.727  AUC-train 0.848\n",
            "Stats - Epoch: 20 AUC-val 0.740  AUC-train 0.847\n",
            "Stats - Epoch: 21 AUC-val 0.729  AUC-train 0.849\n",
            "Stats - Epoch: 22 AUC-val 0.755  AUC-train 0.851\n",
            "Stats - Epoch: 23 AUC-val 0.738  AUC-train 0.855\n",
            "Stats - Epoch: 24 AUC-val 0.752  AUC-train 0.856\n",
            "Stats - Epoch: 25 AUC-val 0.757  AUC-train 0.857\n",
            "Stats - Epoch: 26 AUC-val 0.754  AUC-train 0.857\n",
            "Stats - Epoch: 27 AUC-val 0.749  AUC-train 0.857\n",
            "Stats - Epoch: 28 AUC-val 0.743  AUC-train 0.860\n",
            "Stats - Epoch: 29 AUC-val 0.752  AUC-train 0.863\n",
            "Stats - Epoch: 30 AUC-val 0.748  AUC-train 0.866\n",
            "Stats - Epoch: 31 AUC-val 0.749  AUC-train 0.866\n",
            "Stats - Epoch: 32 AUC-val 0.755  AUC-train 0.868\n",
            "Stats - Epoch: 33 AUC-val 0.740  AUC-train 0.870\n",
            "Stats - Epoch: 34 AUC-val 0.751  AUC-train 0.869\n",
            "Stats - Epoch: 35 AUC-val 0.723  AUC-train 0.869\n",
            "Stats - Epoch: 36 AUC-val 0.748  AUC-train 0.873\n",
            "Stats - Epoch: 37 AUC-val 0.759  AUC-train 0.873\n",
            "Stats - Epoch: 38 AUC-val 0.752  AUC-train 0.874\n",
            "Stats - Epoch: 39 AUC-val 0.741  AUC-train 0.875\n",
            "Stats - Epoch: 40 AUC-val 0.766  AUC-train 0.876\n",
            "Stats - Epoch: 41 AUC-val 0.753  AUC-train 0.877\n",
            "Stats - Epoch: 42 AUC-val 0.766  AUC-train 0.877\n",
            "Stats - Epoch: 43 AUC-val 0.753  AUC-train 0.875\n",
            "Stats - Epoch: 44 AUC-val 0.746  AUC-train 0.877\n",
            "Stats - Epoch: 45 AUC-val 0.752  AUC-train 0.876\n",
            "Stats - Epoch: 46 AUC-val 0.759  AUC-train 0.875\n",
            "Stats - Epoch: 47 AUC-val 0.738  AUC-train 0.876\n",
            "Stats - Epoch: 48 AUC-val 0.763  AUC-train 0.876\n",
            "Stats - Epoch: 49 AUC-val 0.761  AUC-train 0.878\n",
            "Stats - Epoch: 50 AUC-val 0.759  AUC-train 0.878\n",
            "Stats - Epoch: 51 AUC-val 0.766  AUC-train 0.877\n",
            "Stats - Epoch: 52 AUC-val 0.762  AUC-train 0.876\n",
            "Stats - Epoch: 53 AUC-val 0.766  AUC-train 0.879\n",
            "Stats - Epoch: 54 AUC-val 0.778  AUC-train 0.883\n",
            "Stats - Epoch: 55 AUC-val 0.775  AUC-train 0.879\n",
            "Stats - Epoch: 56 AUC-val 0.769  AUC-train 0.881\n",
            "Stats - Epoch: 57 AUC-val 0.766  AUC-train 0.881\n",
            "Stats - Epoch: 58 AUC-val 0.769  AUC-train 0.881\n",
            "Stats - Epoch: 59 AUC-val 0.769  AUC-train 0.882\n",
            "Stats - Epoch: 60 AUC-val 0.768  AUC-train 0.886\n",
            "Stats - Epoch: 61 AUC-val 0.777  AUC-train 0.883\n",
            "Stats - Epoch: 62 AUC-val 0.786  AUC-train 0.886\n",
            "Stats - Epoch: 63 AUC-val 0.780  AUC-train 0.885\n",
            "Stats - Epoch: 64 AUC-val 0.776  AUC-train 0.884\n",
            "Stats - Epoch: 65 AUC-val 0.785  AUC-train 0.885\n",
            "Stats - Epoch: 66 AUC-val 0.792  AUC-train 0.887\n",
            "Stats - Epoch: 67 AUC-val 0.774  AUC-train 0.889\n",
            "Stats - Epoch: 68 AUC-val 0.781  AUC-train 0.889\n",
            "Stats - Epoch: 69 AUC-val 0.747  AUC-train 0.889\n",
            "Stats - Epoch: 70 AUC-val 0.769  AUC-train 0.889\n",
            "Stats - Epoch: 71 AUC-val 0.760  AUC-train 0.888\n",
            "Stats - Epoch: 72 AUC-val 0.761  AUC-train 0.888\n",
            "Stats - Epoch: 73 AUC-val 0.767  AUC-train 0.891\n",
            "Stats - Epoch: 74 AUC-val 0.760  AUC-train 0.892\n",
            "Stats - Epoch: 75 AUC-val 0.773  AUC-train 0.889\n",
            "Stats - Epoch: 76 AUC-val 0.771  AUC-train 0.891\n",
            "Stats - Epoch: 77 AUC-val 0.771  AUC-train 0.888\n",
            "Stats - Epoch: 78 AUC-val 0.795  AUC-train 0.887\n",
            "Stats - Epoch: 79 AUC-val 0.782  AUC-train 0.889\n",
            "Stats - Epoch: 80 AUC-val 0.786  AUC-train 0.890\n",
            "Stats - Epoch: 81 AUC-val 0.778  AUC-train 0.888\n",
            "Stats - Epoch: 82 AUC-val 0.767  AUC-train 0.891\n",
            "Stats - Epoch: 83 AUC-val 0.780  AUC-train 0.893\n",
            "Stats - Epoch: 84 AUC-val 0.784  AUC-train 0.892\n",
            "Stats - Epoch: 85 AUC-val 0.787  AUC-train 0.890\n",
            "Stats - Epoch: 86 AUC-val 0.767  AUC-train 0.892\n",
            "Stats - Epoch: 87 AUC-val 0.759  AUC-train 0.895\n",
            "Stats - Epoch: 88 AUC-val 0.763  AUC-train 0.893\n",
            "Stats - Epoch: 89 AUC-val 0.755  AUC-train 0.895\n",
            "Stats - Epoch: 90 AUC-val 0.774  AUC-train 0.895\n",
            "Stats - Epoch: 91 AUC-val 0.778  AUC-train 0.896\n",
            "Stats - Epoch: 92 AUC-val 0.772  AUC-train 0.895\n",
            "Stats - Epoch: 93 AUC-val 0.779  AUC-train 0.897\n",
            "Stats - Epoch: 94 AUC-val 0.759  AUC-train 0.896\n",
            "Stats - Epoch: 95 AUC-val 0.751  AUC-train 0.892\n",
            "Stats - Epoch: 96 AUC-val 0.755  AUC-train 0.893\n",
            "Stats - Epoch: 97 AUC-val 0.755  AUC-train 0.894\n",
            "Stats - Epoch: 98 AUC-val 0.757  AUC-train 0.894\n",
            "Stats - Epoch: 99 AUC-val 0.763  AUC-train 0.893\n",
            "Stats - Epoch: 100 AUC-val 0.779  AUC-train 0.897\n",
            "Results 100 AUC-val 0.795 0.656 0.582 0.526 0.619 AUC-train 0.887\n",
            "Shapley [0.01316216 0.01175922 0.01492464 0.01950521 0.00874631] [0.02177521]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198281\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.448  AUC-train 0.457\n",
            "Stats - Epoch: 2 AUC-val 0.546  AUC-train 0.466\n",
            "Stats - Epoch: 3 AUC-val 0.593  AUC-train 0.497\n",
            "Stats - Epoch: 4 AUC-val 0.628  AUC-train 0.524\n",
            "Stats - Epoch: 5 AUC-val 0.646  AUC-train 0.546\n",
            "Stats - Epoch: 6 AUC-val 0.634  AUC-train 0.573\n",
            "Stats - Epoch: 7 AUC-val 0.664  AUC-train 0.590\n",
            "Stats - Epoch: 8 AUC-val 0.672  AUC-train 0.609\n",
            "Stats - Epoch: 9 AUC-val 0.658  AUC-train 0.627\n",
            "Stats - Epoch: 10 AUC-val 0.660  AUC-train 0.642\n",
            "Stats - Epoch: 11 AUC-val 0.655  AUC-train 0.667\n",
            "Stats - Epoch: 12 AUC-val 0.644  AUC-train 0.682\n",
            "Stats - Epoch: 13 AUC-val 0.681  AUC-train 0.706\n",
            "Stats - Epoch: 14 AUC-val 0.649  AUC-train 0.727\n",
            "Stats - Epoch: 15 AUC-val 0.644  AUC-train 0.736\n",
            "Stats - Epoch: 16 AUC-val 0.656  AUC-train 0.739\n",
            "Stats - Epoch: 17 AUC-val 0.663  AUC-train 0.756\n",
            "Stats - Epoch: 18 AUC-val 0.662  AUC-train 0.764\n",
            "Stats - Epoch: 19 AUC-val 0.646  AUC-train 0.772\n",
            "Stats - Epoch: 20 AUC-val 0.639  AUC-train 0.783\n",
            "Stats - Epoch: 21 AUC-val 0.645  AUC-train 0.796\n",
            "Stats - Epoch: 22 AUC-val 0.656  AUC-train 0.791\n",
            "Stats - Epoch: 23 AUC-val 0.667  AUC-train 0.801\n",
            "Stats - Epoch: 24 AUC-val 0.664  AUC-train 0.809\n",
            "Stats - Epoch: 25 AUC-val 0.653  AUC-train 0.810\n",
            "Stats - Epoch: 26 AUC-val 0.662  AUC-train 0.814\n",
            "Stats - Epoch: 27 AUC-val 0.637  AUC-train 0.821\n",
            "Stats - Epoch: 28 AUC-val 0.663  AUC-train 0.826\n",
            "Stats - Epoch: 29 AUC-val 0.681  AUC-train 0.829\n",
            "Stats - Epoch: 30 AUC-val 0.642  AUC-train 0.832\n",
            "Stats - Epoch: 31 AUC-val 0.655  AUC-train 0.833\n",
            "Stats - Epoch: 32 AUC-val 0.654  AUC-train 0.833\n",
            "Stats - Epoch: 33 AUC-val 0.652  AUC-train 0.837\n",
            "Stats - Epoch: 34 AUC-val 0.620  AUC-train 0.837\n",
            "Stats - Epoch: 35 AUC-val 0.667  AUC-train 0.838\n",
            "Stats - Epoch: 36 AUC-val 0.633  AUC-train 0.842\n",
            "Stats - Epoch: 37 AUC-val 0.663  AUC-train 0.842\n",
            "Stats - Epoch: 38 AUC-val 0.617  AUC-train 0.846\n",
            "Stats - Epoch: 39 AUC-val 0.652  AUC-train 0.848\n",
            "Stats - Epoch: 40 AUC-val 0.628  AUC-train 0.847\n",
            "Stats - Epoch: 41 AUC-val 0.664  AUC-train 0.851\n",
            "Stats - Epoch: 42 AUC-val 0.668  AUC-train 0.851\n",
            "Stats - Epoch: 43 AUC-val 0.683  AUC-train 0.848\n",
            "Stats - Epoch: 44 AUC-val 0.675  AUC-train 0.850\n",
            "Stats - Epoch: 45 AUC-val 0.686  AUC-train 0.853\n",
            "Stats - Epoch: 46 AUC-val 0.677  AUC-train 0.855\n",
            "Stats - Epoch: 47 AUC-val 0.699  AUC-train 0.858\n",
            "Stats - Epoch: 48 AUC-val 0.653  AUC-train 0.857\n",
            "Stats - Epoch: 49 AUC-val 0.622  AUC-train 0.858\n",
            "Stats - Epoch: 50 AUC-val 0.657  AUC-train 0.861\n",
            "Stats - Epoch: 51 AUC-val 0.646  AUC-train 0.860\n",
            "Stats - Epoch: 52 AUC-val 0.653  AUC-train 0.861\n",
            "Stats - Epoch: 53 AUC-val 0.653  AUC-train 0.864\n",
            "Stats - Epoch: 54 AUC-val 0.683  AUC-train 0.861\n",
            "Stats - Epoch: 55 AUC-val 0.675  AUC-train 0.861\n",
            "Stats - Epoch: 56 AUC-val 0.649  AUC-train 0.859\n",
            "Stats - Epoch: 57 AUC-val 0.655  AUC-train 0.860\n",
            "Stats - Epoch: 58 AUC-val 0.707  AUC-train 0.863\n",
            "Stats - Epoch: 59 AUC-val 0.649  AUC-train 0.861\n",
            "Stats - Epoch: 60 AUC-val 0.665  AUC-train 0.863\n",
            "Stats - Epoch: 61 AUC-val 0.660  AUC-train 0.864\n",
            "Stats - Epoch: 62 AUC-val 0.633  AUC-train 0.863\n",
            "Stats - Epoch: 63 AUC-val 0.654  AUC-train 0.865\n",
            "Stats - Epoch: 64 AUC-val 0.631  AUC-train 0.862\n",
            "Stats - Epoch: 65 AUC-val 0.655  AUC-train 0.865\n",
            "Stats - Epoch: 66 AUC-val 0.655  AUC-train 0.863\n",
            "Stats - Epoch: 67 AUC-val 0.652  AUC-train 0.861\n",
            "Stats - Epoch: 68 AUC-val 0.636  AUC-train 0.867\n",
            "Stats - Epoch: 69 AUC-val 0.617  AUC-train 0.864\n",
            "Stats - Epoch: 70 AUC-val 0.605  AUC-train 0.869\n",
            "Stats - Epoch: 71 AUC-val 0.650  AUC-train 0.869\n",
            "Stats - Epoch: 72 AUC-val 0.667  AUC-train 0.869\n",
            "Stats - Epoch: 73 AUC-val 0.600  AUC-train 0.868\n",
            "Stats - Epoch: 74 AUC-val 0.613  AUC-train 0.870\n",
            "Stats - Epoch: 75 AUC-val 0.633  AUC-train 0.871\n",
            "Stats - Epoch: 76 AUC-val 0.665  AUC-train 0.872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.628  AUC-train 0.872\n",
            "Stats - Epoch: 78 AUC-val 0.634  AUC-train 0.874\n",
            "Stats - Epoch: 79 AUC-val 0.634  AUC-train 0.875\n",
            "Stats - Epoch: 80 AUC-val 0.626  AUC-train 0.874\n",
            "Stats - Epoch: 81 AUC-val 0.647  AUC-train 0.874\n",
            "Stats - Epoch: 82 AUC-val 0.648  AUC-train 0.875\n",
            "Stats - Epoch: 83 AUC-val 0.641  AUC-train 0.876\n",
            "Stats - Epoch: 84 AUC-val 0.674  AUC-train 0.872\n",
            "Stats - Epoch: 85 AUC-val 0.641  AUC-train 0.873\n",
            "Stats - Epoch: 86 AUC-val 0.648  AUC-train 0.873\n",
            "Stats - Epoch: 87 AUC-val 0.666  AUC-train 0.872\n",
            "Stats - Epoch: 88 AUC-val 0.656  AUC-train 0.874\n",
            "Stats - Epoch: 89 AUC-val 0.665  AUC-train 0.874\n",
            "Stats - Epoch: 90 AUC-val 0.639  AUC-train 0.874\n",
            "Stats - Epoch: 91 AUC-val 0.626  AUC-train 0.876\n",
            "Stats - Epoch: 92 AUC-val 0.653  AUC-train 0.877\n",
            "Stats - Epoch: 93 AUC-val 0.645  AUC-train 0.878\n",
            "Stats - Epoch: 94 AUC-val 0.623  AUC-train 0.878\n",
            "Stats - Epoch: 95 AUC-val 0.664  AUC-train 0.880\n",
            "Stats - Epoch: 96 AUC-val 0.613  AUC-train 0.878\n",
            "Stats - Epoch: 97 AUC-val 0.623  AUC-train 0.879\n",
            "Stats - Epoch: 98 AUC-val 0.624  AUC-train 0.875\n",
            "Stats - Epoch: 99 AUC-val 0.638  AUC-train 0.870\n",
            "Stats - Epoch: 100 AUC-val 0.636  AUC-train 0.871\n",
            "Results 100 AUC-val 0.707 0.693 0.680 0.530 0.676 AUC-train 0.863\n",
            "Shapley [0.0106997  0.01321584 0.01489328 0.01383874 0.00384775] [0.01369373]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.195901\n",
            "         Iterations 9\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.305  AUC-train 0.509\n",
            "Stats - Epoch: 2 AUC-val 0.355  AUC-train 0.528\n",
            "Stats - Epoch: 3 AUC-val 0.364  AUC-train 0.565\n",
            "Stats - Epoch: 4 AUC-val 0.354  AUC-train 0.598\n",
            "Stats - Epoch: 5 AUC-val 0.340  AUC-train 0.620\n",
            "Stats - Epoch: 6 AUC-val 0.345  AUC-train 0.644\n",
            "Stats - Epoch: 7 AUC-val 0.363  AUC-train 0.665\n",
            "Stats - Epoch: 8 AUC-val 0.372  AUC-train 0.669\n",
            "Stats - Epoch: 9 AUC-val 0.386  AUC-train 0.691\n",
            "Stats - Epoch: 10 AUC-val 0.396  AUC-train 0.706\n",
            "Stats - Epoch: 11 AUC-val 0.393  AUC-train 0.710\n",
            "Stats - Epoch: 12 AUC-val 0.402  AUC-train 0.725\n",
            "Stats - Epoch: 13 AUC-val 0.407  AUC-train 0.726\n",
            "Stats - Epoch: 14 AUC-val 0.405  AUC-train 0.743\n",
            "Stats - Epoch: 15 AUC-val 0.410  AUC-train 0.741\n",
            "Stats - Epoch: 16 AUC-val 0.410  AUC-train 0.754\n",
            "Stats - Epoch: 17 AUC-val 0.417  AUC-train 0.756\n",
            "Stats - Epoch: 18 AUC-val 0.416  AUC-train 0.767\n",
            "Stats - Epoch: 19 AUC-val 0.426  AUC-train 0.772\n",
            "Stats - Epoch: 20 AUC-val 0.412  AUC-train 0.776\n",
            "Stats - Epoch: 21 AUC-val 0.414  AUC-train 0.781\n",
            "Stats - Epoch: 22 AUC-val 0.421  AUC-train 0.786\n",
            "Stats - Epoch: 23 AUC-val 0.426  AUC-train 0.789\n",
            "Stats - Epoch: 24 AUC-val 0.424  AUC-train 0.799\n",
            "Stats - Epoch: 25 AUC-val 0.431  AUC-train 0.795\n",
            "Stats - Epoch: 26 AUC-val 0.431  AUC-train 0.802\n",
            "Stats - Epoch: 27 AUC-val 0.441  AUC-train 0.802\n",
            "Stats - Epoch: 28 AUC-val 0.440  AUC-train 0.800\n",
            "Stats - Epoch: 29 AUC-val 0.439  AUC-train 0.805\n",
            "Stats - Epoch: 30 AUC-val 0.444  AUC-train 0.812\n",
            "Stats - Epoch: 31 AUC-val 0.448  AUC-train 0.811\n",
            "Stats - Epoch: 32 AUC-val 0.451  AUC-train 0.813\n",
            "Stats - Epoch: 33 AUC-val 0.453  AUC-train 0.820\n",
            "Stats - Epoch: 34 AUC-val 0.450  AUC-train 0.818\n",
            "Stats - Epoch: 35 AUC-val 0.454  AUC-train 0.811\n",
            "Stats - Epoch: 36 AUC-val 0.459  AUC-train 0.818\n",
            "Stats - Epoch: 37 AUC-val 0.465  AUC-train 0.816\n",
            "Stats - Epoch: 38 AUC-val 0.459  AUC-train 0.825\n",
            "Stats - Epoch: 39 AUC-val 0.467  AUC-train 0.823\n",
            "Stats - Epoch: 40 AUC-val 0.471  AUC-train 0.826\n",
            "Stats - Epoch: 41 AUC-val 0.469  AUC-train 0.827\n",
            "Stats - Epoch: 42 AUC-val 0.480  AUC-train 0.828\n",
            "Stats - Epoch: 43 AUC-val 0.478  AUC-train 0.827\n",
            "Stats - Epoch: 44 AUC-val 0.480  AUC-train 0.828\n",
            "Stats - Epoch: 45 AUC-val 0.478  AUC-train 0.827\n",
            "Stats - Epoch: 46 AUC-val 0.478  AUC-train 0.829\n",
            "Stats - Epoch: 47 AUC-val 0.476  AUC-train 0.832\n",
            "Stats - Epoch: 48 AUC-val 0.475  AUC-train 0.828\n",
            "Stats - Epoch: 49 AUC-val 0.475  AUC-train 0.828\n",
            "Stats - Epoch: 50 AUC-val 0.478  AUC-train 0.832\n",
            "Stats - Epoch: 51 AUC-val 0.473  AUC-train 0.831\n",
            "Stats - Epoch: 52 AUC-val 0.478  AUC-train 0.828\n",
            "Stats - Epoch: 53 AUC-val 0.478  AUC-train 0.831\n",
            "Stats - Epoch: 54 AUC-val 0.478  AUC-train 0.833\n",
            "Stats - Epoch: 55 AUC-val 0.480  AUC-train 0.832\n",
            "Stats - Epoch: 56 AUC-val 0.478  AUC-train 0.830\n",
            "Stats - Epoch: 57 AUC-val 0.484  AUC-train 0.833\n",
            "Stats - Epoch: 58 AUC-val 0.480  AUC-train 0.829\n",
            "Stats - Epoch: 59 AUC-val 0.483  AUC-train 0.832\n",
            "Stats - Epoch: 60 AUC-val 0.480  AUC-train 0.835\n",
            "Stats - Epoch: 61 AUC-val 0.476  AUC-train 0.838\n",
            "Stats - Epoch: 62 AUC-val 0.479  AUC-train 0.836\n",
            "Stats - Epoch: 63 AUC-val 0.492  AUC-train 0.837\n",
            "Stats - Epoch: 64 AUC-val 0.483  AUC-train 0.834\n",
            "Stats - Epoch: 65 AUC-val 0.490  AUC-train 0.837\n",
            "Stats - Epoch: 66 AUC-val 0.483  AUC-train 0.839\n",
            "Stats - Epoch: 67 AUC-val 0.491  AUC-train 0.836\n",
            "Stats - Epoch: 68 AUC-val 0.488  AUC-train 0.837\n",
            "Stats - Epoch: 69 AUC-val 0.485  AUC-train 0.838\n",
            "Stats - Epoch: 70 AUC-val 0.486  AUC-train 0.840\n",
            "Stats - Epoch: 71 AUC-val 0.487  AUC-train 0.839\n",
            "Stats - Epoch: 72 AUC-val 0.495  AUC-train 0.834\n",
            "Stats - Epoch: 73 AUC-val 0.489  AUC-train 0.834\n",
            "Stats - Epoch: 74 AUC-val 0.488  AUC-train 0.833\n",
            "Stats - Epoch: 75 AUC-val 0.488  AUC-train 0.836\n",
            "Stats - Epoch: 76 AUC-val 0.495  AUC-train 0.833\n",
            "Stats - Epoch: 77 AUC-val 0.494  AUC-train 0.837\n",
            "Stats - Epoch: 78 AUC-val 0.495  AUC-train 0.838\n",
            "Stats - Epoch: 79 AUC-val 0.491  AUC-train 0.840\n",
            "Stats - Epoch: 80 AUC-val 0.490  AUC-train 0.837\n",
            "Stats - Epoch: 81 AUC-val 0.496  AUC-train 0.838\n",
            "Stats - Epoch: 82 AUC-val 0.492  AUC-train 0.840\n",
            "Stats - Epoch: 83 AUC-val 0.494  AUC-train 0.841\n",
            "Stats - Epoch: 84 AUC-val 0.494  AUC-train 0.838\n",
            "Stats - Epoch: 85 AUC-val 0.491  AUC-train 0.839\n",
            "Stats - Epoch: 86 AUC-val 0.493  AUC-train 0.839\n",
            "Stats - Epoch: 87 AUC-val 0.496  AUC-train 0.839\n",
            "Stats - Epoch: 88 AUC-val 0.496  AUC-train 0.840\n",
            "Stats - Epoch: 89 AUC-val 0.492  AUC-train 0.840\n",
            "Stats - Epoch: 90 AUC-val 0.493  AUC-train 0.839\n",
            "Stats - Epoch: 91 AUC-val 0.494  AUC-train 0.838\n",
            "Stats - Epoch: 92 AUC-val 0.500  AUC-train 0.832\n",
            "Stats - Epoch: 93 AUC-val 0.502  AUC-train 0.837\n",
            "Stats - Epoch: 94 AUC-val 0.490  AUC-train 0.838\n",
            "Stats - Epoch: 95 AUC-val 0.493  AUC-train 0.835\n",
            "Stats - Epoch: 96 AUC-val 0.498  AUC-train 0.836\n",
            "Stats - Epoch: 97 AUC-val 0.495  AUC-train 0.838\n",
            "Stats - Epoch: 98 AUC-val 0.490  AUC-train 0.837\n",
            "Stats - Epoch: 99 AUC-val 0.503  AUC-train 0.832\n",
            "Stats - Epoch: 100 AUC-val 0.491  AUC-train 0.838\n",
            "Results 100 AUC-val 0.503 0.503 0.559 0.468 0.617 AUC-train 0.832\n",
            "Shapley [0.00537619 0.00635433 0.02011718 0.0099283  0.00458753] [0.01884363]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.185650\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.281  AUC-train 0.527\n",
            "Stats - Epoch: 2 AUC-val 0.368  AUC-train 0.643\n",
            "Stats - Epoch: 3 AUC-val 0.410  AUC-train 0.715\n",
            "Stats - Epoch: 4 AUC-val 0.383  AUC-train 0.769\n",
            "Stats - Epoch: 5 AUC-val 0.381  AUC-train 0.813\n",
            "Stats - Epoch: 6 AUC-val 0.358  AUC-train 0.848\n",
            "Stats - Epoch: 7 AUC-val 0.340  AUC-train 0.875\n",
            "Stats - Epoch: 8 AUC-val 0.317  AUC-train 0.894\n",
            "Stats - Epoch: 9 AUC-val 0.319  AUC-train 0.906\n",
            "Stats - Epoch: 10 AUC-val 0.324  AUC-train 0.918\n",
            "Stats - Epoch: 11 AUC-val 0.325  AUC-train 0.924\n",
            "Stats - Epoch: 12 AUC-val 0.312  AUC-train 0.933\n",
            "Stats - Epoch: 13 AUC-val 0.327  AUC-train 0.937\n",
            "Stats - Epoch: 14 AUC-val 0.333  AUC-train 0.942\n",
            "Stats - Epoch: 15 AUC-val 0.326  AUC-train 0.943\n",
            "Stats - Epoch: 16 AUC-val 0.349  AUC-train 0.950\n",
            "Stats - Epoch: 17 AUC-val 0.355  AUC-train 0.948\n",
            "Stats - Epoch: 18 AUC-val 0.361  AUC-train 0.949\n",
            "Stats - Epoch: 19 AUC-val 0.379  AUC-train 0.954\n",
            "Stats - Epoch: 20 AUC-val 0.346  AUC-train 0.954\n",
            "Stats - Epoch: 21 AUC-val 0.363  AUC-train 0.953\n",
            "Stats - Epoch: 22 AUC-val 0.368  AUC-train 0.954\n",
            "Stats - Epoch: 23 AUC-val 0.364  AUC-train 0.960\n",
            "Stats - Epoch: 24 AUC-val 0.377  AUC-train 0.961\n",
            "Stats - Epoch: 25 AUC-val 0.370  AUC-train 0.960\n",
            "Stats - Epoch: 26 AUC-val 0.374  AUC-train 0.959\n",
            "Stats - Epoch: 27 AUC-val 0.411  AUC-train 0.957\n",
            "Stats - Epoch: 28 AUC-val 0.390  AUC-train 0.959\n",
            "Stats - Epoch: 29 AUC-val 0.405  AUC-train 0.961\n",
            "Stats - Epoch: 30 AUC-val 0.395  AUC-train 0.965\n",
            "Stats - Epoch: 31 AUC-val 0.388  AUC-train 0.966\n",
            "Stats - Epoch: 32 AUC-val 0.414  AUC-train 0.967\n",
            "Stats - Epoch: 33 AUC-val 0.379  AUC-train 0.967\n",
            "Stats - Epoch: 34 AUC-val 0.404  AUC-train 0.961\n",
            "Stats - Epoch: 35 AUC-val 0.408  AUC-train 0.962\n",
            "Stats - Epoch: 36 AUC-val 0.398  AUC-train 0.963\n",
            "Stats - Epoch: 37 AUC-val 0.412  AUC-train 0.966\n",
            "Stats - Epoch: 38 AUC-val 0.417  AUC-train 0.966\n",
            "Stats - Epoch: 39 AUC-val 0.395  AUC-train 0.966\n",
            "Stats - Epoch: 40 AUC-val 0.436  AUC-train 0.963\n",
            "Stats - Epoch: 41 AUC-val 0.409  AUC-train 0.965\n",
            "Stats - Epoch: 42 AUC-val 0.414  AUC-train 0.961\n",
            "Stats - Epoch: 43 AUC-val 0.428  AUC-train 0.961\n",
            "Stats - Epoch: 44 AUC-val 0.413  AUC-train 0.961\n",
            "Stats - Epoch: 45 AUC-val 0.414  AUC-train 0.962\n",
            "Stats - Epoch: 46 AUC-val 0.405  AUC-train 0.961\n",
            "Stats - Epoch: 47 AUC-val 0.429  AUC-train 0.963\n",
            "Stats - Epoch: 48 AUC-val 0.425  AUC-train 0.959\n",
            "Stats - Epoch: 49 AUC-val 0.425  AUC-train 0.959\n",
            "Stats - Epoch: 50 AUC-val 0.420  AUC-train 0.962\n",
            "Stats - Epoch: 51 AUC-val 0.421  AUC-train 0.964\n",
            "Stats - Epoch: 52 AUC-val 0.414  AUC-train 0.963\n",
            "Stats - Epoch: 53 AUC-val 0.425  AUC-train 0.963\n",
            "Stats - Epoch: 54 AUC-val 0.421  AUC-train 0.964\n",
            "Stats - Epoch: 55 AUC-val 0.437  AUC-train 0.958\n",
            "Stats - Epoch: 56 AUC-val 0.423  AUC-train 0.962\n",
            "Stats - Epoch: 57 AUC-val 0.441  AUC-train 0.962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.462  AUC-train 0.961\n",
            "Stats - Epoch: 59 AUC-val 0.426  AUC-train 0.963\n",
            "Stats - Epoch: 60 AUC-val 0.428  AUC-train 0.963\n",
            "Stats - Epoch: 61 AUC-val 0.452  AUC-train 0.961\n",
            "Stats - Epoch: 62 AUC-val 0.424  AUC-train 0.962\n",
            "Stats - Epoch: 63 AUC-val 0.440  AUC-train 0.961\n",
            "Stats - Epoch: 64 AUC-val 0.457  AUC-train 0.954\n",
            "Stats - Epoch: 65 AUC-val 0.437  AUC-train 0.959\n",
            "Stats - Epoch: 66 AUC-val 0.435  AUC-train 0.961\n",
            "Stats - Epoch: 67 AUC-val 0.423  AUC-train 0.959\n",
            "Stats - Epoch: 68 AUC-val 0.427  AUC-train 0.959\n",
            "Stats - Epoch: 69 AUC-val 0.455  AUC-train 0.963\n",
            "Stats - Epoch: 70 AUC-val 0.441  AUC-train 0.961\n",
            "Stats - Epoch: 71 AUC-val 0.424  AUC-train 0.961\n",
            "Stats - Epoch: 72 AUC-val 0.438  AUC-train 0.958\n",
            "Stats - Epoch: 73 AUC-val 0.457  AUC-train 0.955\n",
            "Stats - Epoch: 74 AUC-val 0.456  AUC-train 0.954\n",
            "Stats - Epoch: 75 AUC-val 0.439  AUC-train 0.958\n",
            "Stats - Epoch: 76 AUC-val 0.453  AUC-train 0.957\n",
            "Stats - Epoch: 77 AUC-val 0.440  AUC-train 0.959\n",
            "Stats - Epoch: 78 AUC-val 0.448  AUC-train 0.948\n",
            "Stats - Epoch: 79 AUC-val 0.424  AUC-train 0.956\n",
            "Stats - Epoch: 80 AUC-val 0.425  AUC-train 0.959\n",
            "Stats - Epoch: 81 AUC-val 0.419  AUC-train 0.962\n",
            "Stats - Epoch: 82 AUC-val 0.420  AUC-train 0.963\n",
            "Stats - Epoch: 83 AUC-val 0.450  AUC-train 0.958\n",
            "Stats - Epoch: 84 AUC-val 0.444  AUC-train 0.955\n",
            "Stats - Epoch: 85 AUC-val 0.438  AUC-train 0.956\n",
            "Stats - Epoch: 86 AUC-val 0.458  AUC-train 0.956\n",
            "Stats - Epoch: 87 AUC-val 0.439  AUC-train 0.958\n",
            "Stats - Epoch: 88 AUC-val 0.447  AUC-train 0.960\n",
            "Stats - Epoch: 89 AUC-val 0.422  AUC-train 0.955\n",
            "Stats - Epoch: 90 AUC-val 0.419  AUC-train 0.960\n",
            "Stats - Epoch: 91 AUC-val 0.430  AUC-train 0.959\n",
            "Stats - Epoch: 92 AUC-val 0.439  AUC-train 0.959\n",
            "Stats - Epoch: 93 AUC-val 0.445  AUC-train 0.961\n",
            "Stats - Epoch: 94 AUC-val 0.455  AUC-train 0.958\n",
            "Stats - Epoch: 95 AUC-val 0.434  AUC-train 0.955\n",
            "Stats - Epoch: 96 AUC-val 0.449  AUC-train 0.955\n",
            "Stats - Epoch: 97 AUC-val 0.438  AUC-train 0.957\n",
            "Stats - Epoch: 98 AUC-val 0.414  AUC-train 0.961\n",
            "Stats - Epoch: 99 AUC-val 0.455  AUC-train 0.955\n",
            "Stats - Epoch: 100 AUC-val 0.440  AUC-train 0.957\n",
            "Results 100 AUC-val 0.462 0.400 0.373 0.272 0.636 AUC-train 0.961\n",
            "Shapley [0.02461225 0.00964936 0.00822786 0.03472959 0.0134031 ] [0.03325117]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.178699\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.265  AUC-train 0.547\n",
            "Stats - Epoch: 2 AUC-val 0.253  AUC-train 0.570\n",
            "Stats - Epoch: 3 AUC-val 0.228  AUC-train 0.589\n",
            "Stats - Epoch: 4 AUC-val 0.219  AUC-train 0.605\n",
            "Stats - Epoch: 5 AUC-val 0.207  AUC-train 0.632\n",
            "Stats - Epoch: 6 AUC-val 0.216  AUC-train 0.666\n",
            "Stats - Epoch: 7 AUC-val 0.227  AUC-train 0.686\n",
            "Stats - Epoch: 8 AUC-val 0.272  AUC-train 0.708\n",
            "Stats - Epoch: 9 AUC-val 0.308  AUC-train 0.721\n",
            "Stats - Epoch: 10 AUC-val 0.395  AUC-train 0.734\n",
            "Stats - Epoch: 11 AUC-val 0.403  AUC-train 0.752\n",
            "Stats - Epoch: 12 AUC-val 0.507  AUC-train 0.766\n",
            "Stats - Epoch: 13 AUC-val 0.408  AUC-train 0.778\n",
            "Stats - Epoch: 14 AUC-val 0.502  AUC-train 0.784\n",
            "Stats - Epoch: 15 AUC-val 0.458  AUC-train 0.787\n",
            "Stats - Epoch: 16 AUC-val 0.517  AUC-train 0.788\n",
            "Stats - Epoch: 17 AUC-val 0.484  AUC-train 0.793\n",
            "Stats - Epoch: 18 AUC-val 0.502  AUC-train 0.797\n",
            "Stats - Epoch: 19 AUC-val 0.531  AUC-train 0.797\n",
            "Stats - Epoch: 20 AUC-val 0.500  AUC-train 0.802\n",
            "Stats - Epoch: 21 AUC-val 0.571  AUC-train 0.805\n",
            "Stats - Epoch: 22 AUC-val 0.517  AUC-train 0.799\n",
            "Stats - Epoch: 23 AUC-val 0.507  AUC-train 0.802\n",
            "Stats - Epoch: 24 AUC-val 0.565  AUC-train 0.803\n",
            "Stats - Epoch: 25 AUC-val 0.467  AUC-train 0.808\n",
            "Stats - Epoch: 26 AUC-val 0.565  AUC-train 0.811\n",
            "Stats - Epoch: 27 AUC-val 0.549  AUC-train 0.809\n",
            "Stats - Epoch: 28 AUC-val 0.547  AUC-train 0.809\n",
            "Stats - Epoch: 29 AUC-val 0.563  AUC-train 0.808\n",
            "Stats - Epoch: 30 AUC-val 0.556  AUC-train 0.810\n",
            "Stats - Epoch: 31 AUC-val 0.558  AUC-train 0.809\n",
            "Stats - Epoch: 32 AUC-val 0.542  AUC-train 0.816\n",
            "Stats - Epoch: 33 AUC-val 0.588  AUC-train 0.815\n",
            "Stats - Epoch: 34 AUC-val 0.520  AUC-train 0.817\n",
            "Stats - Epoch: 35 AUC-val 0.580  AUC-train 0.817\n",
            "Stats - Epoch: 36 AUC-val 0.530  AUC-train 0.820\n",
            "Stats - Epoch: 37 AUC-val 0.567  AUC-train 0.820\n",
            "Stats - Epoch: 38 AUC-val 0.553  AUC-train 0.822\n",
            "Stats - Epoch: 39 AUC-val 0.579  AUC-train 0.822\n",
            "Stats - Epoch: 40 AUC-val 0.547  AUC-train 0.817\n",
            "Stats - Epoch: 41 AUC-val 0.552  AUC-train 0.822\n",
            "Stats - Epoch: 42 AUC-val 0.564  AUC-train 0.827\n",
            "Stats - Epoch: 43 AUC-val 0.540  AUC-train 0.821\n",
            "Stats - Epoch: 44 AUC-val 0.577  AUC-train 0.820\n",
            "Stats - Epoch: 45 AUC-val 0.523  AUC-train 0.825\n",
            "Stats - Epoch: 46 AUC-val 0.542  AUC-train 0.825\n",
            "Stats - Epoch: 47 AUC-val 0.568  AUC-train 0.824\n",
            "Stats - Epoch: 48 AUC-val 0.521  AUC-train 0.826\n",
            "Stats - Epoch: 49 AUC-val 0.568  AUC-train 0.823\n",
            "Stats - Epoch: 50 AUC-val 0.568  AUC-train 0.823\n",
            "Stats - Epoch: 51 AUC-val 0.547  AUC-train 0.827\n",
            "Stats - Epoch: 52 AUC-val 0.569  AUC-train 0.829\n",
            "Stats - Epoch: 53 AUC-val 0.589  AUC-train 0.821\n",
            "Stats - Epoch: 54 AUC-val 0.542  AUC-train 0.825\n",
            "Stats - Epoch: 55 AUC-val 0.535  AUC-train 0.826\n",
            "Stats - Epoch: 56 AUC-val 0.563  AUC-train 0.821\n",
            "Stats - Epoch: 57 AUC-val 0.567  AUC-train 0.825\n",
            "Stats - Epoch: 58 AUC-val 0.572  AUC-train 0.825\n",
            "Stats - Epoch: 59 AUC-val 0.586  AUC-train 0.823\n",
            "Stats - Epoch: 60 AUC-val 0.572  AUC-train 0.825\n",
            "Stats - Epoch: 61 AUC-val 0.570  AUC-train 0.828\n",
            "Stats - Epoch: 62 AUC-val 0.569  AUC-train 0.830\n",
            "Stats - Epoch: 63 AUC-val 0.597  AUC-train 0.829\n",
            "Stats - Epoch: 64 AUC-val 0.567  AUC-train 0.832\n",
            "Stats - Epoch: 65 AUC-val 0.572  AUC-train 0.830\n",
            "Stats - Epoch: 66 AUC-val 0.587  AUC-train 0.824\n",
            "Stats - Epoch: 67 AUC-val 0.562  AUC-train 0.827\n",
            "Stats - Epoch: 68 AUC-val 0.560  AUC-train 0.832\n",
            "Stats - Epoch: 69 AUC-val 0.583  AUC-train 0.832\n",
            "Stats - Epoch: 70 AUC-val 0.584  AUC-train 0.833\n",
            "Stats - Epoch: 71 AUC-val 0.566  AUC-train 0.830\n",
            "Stats - Epoch: 72 AUC-val 0.571  AUC-train 0.832\n",
            "Stats - Epoch: 73 AUC-val 0.550  AUC-train 0.832\n",
            "Stats - Epoch: 74 AUC-val 0.564  AUC-train 0.835\n",
            "Stats - Epoch: 75 AUC-val 0.563  AUC-train 0.833\n",
            "Stats - Epoch: 76 AUC-val 0.577  AUC-train 0.830\n",
            "Stats - Epoch: 77 AUC-val 0.596  AUC-train 0.830\n",
            "Stats - Epoch: 78 AUC-val 0.599  AUC-train 0.830\n",
            "Stats - Epoch: 79 AUC-val 0.595  AUC-train 0.828\n",
            "Stats - Epoch: 80 AUC-val 0.598  AUC-train 0.825\n",
            "Stats - Epoch: 81 AUC-val 0.586  AUC-train 0.829\n",
            "Stats - Epoch: 82 AUC-val 0.580  AUC-train 0.821\n",
            "Stats - Epoch: 83 AUC-val 0.565  AUC-train 0.819\n",
            "Stats - Epoch: 84 AUC-val 0.580  AUC-train 0.823\n",
            "Stats - Epoch: 85 AUC-val 0.555  AUC-train 0.824\n",
            "Stats - Epoch: 86 AUC-val 0.559  AUC-train 0.826\n",
            "Stats - Epoch: 87 AUC-val 0.569  AUC-train 0.824\n",
            "Stats - Epoch: 88 AUC-val 0.566  AUC-train 0.825\n",
            "Stats - Epoch: 89 AUC-val 0.560  AUC-train 0.827\n",
            "Stats - Epoch: 90 AUC-val 0.550  AUC-train 0.830\n",
            "Stats - Epoch: 91 AUC-val 0.589  AUC-train 0.830\n",
            "Stats - Epoch: 92 AUC-val 0.574  AUC-train 0.829\n",
            "Stats - Epoch: 93 AUC-val 0.560  AUC-train 0.829\n",
            "Stats - Epoch: 94 AUC-val 0.579  AUC-train 0.828\n",
            "Stats - Epoch: 95 AUC-val 0.607  AUC-train 0.825\n",
            "Stats - Epoch: 96 AUC-val 0.579  AUC-train 0.828\n",
            "Stats - Epoch: 97 AUC-val 0.571  AUC-train 0.828\n",
            "Stats - Epoch: 98 AUC-val 0.597  AUC-train 0.827\n",
            "Stats - Epoch: 99 AUC-val 0.614  AUC-train 0.822\n",
            "Stats - Epoch: 100 AUC-val 0.589  AUC-train 0.825\n",
            "Results 100 AUC-val 0.614 0.631 0.600 0.485 0.631 AUC-train 0.822\n",
            "Shapley [0.01173874 0.0095139  0.01793215 0.00911731 0.00345233] [0.00932093]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196376\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.358  AUC-train 0.524\n",
            "Stats - Epoch: 2 AUC-val 0.417  AUC-train 0.591\n",
            "Stats - Epoch: 3 AUC-val 0.453  AUC-train 0.672\n",
            "Stats - Epoch: 4 AUC-val 0.539  AUC-train 0.748\n",
            "Stats - Epoch: 5 AUC-val 0.601  AUC-train 0.786\n",
            "Stats - Epoch: 6 AUC-val 0.609  AUC-train 0.811\n",
            "Stats - Epoch: 7 AUC-val 0.618  AUC-train 0.820\n",
            "Stats - Epoch: 8 AUC-val 0.612  AUC-train 0.830\n",
            "Stats - Epoch: 9 AUC-val 0.639  AUC-train 0.838\n",
            "Stats - Epoch: 10 AUC-val 0.660  AUC-train 0.849\n",
            "Stats - Epoch: 11 AUC-val 0.674  AUC-train 0.853\n",
            "Stats - Epoch: 12 AUC-val 0.678  AUC-train 0.860\n",
            "Stats - Epoch: 13 AUC-val 0.677  AUC-train 0.864\n",
            "Stats - Epoch: 14 AUC-val 0.691  AUC-train 0.867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.690  AUC-train 0.868\n",
            "Stats - Epoch: 16 AUC-val 0.679  AUC-train 0.870\n",
            "Stats - Epoch: 17 AUC-val 0.701  AUC-train 0.875\n",
            "Stats - Epoch: 18 AUC-val 0.704  AUC-train 0.877\n",
            "Stats - Epoch: 19 AUC-val 0.690  AUC-train 0.877\n",
            "Stats - Epoch: 20 AUC-val 0.740  AUC-train 0.882\n",
            "Stats - Epoch: 21 AUC-val 0.729  AUC-train 0.884\n",
            "Stats - Epoch: 22 AUC-val 0.692  AUC-train 0.884\n",
            "Stats - Epoch: 23 AUC-val 0.713  AUC-train 0.889\n",
            "Stats - Epoch: 24 AUC-val 0.719  AUC-train 0.891\n",
            "Stats - Epoch: 25 AUC-val 0.728  AUC-train 0.892\n",
            "Stats - Epoch: 26 AUC-val 0.729  AUC-train 0.894\n",
            "Stats - Epoch: 27 AUC-val 0.707  AUC-train 0.895\n",
            "Stats - Epoch: 28 AUC-val 0.716  AUC-train 0.894\n",
            "Stats - Epoch: 29 AUC-val 0.728  AUC-train 0.899\n",
            "Stats - Epoch: 30 AUC-val 0.724  AUC-train 0.902\n",
            "Stats - Epoch: 31 AUC-val 0.728  AUC-train 0.906\n",
            "Stats - Epoch: 32 AUC-val 0.720  AUC-train 0.904\n",
            "Stats - Epoch: 33 AUC-val 0.719  AUC-train 0.908\n",
            "Stats - Epoch: 34 AUC-val 0.709  AUC-train 0.907\n",
            "Stats - Epoch: 35 AUC-val 0.716  AUC-train 0.908\n",
            "Stats - Epoch: 36 AUC-val 0.721  AUC-train 0.906\n",
            "Stats - Epoch: 37 AUC-val 0.721  AUC-train 0.910\n",
            "Stats - Epoch: 38 AUC-val 0.717  AUC-train 0.912\n",
            "Stats - Epoch: 39 AUC-val 0.716  AUC-train 0.914\n",
            "Stats - Epoch: 40 AUC-val 0.717  AUC-train 0.915\n",
            "Stats - Epoch: 41 AUC-val 0.717  AUC-train 0.915\n",
            "Stats - Epoch: 42 AUC-val 0.761  AUC-train 0.917\n",
            "Stats - Epoch: 43 AUC-val 0.739  AUC-train 0.918\n",
            "Stats - Epoch: 44 AUC-val 0.706  AUC-train 0.920\n",
            "Stats - Epoch: 45 AUC-val 0.712  AUC-train 0.916\n",
            "Stats - Epoch: 46 AUC-val 0.719  AUC-train 0.920\n",
            "Stats - Epoch: 47 AUC-val 0.733  AUC-train 0.920\n",
            "Stats - Epoch: 48 AUC-val 0.709  AUC-train 0.922\n",
            "Stats - Epoch: 49 AUC-val 0.718  AUC-train 0.922\n",
            "Stats - Epoch: 50 AUC-val 0.718  AUC-train 0.921\n",
            "Stats - Epoch: 51 AUC-val 0.712  AUC-train 0.922\n",
            "Stats - Epoch: 52 AUC-val 0.723  AUC-train 0.924\n",
            "Stats - Epoch: 53 AUC-val 0.707  AUC-train 0.925\n",
            "Stats - Epoch: 54 AUC-val 0.717  AUC-train 0.927\n",
            "Stats - Epoch: 55 AUC-val 0.703  AUC-train 0.927\n",
            "Stats - Epoch: 56 AUC-val 0.729  AUC-train 0.930\n",
            "Stats - Epoch: 57 AUC-val 0.743  AUC-train 0.930\n",
            "Stats - Epoch: 58 AUC-val 0.740  AUC-train 0.931\n",
            "Stats - Epoch: 59 AUC-val 0.731  AUC-train 0.932\n",
            "Stats - Epoch: 60 AUC-val 0.741  AUC-train 0.933\n",
            "Stats - Epoch: 61 AUC-val 0.750  AUC-train 0.934\n",
            "Stats - Epoch: 62 AUC-val 0.731  AUC-train 0.932\n",
            "Stats - Epoch: 63 AUC-val 0.735  AUC-train 0.930\n",
            "Stats - Epoch: 64 AUC-val 0.752  AUC-train 0.930\n",
            "Stats - Epoch: 65 AUC-val 0.741  AUC-train 0.932\n",
            "Stats - Epoch: 66 AUC-val 0.724  AUC-train 0.933\n",
            "Stats - Epoch: 67 AUC-val 0.743  AUC-train 0.934\n",
            "Stats - Epoch: 68 AUC-val 0.734  AUC-train 0.934\n",
            "Stats - Epoch: 69 AUC-val 0.734  AUC-train 0.933\n",
            "Stats - Epoch: 70 AUC-val 0.736  AUC-train 0.933\n",
            "Stats - Epoch: 71 AUC-val 0.729  AUC-train 0.930\n",
            "Stats - Epoch: 72 AUC-val 0.746  AUC-train 0.930\n",
            "Stats - Epoch: 73 AUC-val 0.746  AUC-train 0.932\n",
            "Stats - Epoch: 74 AUC-val 0.723  AUC-train 0.935\n",
            "Stats - Epoch: 75 AUC-val 0.755  AUC-train 0.938\n",
            "Stats - Epoch: 76 AUC-val 0.769  AUC-train 0.938\n",
            "Stats - Epoch: 77 AUC-val 0.731  AUC-train 0.936\n",
            "Stats - Epoch: 78 AUC-val 0.769  AUC-train 0.936\n",
            "Stats - Epoch: 79 AUC-val 0.738  AUC-train 0.939\n",
            "Stats - Epoch: 80 AUC-val 0.740  AUC-train 0.939\n",
            "Stats - Epoch: 81 AUC-val 0.737  AUC-train 0.939\n",
            "Stats - Epoch: 82 AUC-val 0.743  AUC-train 0.940\n",
            "Stats - Epoch: 83 AUC-val 0.744  AUC-train 0.940\n",
            "Stats - Epoch: 84 AUC-val 0.730  AUC-train 0.941\n",
            "Stats - Epoch: 85 AUC-val 0.741  AUC-train 0.941\n",
            "Stats - Epoch: 86 AUC-val 0.724  AUC-train 0.941\n",
            "Stats - Epoch: 87 AUC-val 0.734  AUC-train 0.942\n",
            "Stats - Epoch: 88 AUC-val 0.738  AUC-train 0.943\n",
            "Stats - Epoch: 89 AUC-val 0.737  AUC-train 0.943\n",
            "Stats - Epoch: 90 AUC-val 0.721  AUC-train 0.942\n",
            "Stats - Epoch: 91 AUC-val 0.728  AUC-train 0.941\n",
            "Stats - Epoch: 92 AUC-val 0.709  AUC-train 0.941\n",
            "Stats - Epoch: 93 AUC-val 0.729  AUC-train 0.943\n",
            "Stats - Epoch: 94 AUC-val 0.727  AUC-train 0.941\n",
            "Stats - Epoch: 95 AUC-val 0.717  AUC-train 0.941\n",
            "Stats - Epoch: 96 AUC-val 0.709  AUC-train 0.942\n",
            "Stats - Epoch: 97 AUC-val 0.724  AUC-train 0.942\n",
            "Stats - Epoch: 98 AUC-val 0.711  AUC-train 0.942\n",
            "Stats - Epoch: 99 AUC-val 0.729  AUC-train 0.944\n",
            "Stats - Epoch: 100 AUC-val 0.725  AUC-train 0.942\n",
            "Results 100 AUC-val 0.769 0.618 0.499 0.511 0.651 AUC-train 0.938\n",
            "Shapley [0.01550113 0.01801339 0.01741016 0.02437723 0.01040128] [0.0196108]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199679\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.470  AUC-train 0.488\n",
            "Stats - Epoch: 2 AUC-val 0.598  AUC-train 0.514\n",
            "Stats - Epoch: 3 AUC-val 0.624  AUC-train 0.557\n",
            "Stats - Epoch: 4 AUC-val 0.614  AUC-train 0.599\n",
            "Stats - Epoch: 5 AUC-val 0.610  AUC-train 0.652\n",
            "Stats - Epoch: 6 AUC-val 0.616  AUC-train 0.676\n",
            "Stats - Epoch: 7 AUC-val 0.631  AUC-train 0.706\n",
            "Stats - Epoch: 8 AUC-val 0.625  AUC-train 0.728\n",
            "Stats - Epoch: 9 AUC-val 0.622  AUC-train 0.747\n",
            "Stats - Epoch: 10 AUC-val 0.619  AUC-train 0.760\n",
            "Stats - Epoch: 11 AUC-val 0.622  AUC-train 0.772\n",
            "Stats - Epoch: 12 AUC-val 0.631  AUC-train 0.788\n",
            "Stats - Epoch: 13 AUC-val 0.626  AUC-train 0.794\n",
            "Stats - Epoch: 14 AUC-val 0.627  AUC-train 0.802\n",
            "Stats - Epoch: 15 AUC-val 0.622  AUC-train 0.806\n",
            "Stats - Epoch: 16 AUC-val 0.644  AUC-train 0.813\n",
            "Stats - Epoch: 17 AUC-val 0.648  AUC-train 0.820\n",
            "Stats - Epoch: 18 AUC-val 0.627  AUC-train 0.822\n",
            "Stats - Epoch: 19 AUC-val 0.653  AUC-train 0.827\n",
            "Stats - Epoch: 20 AUC-val 0.648  AUC-train 0.831\n",
            "Stats - Epoch: 21 AUC-val 0.654  AUC-train 0.836\n",
            "Stats - Epoch: 22 AUC-val 0.630  AUC-train 0.836\n",
            "Stats - Epoch: 23 AUC-val 0.640  AUC-train 0.841\n",
            "Stats - Epoch: 24 AUC-val 0.636  AUC-train 0.847\n",
            "Stats - Epoch: 25 AUC-val 0.639  AUC-train 0.850\n",
            "Stats - Epoch: 26 AUC-val 0.646  AUC-train 0.855\n",
            "Stats - Epoch: 27 AUC-val 0.634  AUC-train 0.858\n",
            "Stats - Epoch: 28 AUC-val 0.673  AUC-train 0.862\n",
            "Stats - Epoch: 29 AUC-val 0.636  AUC-train 0.862\n",
            "Stats - Epoch: 30 AUC-val 0.646  AUC-train 0.866\n",
            "Stats - Epoch: 31 AUC-val 0.645  AUC-train 0.870\n",
            "Stats - Epoch: 32 AUC-val 0.654  AUC-train 0.870\n",
            "Stats - Epoch: 33 AUC-val 0.659  AUC-train 0.874\n",
            "Stats - Epoch: 34 AUC-val 0.631  AUC-train 0.872\n",
            "Stats - Epoch: 35 AUC-val 0.648  AUC-train 0.879\n",
            "Stats - Epoch: 36 AUC-val 0.663  AUC-train 0.878\n",
            "Stats - Epoch: 37 AUC-val 0.632  AUC-train 0.881\n",
            "Stats - Epoch: 38 AUC-val 0.619  AUC-train 0.883\n",
            "Stats - Epoch: 39 AUC-val 0.603  AUC-train 0.885\n",
            "Stats - Epoch: 40 AUC-val 0.610  AUC-train 0.886\n",
            "Stats - Epoch: 41 AUC-val 0.663  AUC-train 0.885\n",
            "Stats - Epoch: 42 AUC-val 0.624  AUC-train 0.888\n",
            "Stats - Epoch: 43 AUC-val 0.626  AUC-train 0.889\n",
            "Stats - Epoch: 44 AUC-val 0.633  AUC-train 0.891\n",
            "Stats - Epoch: 45 AUC-val 0.605  AUC-train 0.890\n",
            "Stats - Epoch: 46 AUC-val 0.617  AUC-train 0.891\n",
            "Stats - Epoch: 47 AUC-val 0.624  AUC-train 0.893\n",
            "Stats - Epoch: 48 AUC-val 0.611  AUC-train 0.892\n",
            "Stats - Epoch: 49 AUC-val 0.631  AUC-train 0.893\n",
            "Stats - Epoch: 50 AUC-val 0.627  AUC-train 0.893\n",
            "Stats - Epoch: 51 AUC-val 0.607  AUC-train 0.895\n",
            "Stats - Epoch: 52 AUC-val 0.608  AUC-train 0.896\n",
            "Stats - Epoch: 53 AUC-val 0.644  AUC-train 0.895\n",
            "Stats - Epoch: 54 AUC-val 0.607  AUC-train 0.897\n",
            "Stats - Epoch: 55 AUC-val 0.631  AUC-train 0.894\n",
            "Stats - Epoch: 56 AUC-val 0.624  AUC-train 0.897\n",
            "Stats - Epoch: 57 AUC-val 0.601  AUC-train 0.895\n",
            "Stats - Epoch: 58 AUC-val 0.591  AUC-train 0.897\n",
            "Stats - Epoch: 59 AUC-val 0.602  AUC-train 0.891\n",
            "Stats - Epoch: 60 AUC-val 0.611  AUC-train 0.896\n",
            "Stats - Epoch: 61 AUC-val 0.609  AUC-train 0.895\n",
            "Stats - Epoch: 62 AUC-val 0.604  AUC-train 0.901\n",
            "Stats - Epoch: 63 AUC-val 0.624  AUC-train 0.901\n",
            "Stats - Epoch: 64 AUC-val 0.600  AUC-train 0.899\n",
            "Stats - Epoch: 65 AUC-val 0.600  AUC-train 0.899\n",
            "Stats - Epoch: 66 AUC-val 0.559  AUC-train 0.895\n",
            "Stats - Epoch: 67 AUC-val 0.572  AUC-train 0.899\n",
            "Stats - Epoch: 68 AUC-val 0.609  AUC-train 0.903\n",
            "Stats - Epoch: 69 AUC-val 0.600  AUC-train 0.906\n",
            "Stats - Epoch: 70 AUC-val 0.613  AUC-train 0.907\n",
            "Stats - Epoch: 71 AUC-val 0.619  AUC-train 0.906\n",
            "Stats - Epoch: 72 AUC-val 0.626  AUC-train 0.909\n",
            "Stats - Epoch: 73 AUC-val 0.607  AUC-train 0.908\n",
            "Stats - Epoch: 74 AUC-val 0.626  AUC-train 0.909\n",
            "Stats - Epoch: 75 AUC-val 0.587  AUC-train 0.911\n",
            "Stats - Epoch: 76 AUC-val 0.543  AUC-train 0.907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.566  AUC-train 0.910\n",
            "Stats - Epoch: 78 AUC-val 0.544  AUC-train 0.910\n",
            "Stats - Epoch: 79 AUC-val 0.572  AUC-train 0.909\n",
            "Stats - Epoch: 80 AUC-val 0.549  AUC-train 0.911\n",
            "Stats - Epoch: 81 AUC-val 0.545  AUC-train 0.913\n",
            "Stats - Epoch: 82 AUC-val 0.570  AUC-train 0.914\n",
            "Stats - Epoch: 83 AUC-val 0.583  AUC-train 0.916\n",
            "Stats - Epoch: 84 AUC-val 0.600  AUC-train 0.914\n",
            "Stats - Epoch: 85 AUC-val 0.629  AUC-train 0.916\n",
            "Stats - Epoch: 86 AUC-val 0.586  AUC-train 0.917\n",
            "Stats - Epoch: 87 AUC-val 0.560  AUC-train 0.918\n",
            "Stats - Epoch: 88 AUC-val 0.593  AUC-train 0.918\n",
            "Stats - Epoch: 89 AUC-val 0.563  AUC-train 0.919\n",
            "Stats - Epoch: 90 AUC-val 0.630  AUC-train 0.920\n",
            "Stats - Epoch: 91 AUC-val 0.579  AUC-train 0.921\n",
            "Stats - Epoch: 92 AUC-val 0.571  AUC-train 0.921\n",
            "Stats - Epoch: 93 AUC-val 0.607  AUC-train 0.921\n",
            "Stats - Epoch: 94 AUC-val 0.589  AUC-train 0.922\n",
            "Stats - Epoch: 95 AUC-val 0.602  AUC-train 0.922\n",
            "Stats - Epoch: 96 AUC-val 0.609  AUC-train 0.920\n",
            "Stats - Epoch: 97 AUC-val 0.611  AUC-train 0.918\n",
            "Stats - Epoch: 98 AUC-val 0.588  AUC-train 0.918\n",
            "Stats - Epoch: 99 AUC-val 0.598  AUC-train 0.920\n",
            "Stats - Epoch: 100 AUC-val 0.617  AUC-train 0.919\n",
            "Results 100 AUC-val 0.673 0.607 0.624 0.479 0.666 AUC-train 0.862\n",
            "Shapley [0.01091201 0.01664559 0.01606035 0.0176025  0.00606794] [0.01502185]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.195423\n",
            "         Iterations 9\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.285  AUC-train 0.519\n",
            "Stats - Epoch: 2 AUC-val 0.316  AUC-train 0.546\n",
            "Stats - Epoch: 3 AUC-val 0.359  AUC-train 0.586\n",
            "Stats - Epoch: 4 AUC-val 0.390  AUC-train 0.616\n",
            "Stats - Epoch: 5 AUC-val 0.405  AUC-train 0.642\n",
            "Stats - Epoch: 6 AUC-val 0.417  AUC-train 0.663\n",
            "Stats - Epoch: 7 AUC-val 0.425  AUC-train 0.682\n",
            "Stats - Epoch: 8 AUC-val 0.428  AUC-train 0.690\n",
            "Stats - Epoch: 9 AUC-val 0.440  AUC-train 0.706\n",
            "Stats - Epoch: 10 AUC-val 0.429  AUC-train 0.720\n",
            "Stats - Epoch: 11 AUC-val 0.437  AUC-train 0.727\n",
            "Stats - Epoch: 12 AUC-val 0.434  AUC-train 0.739\n",
            "Stats - Epoch: 13 AUC-val 0.446  AUC-train 0.745\n",
            "Stats - Epoch: 14 AUC-val 0.442  AUC-train 0.753\n",
            "Stats - Epoch: 15 AUC-val 0.438  AUC-train 0.765\n",
            "Stats - Epoch: 16 AUC-val 0.444  AUC-train 0.769\n",
            "Stats - Epoch: 17 AUC-val 0.450  AUC-train 0.773\n",
            "Stats - Epoch: 18 AUC-val 0.445  AUC-train 0.784\n",
            "Stats - Epoch: 19 AUC-val 0.447  AUC-train 0.787\n",
            "Stats - Epoch: 20 AUC-val 0.447  AUC-train 0.789\n",
            "Stats - Epoch: 21 AUC-val 0.434  AUC-train 0.794\n",
            "Stats - Epoch: 22 AUC-val 0.446  AUC-train 0.801\n",
            "Stats - Epoch: 23 AUC-val 0.451  AUC-train 0.803\n",
            "Stats - Epoch: 24 AUC-val 0.454  AUC-train 0.808\n",
            "Stats - Epoch: 25 AUC-val 0.457  AUC-train 0.803\n",
            "Stats - Epoch: 26 AUC-val 0.455  AUC-train 0.813\n",
            "Stats - Epoch: 27 AUC-val 0.457  AUC-train 0.812\n",
            "Stats - Epoch: 28 AUC-val 0.468  AUC-train 0.818\n",
            "Stats - Epoch: 29 AUC-val 0.463  AUC-train 0.816\n",
            "Stats - Epoch: 30 AUC-val 0.456  AUC-train 0.822\n",
            "Stats - Epoch: 31 AUC-val 0.464  AUC-train 0.823\n",
            "Stats - Epoch: 32 AUC-val 0.463  AUC-train 0.824\n",
            "Stats - Epoch: 33 AUC-val 0.461  AUC-train 0.827\n",
            "Stats - Epoch: 34 AUC-val 0.462  AUC-train 0.825\n",
            "Stats - Epoch: 35 AUC-val 0.470  AUC-train 0.826\n",
            "Stats - Epoch: 36 AUC-val 0.471  AUC-train 0.822\n",
            "Stats - Epoch: 37 AUC-val 0.472  AUC-train 0.830\n",
            "Stats - Epoch: 38 AUC-val 0.466  AUC-train 0.831\n",
            "Stats - Epoch: 39 AUC-val 0.460  AUC-train 0.830\n",
            "Stats - Epoch: 40 AUC-val 0.474  AUC-train 0.833\n",
            "Stats - Epoch: 41 AUC-val 0.470  AUC-train 0.835\n",
            "Stats - Epoch: 42 AUC-val 0.472  AUC-train 0.834\n",
            "Stats - Epoch: 43 AUC-val 0.469  AUC-train 0.835\n",
            "Stats - Epoch: 44 AUC-val 0.475  AUC-train 0.833\n",
            "Stats - Epoch: 45 AUC-val 0.471  AUC-train 0.836\n",
            "Stats - Epoch: 46 AUC-val 0.470  AUC-train 0.838\n",
            "Stats - Epoch: 47 AUC-val 0.474  AUC-train 0.836\n",
            "Stats - Epoch: 48 AUC-val 0.470  AUC-train 0.834\n",
            "Stats - Epoch: 49 AUC-val 0.469  AUC-train 0.837\n",
            "Stats - Epoch: 50 AUC-val 0.469  AUC-train 0.840\n",
            "Stats - Epoch: 51 AUC-val 0.472  AUC-train 0.839\n",
            "Stats - Epoch: 52 AUC-val 0.469  AUC-train 0.839\n",
            "Stats - Epoch: 53 AUC-val 0.471  AUC-train 0.841\n",
            "Stats - Epoch: 54 AUC-val 0.472  AUC-train 0.841\n",
            "Stats - Epoch: 55 AUC-val 0.471  AUC-train 0.842\n",
            "Stats - Epoch: 56 AUC-val 0.477  AUC-train 0.839\n",
            "Stats - Epoch: 57 AUC-val 0.471  AUC-train 0.839\n",
            "Stats - Epoch: 58 AUC-val 0.479  AUC-train 0.840\n",
            "Stats - Epoch: 59 AUC-val 0.478  AUC-train 0.840\n",
            "Stats - Epoch: 60 AUC-val 0.476  AUC-train 0.843\n",
            "Stats - Epoch: 61 AUC-val 0.472  AUC-train 0.844\n",
            "Stats - Epoch: 62 AUC-val 0.476  AUC-train 0.844\n",
            "Stats - Epoch: 63 AUC-val 0.480  AUC-train 0.845\n",
            "Stats - Epoch: 64 AUC-val 0.478  AUC-train 0.843\n",
            "Stats - Epoch: 65 AUC-val 0.478  AUC-train 0.842\n",
            "Stats - Epoch: 66 AUC-val 0.474  AUC-train 0.842\n",
            "Stats - Epoch: 67 AUC-val 0.474  AUC-train 0.844\n",
            "Stats - Epoch: 68 AUC-val 0.479  AUC-train 0.844\n",
            "Stats - Epoch: 69 AUC-val 0.479  AUC-train 0.845\n",
            "Stats - Epoch: 70 AUC-val 0.471  AUC-train 0.846\n",
            "Stats - Epoch: 71 AUC-val 0.471  AUC-train 0.847\n",
            "Stats - Epoch: 72 AUC-val 0.483  AUC-train 0.845\n",
            "Stats - Epoch: 73 AUC-val 0.480  AUC-train 0.843\n",
            "Stats - Epoch: 74 AUC-val 0.483  AUC-train 0.841\n",
            "Stats - Epoch: 75 AUC-val 0.487  AUC-train 0.844\n",
            "Stats - Epoch: 76 AUC-val 0.481  AUC-train 0.845\n",
            "Stats - Epoch: 77 AUC-val 0.483  AUC-train 0.844\n",
            "Stats - Epoch: 78 AUC-val 0.487  AUC-train 0.846\n",
            "Stats - Epoch: 79 AUC-val 0.483  AUC-train 0.848\n",
            "Stats - Epoch: 80 AUC-val 0.481  AUC-train 0.848\n",
            "Stats - Epoch: 81 AUC-val 0.482  AUC-train 0.847\n",
            "Stats - Epoch: 82 AUC-val 0.478  AUC-train 0.848\n",
            "Stats - Epoch: 83 AUC-val 0.480  AUC-train 0.850\n",
            "Stats - Epoch: 84 AUC-val 0.486  AUC-train 0.848\n",
            "Stats - Epoch: 85 AUC-val 0.483  AUC-train 0.848\n",
            "Stats - Epoch: 86 AUC-val 0.488  AUC-train 0.850\n",
            "Stats - Epoch: 87 AUC-val 0.484  AUC-train 0.847\n",
            "Stats - Epoch: 88 AUC-val 0.484  AUC-train 0.847\n",
            "Stats - Epoch: 89 AUC-val 0.481  AUC-train 0.850\n",
            "Stats - Epoch: 90 AUC-val 0.482  AUC-train 0.847\n",
            "Stats - Epoch: 91 AUC-val 0.484  AUC-train 0.847\n",
            "Stats - Epoch: 92 AUC-val 0.488  AUC-train 0.846\n",
            "Stats - Epoch: 93 AUC-val 0.477  AUC-train 0.849\n",
            "Stats - Epoch: 94 AUC-val 0.471  AUC-train 0.848\n",
            "Stats - Epoch: 95 AUC-val 0.489  AUC-train 0.847\n",
            "Stats - Epoch: 96 AUC-val 0.476  AUC-train 0.849\n",
            "Stats - Epoch: 97 AUC-val 0.479  AUC-train 0.850\n",
            "Stats - Epoch: 98 AUC-val 0.478  AUC-train 0.851\n",
            "Stats - Epoch: 99 AUC-val 0.490  AUC-train 0.846\n",
            "Stats - Epoch: 100 AUC-val 0.486  AUC-train 0.849\n",
            "Results 100 AUC-val 0.490 0.498 0.558 0.477 0.608 AUC-train 0.846\n",
            "Shapley [0.00573932 0.00659229 0.01900871 0.00969064 0.00447532] [0.01913736]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186533\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.159  AUC-train 0.527\n",
            "Stats - Epoch: 2 AUC-val 0.288  AUC-train 0.674\n",
            "Stats - Epoch: 3 AUC-val 0.317  AUC-train 0.761\n",
            "Stats - Epoch: 4 AUC-val 0.335  AUC-train 0.806\n",
            "Stats - Epoch: 5 AUC-val 0.334  AUC-train 0.848\n",
            "Stats - Epoch: 6 AUC-val 0.318  AUC-train 0.881\n",
            "Stats - Epoch: 7 AUC-val 0.313  AUC-train 0.897\n",
            "Stats - Epoch: 8 AUC-val 0.300  AUC-train 0.912\n",
            "Stats - Epoch: 9 AUC-val 0.323  AUC-train 0.926\n",
            "Stats - Epoch: 10 AUC-val 0.343  AUC-train 0.937\n",
            "Stats - Epoch: 11 AUC-val 0.347  AUC-train 0.942\n",
            "Stats - Epoch: 12 AUC-val 0.332  AUC-train 0.951\n",
            "Stats - Epoch: 13 AUC-val 0.359  AUC-train 0.955\n",
            "Stats - Epoch: 14 AUC-val 0.373  AUC-train 0.959\n",
            "Stats - Epoch: 15 AUC-val 0.354  AUC-train 0.962\n",
            "Stats - Epoch: 16 AUC-val 0.381  AUC-train 0.963\n",
            "Stats - Epoch: 17 AUC-val 0.378  AUC-train 0.959\n",
            "Stats - Epoch: 18 AUC-val 0.386  AUC-train 0.961\n",
            "Stats - Epoch: 19 AUC-val 0.381  AUC-train 0.968\n",
            "Stats - Epoch: 20 AUC-val 0.384  AUC-train 0.967\n",
            "Stats - Epoch: 21 AUC-val 0.385  AUC-train 0.969\n",
            "Stats - Epoch: 22 AUC-val 0.405  AUC-train 0.967\n",
            "Stats - Epoch: 23 AUC-val 0.380  AUC-train 0.971\n",
            "Stats - Epoch: 24 AUC-val 0.409  AUC-train 0.971\n",
            "Stats - Epoch: 25 AUC-val 0.406  AUC-train 0.967\n",
            "Stats - Epoch: 26 AUC-val 0.403  AUC-train 0.969\n",
            "Stats - Epoch: 27 AUC-val 0.429  AUC-train 0.968\n",
            "Stats - Epoch: 28 AUC-val 0.406  AUC-train 0.972\n",
            "Stats - Epoch: 29 AUC-val 0.409  AUC-train 0.970\n",
            "Stats - Epoch: 30 AUC-val 0.413  AUC-train 0.974\n",
            "Stats - Epoch: 31 AUC-val 0.411  AUC-train 0.974\n",
            "Stats - Epoch: 32 AUC-val 0.428  AUC-train 0.974\n",
            "Stats - Epoch: 33 AUC-val 0.397  AUC-train 0.975\n",
            "Stats - Epoch: 34 AUC-val 0.421  AUC-train 0.967\n",
            "Stats - Epoch: 35 AUC-val 0.431  AUC-train 0.971\n",
            "Stats - Epoch: 36 AUC-val 0.456  AUC-train 0.966\n",
            "Stats - Epoch: 37 AUC-val 0.434  AUC-train 0.970\n",
            "Stats - Epoch: 38 AUC-val 0.422  AUC-train 0.971\n",
            "Stats - Epoch: 39 AUC-val 0.412  AUC-train 0.972\n",
            "Stats - Epoch: 40 AUC-val 0.419  AUC-train 0.975\n",
            "Stats - Epoch: 41 AUC-val 0.429  AUC-train 0.973\n",
            "Stats - Epoch: 42 AUC-val 0.436  AUC-train 0.970\n",
            "Stats - Epoch: 43 AUC-val 0.444  AUC-train 0.971\n",
            "Stats - Epoch: 44 AUC-val 0.432  AUC-train 0.970\n",
            "Stats - Epoch: 45 AUC-val 0.448  AUC-train 0.969\n",
            "Stats - Epoch: 46 AUC-val 0.442  AUC-train 0.972\n",
            "Stats - Epoch: 47 AUC-val 0.438  AUC-train 0.971\n",
            "Stats - Epoch: 48 AUC-val 0.432  AUC-train 0.969\n",
            "Stats - Epoch: 49 AUC-val 0.425  AUC-train 0.969\n",
            "Stats - Epoch: 50 AUC-val 0.437  AUC-train 0.970\n",
            "Stats - Epoch: 51 AUC-val 0.434  AUC-train 0.971\n",
            "Stats - Epoch: 52 AUC-val 0.427  AUC-train 0.972\n",
            "Stats - Epoch: 53 AUC-val 0.447  AUC-train 0.971\n",
            "Stats - Epoch: 54 AUC-val 0.448  AUC-train 0.971\n",
            "Stats - Epoch: 55 AUC-val 0.459  AUC-train 0.965\n",
            "Stats - Epoch: 56 AUC-val 0.431  AUC-train 0.971\n",
            "Stats - Epoch: 57 AUC-val 0.436  AUC-train 0.968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.439  AUC-train 0.972\n",
            "Stats - Epoch: 59 AUC-val 0.429  AUC-train 0.971\n",
            "Stats - Epoch: 60 AUC-val 0.440  AUC-train 0.972\n",
            "Stats - Epoch: 61 AUC-val 0.450  AUC-train 0.968\n",
            "Stats - Epoch: 62 AUC-val 0.428  AUC-train 0.974\n",
            "Stats - Epoch: 63 AUC-val 0.448  AUC-train 0.971\n",
            "Stats - Epoch: 64 AUC-val 0.434  AUC-train 0.964\n",
            "Stats - Epoch: 65 AUC-val 0.432  AUC-train 0.970\n",
            "Stats - Epoch: 66 AUC-val 0.422  AUC-train 0.972\n",
            "Stats - Epoch: 67 AUC-val 0.436  AUC-train 0.970\n",
            "Stats - Epoch: 68 AUC-val 0.434  AUC-train 0.972\n",
            "Stats - Epoch: 69 AUC-val 0.452  AUC-train 0.973\n",
            "Stats - Epoch: 70 AUC-val 0.426  AUC-train 0.972\n",
            "Stats - Epoch: 71 AUC-val 0.457  AUC-train 0.970\n",
            "Stats - Epoch: 72 AUC-val 0.450  AUC-train 0.964\n",
            "Stats - Epoch: 73 AUC-val 0.445  AUC-train 0.963\n",
            "Stats - Epoch: 74 AUC-val 0.445  AUC-train 0.963\n",
            "Stats - Epoch: 75 AUC-val 0.441  AUC-train 0.968\n",
            "Stats - Epoch: 76 AUC-val 0.457  AUC-train 0.967\n",
            "Stats - Epoch: 77 AUC-val 0.438  AUC-train 0.964\n",
            "Stats - Epoch: 78 AUC-val 0.443  AUC-train 0.954\n",
            "Stats - Epoch: 79 AUC-val 0.418  AUC-train 0.968\n",
            "Stats - Epoch: 80 AUC-val 0.432  AUC-train 0.969\n",
            "Stats - Epoch: 81 AUC-val 0.429  AUC-train 0.969\n",
            "Stats - Epoch: 82 AUC-val 0.439  AUC-train 0.973\n",
            "Stats - Epoch: 83 AUC-val 0.432  AUC-train 0.971\n",
            "Stats - Epoch: 84 AUC-val 0.471  AUC-train 0.966\n",
            "Stats - Epoch: 85 AUC-val 0.438  AUC-train 0.966\n",
            "Stats - Epoch: 86 AUC-val 0.447  AUC-train 0.968\n",
            "Stats - Epoch: 87 AUC-val 0.425  AUC-train 0.971\n",
            "Stats - Epoch: 88 AUC-val 0.444  AUC-train 0.969\n",
            "Stats - Epoch: 89 AUC-val 0.431  AUC-train 0.969\n",
            "Stats - Epoch: 90 AUC-val 0.434  AUC-train 0.970\n",
            "Stats - Epoch: 91 AUC-val 0.462  AUC-train 0.971\n",
            "Stats - Epoch: 92 AUC-val 0.426  AUC-train 0.970\n",
            "Stats - Epoch: 93 AUC-val 0.443  AUC-train 0.973\n",
            "Stats - Epoch: 94 AUC-val 0.438  AUC-train 0.965\n",
            "Stats - Epoch: 95 AUC-val 0.420  AUC-train 0.967\n",
            "Stats - Epoch: 96 AUC-val 0.416  AUC-train 0.967\n",
            "Stats - Epoch: 97 AUC-val 0.437  AUC-train 0.966\n",
            "Stats - Epoch: 98 AUC-val 0.434  AUC-train 0.969\n",
            "Stats - Epoch: 99 AUC-val 0.427  AUC-train 0.966\n",
            "Stats - Epoch: 100 AUC-val 0.422  AUC-train 0.968\n",
            "Results 100 AUC-val 0.471 0.396 0.333 0.222 0.548 AUC-train 0.966\n",
            "Shapley [0.02554136 0.00923659 0.00656528 0.03700522 0.00940651] [0.04246649]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.177786\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.224  AUC-train 0.555\n",
            "Stats - Epoch: 2 AUC-val 0.232  AUC-train 0.581\n",
            "Stats - Epoch: 3 AUC-val 0.222  AUC-train 0.598\n",
            "Stats - Epoch: 4 AUC-val 0.187  AUC-train 0.622\n",
            "Stats - Epoch: 5 AUC-val 0.201  AUC-train 0.657\n",
            "Stats - Epoch: 6 AUC-val 0.234  AUC-train 0.687\n",
            "Stats - Epoch: 7 AUC-val 0.257  AUC-train 0.716\n",
            "Stats - Epoch: 8 AUC-val 0.365  AUC-train 0.731\n",
            "Stats - Epoch: 9 AUC-val 0.392  AUC-train 0.757\n",
            "Stats - Epoch: 10 AUC-val 0.431  AUC-train 0.771\n",
            "Stats - Epoch: 11 AUC-val 0.437  AUC-train 0.782\n",
            "Stats - Epoch: 12 AUC-val 0.424  AUC-train 0.788\n",
            "Stats - Epoch: 13 AUC-val 0.495  AUC-train 0.797\n",
            "Stats - Epoch: 14 AUC-val 0.427  AUC-train 0.798\n",
            "Stats - Epoch: 15 AUC-val 0.446  AUC-train 0.806\n",
            "Stats - Epoch: 16 AUC-val 0.530  AUC-train 0.809\n",
            "Stats - Epoch: 17 AUC-val 0.486  AUC-train 0.812\n",
            "Stats - Epoch: 18 AUC-val 0.475  AUC-train 0.815\n",
            "Stats - Epoch: 19 AUC-val 0.512  AUC-train 0.815\n",
            "Stats - Epoch: 20 AUC-val 0.523  AUC-train 0.820\n",
            "Stats - Epoch: 21 AUC-val 0.518  AUC-train 0.821\n",
            "Stats - Epoch: 22 AUC-val 0.556  AUC-train 0.824\n",
            "Stats - Epoch: 23 AUC-val 0.565  AUC-train 0.823\n",
            "Stats - Epoch: 24 AUC-val 0.544  AUC-train 0.825\n",
            "Stats - Epoch: 25 AUC-val 0.474  AUC-train 0.831\n",
            "Stats - Epoch: 26 AUC-val 0.533  AUC-train 0.827\n",
            "Stats - Epoch: 27 AUC-val 0.549  AUC-train 0.827\n",
            "Stats - Epoch: 28 AUC-val 0.572  AUC-train 0.830\n",
            "Stats - Epoch: 29 AUC-val 0.552  AUC-train 0.832\n",
            "Stats - Epoch: 30 AUC-val 0.566  AUC-train 0.833\n",
            "Stats - Epoch: 31 AUC-val 0.569  AUC-train 0.831\n",
            "Stats - Epoch: 32 AUC-val 0.567  AUC-train 0.833\n",
            "Stats - Epoch: 33 AUC-val 0.581  AUC-train 0.834\n",
            "Stats - Epoch: 34 AUC-val 0.563  AUC-train 0.836\n",
            "Stats - Epoch: 35 AUC-val 0.553  AUC-train 0.837\n",
            "Stats - Epoch: 36 AUC-val 0.581  AUC-train 0.838\n",
            "Stats - Epoch: 37 AUC-val 0.564  AUC-train 0.838\n",
            "Stats - Epoch: 38 AUC-val 0.593  AUC-train 0.834\n",
            "Stats - Epoch: 39 AUC-val 0.578  AUC-train 0.839\n",
            "Stats - Epoch: 40 AUC-val 0.577  AUC-train 0.833\n",
            "Stats - Epoch: 41 AUC-val 0.575  AUC-train 0.836\n",
            "Stats - Epoch: 42 AUC-val 0.597  AUC-train 0.833\n",
            "Stats - Epoch: 43 AUC-val 0.585  AUC-train 0.829\n",
            "Stats - Epoch: 44 AUC-val 0.622  AUC-train 0.826\n",
            "Stats - Epoch: 45 AUC-val 0.591  AUC-train 0.831\n",
            "Stats - Epoch: 46 AUC-val 0.590  AUC-train 0.828\n",
            "Stats - Epoch: 47 AUC-val 0.574  AUC-train 0.831\n",
            "Stats - Epoch: 48 AUC-val 0.586  AUC-train 0.830\n",
            "Stats - Epoch: 49 AUC-val 0.578  AUC-train 0.835\n",
            "Stats - Epoch: 50 AUC-val 0.603  AUC-train 0.832\n",
            "Stats - Epoch: 51 AUC-val 0.576  AUC-train 0.836\n",
            "Stats - Epoch: 52 AUC-val 0.564  AUC-train 0.840\n",
            "Stats - Epoch: 53 AUC-val 0.563  AUC-train 0.842\n",
            "Stats - Epoch: 54 AUC-val 0.595  AUC-train 0.841\n",
            "Stats - Epoch: 55 AUC-val 0.569  AUC-train 0.838\n",
            "Stats - Epoch: 56 AUC-val 0.561  AUC-train 0.838\n",
            "Stats - Epoch: 57 AUC-val 0.580  AUC-train 0.842\n",
            "Stats - Epoch: 58 AUC-val 0.598  AUC-train 0.836\n",
            "Stats - Epoch: 59 AUC-val 0.598  AUC-train 0.837\n",
            "Stats - Epoch: 60 AUC-val 0.614  AUC-train 0.840\n",
            "Stats - Epoch: 61 AUC-val 0.589  AUC-train 0.839\n",
            "Stats - Epoch: 62 AUC-val 0.593  AUC-train 0.838\n",
            "Stats - Epoch: 63 AUC-val 0.597  AUC-train 0.841\n",
            "Stats - Epoch: 64 AUC-val 0.595  AUC-train 0.838\n",
            "Stats - Epoch: 65 AUC-val 0.593  AUC-train 0.837\n",
            "Stats - Epoch: 66 AUC-val 0.591  AUC-train 0.836\n",
            "Stats - Epoch: 67 AUC-val 0.595  AUC-train 0.839\n",
            "Stats - Epoch: 68 AUC-val 0.583  AUC-train 0.842\n",
            "Stats - Epoch: 69 AUC-val 0.587  AUC-train 0.845\n",
            "Stats - Epoch: 70 AUC-val 0.593  AUC-train 0.846\n",
            "Stats - Epoch: 71 AUC-val 0.600  AUC-train 0.841\n",
            "Stats - Epoch: 72 AUC-val 0.618  AUC-train 0.842\n",
            "Stats - Epoch: 73 AUC-val 0.600  AUC-train 0.838\n",
            "Stats - Epoch: 74 AUC-val 0.593  AUC-train 0.843\n",
            "Stats - Epoch: 75 AUC-val 0.584  AUC-train 0.843\n",
            "Stats - Epoch: 76 AUC-val 0.591  AUC-train 0.842\n",
            "Stats - Epoch: 77 AUC-val 0.593  AUC-train 0.840\n",
            "Stats - Epoch: 78 AUC-val 0.600  AUC-train 0.844\n",
            "Stats - Epoch: 79 AUC-val 0.605  AUC-train 0.844\n",
            "Stats - Epoch: 80 AUC-val 0.619  AUC-train 0.842\n",
            "Stats - Epoch: 81 AUC-val 0.616  AUC-train 0.840\n",
            "Stats - Epoch: 82 AUC-val 0.681  AUC-train 0.846\n",
            "Stats - Epoch: 83 AUC-val 0.596  AUC-train 0.849\n",
            "Stats - Epoch: 84 AUC-val 0.584  AUC-train 0.848\n",
            "Stats - Epoch: 85 AUC-val 0.603  AUC-train 0.846\n",
            "Stats - Epoch: 86 AUC-val 0.602  AUC-train 0.849\n",
            "Stats - Epoch: 87 AUC-val 0.617  AUC-train 0.849\n",
            "Stats - Epoch: 88 AUC-val 0.598  AUC-train 0.846\n",
            "Stats - Epoch: 89 AUC-val 0.601  AUC-train 0.849\n",
            "Stats - Epoch: 90 AUC-val 0.609  AUC-train 0.851\n",
            "Stats - Epoch: 91 AUC-val 0.594  AUC-train 0.849\n",
            "Stats - Epoch: 92 AUC-val 0.595  AUC-train 0.843\n",
            "Stats - Epoch: 93 AUC-val 0.606  AUC-train 0.844\n",
            "Stats - Epoch: 94 AUC-val 0.602  AUC-train 0.847\n",
            "Stats - Epoch: 95 AUC-val 0.612  AUC-train 0.846\n",
            "Stats - Epoch: 96 AUC-val 0.606  AUC-train 0.850\n",
            "Stats - Epoch: 97 AUC-val 0.616  AUC-train 0.851\n",
            "Stats - Epoch: 98 AUC-val 0.638  AUC-train 0.846\n",
            "Stats - Epoch: 99 AUC-val 0.596  AUC-train 0.847\n",
            "Stats - Epoch: 100 AUC-val 0.593  AUC-train 0.848\n",
            "Results 100 AUC-val 0.681 0.663 0.632 0.523 0.657 AUC-train 0.846\n",
            "Shapley [0.01172592 0.00875706 0.01428713 0.01113889 0.0037453 ] [0.00715932]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196358\n",
            "         Iterations 7\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.335  AUC-train 0.535\n",
            "Stats - Epoch: 2 AUC-val 0.383  AUC-train 0.612\n",
            "Stats - Epoch: 3 AUC-val 0.475  AUC-train 0.712\n",
            "Stats - Epoch: 4 AUC-val 0.571  AUC-train 0.771\n",
            "Stats - Epoch: 5 AUC-val 0.600  AUC-train 0.801\n",
            "Stats - Epoch: 6 AUC-val 0.641  AUC-train 0.821\n",
            "Stats - Epoch: 7 AUC-val 0.669  AUC-train 0.837\n",
            "Stats - Epoch: 8 AUC-val 0.664  AUC-train 0.849\n",
            "Stats - Epoch: 9 AUC-val 0.695  AUC-train 0.856\n",
            "Stats - Epoch: 10 AUC-val 0.695  AUC-train 0.863\n",
            "Stats - Epoch: 11 AUC-val 0.717  AUC-train 0.874\n",
            "Stats - Epoch: 12 AUC-val 0.711  AUC-train 0.880\n",
            "Stats - Epoch: 13 AUC-val 0.723  AUC-train 0.885\n",
            "Stats - Epoch: 14 AUC-val 0.720  AUC-train 0.889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.740  AUC-train 0.893\n",
            "Stats - Epoch: 16 AUC-val 0.733  AUC-train 0.897\n",
            "Stats - Epoch: 17 AUC-val 0.763  AUC-train 0.901\n",
            "Stats - Epoch: 18 AUC-val 0.767  AUC-train 0.905\n",
            "Stats - Epoch: 19 AUC-val 0.743  AUC-train 0.909\n",
            "Stats - Epoch: 20 AUC-val 0.729  AUC-train 0.913\n",
            "Stats - Epoch: 21 AUC-val 0.736  AUC-train 0.917\n",
            "Stats - Epoch: 22 AUC-val 0.744  AUC-train 0.918\n",
            "Stats - Epoch: 23 AUC-val 0.760  AUC-train 0.922\n",
            "Stats - Epoch: 24 AUC-val 0.732  AUC-train 0.924\n",
            "Stats - Epoch: 25 AUC-val 0.735  AUC-train 0.927\n",
            "Stats - Epoch: 26 AUC-val 0.739  AUC-train 0.927\n",
            "Stats - Epoch: 27 AUC-val 0.728  AUC-train 0.928\n",
            "Stats - Epoch: 28 AUC-val 0.740  AUC-train 0.928\n",
            "Stats - Epoch: 29 AUC-val 0.731  AUC-train 0.930\n",
            "Stats - Epoch: 30 AUC-val 0.753  AUC-train 0.933\n",
            "Stats - Epoch: 31 AUC-val 0.742  AUC-train 0.937\n",
            "Stats - Epoch: 32 AUC-val 0.747  AUC-train 0.938\n",
            "Stats - Epoch: 33 AUC-val 0.740  AUC-train 0.940\n",
            "Stats - Epoch: 34 AUC-val 0.741  AUC-train 0.939\n",
            "Stats - Epoch: 35 AUC-val 0.726  AUC-train 0.940\n",
            "Stats - Epoch: 36 AUC-val 0.745  AUC-train 0.942\n",
            "Stats - Epoch: 37 AUC-val 0.749  AUC-train 0.943\n",
            "Stats - Epoch: 38 AUC-val 0.722  AUC-train 0.941\n",
            "Stats - Epoch: 39 AUC-val 0.743  AUC-train 0.943\n",
            "Stats - Epoch: 40 AUC-val 0.759  AUC-train 0.941\n",
            "Stats - Epoch: 41 AUC-val 0.740  AUC-train 0.943\n",
            "Stats - Epoch: 42 AUC-val 0.727  AUC-train 0.945\n",
            "Stats - Epoch: 43 AUC-val 0.726  AUC-train 0.945\n",
            "Stats - Epoch: 44 AUC-val 0.714  AUC-train 0.945\n",
            "Stats - Epoch: 45 AUC-val 0.729  AUC-train 0.946\n",
            "Stats - Epoch: 46 AUC-val 0.728  AUC-train 0.948\n",
            "Stats - Epoch: 47 AUC-val 0.736  AUC-train 0.951\n",
            "Stats - Epoch: 48 AUC-val 0.734  AUC-train 0.951\n",
            "Stats - Epoch: 49 AUC-val 0.738  AUC-train 0.951\n",
            "Stats - Epoch: 50 AUC-val 0.752  AUC-train 0.951\n",
            "Stats - Epoch: 51 AUC-val 0.732  AUC-train 0.952\n",
            "Stats - Epoch: 52 AUC-val 0.729  AUC-train 0.954\n",
            "Stats - Epoch: 53 AUC-val 0.727  AUC-train 0.952\n",
            "Stats - Epoch: 54 AUC-val 0.741  AUC-train 0.952\n",
            "Stats - Epoch: 55 AUC-val 0.719  AUC-train 0.954\n",
            "Stats - Epoch: 56 AUC-val 0.746  AUC-train 0.953\n",
            "Stats - Epoch: 57 AUC-val 0.716  AUC-train 0.953\n",
            "Stats - Epoch: 58 AUC-val 0.757  AUC-train 0.956\n",
            "Stats - Epoch: 59 AUC-val 0.724  AUC-train 0.955\n",
            "Stats - Epoch: 60 AUC-val 0.746  AUC-train 0.957\n",
            "Stats - Epoch: 61 AUC-val 0.745  AUC-train 0.959\n",
            "Stats - Epoch: 62 AUC-val 0.734  AUC-train 0.960\n",
            "Stats - Epoch: 63 AUC-val 0.755  AUC-train 0.960\n",
            "Stats - Epoch: 64 AUC-val 0.736  AUC-train 0.959\n",
            "Stats - Epoch: 65 AUC-val 0.754  AUC-train 0.958\n",
            "Stats - Epoch: 66 AUC-val 0.733  AUC-train 0.959\n",
            "Stats - Epoch: 67 AUC-val 0.760  AUC-train 0.955\n",
            "Stats - Epoch: 68 AUC-val 0.736  AUC-train 0.957\n",
            "Stats - Epoch: 69 AUC-val 0.735  AUC-train 0.960\n",
            "Stats - Epoch: 70 AUC-val 0.726  AUC-train 0.962\n",
            "Stats - Epoch: 71 AUC-val 0.733  AUC-train 0.961\n",
            "Stats - Epoch: 72 AUC-val 0.748  AUC-train 0.962\n",
            "Stats - Epoch: 73 AUC-val 0.741  AUC-train 0.961\n",
            "Stats - Epoch: 74 AUC-val 0.735  AUC-train 0.962\n",
            "Stats - Epoch: 75 AUC-val 0.750  AUC-train 0.961\n",
            "Stats - Epoch: 76 AUC-val 0.741  AUC-train 0.962\n",
            "Stats - Epoch: 77 AUC-val 0.757  AUC-train 0.963\n",
            "Stats - Epoch: 78 AUC-val 0.747  AUC-train 0.961\n",
            "Stats - Epoch: 79 AUC-val 0.739  AUC-train 0.964\n",
            "Stats - Epoch: 80 AUC-val 0.728  AUC-train 0.965\n",
            "Stats - Epoch: 81 AUC-val 0.733  AUC-train 0.964\n",
            "Stats - Epoch: 82 AUC-val 0.693  AUC-train 0.963\n",
            "Stats - Epoch: 83 AUC-val 0.732  AUC-train 0.963\n",
            "Stats - Epoch: 84 AUC-val 0.706  AUC-train 0.963\n",
            "Stats - Epoch: 85 AUC-val 0.728  AUC-train 0.963\n",
            "Stats - Epoch: 86 AUC-val 0.738  AUC-train 0.964\n",
            "Stats - Epoch: 87 AUC-val 0.726  AUC-train 0.962\n",
            "Stats - Epoch: 88 AUC-val 0.719  AUC-train 0.964\n",
            "Stats - Epoch: 89 AUC-val 0.728  AUC-train 0.965\n",
            "Stats - Epoch: 90 AUC-val 0.730  AUC-train 0.964\n",
            "Stats - Epoch: 91 AUC-val 0.702  AUC-train 0.964\n",
            "Stats - Epoch: 92 AUC-val 0.723  AUC-train 0.962\n",
            "Stats - Epoch: 93 AUC-val 0.727  AUC-train 0.965\n",
            "Stats - Epoch: 94 AUC-val 0.719  AUC-train 0.966\n",
            "Stats - Epoch: 95 AUC-val 0.731  AUC-train 0.967\n",
            "Stats - Epoch: 96 AUC-val 0.695  AUC-train 0.968\n",
            "Stats - Epoch: 97 AUC-val 0.713  AUC-train 0.966\n",
            "Stats - Epoch: 98 AUC-val 0.717  AUC-train 0.966\n",
            "Stats - Epoch: 99 AUC-val 0.714  AUC-train 0.966\n",
            "Stats - Epoch: 100 AUC-val 0.724  AUC-train 0.964\n",
            "Results 100 AUC-val 0.767 0.630 0.560 0.449 0.582 AUC-train 0.905\n",
            "Shapley [0.01467054 0.01573433 0.01934789 0.02292098 0.00853471] [0.01956479]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198142\n",
            "         Iterations 7\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.523  AUC-train 0.461\n",
            "Stats - Epoch: 2 AUC-val 0.530  AUC-train 0.513\n",
            "Stats - Epoch: 3 AUC-val 0.545  AUC-train 0.595\n",
            "Stats - Epoch: 4 AUC-val 0.566  AUC-train 0.656\n",
            "Stats - Epoch: 5 AUC-val 0.569  AUC-train 0.696\n",
            "Stats - Epoch: 6 AUC-val 0.571  AUC-train 0.730\n",
            "Stats - Epoch: 7 AUC-val 0.598  AUC-train 0.747\n",
            "Stats - Epoch: 8 AUC-val 0.612  AUC-train 0.767\n",
            "Stats - Epoch: 9 AUC-val 0.602  AUC-train 0.779\n",
            "Stats - Epoch: 10 AUC-val 0.598  AUC-train 0.795\n",
            "Stats - Epoch: 11 AUC-val 0.581  AUC-train 0.807\n",
            "Stats - Epoch: 12 AUC-val 0.586  AUC-train 0.819\n",
            "Stats - Epoch: 13 AUC-val 0.586  AUC-train 0.831\n",
            "Stats - Epoch: 14 AUC-val 0.605  AUC-train 0.835\n",
            "Stats - Epoch: 15 AUC-val 0.610  AUC-train 0.839\n",
            "Stats - Epoch: 16 AUC-val 0.611  AUC-train 0.846\n",
            "Stats - Epoch: 17 AUC-val 0.574  AUC-train 0.852\n",
            "Stats - Epoch: 18 AUC-val 0.587  AUC-train 0.860\n",
            "Stats - Epoch: 19 AUC-val 0.584  AUC-train 0.861\n",
            "Stats - Epoch: 20 AUC-val 0.572  AUC-train 0.864\n",
            "Stats - Epoch: 21 AUC-val 0.576  AUC-train 0.868\n",
            "Stats - Epoch: 22 AUC-val 0.585  AUC-train 0.873\n",
            "Stats - Epoch: 23 AUC-val 0.611  AUC-train 0.877\n",
            "Stats - Epoch: 24 AUC-val 0.593  AUC-train 0.880\n",
            "Stats - Epoch: 25 AUC-val 0.595  AUC-train 0.880\n",
            "Stats - Epoch: 26 AUC-val 0.566  AUC-train 0.882\n",
            "Stats - Epoch: 27 AUC-val 0.596  AUC-train 0.882\n",
            "Stats - Epoch: 28 AUC-val 0.567  AUC-train 0.888\n",
            "Stats - Epoch: 29 AUC-val 0.588  AUC-train 0.889\n",
            "Stats - Epoch: 30 AUC-val 0.585  AUC-train 0.894\n",
            "Stats - Epoch: 31 AUC-val 0.560  AUC-train 0.897\n",
            "Stats - Epoch: 32 AUC-val 0.592  AUC-train 0.898\n",
            "Stats - Epoch: 33 AUC-val 0.580  AUC-train 0.900\n",
            "Stats - Epoch: 34 AUC-val 0.604  AUC-train 0.900\n",
            "Stats - Epoch: 35 AUC-val 0.573  AUC-train 0.904\n",
            "Stats - Epoch: 36 AUC-val 0.562  AUC-train 0.906\n",
            "Stats - Epoch: 37 AUC-val 0.583  AUC-train 0.908\n",
            "Stats - Epoch: 38 AUC-val 0.575  AUC-train 0.913\n",
            "Stats - Epoch: 39 AUC-val 0.632  AUC-train 0.911\n",
            "Stats - Epoch: 40 AUC-val 0.560  AUC-train 0.915\n",
            "Stats - Epoch: 41 AUC-val 0.601  AUC-train 0.915\n",
            "Stats - Epoch: 42 AUC-val 0.595  AUC-train 0.919\n",
            "Stats - Epoch: 43 AUC-val 0.609  AUC-train 0.917\n",
            "Stats - Epoch: 44 AUC-val 0.578  AUC-train 0.920\n",
            "Stats - Epoch: 45 AUC-val 0.598  AUC-train 0.919\n",
            "Stats - Epoch: 46 AUC-val 0.571  AUC-train 0.921\n",
            "Stats - Epoch: 47 AUC-val 0.581  AUC-train 0.923\n",
            "Stats - Epoch: 48 AUC-val 0.576  AUC-train 0.923\n",
            "Stats - Epoch: 49 AUC-val 0.542  AUC-train 0.924\n",
            "Stats - Epoch: 50 AUC-val 0.570  AUC-train 0.923\n",
            "Stats - Epoch: 51 AUC-val 0.541  AUC-train 0.927\n",
            "Stats - Epoch: 52 AUC-val 0.550  AUC-train 0.929\n",
            "Stats - Epoch: 53 AUC-val 0.574  AUC-train 0.931\n",
            "Stats - Epoch: 54 AUC-val 0.602  AUC-train 0.934\n",
            "Stats - Epoch: 55 AUC-val 0.543  AUC-train 0.934\n",
            "Stats - Epoch: 56 AUC-val 0.589  AUC-train 0.933\n",
            "Stats - Epoch: 57 AUC-val 0.622  AUC-train 0.936\n",
            "Stats - Epoch: 58 AUC-val 0.562  AUC-train 0.936\n",
            "Stats - Epoch: 59 AUC-val 0.555  AUC-train 0.938\n",
            "Stats - Epoch: 60 AUC-val 0.554  AUC-train 0.940\n",
            "Stats - Epoch: 61 AUC-val 0.579  AUC-train 0.939\n",
            "Stats - Epoch: 62 AUC-val 0.617  AUC-train 0.938\n",
            "Stats - Epoch: 63 AUC-val 0.616  AUC-train 0.938\n",
            "Stats - Epoch: 64 AUC-val 0.585  AUC-train 0.938\n",
            "Stats - Epoch: 65 AUC-val 0.599  AUC-train 0.940\n",
            "Stats - Epoch: 66 AUC-val 0.607  AUC-train 0.941\n",
            "Stats - Epoch: 67 AUC-val 0.560  AUC-train 0.942\n",
            "Stats - Epoch: 68 AUC-val 0.621  AUC-train 0.940\n",
            "Stats - Epoch: 69 AUC-val 0.591  AUC-train 0.942\n",
            "Stats - Epoch: 70 AUC-val 0.553  AUC-train 0.943\n",
            "Stats - Epoch: 71 AUC-val 0.560  AUC-train 0.944\n",
            "Stats - Epoch: 72 AUC-val 0.545  AUC-train 0.945\n",
            "Stats - Epoch: 73 AUC-val 0.552  AUC-train 0.943\n",
            "Stats - Epoch: 74 AUC-val 0.569  AUC-train 0.945\n",
            "Stats - Epoch: 75 AUC-val 0.597  AUC-train 0.945\n",
            "Stats - Epoch: 76 AUC-val 0.595  AUC-train 0.946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.591  AUC-train 0.947\n",
            "Stats - Epoch: 78 AUC-val 0.626  AUC-train 0.948\n",
            "Stats - Epoch: 79 AUC-val 0.593  AUC-train 0.951\n",
            "Stats - Epoch: 80 AUC-val 0.584  AUC-train 0.947\n",
            "Stats - Epoch: 81 AUC-val 0.595  AUC-train 0.947\n",
            "Stats - Epoch: 82 AUC-val 0.606  AUC-train 0.950\n",
            "Stats - Epoch: 83 AUC-val 0.558  AUC-train 0.949\n",
            "Stats - Epoch: 84 AUC-val 0.574  AUC-train 0.952\n",
            "Stats - Epoch: 85 AUC-val 0.630  AUC-train 0.955\n",
            "Stats - Epoch: 86 AUC-val 0.609  AUC-train 0.956\n",
            "Stats - Epoch: 87 AUC-val 0.599  AUC-train 0.957\n",
            "Stats - Epoch: 88 AUC-val 0.595  AUC-train 0.958\n",
            "Stats - Epoch: 89 AUC-val 0.612  AUC-train 0.955\n",
            "Stats - Epoch: 90 AUC-val 0.607  AUC-train 0.957\n",
            "Stats - Epoch: 91 AUC-val 0.605  AUC-train 0.957\n",
            "Stats - Epoch: 92 AUC-val 0.636  AUC-train 0.956\n",
            "Stats - Epoch: 93 AUC-val 0.638  AUC-train 0.957\n",
            "Stats - Epoch: 94 AUC-val 0.569  AUC-train 0.959\n",
            "Stats - Epoch: 95 AUC-val 0.603  AUC-train 0.959\n",
            "Stats - Epoch: 96 AUC-val 0.617  AUC-train 0.953\n",
            "Stats - Epoch: 97 AUC-val 0.625  AUC-train 0.952\n",
            "Stats - Epoch: 98 AUC-val 0.632  AUC-train 0.951\n",
            "Stats - Epoch: 99 AUC-val 0.624  AUC-train 0.955\n",
            "Stats - Epoch: 100 AUC-val 0.616  AUC-train 0.956\n",
            "Results 100 AUC-val 0.638 0.712 0.595 0.497 0.705 AUC-train 0.957\n",
            "Shapley [0.01311782 0.01487538 0.01133034 0.02083163 0.00792064] [0.01453951]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197107\n",
            "         Iterations 9\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.392  AUC-train 0.483\n",
            "Stats - Epoch: 2 AUC-val 0.381  AUC-train 0.549\n",
            "Stats - Epoch: 3 AUC-val 0.419  AUC-train 0.592\n",
            "Stats - Epoch: 4 AUC-val 0.442  AUC-train 0.624\n",
            "Stats - Epoch: 5 AUC-val 0.438  AUC-train 0.646\n",
            "Stats - Epoch: 6 AUC-val 0.433  AUC-train 0.672\n",
            "Stats - Epoch: 7 AUC-val 0.429  AUC-train 0.689\n",
            "Stats - Epoch: 8 AUC-val 0.422  AUC-train 0.703\n",
            "Stats - Epoch: 9 AUC-val 0.419  AUC-train 0.720\n",
            "Stats - Epoch: 10 AUC-val 0.420  AUC-train 0.732\n",
            "Stats - Epoch: 11 AUC-val 0.422  AUC-train 0.739\n",
            "Stats - Epoch: 12 AUC-val 0.431  AUC-train 0.752\n",
            "Stats - Epoch: 13 AUC-val 0.422  AUC-train 0.754\n",
            "Stats - Epoch: 14 AUC-val 0.433  AUC-train 0.767\n",
            "Stats - Epoch: 15 AUC-val 0.421  AUC-train 0.767\n",
            "Stats - Epoch: 16 AUC-val 0.432  AUC-train 0.772\n",
            "Stats - Epoch: 17 AUC-val 0.432  AUC-train 0.774\n",
            "Stats - Epoch: 18 AUC-val 0.429  AUC-train 0.782\n",
            "Stats - Epoch: 19 AUC-val 0.434  AUC-train 0.791\n",
            "Stats - Epoch: 20 AUC-val 0.436  AUC-train 0.795\n",
            "Stats - Epoch: 21 AUC-val 0.432  AUC-train 0.796\n",
            "Stats - Epoch: 22 AUC-val 0.436  AUC-train 0.801\n",
            "Stats - Epoch: 23 AUC-val 0.438  AUC-train 0.805\n",
            "Stats - Epoch: 24 AUC-val 0.438  AUC-train 0.809\n",
            "Stats - Epoch: 25 AUC-val 0.435  AUC-train 0.806\n",
            "Stats - Epoch: 26 AUC-val 0.448  AUC-train 0.815\n",
            "Stats - Epoch: 27 AUC-val 0.452  AUC-train 0.818\n",
            "Stats - Epoch: 28 AUC-val 0.449  AUC-train 0.821\n",
            "Stats - Epoch: 29 AUC-val 0.447  AUC-train 0.816\n",
            "Stats - Epoch: 30 AUC-val 0.449  AUC-train 0.823\n",
            "Stats - Epoch: 31 AUC-val 0.448  AUC-train 0.829\n",
            "Stats - Epoch: 32 AUC-val 0.447  AUC-train 0.823\n",
            "Stats - Epoch: 33 AUC-val 0.453  AUC-train 0.830\n",
            "Stats - Epoch: 34 AUC-val 0.455  AUC-train 0.833\n",
            "Stats - Epoch: 35 AUC-val 0.458  AUC-train 0.831\n",
            "Stats - Epoch: 36 AUC-val 0.464  AUC-train 0.831\n",
            "Stats - Epoch: 37 AUC-val 0.462  AUC-train 0.835\n",
            "Stats - Epoch: 38 AUC-val 0.456  AUC-train 0.836\n",
            "Stats - Epoch: 39 AUC-val 0.450  AUC-train 0.836\n",
            "Stats - Epoch: 40 AUC-val 0.461  AUC-train 0.835\n",
            "Stats - Epoch: 41 AUC-val 0.462  AUC-train 0.840\n",
            "Stats - Epoch: 42 AUC-val 0.462  AUC-train 0.839\n",
            "Stats - Epoch: 43 AUC-val 0.469  AUC-train 0.838\n",
            "Stats - Epoch: 44 AUC-val 0.466  AUC-train 0.837\n",
            "Stats - Epoch: 45 AUC-val 0.470  AUC-train 0.839\n",
            "Stats - Epoch: 46 AUC-val 0.470  AUC-train 0.844\n",
            "Stats - Epoch: 47 AUC-val 0.474  AUC-train 0.843\n",
            "Stats - Epoch: 48 AUC-val 0.469  AUC-train 0.837\n",
            "Stats - Epoch: 49 AUC-val 0.472  AUC-train 0.844\n",
            "Stats - Epoch: 50 AUC-val 0.464  AUC-train 0.847\n",
            "Stats - Epoch: 51 AUC-val 0.470  AUC-train 0.847\n",
            "Stats - Epoch: 52 AUC-val 0.472  AUC-train 0.848\n",
            "Stats - Epoch: 53 AUC-val 0.474  AUC-train 0.846\n",
            "Stats - Epoch: 54 AUC-val 0.471  AUC-train 0.847\n",
            "Stats - Epoch: 55 AUC-val 0.472  AUC-train 0.848\n",
            "Stats - Epoch: 56 AUC-val 0.473  AUC-train 0.846\n",
            "Stats - Epoch: 57 AUC-val 0.474  AUC-train 0.847\n",
            "Stats - Epoch: 58 AUC-val 0.472  AUC-train 0.842\n",
            "Stats - Epoch: 59 AUC-val 0.478  AUC-train 0.848\n",
            "Stats - Epoch: 60 AUC-val 0.467  AUC-train 0.850\n",
            "Stats - Epoch: 61 AUC-val 0.474  AUC-train 0.852\n",
            "Stats - Epoch: 62 AUC-val 0.474  AUC-train 0.854\n",
            "Stats - Epoch: 63 AUC-val 0.472  AUC-train 0.854\n",
            "Stats - Epoch: 64 AUC-val 0.474  AUC-train 0.849\n",
            "Stats - Epoch: 65 AUC-val 0.472  AUC-train 0.853\n",
            "Stats - Epoch: 66 AUC-val 0.477  AUC-train 0.854\n",
            "Stats - Epoch: 67 AUC-val 0.469  AUC-train 0.855\n",
            "Stats - Epoch: 68 AUC-val 0.475  AUC-train 0.854\n",
            "Stats - Epoch: 69 AUC-val 0.480  AUC-train 0.856\n",
            "Stats - Epoch: 70 AUC-val 0.478  AUC-train 0.858\n",
            "Stats - Epoch: 71 AUC-val 0.474  AUC-train 0.857\n",
            "Stats - Epoch: 72 AUC-val 0.481  AUC-train 0.854\n",
            "Stats - Epoch: 73 AUC-val 0.479  AUC-train 0.856\n",
            "Stats - Epoch: 74 AUC-val 0.486  AUC-train 0.851\n",
            "Stats - Epoch: 75 AUC-val 0.483  AUC-train 0.854\n",
            "Stats - Epoch: 76 AUC-val 0.479  AUC-train 0.854\n",
            "Stats - Epoch: 77 AUC-val 0.480  AUC-train 0.856\n",
            "Stats - Epoch: 78 AUC-val 0.474  AUC-train 0.858\n",
            "Stats - Epoch: 79 AUC-val 0.485  AUC-train 0.860\n",
            "Stats - Epoch: 80 AUC-val 0.478  AUC-train 0.859\n",
            "Stats - Epoch: 81 AUC-val 0.488  AUC-train 0.859\n",
            "Stats - Epoch: 82 AUC-val 0.488  AUC-train 0.860\n",
            "Stats - Epoch: 83 AUC-val 0.486  AUC-train 0.861\n",
            "Stats - Epoch: 84 AUC-val 0.486  AUC-train 0.854\n",
            "Stats - Epoch: 85 AUC-val 0.484  AUC-train 0.860\n",
            "Stats - Epoch: 86 AUC-val 0.485  AUC-train 0.862\n",
            "Stats - Epoch: 87 AUC-val 0.485  AUC-train 0.859\n",
            "Stats - Epoch: 88 AUC-val 0.483  AUC-train 0.861\n",
            "Stats - Epoch: 89 AUC-val 0.481  AUC-train 0.862\n",
            "Stats - Epoch: 90 AUC-val 0.486  AUC-train 0.861\n",
            "Stats - Epoch: 91 AUC-val 0.490  AUC-train 0.862\n",
            "Stats - Epoch: 92 AUC-val 0.484  AUC-train 0.861\n",
            "Stats - Epoch: 93 AUC-val 0.485  AUC-train 0.859\n",
            "Stats - Epoch: 94 AUC-val 0.482  AUC-train 0.861\n",
            "Stats - Epoch: 95 AUC-val 0.478  AUC-train 0.856\n",
            "Stats - Epoch: 96 AUC-val 0.478  AUC-train 0.860\n",
            "Stats - Epoch: 97 AUC-val 0.486  AUC-train 0.864\n",
            "Stats - Epoch: 98 AUC-val 0.484  AUC-train 0.864\n",
            "Stats - Epoch: 99 AUC-val 0.482  AUC-train 0.863\n",
            "Stats - Epoch: 100 AUC-val 0.484  AUC-train 0.862\n",
            "Results 100 AUC-val 0.490 0.497 0.552 0.467 0.625 AUC-train 0.862\n",
            "Shapley [0.00610396 0.00649201 0.01873754 0.01109536 0.00407785] [0.01821341]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188077\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.222  AUC-train 0.531\n",
            "Stats - Epoch: 2 AUC-val 0.338  AUC-train 0.672\n",
            "Stats - Epoch: 3 AUC-val 0.440  AUC-train 0.774\n",
            "Stats - Epoch: 4 AUC-val 0.454  AUC-train 0.825\n",
            "Stats - Epoch: 5 AUC-val 0.442  AUC-train 0.864\n",
            "Stats - Epoch: 6 AUC-val 0.444  AUC-train 0.892\n",
            "Stats - Epoch: 7 AUC-val 0.419  AUC-train 0.910\n",
            "Stats - Epoch: 8 AUC-val 0.436  AUC-train 0.929\n",
            "Stats - Epoch: 9 AUC-val 0.443  AUC-train 0.938\n",
            "Stats - Epoch: 10 AUC-val 0.422  AUC-train 0.948\n",
            "Stats - Epoch: 11 AUC-val 0.422  AUC-train 0.950\n",
            "Stats - Epoch: 12 AUC-val 0.427  AUC-train 0.957\n",
            "Stats - Epoch: 13 AUC-val 0.414  AUC-train 0.964\n",
            "Stats - Epoch: 14 AUC-val 0.428  AUC-train 0.963\n",
            "Stats - Epoch: 15 AUC-val 0.401  AUC-train 0.969\n",
            "Stats - Epoch: 16 AUC-val 0.419  AUC-train 0.968\n",
            "Stats - Epoch: 17 AUC-val 0.428  AUC-train 0.970\n",
            "Stats - Epoch: 18 AUC-val 0.437  AUC-train 0.969\n",
            "Stats - Epoch: 19 AUC-val 0.403  AUC-train 0.973\n",
            "Stats - Epoch: 20 AUC-val 0.399  AUC-train 0.971\n",
            "Stats - Epoch: 21 AUC-val 0.415  AUC-train 0.975\n",
            "Stats - Epoch: 22 AUC-val 0.440  AUC-train 0.970\n",
            "Stats - Epoch: 23 AUC-val 0.405  AUC-train 0.976\n",
            "Stats - Epoch: 24 AUC-val 0.435  AUC-train 0.974\n",
            "Stats - Epoch: 25 AUC-val 0.423  AUC-train 0.972\n",
            "Stats - Epoch: 26 AUC-val 0.459  AUC-train 0.971\n",
            "Stats - Epoch: 27 AUC-val 0.455  AUC-train 0.972\n",
            "Stats - Epoch: 28 AUC-val 0.453  AUC-train 0.974\n",
            "Stats - Epoch: 29 AUC-val 0.443  AUC-train 0.976\n",
            "Stats - Epoch: 30 AUC-val 0.448  AUC-train 0.977\n",
            "Stats - Epoch: 31 AUC-val 0.462  AUC-train 0.978\n",
            "Stats - Epoch: 32 AUC-val 0.460  AUC-train 0.979\n",
            "Stats - Epoch: 33 AUC-val 0.421  AUC-train 0.979\n",
            "Stats - Epoch: 34 AUC-val 0.463  AUC-train 0.976\n",
            "Stats - Epoch: 35 AUC-val 0.445  AUC-train 0.979\n",
            "Stats - Epoch: 36 AUC-val 0.464  AUC-train 0.977\n",
            "Stats - Epoch: 37 AUC-val 0.459  AUC-train 0.979\n",
            "Stats - Epoch: 38 AUC-val 0.429  AUC-train 0.982\n",
            "Stats - Epoch: 39 AUC-val 0.453  AUC-train 0.979\n",
            "Stats - Epoch: 40 AUC-val 0.467  AUC-train 0.979\n",
            "Stats - Epoch: 41 AUC-val 0.468  AUC-train 0.979\n",
            "Stats - Epoch: 42 AUC-val 0.455  AUC-train 0.977\n",
            "Stats - Epoch: 43 AUC-val 0.459  AUC-train 0.973\n",
            "Stats - Epoch: 44 AUC-val 0.455  AUC-train 0.977\n",
            "Stats - Epoch: 45 AUC-val 0.460  AUC-train 0.977\n",
            "Stats - Epoch: 46 AUC-val 0.458  AUC-train 0.977\n",
            "Stats - Epoch: 47 AUC-val 0.453  AUC-train 0.980\n",
            "Stats - Epoch: 48 AUC-val 0.438  AUC-train 0.976\n",
            "Stats - Epoch: 49 AUC-val 0.439  AUC-train 0.974\n",
            "Stats - Epoch: 50 AUC-val 0.453  AUC-train 0.974\n",
            "Stats - Epoch: 51 AUC-val 0.451  AUC-train 0.975\n",
            "Stats - Epoch: 52 AUC-val 0.435  AUC-train 0.974\n",
            "Stats - Epoch: 53 AUC-val 0.445  AUC-train 0.976\n",
            "Stats - Epoch: 54 AUC-val 0.442  AUC-train 0.978\n",
            "Stats - Epoch: 55 AUC-val 0.444  AUC-train 0.974\n",
            "Stats - Epoch: 56 AUC-val 0.452  AUC-train 0.977\n",
            "Stats - Epoch: 57 AUC-val 0.460  AUC-train 0.975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.462  AUC-train 0.978\n",
            "Stats - Epoch: 59 AUC-val 0.455  AUC-train 0.978\n",
            "Stats - Epoch: 60 AUC-val 0.454  AUC-train 0.979\n",
            "Stats - Epoch: 61 AUC-val 0.464  AUC-train 0.978\n",
            "Stats - Epoch: 62 AUC-val 0.472  AUC-train 0.978\n",
            "Stats - Epoch: 63 AUC-val 0.466  AUC-train 0.978\n",
            "Stats - Epoch: 64 AUC-val 0.459  AUC-train 0.969\n",
            "Stats - Epoch: 65 AUC-val 0.443  AUC-train 0.974\n",
            "Stats - Epoch: 66 AUC-val 0.444  AUC-train 0.975\n",
            "Stats - Epoch: 67 AUC-val 0.453  AUC-train 0.973\n",
            "Stats - Epoch: 68 AUC-val 0.431  AUC-train 0.973\n",
            "Stats - Epoch: 69 AUC-val 0.456  AUC-train 0.977\n",
            "Stats - Epoch: 70 AUC-val 0.456  AUC-train 0.975\n",
            "Stats - Epoch: 71 AUC-val 0.462  AUC-train 0.976\n",
            "Stats - Epoch: 72 AUC-val 0.471  AUC-train 0.971\n",
            "Stats - Epoch: 73 AUC-val 0.479  AUC-train 0.973\n",
            "Stats - Epoch: 74 AUC-val 0.476  AUC-train 0.974\n",
            "Stats - Epoch: 75 AUC-val 0.471  AUC-train 0.967\n",
            "Stats - Epoch: 76 AUC-val 0.456  AUC-train 0.972\n",
            "Stats - Epoch: 77 AUC-val 0.454  AUC-train 0.974\n",
            "Stats - Epoch: 78 AUC-val 0.443  AUC-train 0.967\n",
            "Stats - Epoch: 79 AUC-val 0.459  AUC-train 0.973\n",
            "Stats - Epoch: 80 AUC-val 0.462  AUC-train 0.975\n",
            "Stats - Epoch: 81 AUC-val 0.436  AUC-train 0.976\n",
            "Stats - Epoch: 82 AUC-val 0.439  AUC-train 0.977\n",
            "Stats - Epoch: 83 AUC-val 0.435  AUC-train 0.975\n",
            "Stats - Epoch: 84 AUC-val 0.433  AUC-train 0.973\n",
            "Stats - Epoch: 85 AUC-val 0.433  AUC-train 0.973\n",
            "Stats - Epoch: 86 AUC-val 0.452  AUC-train 0.972\n",
            "Stats - Epoch: 87 AUC-val 0.444  AUC-train 0.974\n",
            "Stats - Epoch: 88 AUC-val 0.447  AUC-train 0.974\n",
            "Stats - Epoch: 89 AUC-val 0.418  AUC-train 0.975\n",
            "Stats - Epoch: 90 AUC-val 0.433  AUC-train 0.975\n",
            "Stats - Epoch: 91 AUC-val 0.454  AUC-train 0.975\n",
            "Stats - Epoch: 92 AUC-val 0.460  AUC-train 0.969\n",
            "Stats - Epoch: 93 AUC-val 0.443  AUC-train 0.976\n",
            "Stats - Epoch: 94 AUC-val 0.433  AUC-train 0.973\n",
            "Stats - Epoch: 95 AUC-val 0.441  AUC-train 0.973\n",
            "Stats - Epoch: 96 AUC-val 0.427  AUC-train 0.970\n",
            "Stats - Epoch: 97 AUC-val 0.424  AUC-train 0.971\n",
            "Stats - Epoch: 98 AUC-val 0.421  AUC-train 0.976\n",
            "Stats - Epoch: 99 AUC-val 0.440  AUC-train 0.972\n",
            "Stats - Epoch: 100 AUC-val 0.424  AUC-train 0.972\n",
            "Results 100 AUC-val 0.479 0.421 0.276 0.191 0.569 AUC-train 0.973\n",
            "Shapley [0.02666589 0.00933743 0.00850358 0.0393474  0.00956609] [0.04201362]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.182013\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.223  AUC-train 0.570\n",
            "Stats - Epoch: 2 AUC-val 0.194  AUC-train 0.581\n",
            "Stats - Epoch: 3 AUC-val 0.166  AUC-train 0.603\n",
            "Stats - Epoch: 4 AUC-val 0.178  AUC-train 0.646\n",
            "Stats - Epoch: 5 AUC-val 0.186  AUC-train 0.684\n",
            "Stats - Epoch: 6 AUC-val 0.230  AUC-train 0.714\n",
            "Stats - Epoch: 7 AUC-val 0.283  AUC-train 0.740\n",
            "Stats - Epoch: 8 AUC-val 0.310  AUC-train 0.758\n",
            "Stats - Epoch: 9 AUC-val 0.429  AUC-train 0.772\n",
            "Stats - Epoch: 10 AUC-val 0.421  AUC-train 0.790\n",
            "Stats - Epoch: 11 AUC-val 0.484  AUC-train 0.794\n",
            "Stats - Epoch: 12 AUC-val 0.474  AUC-train 0.805\n",
            "Stats - Epoch: 13 AUC-val 0.495  AUC-train 0.809\n",
            "Stats - Epoch: 14 AUC-val 0.466  AUC-train 0.815\n",
            "Stats - Epoch: 15 AUC-val 0.476  AUC-train 0.818\n",
            "Stats - Epoch: 16 AUC-val 0.538  AUC-train 0.825\n",
            "Stats - Epoch: 17 AUC-val 0.503  AUC-train 0.826\n",
            "Stats - Epoch: 18 AUC-val 0.497  AUC-train 0.831\n",
            "Stats - Epoch: 19 AUC-val 0.517  AUC-train 0.831\n",
            "Stats - Epoch: 20 AUC-val 0.519  AUC-train 0.834\n",
            "Stats - Epoch: 21 AUC-val 0.566  AUC-train 0.833\n",
            "Stats - Epoch: 22 AUC-val 0.572  AUC-train 0.835\n",
            "Stats - Epoch: 23 AUC-val 0.563  AUC-train 0.838\n",
            "Stats - Epoch: 24 AUC-val 0.550  AUC-train 0.839\n",
            "Stats - Epoch: 25 AUC-val 0.597  AUC-train 0.840\n",
            "Stats - Epoch: 26 AUC-val 0.567  AUC-train 0.839\n",
            "Stats - Epoch: 27 AUC-val 0.564  AUC-train 0.844\n",
            "Stats - Epoch: 28 AUC-val 0.573  AUC-train 0.846\n",
            "Stats - Epoch: 29 AUC-val 0.597  AUC-train 0.844\n",
            "Stats - Epoch: 30 AUC-val 0.592  AUC-train 0.846\n",
            "Stats - Epoch: 31 AUC-val 0.543  AUC-train 0.848\n",
            "Stats - Epoch: 32 AUC-val 0.559  AUC-train 0.851\n",
            "Stats - Epoch: 33 AUC-val 0.567  AUC-train 0.856\n",
            "Stats - Epoch: 34 AUC-val 0.576  AUC-train 0.851\n",
            "Stats - Epoch: 35 AUC-val 0.559  AUC-train 0.853\n",
            "Stats - Epoch: 36 AUC-val 0.537  AUC-train 0.856\n",
            "Stats - Epoch: 37 AUC-val 0.589  AUC-train 0.856\n",
            "Stats - Epoch: 38 AUC-val 0.582  AUC-train 0.857\n",
            "Stats - Epoch: 39 AUC-val 0.578  AUC-train 0.857\n",
            "Stats - Epoch: 40 AUC-val 0.603  AUC-train 0.857\n",
            "Stats - Epoch: 41 AUC-val 0.620  AUC-train 0.859\n",
            "Stats - Epoch: 42 AUC-val 0.611  AUC-train 0.859\n",
            "Stats - Epoch: 43 AUC-val 0.600  AUC-train 0.863\n",
            "Stats - Epoch: 44 AUC-val 0.591  AUC-train 0.863\n",
            "Stats - Epoch: 45 AUC-val 0.605  AUC-train 0.861\n",
            "Stats - Epoch: 46 AUC-val 0.624  AUC-train 0.866\n",
            "Stats - Epoch: 47 AUC-val 0.608  AUC-train 0.868\n",
            "Stats - Epoch: 48 AUC-val 0.591  AUC-train 0.862\n",
            "Stats - Epoch: 49 AUC-val 0.597  AUC-train 0.866\n",
            "Stats - Epoch: 50 AUC-val 0.579  AUC-train 0.864\n",
            "Stats - Epoch: 51 AUC-val 0.591  AUC-train 0.860\n",
            "Stats - Epoch: 52 AUC-val 0.607  AUC-train 0.860\n",
            "Stats - Epoch: 53 AUC-val 0.608  AUC-train 0.862\n",
            "Stats - Epoch: 54 AUC-val 0.599  AUC-train 0.869\n",
            "Stats - Epoch: 55 AUC-val 0.613  AUC-train 0.864\n",
            "Stats - Epoch: 56 AUC-val 0.623  AUC-train 0.866\n",
            "Stats - Epoch: 57 AUC-val 0.603  AUC-train 0.869\n",
            "Stats - Epoch: 58 AUC-val 0.617  AUC-train 0.870\n",
            "Stats - Epoch: 59 AUC-val 0.616  AUC-train 0.870\n",
            "Stats - Epoch: 60 AUC-val 0.600  AUC-train 0.873\n",
            "Stats - Epoch: 61 AUC-val 0.607  AUC-train 0.869\n",
            "Stats - Epoch: 62 AUC-val 0.612  AUC-train 0.869\n",
            "Stats - Epoch: 63 AUC-val 0.629  AUC-train 0.869\n",
            "Stats - Epoch: 64 AUC-val 0.605  AUC-train 0.868\n",
            "Stats - Epoch: 65 AUC-val 0.585  AUC-train 0.874\n",
            "Stats - Epoch: 66 AUC-val 0.597  AUC-train 0.875\n",
            "Stats - Epoch: 67 AUC-val 0.600  AUC-train 0.866\n",
            "Stats - Epoch: 68 AUC-val 0.603  AUC-train 0.869\n",
            "Stats - Epoch: 69 AUC-val 0.604  AUC-train 0.871\n",
            "Stats - Epoch: 70 AUC-val 0.599  AUC-train 0.871\n",
            "Stats - Epoch: 71 AUC-val 0.640  AUC-train 0.869\n",
            "Stats - Epoch: 72 AUC-val 0.622  AUC-train 0.869\n",
            "Stats - Epoch: 73 AUC-val 0.625  AUC-train 0.867\n",
            "Stats - Epoch: 74 AUC-val 0.619  AUC-train 0.873\n",
            "Stats - Epoch: 75 AUC-val 0.612  AUC-train 0.864\n",
            "Stats - Epoch: 76 AUC-val 0.612  AUC-train 0.867\n",
            "Stats - Epoch: 77 AUC-val 0.602  AUC-train 0.867\n",
            "Stats - Epoch: 78 AUC-val 0.608  AUC-train 0.871\n",
            "Stats - Epoch: 79 AUC-val 0.611  AUC-train 0.876\n",
            "Stats - Epoch: 80 AUC-val 0.605  AUC-train 0.880\n",
            "Stats - Epoch: 81 AUC-val 0.599  AUC-train 0.881\n",
            "Stats - Epoch: 82 AUC-val 0.620  AUC-train 0.878\n",
            "Stats - Epoch: 83 AUC-val 0.623  AUC-train 0.876\n",
            "Stats - Epoch: 84 AUC-val 0.590  AUC-train 0.874\n",
            "Stats - Epoch: 85 AUC-val 0.598  AUC-train 0.876\n",
            "Stats - Epoch: 86 AUC-val 0.585  AUC-train 0.873\n",
            "Stats - Epoch: 87 AUC-val 0.605  AUC-train 0.879\n",
            "Stats - Epoch: 88 AUC-val 0.608  AUC-train 0.881\n",
            "Stats - Epoch: 89 AUC-val 0.583  AUC-train 0.879\n",
            "Stats - Epoch: 90 AUC-val 0.607  AUC-train 0.881\n",
            "Stats - Epoch: 91 AUC-val 0.606  AUC-train 0.881\n",
            "Stats - Epoch: 92 AUC-val 0.629  AUC-train 0.883\n",
            "Stats - Epoch: 93 AUC-val 0.612  AUC-train 0.881\n",
            "Stats - Epoch: 94 AUC-val 0.620  AUC-train 0.887\n",
            "Stats - Epoch: 95 AUC-val 0.605  AUC-train 0.884\n",
            "Stats - Epoch: 96 AUC-val 0.608  AUC-train 0.886\n",
            "Stats - Epoch: 97 AUC-val 0.626  AUC-train 0.882\n",
            "Stats - Epoch: 98 AUC-val 0.617  AUC-train 0.885\n",
            "Stats - Epoch: 99 AUC-val 0.617  AUC-train 0.887\n",
            "Stats - Epoch: 100 AUC-val 0.624  AUC-train 0.884\n",
            "Results 100 AUC-val 0.640 0.643 0.603 0.511 0.607 AUC-train 0.869\n",
            "Shapley [0.01480071 0.01182049 0.01792568 0.01235781 0.00560028] [0.00734951]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.191843\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.345  AUC-train 0.535\n",
            "Stats - Epoch: 2 AUC-val 0.411  AUC-train 0.653\n",
            "Stats - Epoch: 3 AUC-val 0.524  AUC-train 0.748\n",
            "Stats - Epoch: 4 AUC-val 0.586  AUC-train 0.799\n",
            "Stats - Epoch: 5 AUC-val 0.625  AUC-train 0.825\n",
            "Stats - Epoch: 6 AUC-val 0.640  AUC-train 0.842\n",
            "Stats - Epoch: 7 AUC-val 0.672  AUC-train 0.858\n",
            "Stats - Epoch: 8 AUC-val 0.689  AUC-train 0.868\n",
            "Stats - Epoch: 9 AUC-val 0.707  AUC-train 0.875\n",
            "Stats - Epoch: 10 AUC-val 0.711  AUC-train 0.883\n",
            "Stats - Epoch: 11 AUC-val 0.730  AUC-train 0.890\n",
            "Stats - Epoch: 12 AUC-val 0.712  AUC-train 0.896\n",
            "Stats - Epoch: 13 AUC-val 0.720  AUC-train 0.899\n",
            "Stats - Epoch: 14 AUC-val 0.735  AUC-train 0.907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.737  AUC-train 0.909\n",
            "Stats - Epoch: 16 AUC-val 0.735  AUC-train 0.913\n",
            "Stats - Epoch: 17 AUC-val 0.748  AUC-train 0.920\n",
            "Stats - Epoch: 18 AUC-val 0.757  AUC-train 0.921\n",
            "Stats - Epoch: 19 AUC-val 0.739  AUC-train 0.927\n",
            "Stats - Epoch: 20 AUC-val 0.758  AUC-train 0.929\n",
            "Stats - Epoch: 21 AUC-val 0.737  AUC-train 0.931\n",
            "Stats - Epoch: 22 AUC-val 0.735  AUC-train 0.933\n",
            "Stats - Epoch: 23 AUC-val 0.760  AUC-train 0.936\n",
            "Stats - Epoch: 24 AUC-val 0.773  AUC-train 0.939\n",
            "Stats - Epoch: 25 AUC-val 0.774  AUC-train 0.941\n",
            "Stats - Epoch: 26 AUC-val 0.757  AUC-train 0.941\n",
            "Stats - Epoch: 27 AUC-val 0.762  AUC-train 0.945\n",
            "Stats - Epoch: 28 AUC-val 0.770  AUC-train 0.947\n",
            "Stats - Epoch: 29 AUC-val 0.748  AUC-train 0.949\n",
            "Stats - Epoch: 30 AUC-val 0.757  AUC-train 0.949\n",
            "Stats - Epoch: 31 AUC-val 0.742  AUC-train 0.953\n",
            "Stats - Epoch: 32 AUC-val 0.745  AUC-train 0.953\n",
            "Stats - Epoch: 33 AUC-val 0.774  AUC-train 0.956\n",
            "Stats - Epoch: 34 AUC-val 0.737  AUC-train 0.954\n",
            "Stats - Epoch: 35 AUC-val 0.734  AUC-train 0.958\n",
            "Stats - Epoch: 36 AUC-val 0.722  AUC-train 0.958\n",
            "Stats - Epoch: 37 AUC-val 0.745  AUC-train 0.961\n",
            "Stats - Epoch: 38 AUC-val 0.733  AUC-train 0.959\n",
            "Stats - Epoch: 39 AUC-val 0.720  AUC-train 0.959\n",
            "Stats - Epoch: 40 AUC-val 0.726  AUC-train 0.962\n",
            "Stats - Epoch: 41 AUC-val 0.722  AUC-train 0.961\n",
            "Stats - Epoch: 42 AUC-val 0.715  AUC-train 0.963\n",
            "Stats - Epoch: 43 AUC-val 0.702  AUC-train 0.963\n",
            "Stats - Epoch: 44 AUC-val 0.699  AUC-train 0.961\n",
            "Stats - Epoch: 45 AUC-val 0.722  AUC-train 0.963\n",
            "Stats - Epoch: 46 AUC-val 0.721  AUC-train 0.962\n",
            "Stats - Epoch: 47 AUC-val 0.725  AUC-train 0.964\n",
            "Stats - Epoch: 48 AUC-val 0.702  AUC-train 0.967\n",
            "Stats - Epoch: 49 AUC-val 0.701  AUC-train 0.964\n",
            "Stats - Epoch: 50 AUC-val 0.708  AUC-train 0.963\n",
            "Stats - Epoch: 51 AUC-val 0.717  AUC-train 0.965\n",
            "Stats - Epoch: 52 AUC-val 0.734  AUC-train 0.966\n",
            "Stats - Epoch: 53 AUC-val 0.712  AUC-train 0.968\n",
            "Stats - Epoch: 54 AUC-val 0.725  AUC-train 0.967\n",
            "Stats - Epoch: 55 AUC-val 0.686  AUC-train 0.969\n",
            "Stats - Epoch: 56 AUC-val 0.695  AUC-train 0.970\n",
            "Stats - Epoch: 57 AUC-val 0.718  AUC-train 0.968\n",
            "Stats - Epoch: 58 AUC-val 0.702  AUC-train 0.969\n",
            "Stats - Epoch: 59 AUC-val 0.707  AUC-train 0.967\n",
            "Stats - Epoch: 60 AUC-val 0.695  AUC-train 0.970\n",
            "Stats - Epoch: 61 AUC-val 0.705  AUC-train 0.968\n",
            "Stats - Epoch: 62 AUC-val 0.720  AUC-train 0.971\n",
            "Stats - Epoch: 63 AUC-val 0.693  AUC-train 0.970\n",
            "Stats - Epoch: 64 AUC-val 0.687  AUC-train 0.969\n",
            "Stats - Epoch: 65 AUC-val 0.712  AUC-train 0.971\n",
            "Stats - Epoch: 66 AUC-val 0.708  AUC-train 0.969\n",
            "Stats - Epoch: 67 AUC-val 0.703  AUC-train 0.970\n",
            "Stats - Epoch: 68 AUC-val 0.703  AUC-train 0.969\n",
            "Stats - Epoch: 69 AUC-val 0.693  AUC-train 0.972\n",
            "Stats - Epoch: 70 AUC-val 0.702  AUC-train 0.972\n",
            "Stats - Epoch: 71 AUC-val 0.700  AUC-train 0.971\n",
            "Stats - Epoch: 72 AUC-val 0.703  AUC-train 0.971\n",
            "Stats - Epoch: 73 AUC-val 0.683  AUC-train 0.972\n",
            "Stats - Epoch: 74 AUC-val 0.710  AUC-train 0.971\n",
            "Stats - Epoch: 75 AUC-val 0.705  AUC-train 0.970\n",
            "Stats - Epoch: 76 AUC-val 0.729  AUC-train 0.971\n",
            "Stats - Epoch: 77 AUC-val 0.701  AUC-train 0.968\n",
            "Stats - Epoch: 78 AUC-val 0.707  AUC-train 0.972\n",
            "Stats - Epoch: 79 AUC-val 0.697  AUC-train 0.973\n",
            "Stats - Epoch: 80 AUC-val 0.683  AUC-train 0.972\n",
            "Stats - Epoch: 81 AUC-val 0.714  AUC-train 0.975\n",
            "Stats - Epoch: 82 AUC-val 0.698  AUC-train 0.975\n",
            "Stats - Epoch: 83 AUC-val 0.698  AUC-train 0.976\n",
            "Stats - Epoch: 84 AUC-val 0.702  AUC-train 0.973\n",
            "Stats - Epoch: 85 AUC-val 0.698  AUC-train 0.971\n",
            "Stats - Epoch: 86 AUC-val 0.681  AUC-train 0.973\n",
            "Stats - Epoch: 87 AUC-val 0.673  AUC-train 0.974\n",
            "Stats - Epoch: 88 AUC-val 0.695  AUC-train 0.975\n",
            "Stats - Epoch: 89 AUC-val 0.700  AUC-train 0.973\n",
            "Stats - Epoch: 90 AUC-val 0.667  AUC-train 0.976\n",
            "Stats - Epoch: 91 AUC-val 0.684  AUC-train 0.974\n",
            "Stats - Epoch: 92 AUC-val 0.673  AUC-train 0.976\n",
            "Stats - Epoch: 93 AUC-val 0.672  AUC-train 0.978\n",
            "Stats - Epoch: 94 AUC-val 0.674  AUC-train 0.976\n",
            "Stats - Epoch: 95 AUC-val 0.669  AUC-train 0.972\n",
            "Stats - Epoch: 96 AUC-val 0.688  AUC-train 0.973\n",
            "Stats - Epoch: 97 AUC-val 0.667  AUC-train 0.976\n",
            "Stats - Epoch: 98 AUC-val 0.704  AUC-train 0.975\n",
            "Stats - Epoch: 99 AUC-val 0.713  AUC-train 0.975\n",
            "Stats - Epoch: 100 AUC-val 0.691  AUC-train 0.976\n",
            "Results 100 AUC-val 0.774 0.619 0.496 0.467 0.608 AUC-train 0.941\n",
            "Shapley [0.01538363 0.01649082 0.01661214 0.024755   0.0107002 ] [0.01370883]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198631\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.586  AUC-train 0.469\n",
            "Stats - Epoch: 2 AUC-val 0.607  AUC-train 0.542\n",
            "Stats - Epoch: 3 AUC-val 0.616  AUC-train 0.629\n",
            "Stats - Epoch: 4 AUC-val 0.625  AUC-train 0.680\n",
            "Stats - Epoch: 5 AUC-val 0.635  AUC-train 0.720\n",
            "Stats - Epoch: 6 AUC-val 0.631  AUC-train 0.749\n",
            "Stats - Epoch: 7 AUC-val 0.626  AUC-train 0.775\n",
            "Stats - Epoch: 8 AUC-val 0.631  AUC-train 0.795\n",
            "Stats - Epoch: 9 AUC-val 0.631  AUC-train 0.813\n",
            "Stats - Epoch: 10 AUC-val 0.626  AUC-train 0.825\n",
            "Stats - Epoch: 11 AUC-val 0.616  AUC-train 0.837\n",
            "Stats - Epoch: 12 AUC-val 0.621  AUC-train 0.846\n",
            "Stats - Epoch: 13 AUC-val 0.613  AUC-train 0.849\n",
            "Stats - Epoch: 14 AUC-val 0.615  AUC-train 0.861\n",
            "Stats - Epoch: 15 AUC-val 0.595  AUC-train 0.865\n",
            "Stats - Epoch: 16 AUC-val 0.598  AUC-train 0.872\n",
            "Stats - Epoch: 17 AUC-val 0.568  AUC-train 0.881\n",
            "Stats - Epoch: 18 AUC-val 0.584  AUC-train 0.884\n",
            "Stats - Epoch: 19 AUC-val 0.573  AUC-train 0.892\n",
            "Stats - Epoch: 20 AUC-val 0.588  AUC-train 0.897\n",
            "Stats - Epoch: 21 AUC-val 0.614  AUC-train 0.903\n",
            "Stats - Epoch: 22 AUC-val 0.569  AUC-train 0.905\n",
            "Stats - Epoch: 23 AUC-val 0.580  AUC-train 0.911\n",
            "Stats - Epoch: 24 AUC-val 0.589  AUC-train 0.911\n",
            "Stats - Epoch: 25 AUC-val 0.604  AUC-train 0.911\n",
            "Stats - Epoch: 26 AUC-val 0.514  AUC-train 0.915\n",
            "Stats - Epoch: 27 AUC-val 0.578  AUC-train 0.916\n",
            "Stats - Epoch: 28 AUC-val 0.583  AUC-train 0.916\n",
            "Stats - Epoch: 29 AUC-val 0.538  AUC-train 0.922\n",
            "Stats - Epoch: 30 AUC-val 0.561  AUC-train 0.923\n",
            "Stats - Epoch: 31 AUC-val 0.541  AUC-train 0.929\n",
            "Stats - Epoch: 32 AUC-val 0.513  AUC-train 0.928\n",
            "Stats - Epoch: 33 AUC-val 0.569  AUC-train 0.933\n",
            "Stats - Epoch: 34 AUC-val 0.549  AUC-train 0.928\n",
            "Stats - Epoch: 35 AUC-val 0.544  AUC-train 0.933\n",
            "Stats - Epoch: 36 AUC-val 0.570  AUC-train 0.935\n",
            "Stats - Epoch: 37 AUC-val 0.560  AUC-train 0.936\n",
            "Stats - Epoch: 38 AUC-val 0.552  AUC-train 0.937\n",
            "Stats - Epoch: 39 AUC-val 0.553  AUC-train 0.938\n",
            "Stats - Epoch: 40 AUC-val 0.547  AUC-train 0.938\n",
            "Stats - Epoch: 41 AUC-val 0.571  AUC-train 0.940\n",
            "Stats - Epoch: 42 AUC-val 0.526  AUC-train 0.937\n",
            "Stats - Epoch: 43 AUC-val 0.552  AUC-train 0.940\n",
            "Stats - Epoch: 44 AUC-val 0.548  AUC-train 0.941\n",
            "Stats - Epoch: 45 AUC-val 0.565  AUC-train 0.942\n",
            "Stats - Epoch: 46 AUC-val 0.524  AUC-train 0.943\n",
            "Stats - Epoch: 47 AUC-val 0.509  AUC-train 0.944\n",
            "Stats - Epoch: 48 AUC-val 0.550  AUC-train 0.945\n",
            "Stats - Epoch: 49 AUC-val 0.538  AUC-train 0.947\n",
            "Stats - Epoch: 50 AUC-val 0.552  AUC-train 0.948\n",
            "Stats - Epoch: 51 AUC-val 0.523  AUC-train 0.949\n",
            "Stats - Epoch: 52 AUC-val 0.529  AUC-train 0.948\n",
            "Stats - Epoch: 53 AUC-val 0.545  AUC-train 0.952\n",
            "Stats - Epoch: 54 AUC-val 0.542  AUC-train 0.951\n",
            "Stats - Epoch: 55 AUC-val 0.528  AUC-train 0.949\n",
            "Stats - Epoch: 56 AUC-val 0.517  AUC-train 0.955\n",
            "Stats - Epoch: 57 AUC-val 0.568  AUC-train 0.953\n",
            "Stats - Epoch: 58 AUC-val 0.584  AUC-train 0.954\n",
            "Stats - Epoch: 59 AUC-val 0.578  AUC-train 0.955\n",
            "Stats - Epoch: 60 AUC-val 0.581  AUC-train 0.952\n",
            "Stats - Epoch: 61 AUC-val 0.528  AUC-train 0.956\n",
            "Stats - Epoch: 62 AUC-val 0.547  AUC-train 0.958\n",
            "Stats - Epoch: 63 AUC-val 0.522  AUC-train 0.959\n",
            "Stats - Epoch: 64 AUC-val 0.552  AUC-train 0.958\n",
            "Stats - Epoch: 65 AUC-val 0.506  AUC-train 0.960\n",
            "Stats - Epoch: 66 AUC-val 0.517  AUC-train 0.961\n",
            "Stats - Epoch: 67 AUC-val 0.503  AUC-train 0.961\n",
            "Stats - Epoch: 68 AUC-val 0.507  AUC-train 0.960\n",
            "Stats - Epoch: 69 AUC-val 0.527  AUC-train 0.962\n",
            "Stats - Epoch: 70 AUC-val 0.524  AUC-train 0.965\n",
            "Stats - Epoch: 71 AUC-val 0.538  AUC-train 0.960\n",
            "Stats - Epoch: 72 AUC-val 0.591  AUC-train 0.962\n",
            "Stats - Epoch: 73 AUC-val 0.519  AUC-train 0.963\n",
            "Stats - Epoch: 74 AUC-val 0.533  AUC-train 0.965\n",
            "Stats - Epoch: 75 AUC-val 0.534  AUC-train 0.966\n",
            "Stats - Epoch: 76 AUC-val 0.548  AUC-train 0.966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.551  AUC-train 0.966\n",
            "Stats - Epoch: 78 AUC-val 0.571  AUC-train 0.965\n",
            "Stats - Epoch: 79 AUC-val 0.582  AUC-train 0.969\n",
            "Stats - Epoch: 80 AUC-val 0.566  AUC-train 0.968\n",
            "Stats - Epoch: 81 AUC-val 0.557  AUC-train 0.971\n",
            "Stats - Epoch: 82 AUC-val 0.579  AUC-train 0.973\n",
            "Stats - Epoch: 83 AUC-val 0.569  AUC-train 0.973\n",
            "Stats - Epoch: 84 AUC-val 0.557  AUC-train 0.966\n",
            "Stats - Epoch: 85 AUC-val 0.513  AUC-train 0.970\n",
            "Stats - Epoch: 86 AUC-val 0.514  AUC-train 0.972\n",
            "Stats - Epoch: 87 AUC-val 0.497  AUC-train 0.973\n",
            "Stats - Epoch: 88 AUC-val 0.533  AUC-train 0.974\n",
            "Stats - Epoch: 89 AUC-val 0.583  AUC-train 0.975\n",
            "Stats - Epoch: 90 AUC-val 0.564  AUC-train 0.973\n",
            "Stats - Epoch: 91 AUC-val 0.542  AUC-train 0.975\n",
            "Stats - Epoch: 92 AUC-val 0.595  AUC-train 0.973\n",
            "Stats - Epoch: 93 AUC-val 0.589  AUC-train 0.970\n",
            "Stats - Epoch: 94 AUC-val 0.550  AUC-train 0.974\n",
            "Stats - Epoch: 95 AUC-val 0.510  AUC-train 0.976\n",
            "Stats - Epoch: 96 AUC-val 0.508  AUC-train 0.973\n",
            "Stats - Epoch: 97 AUC-val 0.512  AUC-train 0.976\n",
            "Stats - Epoch: 98 AUC-val 0.533  AUC-train 0.972\n",
            "Stats - Epoch: 99 AUC-val 0.586  AUC-train 0.970\n",
            "Stats - Epoch: 100 AUC-val 0.543  AUC-train 0.973\n",
            "Results 100 AUC-val 0.635 0.462 0.483 0.325 0.549 AUC-train 0.720\n",
            "Shapley [0.00410462 0.01084214 0.01498306 0.04776477 0.01101662] [0.05785197]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197179\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.423  AUC-train 0.476\n",
            "Stats - Epoch: 2 AUC-val 0.475  AUC-train 0.536\n",
            "Stats - Epoch: 3 AUC-val 0.455  AUC-train 0.586\n",
            "Stats - Epoch: 4 AUC-val 0.462  AUC-train 0.620\n",
            "Stats - Epoch: 5 AUC-val 0.467  AUC-train 0.641\n",
            "Stats - Epoch: 6 AUC-val 0.446  AUC-train 0.672\n",
            "Stats - Epoch: 7 AUC-val 0.440  AUC-train 0.687\n",
            "Stats - Epoch: 8 AUC-val 0.443  AUC-train 0.700\n",
            "Stats - Epoch: 9 AUC-val 0.433  AUC-train 0.722\n",
            "Stats - Epoch: 10 AUC-val 0.435  AUC-train 0.735\n",
            "Stats - Epoch: 11 AUC-val 0.441  AUC-train 0.742\n",
            "Stats - Epoch: 12 AUC-val 0.433  AUC-train 0.761\n",
            "Stats - Epoch: 13 AUC-val 0.435  AUC-train 0.766\n",
            "Stats - Epoch: 14 AUC-val 0.440  AUC-train 0.777\n",
            "Stats - Epoch: 15 AUC-val 0.435  AUC-train 0.783\n",
            "Stats - Epoch: 16 AUC-val 0.439  AUC-train 0.784\n",
            "Stats - Epoch: 17 AUC-val 0.441  AUC-train 0.789\n",
            "Stats - Epoch: 18 AUC-val 0.444  AUC-train 0.801\n",
            "Stats - Epoch: 19 AUC-val 0.449  AUC-train 0.807\n",
            "Stats - Epoch: 20 AUC-val 0.441  AUC-train 0.806\n",
            "Stats - Epoch: 21 AUC-val 0.444  AUC-train 0.812\n",
            "Stats - Epoch: 22 AUC-val 0.442  AUC-train 0.818\n",
            "Stats - Epoch: 23 AUC-val 0.452  AUC-train 0.822\n",
            "Stats - Epoch: 24 AUC-val 0.458  AUC-train 0.823\n",
            "Stats - Epoch: 25 AUC-val 0.457  AUC-train 0.823\n",
            "Stats - Epoch: 26 AUC-val 0.458  AUC-train 0.830\n",
            "Stats - Epoch: 27 AUC-val 0.459  AUC-train 0.832\n",
            "Stats - Epoch: 28 AUC-val 0.462  AUC-train 0.836\n",
            "Stats - Epoch: 29 AUC-val 0.469  AUC-train 0.827\n",
            "Stats - Epoch: 30 AUC-val 0.466  AUC-train 0.836\n",
            "Stats - Epoch: 31 AUC-val 0.464  AUC-train 0.842\n",
            "Stats - Epoch: 32 AUC-val 0.464  AUC-train 0.844\n",
            "Stats - Epoch: 33 AUC-val 0.465  AUC-train 0.844\n",
            "Stats - Epoch: 34 AUC-val 0.471  AUC-train 0.844\n",
            "Stats - Epoch: 35 AUC-val 0.465  AUC-train 0.846\n",
            "Stats - Epoch: 36 AUC-val 0.475  AUC-train 0.843\n",
            "Stats - Epoch: 37 AUC-val 0.465  AUC-train 0.847\n",
            "Stats - Epoch: 38 AUC-val 0.470  AUC-train 0.849\n",
            "Stats - Epoch: 39 AUC-val 0.466  AUC-train 0.849\n",
            "Stats - Epoch: 40 AUC-val 0.470  AUC-train 0.854\n",
            "Stats - Epoch: 41 AUC-val 0.474  AUC-train 0.854\n",
            "Stats - Epoch: 42 AUC-val 0.472  AUC-train 0.854\n",
            "Stats - Epoch: 43 AUC-val 0.481  AUC-train 0.845\n",
            "Stats - Epoch: 44 AUC-val 0.477  AUC-train 0.854\n",
            "Stats - Epoch: 45 AUC-val 0.476  AUC-train 0.857\n",
            "Stats - Epoch: 46 AUC-val 0.476  AUC-train 0.860\n",
            "Stats - Epoch: 47 AUC-val 0.478  AUC-train 0.858\n",
            "Stats - Epoch: 48 AUC-val 0.467  AUC-train 0.856\n",
            "Stats - Epoch: 49 AUC-val 0.478  AUC-train 0.852\n",
            "Stats - Epoch: 50 AUC-val 0.482  AUC-train 0.859\n",
            "Stats - Epoch: 51 AUC-val 0.474  AUC-train 0.859\n",
            "Stats - Epoch: 52 AUC-val 0.469  AUC-train 0.858\n",
            "Stats - Epoch: 53 AUC-val 0.483  AUC-train 0.862\n",
            "Stats - Epoch: 54 AUC-val 0.482  AUC-train 0.863\n",
            "Stats - Epoch: 55 AUC-val 0.480  AUC-train 0.865\n",
            "Stats - Epoch: 56 AUC-val 0.481  AUC-train 0.859\n",
            "Stats - Epoch: 57 AUC-val 0.482  AUC-train 0.862\n",
            "Stats - Epoch: 58 AUC-val 0.485  AUC-train 0.856\n",
            "Stats - Epoch: 59 AUC-val 0.484  AUC-train 0.861\n",
            "Stats - Epoch: 60 AUC-val 0.474  AUC-train 0.864\n",
            "Stats - Epoch: 61 AUC-val 0.481  AUC-train 0.867\n",
            "Stats - Epoch: 62 AUC-val 0.487  AUC-train 0.866\n",
            "Stats - Epoch: 63 AUC-val 0.488  AUC-train 0.869\n",
            "Stats - Epoch: 64 AUC-val 0.484  AUC-train 0.863\n",
            "Stats - Epoch: 65 AUC-val 0.484  AUC-train 0.868\n",
            "Stats - Epoch: 66 AUC-val 0.487  AUC-train 0.867\n",
            "Stats - Epoch: 67 AUC-val 0.487  AUC-train 0.869\n",
            "Stats - Epoch: 68 AUC-val 0.493  AUC-train 0.868\n",
            "Stats - Epoch: 69 AUC-val 0.488  AUC-train 0.870\n",
            "Stats - Epoch: 70 AUC-val 0.483  AUC-train 0.872\n",
            "Stats - Epoch: 71 AUC-val 0.480  AUC-train 0.870\n",
            "Stats - Epoch: 72 AUC-val 0.489  AUC-train 0.869\n",
            "Stats - Epoch: 73 AUC-val 0.485  AUC-train 0.864\n",
            "Stats - Epoch: 74 AUC-val 0.488  AUC-train 0.866\n",
            "Stats - Epoch: 75 AUC-val 0.486  AUC-train 0.868\n",
            "Stats - Epoch: 76 AUC-val 0.488  AUC-train 0.867\n",
            "Stats - Epoch: 77 AUC-val 0.486  AUC-train 0.869\n",
            "Stats - Epoch: 78 AUC-val 0.490  AUC-train 0.870\n",
            "Stats - Epoch: 79 AUC-val 0.491  AUC-train 0.873\n",
            "Stats - Epoch: 80 AUC-val 0.490  AUC-train 0.870\n",
            "Stats - Epoch: 81 AUC-val 0.493  AUC-train 0.873\n",
            "Stats - Epoch: 82 AUC-val 0.490  AUC-train 0.874\n",
            "Stats - Epoch: 83 AUC-val 0.485  AUC-train 0.874\n",
            "Stats - Epoch: 84 AUC-val 0.493  AUC-train 0.873\n",
            "Stats - Epoch: 85 AUC-val 0.489  AUC-train 0.874\n",
            "Stats - Epoch: 86 AUC-val 0.488  AUC-train 0.876\n",
            "Stats - Epoch: 87 AUC-val 0.486  AUC-train 0.874\n",
            "Stats - Epoch: 88 AUC-val 0.493  AUC-train 0.876\n",
            "Stats - Epoch: 89 AUC-val 0.486  AUC-train 0.876\n",
            "Stats - Epoch: 90 AUC-val 0.488  AUC-train 0.875\n",
            "Stats - Epoch: 91 AUC-val 0.491  AUC-train 0.877\n",
            "Stats - Epoch: 92 AUC-val 0.490  AUC-train 0.876\n",
            "Stats - Epoch: 93 AUC-val 0.487  AUC-train 0.877\n",
            "Stats - Epoch: 94 AUC-val 0.483  AUC-train 0.878\n",
            "Stats - Epoch: 95 AUC-val 0.490  AUC-train 0.874\n",
            "Stats - Epoch: 96 AUC-val 0.484  AUC-train 0.878\n",
            "Stats - Epoch: 97 AUC-val 0.482  AUC-train 0.880\n",
            "Stats - Epoch: 98 AUC-val 0.488  AUC-train 0.879\n",
            "Stats - Epoch: 99 AUC-val 0.489  AUC-train 0.878\n",
            "Stats - Epoch: 100 AUC-val 0.486  AUC-train 0.879\n",
            "Results 100 AUC-val 0.493 0.493 0.548 0.474 0.618 AUC-train 0.873\n",
            "Shapley [0.00608198 0.00569556 0.01916775 0.01027037 0.0041826 ] [0.01819158]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188625\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.288  AUC-train 0.541\n",
            "Stats - Epoch: 2 AUC-val 0.378  AUC-train 0.708\n",
            "Stats - Epoch: 3 AUC-val 0.406  AUC-train 0.790\n",
            "Stats - Epoch: 4 AUC-val 0.378  AUC-train 0.847\n",
            "Stats - Epoch: 5 AUC-val 0.357  AUC-train 0.881\n",
            "Stats - Epoch: 6 AUC-val 0.323  AUC-train 0.905\n",
            "Stats - Epoch: 7 AUC-val 0.299  AUC-train 0.923\n",
            "Stats - Epoch: 8 AUC-val 0.306  AUC-train 0.929\n",
            "Stats - Epoch: 9 AUC-val 0.328  AUC-train 0.945\n",
            "Stats - Epoch: 10 AUC-val 0.334  AUC-train 0.950\n",
            "Stats - Epoch: 11 AUC-val 0.347  AUC-train 0.958\n",
            "Stats - Epoch: 12 AUC-val 0.360  AUC-train 0.965\n",
            "Stats - Epoch: 13 AUC-val 0.360  AUC-train 0.970\n",
            "Stats - Epoch: 14 AUC-val 0.358  AUC-train 0.971\n",
            "Stats - Epoch: 15 AUC-val 0.370  AUC-train 0.970\n",
            "Stats - Epoch: 16 AUC-val 0.378  AUC-train 0.972\n",
            "Stats - Epoch: 17 AUC-val 0.367  AUC-train 0.976\n",
            "Stats - Epoch: 18 AUC-val 0.414  AUC-train 0.970\n",
            "Stats - Epoch: 19 AUC-val 0.380  AUC-train 0.979\n",
            "Stats - Epoch: 20 AUC-val 0.412  AUC-train 0.975\n",
            "Stats - Epoch: 21 AUC-val 0.404  AUC-train 0.975\n",
            "Stats - Epoch: 22 AUC-val 0.404  AUC-train 0.974\n",
            "Stats - Epoch: 23 AUC-val 0.405  AUC-train 0.978\n",
            "Stats - Epoch: 24 AUC-val 0.411  AUC-train 0.979\n",
            "Stats - Epoch: 25 AUC-val 0.397  AUC-train 0.980\n",
            "Stats - Epoch: 26 AUC-val 0.412  AUC-train 0.976\n",
            "Stats - Epoch: 27 AUC-val 0.424  AUC-train 0.975\n",
            "Stats - Epoch: 28 AUC-val 0.410  AUC-train 0.977\n",
            "Stats - Epoch: 29 AUC-val 0.413  AUC-train 0.978\n",
            "Stats - Epoch: 30 AUC-val 0.415  AUC-train 0.980\n",
            "Stats - Epoch: 31 AUC-val 0.422  AUC-train 0.983\n",
            "Stats - Epoch: 32 AUC-val 0.438  AUC-train 0.984\n",
            "Stats - Epoch: 33 AUC-val 0.410  AUC-train 0.984\n",
            "Stats - Epoch: 34 AUC-val 0.442  AUC-train 0.982\n",
            "Stats - Epoch: 35 AUC-val 0.436  AUC-train 0.981\n",
            "Stats - Epoch: 36 AUC-val 0.434  AUC-train 0.982\n",
            "Stats - Epoch: 37 AUC-val 0.415  AUC-train 0.981\n",
            "Stats - Epoch: 38 AUC-val 0.432  AUC-train 0.982\n",
            "Stats - Epoch: 39 AUC-val 0.440  AUC-train 0.981\n",
            "Stats - Epoch: 40 AUC-val 0.458  AUC-train 0.978\n",
            "Stats - Epoch: 41 AUC-val 0.449  AUC-train 0.979\n",
            "Stats - Epoch: 42 AUC-val 0.436  AUC-train 0.977\n",
            "Stats - Epoch: 43 AUC-val 0.459  AUC-train 0.981\n",
            "Stats - Epoch: 44 AUC-val 0.440  AUC-train 0.979\n",
            "Stats - Epoch: 45 AUC-val 0.459  AUC-train 0.978\n",
            "Stats - Epoch: 46 AUC-val 0.452  AUC-train 0.982\n",
            "Stats - Epoch: 47 AUC-val 0.446  AUC-train 0.981\n",
            "Stats - Epoch: 48 AUC-val 0.454  AUC-train 0.975\n",
            "Stats - Epoch: 49 AUC-val 0.433  AUC-train 0.979\n",
            "Stats - Epoch: 50 AUC-val 0.438  AUC-train 0.979\n",
            "Stats - Epoch: 51 AUC-val 0.450  AUC-train 0.979\n",
            "Stats - Epoch: 52 AUC-val 0.435  AUC-train 0.978\n",
            "Stats - Epoch: 53 AUC-val 0.448  AUC-train 0.981\n",
            "Stats - Epoch: 54 AUC-val 0.475  AUC-train 0.979\n",
            "Stats - Epoch: 55 AUC-val 0.475  AUC-train 0.977\n",
            "Stats - Epoch: 56 AUC-val 0.454  AUC-train 0.979\n",
            "Stats - Epoch: 57 AUC-val 0.447  AUC-train 0.978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.471  AUC-train 0.978\n",
            "Stats - Epoch: 59 AUC-val 0.459  AUC-train 0.978\n",
            "Stats - Epoch: 60 AUC-val 0.460  AUC-train 0.978\n",
            "Stats - Epoch: 61 AUC-val 0.464  AUC-train 0.980\n",
            "Stats - Epoch: 62 AUC-val 0.457  AUC-train 0.981\n",
            "Stats - Epoch: 63 AUC-val 0.468  AUC-train 0.980\n",
            "Stats - Epoch: 64 AUC-val 0.469  AUC-train 0.971\n",
            "Stats - Epoch: 65 AUC-val 0.452  AUC-train 0.976\n",
            "Stats - Epoch: 66 AUC-val 0.448  AUC-train 0.979\n",
            "Stats - Epoch: 67 AUC-val 0.449  AUC-train 0.979\n",
            "Stats - Epoch: 68 AUC-val 0.452  AUC-train 0.978\n",
            "Stats - Epoch: 69 AUC-val 0.470  AUC-train 0.981\n",
            "Stats - Epoch: 70 AUC-val 0.475  AUC-train 0.980\n",
            "Stats - Epoch: 71 AUC-val 0.467  AUC-train 0.978\n",
            "Stats - Epoch: 72 AUC-val 0.490  AUC-train 0.975\n",
            "Stats - Epoch: 73 AUC-val 0.477  AUC-train 0.976\n",
            "Stats - Epoch: 74 AUC-val 0.468  AUC-train 0.976\n",
            "Stats - Epoch: 75 AUC-val 0.469  AUC-train 0.970\n",
            "Stats - Epoch: 76 AUC-val 0.480  AUC-train 0.972\n",
            "Stats - Epoch: 77 AUC-val 0.467  AUC-train 0.976\n",
            "Stats - Epoch: 78 AUC-val 0.478  AUC-train 0.967\n",
            "Stats - Epoch: 79 AUC-val 0.459  AUC-train 0.974\n",
            "Stats - Epoch: 80 AUC-val 0.459  AUC-train 0.974\n",
            "Stats - Epoch: 81 AUC-val 0.465  AUC-train 0.975\n",
            "Stats - Epoch: 82 AUC-val 0.469  AUC-train 0.978\n",
            "Stats - Epoch: 83 AUC-val 0.485  AUC-train 0.973\n",
            "Stats - Epoch: 84 AUC-val 0.469  AUC-train 0.977\n",
            "Stats - Epoch: 85 AUC-val 0.464  AUC-train 0.978\n",
            "Stats - Epoch: 86 AUC-val 0.460  AUC-train 0.976\n",
            "Stats - Epoch: 87 AUC-val 0.454  AUC-train 0.977\n",
            "Stats - Epoch: 88 AUC-val 0.464  AUC-train 0.976\n",
            "Stats - Epoch: 89 AUC-val 0.498  AUC-train 0.967\n",
            "Stats - Epoch: 90 AUC-val 0.467  AUC-train 0.975\n",
            "Stats - Epoch: 91 AUC-val 0.480  AUC-train 0.976\n",
            "Stats - Epoch: 92 AUC-val 0.473  AUC-train 0.974\n",
            "Stats - Epoch: 93 AUC-val 0.453  AUC-train 0.979\n",
            "Stats - Epoch: 94 AUC-val 0.471  AUC-train 0.973\n",
            "Stats - Epoch: 95 AUC-val 0.440  AUC-train 0.973\n",
            "Stats - Epoch: 96 AUC-val 0.441  AUC-train 0.970\n",
            "Stats - Epoch: 97 AUC-val 0.452  AUC-train 0.974\n",
            "Stats - Epoch: 98 AUC-val 0.449  AUC-train 0.977\n",
            "Stats - Epoch: 99 AUC-val 0.447  AUC-train 0.971\n",
            "Stats - Epoch: 100 AUC-val 0.449  AUC-train 0.974\n",
            "Results 100 AUC-val 0.498 0.457 0.346 0.188 0.530 AUC-train 0.967\n",
            "Shapley [0.02480843 0.00787034 0.00793257 0.03455264 0.00813459] [0.03421081]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.181928\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.237  AUC-train 0.571\n",
            "Stats - Epoch: 2 AUC-val 0.226  AUC-train 0.608\n",
            "Stats - Epoch: 3 AUC-val 0.217  AUC-train 0.630\n",
            "Stats - Epoch: 4 AUC-val 0.237  AUC-train 0.683\n",
            "Stats - Epoch: 5 AUC-val 0.293  AUC-train 0.721\n",
            "Stats - Epoch: 6 AUC-val 0.322  AUC-train 0.742\n",
            "Stats - Epoch: 7 AUC-val 0.332  AUC-train 0.767\n",
            "Stats - Epoch: 8 AUC-val 0.443  AUC-train 0.788\n",
            "Stats - Epoch: 9 AUC-val 0.426  AUC-train 0.801\n",
            "Stats - Epoch: 10 AUC-val 0.429  AUC-train 0.812\n",
            "Stats - Epoch: 11 AUC-val 0.472  AUC-train 0.821\n",
            "Stats - Epoch: 12 AUC-val 0.482  AUC-train 0.827\n",
            "Stats - Epoch: 13 AUC-val 0.448  AUC-train 0.835\n",
            "Stats - Epoch: 14 AUC-val 0.479  AUC-train 0.839\n",
            "Stats - Epoch: 15 AUC-val 0.505  AUC-train 0.843\n",
            "Stats - Epoch: 16 AUC-val 0.530  AUC-train 0.843\n",
            "Stats - Epoch: 17 AUC-val 0.491  AUC-train 0.849\n",
            "Stats - Epoch: 18 AUC-val 0.586  AUC-train 0.848\n",
            "Stats - Epoch: 19 AUC-val 0.524  AUC-train 0.851\n",
            "Stats - Epoch: 20 AUC-val 0.531  AUC-train 0.858\n",
            "Stats - Epoch: 21 AUC-val 0.546  AUC-train 0.862\n",
            "Stats - Epoch: 22 AUC-val 0.575  AUC-train 0.858\n",
            "Stats - Epoch: 23 AUC-val 0.558  AUC-train 0.862\n",
            "Stats - Epoch: 24 AUC-val 0.558  AUC-train 0.862\n",
            "Stats - Epoch: 25 AUC-val 0.547  AUC-train 0.868\n",
            "Stats - Epoch: 26 AUC-val 0.557  AUC-train 0.871\n",
            "Stats - Epoch: 27 AUC-val 0.555  AUC-train 0.872\n",
            "Stats - Epoch: 28 AUC-val 0.548  AUC-train 0.872\n",
            "Stats - Epoch: 29 AUC-val 0.578  AUC-train 0.871\n",
            "Stats - Epoch: 30 AUC-val 0.569  AUC-train 0.874\n",
            "Stats - Epoch: 31 AUC-val 0.569  AUC-train 0.876\n",
            "Stats - Epoch: 32 AUC-val 0.569  AUC-train 0.876\n",
            "Stats - Epoch: 33 AUC-val 0.552  AUC-train 0.873\n",
            "Stats - Epoch: 34 AUC-val 0.580  AUC-train 0.872\n",
            "Stats - Epoch: 35 AUC-val 0.560  AUC-train 0.876\n",
            "Stats - Epoch: 36 AUC-val 0.597  AUC-train 0.876\n",
            "Stats - Epoch: 37 AUC-val 0.565  AUC-train 0.878\n",
            "Stats - Epoch: 38 AUC-val 0.590  AUC-train 0.879\n",
            "Stats - Epoch: 39 AUC-val 0.543  AUC-train 0.879\n",
            "Stats - Epoch: 40 AUC-val 0.550  AUC-train 0.881\n",
            "Stats - Epoch: 41 AUC-val 0.554  AUC-train 0.879\n",
            "Stats - Epoch: 42 AUC-val 0.585  AUC-train 0.879\n",
            "Stats - Epoch: 43 AUC-val 0.562  AUC-train 0.882\n",
            "Stats - Epoch: 44 AUC-val 0.572  AUC-train 0.883\n",
            "Stats - Epoch: 45 AUC-val 0.599  AUC-train 0.886\n",
            "Stats - Epoch: 46 AUC-val 0.565  AUC-train 0.887\n",
            "Stats - Epoch: 47 AUC-val 0.609  AUC-train 0.888\n",
            "Stats - Epoch: 48 AUC-val 0.610  AUC-train 0.888\n",
            "Stats - Epoch: 49 AUC-val 0.611  AUC-train 0.891\n",
            "Stats - Epoch: 50 AUC-val 0.591  AUC-train 0.891\n",
            "Stats - Epoch: 51 AUC-val 0.603  AUC-train 0.888\n",
            "Stats - Epoch: 52 AUC-val 0.603  AUC-train 0.888\n",
            "Stats - Epoch: 53 AUC-val 0.611  AUC-train 0.883\n",
            "Stats - Epoch: 54 AUC-val 0.622  AUC-train 0.883\n",
            "Stats - Epoch: 55 AUC-val 0.598  AUC-train 0.888\n",
            "Stats - Epoch: 56 AUC-val 0.615  AUC-train 0.889\n",
            "Stats - Epoch: 57 AUC-val 0.590  AUC-train 0.895\n",
            "Stats - Epoch: 58 AUC-val 0.603  AUC-train 0.896\n",
            "Stats - Epoch: 59 AUC-val 0.597  AUC-train 0.891\n",
            "Stats - Epoch: 60 AUC-val 0.592  AUC-train 0.894\n",
            "Stats - Epoch: 61 AUC-val 0.609  AUC-train 0.896\n",
            "Stats - Epoch: 62 AUC-val 0.600  AUC-train 0.899\n",
            "Stats - Epoch: 63 AUC-val 0.589  AUC-train 0.899\n",
            "Stats - Epoch: 64 AUC-val 0.597  AUC-train 0.890\n",
            "Stats - Epoch: 65 AUC-val 0.597  AUC-train 0.888\n",
            "Stats - Epoch: 66 AUC-val 0.595  AUC-train 0.892\n",
            "Stats - Epoch: 67 AUC-val 0.590  AUC-train 0.897\n",
            "Stats - Epoch: 68 AUC-val 0.626  AUC-train 0.895\n",
            "Stats - Epoch: 69 AUC-val 0.599  AUC-train 0.892\n",
            "Stats - Epoch: 70 AUC-val 0.631  AUC-train 0.894\n",
            "Stats - Epoch: 71 AUC-val 0.632  AUC-train 0.896\n",
            "Stats - Epoch: 72 AUC-val 0.598  AUC-train 0.897\n",
            "Stats - Epoch: 73 AUC-val 0.590  AUC-train 0.896\n",
            "Stats - Epoch: 74 AUC-val 0.618  AUC-train 0.898\n",
            "Stats - Epoch: 75 AUC-val 0.580  AUC-train 0.904\n",
            "Stats - Epoch: 76 AUC-val 0.590  AUC-train 0.902\n",
            "Stats - Epoch: 77 AUC-val 0.587  AUC-train 0.903\n",
            "Stats - Epoch: 78 AUC-val 0.630  AUC-train 0.900\n",
            "Stats - Epoch: 79 AUC-val 0.578  AUC-train 0.895\n",
            "Stats - Epoch: 80 AUC-val 0.609  AUC-train 0.898\n",
            "Stats - Epoch: 81 AUC-val 0.619  AUC-train 0.904\n",
            "Stats - Epoch: 82 AUC-val 0.597  AUC-train 0.903\n",
            "Stats - Epoch: 83 AUC-val 0.621  AUC-train 0.905\n",
            "Stats - Epoch: 84 AUC-val 0.615  AUC-train 0.901\n",
            "Stats - Epoch: 85 AUC-val 0.593  AUC-train 0.903\n",
            "Stats - Epoch: 86 AUC-val 0.600  AUC-train 0.903\n",
            "Stats - Epoch: 87 AUC-val 0.622  AUC-train 0.905\n",
            "Stats - Epoch: 88 AUC-val 0.612  AUC-train 0.906\n",
            "Stats - Epoch: 89 AUC-val 0.582  AUC-train 0.901\n",
            "Stats - Epoch: 90 AUC-val 0.590  AUC-train 0.899\n",
            "Stats - Epoch: 91 AUC-val 0.584  AUC-train 0.904\n",
            "Stats - Epoch: 92 AUC-val 0.612  AUC-train 0.906\n",
            "Stats - Epoch: 93 AUC-val 0.584  AUC-train 0.908\n",
            "Stats - Epoch: 94 AUC-val 0.612  AUC-train 0.912\n",
            "Stats - Epoch: 95 AUC-val 0.590  AUC-train 0.910\n",
            "Stats - Epoch: 96 AUC-val 0.621  AUC-train 0.911\n",
            "Stats - Epoch: 97 AUC-val 0.629  AUC-train 0.910\n",
            "Stats - Epoch: 98 AUC-val 0.604  AUC-train 0.910\n",
            "Stats - Epoch: 99 AUC-val 0.619  AUC-train 0.904\n",
            "Stats - Epoch: 100 AUC-val 0.651  AUC-train 0.903\n",
            "Results 100 AUC-val 0.651 0.646 0.606 0.503 0.593 AUC-train 0.903\n",
            "Shapley [0.01631818 0.01093522 0.01750807 0.01401344 0.00536296] [0.00478892]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196872\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.336  AUC-train 0.548\n",
            "Stats - Epoch: 2 AUC-val 0.443  AUC-train 0.661\n",
            "Stats - Epoch: 3 AUC-val 0.534  AUC-train 0.762\n",
            "Stats - Epoch: 4 AUC-val 0.590  AUC-train 0.808\n",
            "Stats - Epoch: 5 AUC-val 0.616  AUC-train 0.830\n",
            "Stats - Epoch: 6 AUC-val 0.623  AUC-train 0.846\n",
            "Stats - Epoch: 7 AUC-val 0.641  AUC-train 0.868\n",
            "Stats - Epoch: 8 AUC-val 0.648  AUC-train 0.874\n",
            "Stats - Epoch: 9 AUC-val 0.664  AUC-train 0.889\n",
            "Stats - Epoch: 10 AUC-val 0.666  AUC-train 0.900\n",
            "Stats - Epoch: 11 AUC-val 0.690  AUC-train 0.910\n",
            "Stats - Epoch: 12 AUC-val 0.703  AUC-train 0.914\n",
            "Stats - Epoch: 13 AUC-val 0.709  AUC-train 0.922\n",
            "Stats - Epoch: 14 AUC-val 0.697  AUC-train 0.928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.706  AUC-train 0.931\n",
            "Stats - Epoch: 16 AUC-val 0.719  AUC-train 0.937\n",
            "Stats - Epoch: 17 AUC-val 0.691  AUC-train 0.942\n",
            "Stats - Epoch: 18 AUC-val 0.700  AUC-train 0.943\n",
            "Stats - Epoch: 19 AUC-val 0.707  AUC-train 0.946\n",
            "Stats - Epoch: 20 AUC-val 0.700  AUC-train 0.949\n",
            "Stats - Epoch: 21 AUC-val 0.714  AUC-train 0.948\n",
            "Stats - Epoch: 22 AUC-val 0.699  AUC-train 0.952\n",
            "Stats - Epoch: 23 AUC-val 0.710  AUC-train 0.956\n",
            "Stats - Epoch: 24 AUC-val 0.709  AUC-train 0.956\n",
            "Stats - Epoch: 25 AUC-val 0.702  AUC-train 0.959\n",
            "Stats - Epoch: 26 AUC-val 0.705  AUC-train 0.959\n",
            "Stats - Epoch: 27 AUC-val 0.695  AUC-train 0.959\n",
            "Stats - Epoch: 28 AUC-val 0.714  AUC-train 0.960\n",
            "Stats - Epoch: 29 AUC-val 0.693  AUC-train 0.964\n",
            "Stats - Epoch: 30 AUC-val 0.680  AUC-train 0.966\n",
            "Stats - Epoch: 31 AUC-val 0.681  AUC-train 0.967\n",
            "Stats - Epoch: 32 AUC-val 0.687  AUC-train 0.967\n",
            "Stats - Epoch: 33 AUC-val 0.680  AUC-train 0.967\n",
            "Stats - Epoch: 34 AUC-val 0.675  AUC-train 0.970\n",
            "Stats - Epoch: 35 AUC-val 0.734  AUC-train 0.969\n",
            "Stats - Epoch: 36 AUC-val 0.677  AUC-train 0.972\n",
            "Stats - Epoch: 37 AUC-val 0.705  AUC-train 0.973\n",
            "Stats - Epoch: 38 AUC-val 0.680  AUC-train 0.974\n",
            "Stats - Epoch: 39 AUC-val 0.690  AUC-train 0.971\n",
            "Stats - Epoch: 40 AUC-val 0.697  AUC-train 0.974\n",
            "Stats - Epoch: 41 AUC-val 0.707  AUC-train 0.976\n",
            "Stats - Epoch: 42 AUC-val 0.703  AUC-train 0.974\n",
            "Stats - Epoch: 43 AUC-val 0.727  AUC-train 0.977\n",
            "Stats - Epoch: 44 AUC-val 0.694  AUC-train 0.976\n",
            "Stats - Epoch: 45 AUC-val 0.702  AUC-train 0.979\n",
            "Stats - Epoch: 46 AUC-val 0.694  AUC-train 0.979\n",
            "Stats - Epoch: 47 AUC-val 0.739  AUC-train 0.978\n",
            "Stats - Epoch: 48 AUC-val 0.701  AUC-train 0.977\n",
            "Stats - Epoch: 49 AUC-val 0.701  AUC-train 0.979\n",
            "Stats - Epoch: 50 AUC-val 0.705  AUC-train 0.980\n",
            "Stats - Epoch: 51 AUC-val 0.727  AUC-train 0.981\n",
            "Stats - Epoch: 52 AUC-val 0.727  AUC-train 0.983\n",
            "Stats - Epoch: 53 AUC-val 0.729  AUC-train 0.983\n",
            "Stats - Epoch: 54 AUC-val 0.674  AUC-train 0.984\n",
            "Stats - Epoch: 55 AUC-val 0.698  AUC-train 0.984\n",
            "Stats - Epoch: 56 AUC-val 0.709  AUC-train 0.983\n",
            "Stats - Epoch: 57 AUC-val 0.716  AUC-train 0.984\n",
            "Stats - Epoch: 58 AUC-val 0.718  AUC-train 0.984\n",
            "Stats - Epoch: 59 AUC-val 0.690  AUC-train 0.985\n",
            "Stats - Epoch: 60 AUC-val 0.686  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.692  AUC-train 0.983\n",
            "Stats - Epoch: 62 AUC-val 0.684  AUC-train 0.986\n",
            "Stats - Epoch: 63 AUC-val 0.676  AUC-train 0.982\n",
            "Stats - Epoch: 64 AUC-val 0.700  AUC-train 0.981\n",
            "Stats - Epoch: 65 AUC-val 0.671  AUC-train 0.983\n",
            "Stats - Epoch: 66 AUC-val 0.703  AUC-train 0.985\n",
            "Stats - Epoch: 67 AUC-val 0.698  AUC-train 0.983\n",
            "Stats - Epoch: 68 AUC-val 0.707  AUC-train 0.984\n",
            "Stats - Epoch: 69 AUC-val 0.681  AUC-train 0.985\n",
            "Stats - Epoch: 70 AUC-val 0.691  AUC-train 0.984\n",
            "Stats - Epoch: 71 AUC-val 0.689  AUC-train 0.981\n",
            "Stats - Epoch: 72 AUC-val 0.696  AUC-train 0.983\n",
            "Stats - Epoch: 73 AUC-val 0.669  AUC-train 0.983\n",
            "Stats - Epoch: 74 AUC-val 0.673  AUC-train 0.983\n",
            "Stats - Epoch: 75 AUC-val 0.681  AUC-train 0.981\n",
            "Stats - Epoch: 76 AUC-val 0.703  AUC-train 0.983\n",
            "Stats - Epoch: 77 AUC-val 0.689  AUC-train 0.984\n",
            "Stats - Epoch: 78 AUC-val 0.700  AUC-train 0.985\n",
            "Stats - Epoch: 79 AUC-val 0.712  AUC-train 0.985\n",
            "Stats - Epoch: 80 AUC-val 0.679  AUC-train 0.986\n",
            "Stats - Epoch: 81 AUC-val 0.707  AUC-train 0.985\n",
            "Stats - Epoch: 82 AUC-val 0.696  AUC-train 0.986\n",
            "Stats - Epoch: 83 AUC-val 0.673  AUC-train 0.984\n",
            "Stats - Epoch: 84 AUC-val 0.657  AUC-train 0.986\n",
            "Stats - Epoch: 85 AUC-val 0.688  AUC-train 0.987\n",
            "Stats - Epoch: 86 AUC-val 0.688  AUC-train 0.987\n",
            "Stats - Epoch: 87 AUC-val 0.663  AUC-train 0.987\n",
            "Stats - Epoch: 88 AUC-val 0.705  AUC-train 0.986\n",
            "Stats - Epoch: 89 AUC-val 0.683  AUC-train 0.986\n",
            "Stats - Epoch: 90 AUC-val 0.704  AUC-train 0.986\n",
            "Stats - Epoch: 91 AUC-val 0.671  AUC-train 0.982\n",
            "Stats - Epoch: 92 AUC-val 0.683  AUC-train 0.985\n",
            "Stats - Epoch: 93 AUC-val 0.678  AUC-train 0.985\n",
            "Stats - Epoch: 94 AUC-val 0.654  AUC-train 0.977\n",
            "Stats - Epoch: 95 AUC-val 0.652  AUC-train 0.982\n",
            "Stats - Epoch: 96 AUC-val 0.678  AUC-train 0.982\n",
            "Stats - Epoch: 97 AUC-val 0.698  AUC-train 0.986\n",
            "Stats - Epoch: 98 AUC-val 0.690  AUC-train 0.986\n",
            "Stats - Epoch: 99 AUC-val 0.664  AUC-train 0.985\n",
            "Stats - Epoch: 100 AUC-val 0.665  AUC-train 0.985\n",
            "Results 100 AUC-val 0.739 0.658 0.543 0.500 0.581 AUC-train 0.978\n",
            "Shapley [0.01924216 0.01921633 0.01620253 0.02879655 0.01465918] [0.00799197]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196385\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.514  AUC-train 0.478\n",
            "Stats - Epoch: 2 AUC-val 0.562  AUC-train 0.576\n",
            "Stats - Epoch: 3 AUC-val 0.576  AUC-train 0.670\n",
            "Stats - Epoch: 4 AUC-val 0.594  AUC-train 0.718\n",
            "Stats - Epoch: 5 AUC-val 0.588  AUC-train 0.761\n",
            "Stats - Epoch: 6 AUC-val 0.578  AUC-train 0.787\n",
            "Stats - Epoch: 7 AUC-val 0.594  AUC-train 0.807\n",
            "Stats - Epoch: 8 AUC-val 0.593  AUC-train 0.823\n",
            "Stats - Epoch: 9 AUC-val 0.588  AUC-train 0.838\n",
            "Stats - Epoch: 10 AUC-val 0.586  AUC-train 0.850\n",
            "Stats - Epoch: 11 AUC-val 0.586  AUC-train 0.861\n",
            "Stats - Epoch: 12 AUC-val 0.588  AUC-train 0.864\n",
            "Stats - Epoch: 13 AUC-val 0.601  AUC-train 0.870\n",
            "Stats - Epoch: 14 AUC-val 0.597  AUC-train 0.879\n",
            "Stats - Epoch: 15 AUC-val 0.599  AUC-train 0.881\n",
            "Stats - Epoch: 16 AUC-val 0.601  AUC-train 0.888\n",
            "Stats - Epoch: 17 AUC-val 0.587  AUC-train 0.895\n",
            "Stats - Epoch: 18 AUC-val 0.607  AUC-train 0.898\n",
            "Stats - Epoch: 19 AUC-val 0.598  AUC-train 0.905\n",
            "Stats - Epoch: 20 AUC-val 0.615  AUC-train 0.912\n",
            "Stats - Epoch: 21 AUC-val 0.579  AUC-train 0.912\n",
            "Stats - Epoch: 22 AUC-val 0.546  AUC-train 0.917\n",
            "Stats - Epoch: 23 AUC-val 0.594  AUC-train 0.922\n",
            "Stats - Epoch: 24 AUC-val 0.605  AUC-train 0.924\n",
            "Stats - Epoch: 25 AUC-val 0.569  AUC-train 0.930\n",
            "Stats - Epoch: 26 AUC-val 0.568  AUC-train 0.929\n",
            "Stats - Epoch: 27 AUC-val 0.595  AUC-train 0.931\n",
            "Stats - Epoch: 28 AUC-val 0.581  AUC-train 0.939\n",
            "Stats - Epoch: 29 AUC-val 0.593  AUC-train 0.940\n",
            "Stats - Epoch: 30 AUC-val 0.595  AUC-train 0.945\n",
            "Stats - Epoch: 31 AUC-val 0.556  AUC-train 0.946\n",
            "Stats - Epoch: 32 AUC-val 0.582  AUC-train 0.950\n",
            "Stats - Epoch: 33 AUC-val 0.600  AUC-train 0.950\n",
            "Stats - Epoch: 34 AUC-val 0.619  AUC-train 0.949\n",
            "Stats - Epoch: 35 AUC-val 0.586  AUC-train 0.950\n",
            "Stats - Epoch: 36 AUC-val 0.584  AUC-train 0.953\n",
            "Stats - Epoch: 37 AUC-val 0.620  AUC-train 0.955\n",
            "Stats - Epoch: 38 AUC-val 0.635  AUC-train 0.955\n",
            "Stats - Epoch: 39 AUC-val 0.598  AUC-train 0.957\n",
            "Stats - Epoch: 40 AUC-val 0.649  AUC-train 0.959\n",
            "Stats - Epoch: 41 AUC-val 0.617  AUC-train 0.959\n",
            "Stats - Epoch: 42 AUC-val 0.607  AUC-train 0.960\n",
            "Stats - Epoch: 43 AUC-val 0.644  AUC-train 0.965\n",
            "Stats - Epoch: 44 AUC-val 0.604  AUC-train 0.967\n",
            "Stats - Epoch: 45 AUC-val 0.594  AUC-train 0.965\n",
            "Stats - Epoch: 46 AUC-val 0.614  AUC-train 0.966\n",
            "Stats - Epoch: 47 AUC-val 0.637  AUC-train 0.965\n",
            "Stats - Epoch: 48 AUC-val 0.611  AUC-train 0.965\n",
            "Stats - Epoch: 49 AUC-val 0.566  AUC-train 0.967\n",
            "Stats - Epoch: 50 AUC-val 0.571  AUC-train 0.971\n",
            "Stats - Epoch: 51 AUC-val 0.542  AUC-train 0.972\n",
            "Stats - Epoch: 52 AUC-val 0.570  AUC-train 0.975\n",
            "Stats - Epoch: 53 AUC-val 0.590  AUC-train 0.973\n",
            "Stats - Epoch: 54 AUC-val 0.563  AUC-train 0.972\n",
            "Stats - Epoch: 55 AUC-val 0.547  AUC-train 0.972\n",
            "Stats - Epoch: 56 AUC-val 0.610  AUC-train 0.970\n",
            "Stats - Epoch: 57 AUC-val 0.578  AUC-train 0.968\n",
            "Stats - Epoch: 58 AUC-val 0.638  AUC-train 0.971\n",
            "Stats - Epoch: 59 AUC-val 0.611  AUC-train 0.968\n",
            "Stats - Epoch: 60 AUC-val 0.599  AUC-train 0.973\n",
            "Stats - Epoch: 61 AUC-val 0.574  AUC-train 0.973\n",
            "Stats - Epoch: 62 AUC-val 0.657  AUC-train 0.975\n",
            "Stats - Epoch: 63 AUC-val 0.633  AUC-train 0.976\n",
            "Stats - Epoch: 64 AUC-val 0.594  AUC-train 0.978\n",
            "Stats - Epoch: 65 AUC-val 0.602  AUC-train 0.980\n",
            "Stats - Epoch: 66 AUC-val 0.610  AUC-train 0.980\n",
            "Stats - Epoch: 67 AUC-val 0.634  AUC-train 0.981\n",
            "Stats - Epoch: 68 AUC-val 0.628  AUC-train 0.979\n",
            "Stats - Epoch: 69 AUC-val 0.641  AUC-train 0.980\n",
            "Stats - Epoch: 70 AUC-val 0.584  AUC-train 0.980\n",
            "Stats - Epoch: 71 AUC-val 0.628  AUC-train 0.980\n",
            "Stats - Epoch: 72 AUC-val 0.619  AUC-train 0.982\n",
            "Stats - Epoch: 73 AUC-val 0.609  AUC-train 0.981\n",
            "Stats - Epoch: 74 AUC-val 0.610  AUC-train 0.980\n",
            "Stats - Epoch: 75 AUC-val 0.603  AUC-train 0.980\n",
            "Stats - Epoch: 76 AUC-val 0.650  AUC-train 0.978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.621  AUC-train 0.981\n",
            "Stats - Epoch: 78 AUC-val 0.607  AUC-train 0.983\n",
            "Stats - Epoch: 79 AUC-val 0.592  AUC-train 0.982\n",
            "Stats - Epoch: 80 AUC-val 0.626  AUC-train 0.982\n",
            "Stats - Epoch: 81 AUC-val 0.595  AUC-train 0.984\n",
            "Stats - Epoch: 82 AUC-val 0.641  AUC-train 0.984\n",
            "Stats - Epoch: 83 AUC-val 0.638  AUC-train 0.986\n",
            "Stats - Epoch: 84 AUC-val 0.640  AUC-train 0.984\n",
            "Stats - Epoch: 85 AUC-val 0.651  AUC-train 0.986\n",
            "Stats - Epoch: 86 AUC-val 0.592  AUC-train 0.986\n",
            "Stats - Epoch: 87 AUC-val 0.621  AUC-train 0.979\n",
            "Stats - Epoch: 88 AUC-val 0.648  AUC-train 0.986\n",
            "Stats - Epoch: 89 AUC-val 0.634  AUC-train 0.985\n",
            "Stats - Epoch: 90 AUC-val 0.659  AUC-train 0.984\n",
            "Stats - Epoch: 91 AUC-val 0.647  AUC-train 0.984\n",
            "Stats - Epoch: 92 AUC-val 0.591  AUC-train 0.983\n",
            "Stats - Epoch: 93 AUC-val 0.633  AUC-train 0.985\n",
            "Stats - Epoch: 94 AUC-val 0.654  AUC-train 0.984\n",
            "Stats - Epoch: 95 AUC-val 0.632  AUC-train 0.983\n",
            "Stats - Epoch: 96 AUC-val 0.658  AUC-train 0.984\n",
            "Stats - Epoch: 97 AUC-val 0.610  AUC-train 0.979\n",
            "Stats - Epoch: 98 AUC-val 0.625  AUC-train 0.979\n",
            "Stats - Epoch: 99 AUC-val 0.603  AUC-train 0.980\n",
            "Stats - Epoch: 100 AUC-val 0.596  AUC-train 0.978\n",
            "Results 100 AUC-val 0.659 0.743 0.666 0.516 0.581 AUC-train 0.984\n",
            "Shapley [0.01346727 0.01427145 0.01031938 0.01804658 0.00661513] [0.00516196]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.203306\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.324  AUC-train 0.499\n",
            "Stats - Epoch: 2 AUC-val 0.385  AUC-train 0.546\n",
            "Stats - Epoch: 3 AUC-val 0.425  AUC-train 0.599\n",
            "Stats - Epoch: 4 AUC-val 0.431  AUC-train 0.635\n",
            "Stats - Epoch: 5 AUC-val 0.446  AUC-train 0.663\n",
            "Stats - Epoch: 6 AUC-val 0.424  AUC-train 0.693\n",
            "Stats - Epoch: 7 AUC-val 0.433  AUC-train 0.709\n",
            "Stats - Epoch: 8 AUC-val 0.438  AUC-train 0.722\n",
            "Stats - Epoch: 9 AUC-val 0.437  AUC-train 0.736\n",
            "Stats - Epoch: 10 AUC-val 0.445  AUC-train 0.750\n",
            "Stats - Epoch: 11 AUC-val 0.446  AUC-train 0.757\n",
            "Stats - Epoch: 12 AUC-val 0.450  AUC-train 0.772\n",
            "Stats - Epoch: 13 AUC-val 0.451  AUC-train 0.776\n",
            "Stats - Epoch: 14 AUC-val 0.445  AUC-train 0.786\n",
            "Stats - Epoch: 15 AUC-val 0.446  AUC-train 0.796\n",
            "Stats - Epoch: 16 AUC-val 0.445  AUC-train 0.799\n",
            "Stats - Epoch: 17 AUC-val 0.449  AUC-train 0.801\n",
            "Stats - Epoch: 18 AUC-val 0.447  AUC-train 0.812\n",
            "Stats - Epoch: 19 AUC-val 0.445  AUC-train 0.815\n",
            "Stats - Epoch: 20 AUC-val 0.433  AUC-train 0.818\n",
            "Stats - Epoch: 21 AUC-val 0.443  AUC-train 0.824\n",
            "Stats - Epoch: 22 AUC-val 0.446  AUC-train 0.828\n",
            "Stats - Epoch: 23 AUC-val 0.451  AUC-train 0.832\n",
            "Stats - Epoch: 24 AUC-val 0.450  AUC-train 0.834\n",
            "Stats - Epoch: 25 AUC-val 0.453  AUC-train 0.835\n",
            "Stats - Epoch: 26 AUC-val 0.451  AUC-train 0.839\n",
            "Stats - Epoch: 27 AUC-val 0.461  AUC-train 0.842\n",
            "Stats - Epoch: 28 AUC-val 0.448  AUC-train 0.839\n",
            "Stats - Epoch: 29 AUC-val 0.466  AUC-train 0.839\n",
            "Stats - Epoch: 30 AUC-val 0.465  AUC-train 0.850\n",
            "Stats - Epoch: 31 AUC-val 0.460  AUC-train 0.851\n",
            "Stats - Epoch: 32 AUC-val 0.458  AUC-train 0.851\n",
            "Stats - Epoch: 33 AUC-val 0.463  AUC-train 0.851\n",
            "Stats - Epoch: 34 AUC-val 0.468  AUC-train 0.851\n",
            "Stats - Epoch: 35 AUC-val 0.473  AUC-train 0.850\n",
            "Stats - Epoch: 36 AUC-val 0.475  AUC-train 0.849\n",
            "Stats - Epoch: 37 AUC-val 0.467  AUC-train 0.853\n",
            "Stats - Epoch: 38 AUC-val 0.466  AUC-train 0.855\n",
            "Stats - Epoch: 39 AUC-val 0.472  AUC-train 0.858\n",
            "Stats - Epoch: 40 AUC-val 0.474  AUC-train 0.860\n",
            "Stats - Epoch: 41 AUC-val 0.470  AUC-train 0.861\n",
            "Stats - Epoch: 42 AUC-val 0.480  AUC-train 0.862\n",
            "Stats - Epoch: 43 AUC-val 0.483  AUC-train 0.854\n",
            "Stats - Epoch: 44 AUC-val 0.483  AUC-train 0.858\n",
            "Stats - Epoch: 45 AUC-val 0.470  AUC-train 0.863\n",
            "Stats - Epoch: 46 AUC-val 0.477  AUC-train 0.866\n",
            "Stats - Epoch: 47 AUC-val 0.479  AUC-train 0.861\n",
            "Stats - Epoch: 48 AUC-val 0.471  AUC-train 0.862\n",
            "Stats - Epoch: 49 AUC-val 0.484  AUC-train 0.861\n",
            "Stats - Epoch: 50 AUC-val 0.479  AUC-train 0.866\n",
            "Stats - Epoch: 51 AUC-val 0.479  AUC-train 0.868\n",
            "Stats - Epoch: 52 AUC-val 0.479  AUC-train 0.862\n",
            "Stats - Epoch: 53 AUC-val 0.485  AUC-train 0.869\n",
            "Stats - Epoch: 54 AUC-val 0.479  AUC-train 0.868\n",
            "Stats - Epoch: 55 AUC-val 0.480  AUC-train 0.868\n",
            "Stats - Epoch: 56 AUC-val 0.483  AUC-train 0.861\n",
            "Stats - Epoch: 57 AUC-val 0.483  AUC-train 0.870\n",
            "Stats - Epoch: 58 AUC-val 0.482  AUC-train 0.867\n",
            "Stats - Epoch: 59 AUC-val 0.484  AUC-train 0.867\n",
            "Stats - Epoch: 60 AUC-val 0.476  AUC-train 0.871\n",
            "Stats - Epoch: 61 AUC-val 0.484  AUC-train 0.872\n",
            "Stats - Epoch: 62 AUC-val 0.482  AUC-train 0.871\n",
            "Stats - Epoch: 63 AUC-val 0.496  AUC-train 0.872\n",
            "Stats - Epoch: 64 AUC-val 0.485  AUC-train 0.870\n",
            "Stats - Epoch: 65 AUC-val 0.484  AUC-train 0.872\n",
            "Stats - Epoch: 66 AUC-val 0.482  AUC-train 0.871\n",
            "Stats - Epoch: 67 AUC-val 0.484  AUC-train 0.875\n",
            "Stats - Epoch: 68 AUC-val 0.489  AUC-train 0.873\n",
            "Stats - Epoch: 69 AUC-val 0.483  AUC-train 0.875\n",
            "Stats - Epoch: 70 AUC-val 0.485  AUC-train 0.875\n",
            "Stats - Epoch: 71 AUC-val 0.485  AUC-train 0.876\n",
            "Stats - Epoch: 72 AUC-val 0.493  AUC-train 0.873\n",
            "Stats - Epoch: 73 AUC-val 0.485  AUC-train 0.871\n",
            "Stats - Epoch: 74 AUC-val 0.488  AUC-train 0.872\n",
            "Stats - Epoch: 75 AUC-val 0.489  AUC-train 0.877\n",
            "Stats - Epoch: 76 AUC-val 0.484  AUC-train 0.871\n",
            "Stats - Epoch: 77 AUC-val 0.491  AUC-train 0.875\n",
            "Stats - Epoch: 78 AUC-val 0.496  AUC-train 0.873\n",
            "Stats - Epoch: 79 AUC-val 0.489  AUC-train 0.873\n",
            "Stats - Epoch: 80 AUC-val 0.490  AUC-train 0.878\n",
            "Stats - Epoch: 81 AUC-val 0.490  AUC-train 0.878\n",
            "Stats - Epoch: 82 AUC-val 0.494  AUC-train 0.878\n",
            "Stats - Epoch: 83 AUC-val 0.492  AUC-train 0.878\n",
            "Stats - Epoch: 84 AUC-val 0.481  AUC-train 0.872\n",
            "Stats - Epoch: 85 AUC-val 0.486  AUC-train 0.878\n",
            "Stats - Epoch: 86 AUC-val 0.491  AUC-train 0.881\n",
            "Stats - Epoch: 87 AUC-val 0.486  AUC-train 0.881\n",
            "Stats - Epoch: 88 AUC-val 0.496  AUC-train 0.881\n",
            "Stats - Epoch: 89 AUC-val 0.490  AUC-train 0.881\n",
            "Stats - Epoch: 90 AUC-val 0.496  AUC-train 0.874\n",
            "Stats - Epoch: 91 AUC-val 0.490  AUC-train 0.877\n",
            "Stats - Epoch: 92 AUC-val 0.490  AUC-train 0.874\n",
            "Stats - Epoch: 93 AUC-val 0.488  AUC-train 0.876\n",
            "Stats - Epoch: 94 AUC-val 0.486  AUC-train 0.879\n",
            "Stats - Epoch: 95 AUC-val 0.492  AUC-train 0.874\n",
            "Stats - Epoch: 96 AUC-val 0.496  AUC-train 0.877\n",
            "Stats - Epoch: 97 AUC-val 0.490  AUC-train 0.881\n",
            "Stats - Epoch: 98 AUC-val 0.492  AUC-train 0.879\n",
            "Stats - Epoch: 99 AUC-val 0.501  AUC-train 0.876\n",
            "Stats - Epoch: 100 AUC-val 0.496  AUC-train 0.879\n",
            "Results 100 AUC-val 0.501 0.512 0.572 0.490 0.619 AUC-train 0.876\n",
            "Shapley [0.00731546 0.00759188 0.02048119 0.01213057 0.00436398] [0.01894648]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188619\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.159  AUC-train 0.512\n",
            "Stats - Epoch: 2 AUC-val 0.291  AUC-train 0.707\n",
            "Stats - Epoch: 3 AUC-val 0.311  AUC-train 0.800\n",
            "Stats - Epoch: 4 AUC-val 0.347  AUC-train 0.851\n",
            "Stats - Epoch: 5 AUC-val 0.330  AUC-train 0.889\n",
            "Stats - Epoch: 6 AUC-val 0.295  AUC-train 0.910\n",
            "Stats - Epoch: 7 AUC-val 0.313  AUC-train 0.931\n",
            "Stats - Epoch: 8 AUC-val 0.303  AUC-train 0.942\n",
            "Stats - Epoch: 9 AUC-val 0.299  AUC-train 0.948\n",
            "Stats - Epoch: 10 AUC-val 0.333  AUC-train 0.959\n",
            "Stats - Epoch: 11 AUC-val 0.329  AUC-train 0.964\n",
            "Stats - Epoch: 12 AUC-val 0.349  AUC-train 0.971\n",
            "Stats - Epoch: 13 AUC-val 0.352  AUC-train 0.973\n",
            "Stats - Epoch: 14 AUC-val 0.363  AUC-train 0.976\n",
            "Stats - Epoch: 15 AUC-val 0.357  AUC-train 0.979\n",
            "Stats - Epoch: 16 AUC-val 0.403  AUC-train 0.978\n",
            "Stats - Epoch: 17 AUC-val 0.369  AUC-train 0.979\n",
            "Stats - Epoch: 18 AUC-val 0.372  AUC-train 0.979\n",
            "Stats - Epoch: 19 AUC-val 0.400  AUC-train 0.982\n",
            "Stats - Epoch: 20 AUC-val 0.389  AUC-train 0.980\n",
            "Stats - Epoch: 21 AUC-val 0.397  AUC-train 0.983\n",
            "Stats - Epoch: 22 AUC-val 0.390  AUC-train 0.979\n",
            "Stats - Epoch: 23 AUC-val 0.389  AUC-train 0.983\n",
            "Stats - Epoch: 24 AUC-val 0.394  AUC-train 0.983\n",
            "Stats - Epoch: 25 AUC-val 0.410  AUC-train 0.981\n",
            "Stats - Epoch: 26 AUC-val 0.407  AUC-train 0.983\n",
            "Stats - Epoch: 27 AUC-val 0.437  AUC-train 0.983\n",
            "Stats - Epoch: 28 AUC-val 0.409  AUC-train 0.982\n",
            "Stats - Epoch: 29 AUC-val 0.417  AUC-train 0.980\n",
            "Stats - Epoch: 30 AUC-val 0.405  AUC-train 0.985\n",
            "Stats - Epoch: 31 AUC-val 0.414  AUC-train 0.986\n",
            "Stats - Epoch: 32 AUC-val 0.427  AUC-train 0.986\n",
            "Stats - Epoch: 33 AUC-val 0.392  AUC-train 0.987\n",
            "Stats - Epoch: 34 AUC-val 0.424  AUC-train 0.981\n",
            "Stats - Epoch: 35 AUC-val 0.432  AUC-train 0.983\n",
            "Stats - Epoch: 36 AUC-val 0.402  AUC-train 0.982\n",
            "Stats - Epoch: 37 AUC-val 0.421  AUC-train 0.983\n",
            "Stats - Epoch: 38 AUC-val 0.440  AUC-train 0.986\n",
            "Stats - Epoch: 39 AUC-val 0.440  AUC-train 0.984\n",
            "Stats - Epoch: 40 AUC-val 0.444  AUC-train 0.986\n",
            "Stats - Epoch: 41 AUC-val 0.440  AUC-train 0.984\n",
            "Stats - Epoch: 42 AUC-val 0.447  AUC-train 0.977\n",
            "Stats - Epoch: 43 AUC-val 0.452  AUC-train 0.981\n",
            "Stats - Epoch: 44 AUC-val 0.429  AUC-train 0.984\n",
            "Stats - Epoch: 45 AUC-val 0.429  AUC-train 0.983\n",
            "Stats - Epoch: 46 AUC-val 0.443  AUC-train 0.984\n",
            "Stats - Epoch: 47 AUC-val 0.426  AUC-train 0.984\n",
            "Stats - Epoch: 48 AUC-val 0.441  AUC-train 0.978\n",
            "Stats - Epoch: 49 AUC-val 0.444  AUC-train 0.979\n",
            "Stats - Epoch: 50 AUC-val 0.405  AUC-train 0.976\n",
            "Stats - Epoch: 51 AUC-val 0.427  AUC-train 0.978\n",
            "Stats - Epoch: 52 AUC-val 0.418  AUC-train 0.981\n",
            "Stats - Epoch: 53 AUC-val 0.439  AUC-train 0.982\n",
            "Stats - Epoch: 54 AUC-val 0.468  AUC-train 0.981\n",
            "Stats - Epoch: 55 AUC-val 0.487  AUC-train 0.979\n",
            "Stats - Epoch: 56 AUC-val 0.429  AUC-train 0.981\n",
            "Stats - Epoch: 57 AUC-val 0.450  AUC-train 0.977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.454  AUC-train 0.982\n",
            "Stats - Epoch: 59 AUC-val 0.433  AUC-train 0.975\n",
            "Stats - Epoch: 60 AUC-val 0.445  AUC-train 0.981\n",
            "Stats - Epoch: 61 AUC-val 0.462  AUC-train 0.980\n",
            "Stats - Epoch: 62 AUC-val 0.448  AUC-train 0.982\n",
            "Stats - Epoch: 63 AUC-val 0.483  AUC-train 0.984\n",
            "Stats - Epoch: 64 AUC-val 0.459  AUC-train 0.977\n",
            "Stats - Epoch: 65 AUC-val 0.474  AUC-train 0.981\n",
            "Stats - Epoch: 66 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 67 AUC-val 0.468  AUC-train 0.982\n",
            "Stats - Epoch: 68 AUC-val 0.467  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.475  AUC-train 0.983\n",
            "Stats - Epoch: 70 AUC-val 0.462  AUC-train 0.981\n",
            "Stats - Epoch: 71 AUC-val 0.463  AUC-train 0.979\n",
            "Stats - Epoch: 72 AUC-val 0.457  AUC-train 0.976\n",
            "Stats - Epoch: 73 AUC-val 0.470  AUC-train 0.980\n",
            "Stats - Epoch: 74 AUC-val 0.464  AUC-train 0.977\n",
            "Stats - Epoch: 75 AUC-val 0.463  AUC-train 0.977\n",
            "Stats - Epoch: 76 AUC-val 0.480  AUC-train 0.974\n",
            "Stats - Epoch: 77 AUC-val 0.472  AUC-train 0.980\n",
            "Stats - Epoch: 78 AUC-val 0.484  AUC-train 0.973\n",
            "Stats - Epoch: 79 AUC-val 0.452  AUC-train 0.979\n",
            "Stats - Epoch: 80 AUC-val 0.441  AUC-train 0.977\n",
            "Stats - Epoch: 81 AUC-val 0.451  AUC-train 0.980\n",
            "Stats - Epoch: 82 AUC-val 0.450  AUC-train 0.980\n",
            "Stats - Epoch: 83 AUC-val 0.455  AUC-train 0.980\n",
            "Stats - Epoch: 84 AUC-val 0.458  AUC-train 0.978\n",
            "Stats - Epoch: 85 AUC-val 0.453  AUC-train 0.979\n",
            "Stats - Epoch: 86 AUC-val 0.450  AUC-train 0.979\n",
            "Stats - Epoch: 87 AUC-val 0.461  AUC-train 0.981\n",
            "Stats - Epoch: 88 AUC-val 0.469  AUC-train 0.981\n",
            "Stats - Epoch: 89 AUC-val 0.444  AUC-train 0.977\n",
            "Stats - Epoch: 90 AUC-val 0.424  AUC-train 0.979\n",
            "Stats - Epoch: 91 AUC-val 0.464  AUC-train 0.980\n",
            "Stats - Epoch: 92 AUC-val 0.444  AUC-train 0.977\n",
            "Stats - Epoch: 93 AUC-val 0.448  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.430  AUC-train 0.979\n",
            "Stats - Epoch: 95 AUC-val 0.435  AUC-train 0.978\n",
            "Stats - Epoch: 96 AUC-val 0.445  AUC-train 0.978\n",
            "Stats - Epoch: 97 AUC-val 0.428  AUC-train 0.979\n",
            "Stats - Epoch: 98 AUC-val 0.445  AUC-train 0.980\n",
            "Stats - Epoch: 99 AUC-val 0.448  AUC-train 0.975\n",
            "Stats - Epoch: 100 AUC-val 0.460  AUC-train 0.977\n",
            "Results 100 AUC-val 0.487 0.454 0.303 0.154 0.500 AUC-train 0.979\n",
            "Shapley [0.02813471 0.00964834 0.01021602 0.04220958 0.01234469] [0.04081353]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.183027\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.215  AUC-train 0.613\n",
            "Stats - Epoch: 2 AUC-val 0.205  AUC-train 0.616\n",
            "Stats - Epoch: 3 AUC-val 0.198  AUC-train 0.654\n",
            "Stats - Epoch: 4 AUC-val 0.214  AUC-train 0.702\n",
            "Stats - Epoch: 5 AUC-val 0.251  AUC-train 0.741\n",
            "Stats - Epoch: 6 AUC-val 0.319  AUC-train 0.770\n",
            "Stats - Epoch: 7 AUC-val 0.395  AUC-train 0.785\n",
            "Stats - Epoch: 8 AUC-val 0.453  AUC-train 0.797\n",
            "Stats - Epoch: 9 AUC-val 0.429  AUC-train 0.809\n",
            "Stats - Epoch: 10 AUC-val 0.466  AUC-train 0.819\n",
            "Stats - Epoch: 11 AUC-val 0.484  AUC-train 0.822\n",
            "Stats - Epoch: 12 AUC-val 0.471  AUC-train 0.834\n",
            "Stats - Epoch: 13 AUC-val 0.467  AUC-train 0.837\n",
            "Stats - Epoch: 14 AUC-val 0.489  AUC-train 0.845\n",
            "Stats - Epoch: 15 AUC-val 0.526  AUC-train 0.848\n",
            "Stats - Epoch: 16 AUC-val 0.522  AUC-train 0.848\n",
            "Stats - Epoch: 17 AUC-val 0.579  AUC-train 0.847\n",
            "Stats - Epoch: 18 AUC-val 0.535  AUC-train 0.852\n",
            "Stats - Epoch: 19 AUC-val 0.513  AUC-train 0.855\n",
            "Stats - Epoch: 20 AUC-val 0.525  AUC-train 0.857\n",
            "Stats - Epoch: 21 AUC-val 0.554  AUC-train 0.859\n",
            "Stats - Epoch: 22 AUC-val 0.552  AUC-train 0.861\n",
            "Stats - Epoch: 23 AUC-val 0.564  AUC-train 0.862\n",
            "Stats - Epoch: 24 AUC-val 0.547  AUC-train 0.864\n",
            "Stats - Epoch: 25 AUC-val 0.559  AUC-train 0.865\n",
            "Stats - Epoch: 26 AUC-val 0.560  AUC-train 0.867\n",
            "Stats - Epoch: 27 AUC-val 0.569  AUC-train 0.868\n",
            "Stats - Epoch: 28 AUC-val 0.542  AUC-train 0.870\n",
            "Stats - Epoch: 29 AUC-val 0.543  AUC-train 0.871\n",
            "Stats - Epoch: 30 AUC-val 0.581  AUC-train 0.870\n",
            "Stats - Epoch: 31 AUC-val 0.582  AUC-train 0.870\n",
            "Stats - Epoch: 32 AUC-val 0.567  AUC-train 0.876\n",
            "Stats - Epoch: 33 AUC-val 0.551  AUC-train 0.879\n",
            "Stats - Epoch: 34 AUC-val 0.569  AUC-train 0.875\n",
            "Stats - Epoch: 35 AUC-val 0.599  AUC-train 0.877\n",
            "Stats - Epoch: 36 AUC-val 0.580  AUC-train 0.876\n",
            "Stats - Epoch: 37 AUC-val 0.591  AUC-train 0.883\n",
            "Stats - Epoch: 38 AUC-val 0.600  AUC-train 0.880\n",
            "Stats - Epoch: 39 AUC-val 0.571  AUC-train 0.887\n",
            "Stats - Epoch: 40 AUC-val 0.583  AUC-train 0.881\n",
            "Stats - Epoch: 41 AUC-val 0.600  AUC-train 0.883\n",
            "Stats - Epoch: 42 AUC-val 0.590  AUC-train 0.884\n",
            "Stats - Epoch: 43 AUC-val 0.555  AUC-train 0.883\n",
            "Stats - Epoch: 44 AUC-val 0.600  AUC-train 0.885\n",
            "Stats - Epoch: 45 AUC-val 0.579  AUC-train 0.890\n",
            "Stats - Epoch: 46 AUC-val 0.586  AUC-train 0.887\n",
            "Stats - Epoch: 47 AUC-val 0.583  AUC-train 0.893\n",
            "Stats - Epoch: 48 AUC-val 0.588  AUC-train 0.893\n",
            "Stats - Epoch: 49 AUC-val 0.592  AUC-train 0.895\n",
            "Stats - Epoch: 50 AUC-val 0.583  AUC-train 0.890\n",
            "Stats - Epoch: 51 AUC-val 0.607  AUC-train 0.887\n",
            "Stats - Epoch: 52 AUC-val 0.590  AUC-train 0.891\n",
            "Stats - Epoch: 53 AUC-val 0.600  AUC-train 0.890\n",
            "Stats - Epoch: 54 AUC-val 0.592  AUC-train 0.893\n",
            "Stats - Epoch: 55 AUC-val 0.616  AUC-train 0.895\n",
            "Stats - Epoch: 56 AUC-val 0.591  AUC-train 0.897\n",
            "Stats - Epoch: 57 AUC-val 0.572  AUC-train 0.893\n",
            "Stats - Epoch: 58 AUC-val 0.593  AUC-train 0.897\n",
            "Stats - Epoch: 59 AUC-val 0.578  AUC-train 0.899\n",
            "Stats - Epoch: 60 AUC-val 0.601  AUC-train 0.899\n",
            "Stats - Epoch: 61 AUC-val 0.587  AUC-train 0.904\n",
            "Stats - Epoch: 62 AUC-val 0.597  AUC-train 0.903\n",
            "Stats - Epoch: 63 AUC-val 0.589  AUC-train 0.905\n",
            "Stats - Epoch: 64 AUC-val 0.607  AUC-train 0.903\n",
            "Stats - Epoch: 65 AUC-val 0.598  AUC-train 0.900\n",
            "Stats - Epoch: 66 AUC-val 0.607  AUC-train 0.901\n",
            "Stats - Epoch: 67 AUC-val 0.584  AUC-train 0.905\n",
            "Stats - Epoch: 68 AUC-val 0.588  AUC-train 0.901\n",
            "Stats - Epoch: 69 AUC-val 0.580  AUC-train 0.902\n",
            "Stats - Epoch: 70 AUC-val 0.555  AUC-train 0.903\n",
            "Stats - Epoch: 71 AUC-val 0.584  AUC-train 0.905\n",
            "Stats - Epoch: 72 AUC-val 0.578  AUC-train 0.905\n",
            "Stats - Epoch: 73 AUC-val 0.575  AUC-train 0.901\n",
            "Stats - Epoch: 74 AUC-val 0.573  AUC-train 0.905\n",
            "Stats - Epoch: 75 AUC-val 0.593  AUC-train 0.904\n",
            "Stats - Epoch: 76 AUC-val 0.585  AUC-train 0.900\n",
            "Stats - Epoch: 77 AUC-val 0.586  AUC-train 0.903\n",
            "Stats - Epoch: 78 AUC-val 0.600  AUC-train 0.899\n",
            "Stats - Epoch: 79 AUC-val 0.594  AUC-train 0.907\n",
            "Stats - Epoch: 80 AUC-val 0.592  AUC-train 0.907\n",
            "Stats - Epoch: 81 AUC-val 0.622  AUC-train 0.912\n",
            "Stats - Epoch: 82 AUC-val 0.632  AUC-train 0.913\n",
            "Stats - Epoch: 83 AUC-val 0.619  AUC-train 0.915\n",
            "Stats - Epoch: 84 AUC-val 0.592  AUC-train 0.905\n",
            "Stats - Epoch: 85 AUC-val 0.594  AUC-train 0.909\n",
            "Stats - Epoch: 86 AUC-val 0.620  AUC-train 0.911\n",
            "Stats - Epoch: 87 AUC-val 0.598  AUC-train 0.913\n",
            "Stats - Epoch: 88 AUC-val 0.629  AUC-train 0.912\n",
            "Stats - Epoch: 89 AUC-val 0.649  AUC-train 0.909\n",
            "Stats - Epoch: 90 AUC-val 0.629  AUC-train 0.909\n",
            "Stats - Epoch: 91 AUC-val 0.667  AUC-train 0.906\n",
            "Stats - Epoch: 92 AUC-val 0.589  AUC-train 0.910\n",
            "Stats - Epoch: 93 AUC-val 0.643  AUC-train 0.912\n",
            "Stats - Epoch: 94 AUC-val 0.597  AUC-train 0.909\n",
            "Stats - Epoch: 95 AUC-val 0.642  AUC-train 0.906\n",
            "Stats - Epoch: 96 AUC-val 0.667  AUC-train 0.907\n",
            "Stats - Epoch: 97 AUC-val 0.690  AUC-train 0.910\n",
            "Stats - Epoch: 98 AUC-val 0.624  AUC-train 0.906\n",
            "Stats - Epoch: 99 AUC-val 0.600  AUC-train 0.909\n",
            "Stats - Epoch: 100 AUC-val 0.569  AUC-train 0.912\n",
            "Results 100 AUC-val 0.690 0.648 0.624 0.563 0.717 AUC-train 0.910\n",
            "Shapley [0.01615404 0.01387484 0.01521065 0.01213471 0.00406675] [0.00579123]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.193249\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.350  AUC-train 0.555\n",
            "Stats - Epoch: 2 AUC-val 0.465  AUC-train 0.698\n",
            "Stats - Epoch: 3 AUC-val 0.586  AUC-train 0.790\n",
            "Stats - Epoch: 4 AUC-val 0.637  AUC-train 0.827\n",
            "Stats - Epoch: 5 AUC-val 0.659  AUC-train 0.848\n",
            "Stats - Epoch: 6 AUC-val 0.680  AUC-train 0.866\n",
            "Stats - Epoch: 7 AUC-val 0.700  AUC-train 0.879\n",
            "Stats - Epoch: 8 AUC-val 0.704  AUC-train 0.891\n",
            "Stats - Epoch: 9 AUC-val 0.729  AUC-train 0.900\n",
            "Stats - Epoch: 10 AUC-val 0.737  AUC-train 0.911\n",
            "Stats - Epoch: 11 AUC-val 0.733  AUC-train 0.915\n",
            "Stats - Epoch: 12 AUC-val 0.740  AUC-train 0.923\n",
            "Stats - Epoch: 13 AUC-val 0.743  AUC-train 0.931\n",
            "Stats - Epoch: 14 AUC-val 0.744  AUC-train 0.937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.742  AUC-train 0.940\n",
            "Stats - Epoch: 16 AUC-val 0.740  AUC-train 0.947\n",
            "Stats - Epoch: 17 AUC-val 0.727  AUC-train 0.949\n",
            "Stats - Epoch: 18 AUC-val 0.751  AUC-train 0.954\n",
            "Stats - Epoch: 19 AUC-val 0.757  AUC-train 0.956\n",
            "Stats - Epoch: 20 AUC-val 0.747  AUC-train 0.960\n",
            "Stats - Epoch: 21 AUC-val 0.752  AUC-train 0.962\n",
            "Stats - Epoch: 22 AUC-val 0.733  AUC-train 0.964\n",
            "Stats - Epoch: 23 AUC-val 0.743  AUC-train 0.967\n",
            "Stats - Epoch: 24 AUC-val 0.740  AUC-train 0.968\n",
            "Stats - Epoch: 25 AUC-val 0.743  AUC-train 0.968\n",
            "Stats - Epoch: 26 AUC-val 0.768  AUC-train 0.969\n",
            "Stats - Epoch: 27 AUC-val 0.742  AUC-train 0.972\n",
            "Stats - Epoch: 28 AUC-val 0.738  AUC-train 0.973\n",
            "Stats - Epoch: 29 AUC-val 0.753  AUC-train 0.975\n",
            "Stats - Epoch: 30 AUC-val 0.741  AUC-train 0.977\n",
            "Stats - Epoch: 31 AUC-val 0.741  AUC-train 0.978\n",
            "Stats - Epoch: 32 AUC-val 0.741  AUC-train 0.979\n",
            "Stats - Epoch: 33 AUC-val 0.727  AUC-train 0.979\n",
            "Stats - Epoch: 34 AUC-val 0.739  AUC-train 0.980\n",
            "Stats - Epoch: 35 AUC-val 0.727  AUC-train 0.982\n",
            "Stats - Epoch: 36 AUC-val 0.723  AUC-train 0.981\n",
            "Stats - Epoch: 37 AUC-val 0.739  AUC-train 0.982\n",
            "Stats - Epoch: 38 AUC-val 0.737  AUC-train 0.983\n",
            "Stats - Epoch: 39 AUC-val 0.736  AUC-train 0.984\n",
            "Stats - Epoch: 40 AUC-val 0.723  AUC-train 0.979\n",
            "Stats - Epoch: 41 AUC-val 0.733  AUC-train 0.983\n",
            "Stats - Epoch: 42 AUC-val 0.756  AUC-train 0.984\n",
            "Stats - Epoch: 43 AUC-val 0.709  AUC-train 0.987\n",
            "Stats - Epoch: 44 AUC-val 0.720  AUC-train 0.985\n",
            "Stats - Epoch: 45 AUC-val 0.717  AUC-train 0.987\n",
            "Stats - Epoch: 46 AUC-val 0.725  AUC-train 0.985\n",
            "Stats - Epoch: 47 AUC-val 0.739  AUC-train 0.987\n",
            "Stats - Epoch: 48 AUC-val 0.744  AUC-train 0.987\n",
            "Stats - Epoch: 49 AUC-val 0.738  AUC-train 0.983\n",
            "Stats - Epoch: 50 AUC-val 0.714  AUC-train 0.986\n",
            "Stats - Epoch: 51 AUC-val 0.729  AUC-train 0.987\n",
            "Stats - Epoch: 52 AUC-val 0.740  AUC-train 0.987\n",
            "Stats - Epoch: 53 AUC-val 0.734  AUC-train 0.986\n",
            "Stats - Epoch: 54 AUC-val 0.737  AUC-train 0.986\n",
            "Stats - Epoch: 55 AUC-val 0.723  AUC-train 0.989\n",
            "Stats - Epoch: 56 AUC-val 0.721  AUC-train 0.989\n",
            "Stats - Epoch: 57 AUC-val 0.707  AUC-train 0.989\n",
            "Stats - Epoch: 58 AUC-val 0.715  AUC-train 0.990\n",
            "Stats - Epoch: 59 AUC-val 0.727  AUC-train 0.990\n",
            "Stats - Epoch: 60 AUC-val 0.715  AUC-train 0.991\n",
            "Stats - Epoch: 61 AUC-val 0.721  AUC-train 0.991\n",
            "Stats - Epoch: 62 AUC-val 0.727  AUC-train 0.992\n",
            "Stats - Epoch: 63 AUC-val 0.736  AUC-train 0.991\n",
            "Stats - Epoch: 64 AUC-val 0.710  AUC-train 0.989\n",
            "Stats - Epoch: 65 AUC-val 0.721  AUC-train 0.991\n",
            "Stats - Epoch: 66 AUC-val 0.710  AUC-train 0.992\n",
            "Stats - Epoch: 67 AUC-val 0.712  AUC-train 0.992\n",
            "Stats - Epoch: 68 AUC-val 0.702  AUC-train 0.991\n",
            "Stats - Epoch: 69 AUC-val 0.691  AUC-train 0.991\n",
            "Stats - Epoch: 70 AUC-val 0.708  AUC-train 0.991\n",
            "Stats - Epoch: 71 AUC-val 0.689  AUC-train 0.990\n",
            "Stats - Epoch: 72 AUC-val 0.686  AUC-train 0.988\n",
            "Stats - Epoch: 73 AUC-val 0.696  AUC-train 0.990\n",
            "Stats - Epoch: 74 AUC-val 0.714  AUC-train 0.988\n",
            "Stats - Epoch: 75 AUC-val 0.728  AUC-train 0.990\n",
            "Stats - Epoch: 76 AUC-val 0.713  AUC-train 0.991\n",
            "Stats - Epoch: 77 AUC-val 0.693  AUC-train 0.992\n",
            "Stats - Epoch: 78 AUC-val 0.719  AUC-train 0.993\n",
            "Stats - Epoch: 79 AUC-val 0.690  AUC-train 0.993\n",
            "Stats - Epoch: 80 AUC-val 0.698  AUC-train 0.993\n",
            "Stats - Epoch: 81 AUC-val 0.715  AUC-train 0.993\n",
            "Stats - Epoch: 82 AUC-val 0.703  AUC-train 0.994\n",
            "Stats - Epoch: 83 AUC-val 0.700  AUC-train 0.993\n",
            "Stats - Epoch: 84 AUC-val 0.713  AUC-train 0.994\n",
            "Stats - Epoch: 85 AUC-val 0.688  AUC-train 0.994\n",
            "Stats - Epoch: 86 AUC-val 0.700  AUC-train 0.994\n",
            "Stats - Epoch: 87 AUC-val 0.726  AUC-train 0.995\n",
            "Stats - Epoch: 88 AUC-val 0.700  AUC-train 0.994\n",
            "Stats - Epoch: 89 AUC-val 0.685  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.697  AUC-train 0.994\n",
            "Stats - Epoch: 91 AUC-val 0.687  AUC-train 0.991\n",
            "Stats - Epoch: 92 AUC-val 0.702  AUC-train 0.992\n",
            "Stats - Epoch: 93 AUC-val 0.688  AUC-train 0.990\n",
            "Stats - Epoch: 94 AUC-val 0.673  AUC-train 0.990\n",
            "Stats - Epoch: 95 AUC-val 0.668  AUC-train 0.991\n",
            "Stats - Epoch: 96 AUC-val 0.690  AUC-train 0.992\n",
            "Stats - Epoch: 97 AUC-val 0.697  AUC-train 0.993\n",
            "Stats - Epoch: 98 AUC-val 0.722  AUC-train 0.993\n",
            "Stats - Epoch: 99 AUC-val 0.699  AUC-train 0.994\n",
            "Stats - Epoch: 100 AUC-val 0.715  AUC-train 0.993\n",
            "Results 100 AUC-val 0.768 0.643 0.501 0.446 0.532 AUC-train 0.969\n",
            "Shapley [0.01698863 0.01618126 0.01292951 0.02741045 0.01256894] [0.0139546]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198440\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.569  AUC-train 0.504\n",
            "Stats - Epoch: 2 AUC-val 0.605  AUC-train 0.623\n",
            "Stats - Epoch: 3 AUC-val 0.619  AUC-train 0.714\n",
            "Stats - Epoch: 4 AUC-val 0.619  AUC-train 0.763\n",
            "Stats - Epoch: 5 AUC-val 0.609  AUC-train 0.802\n",
            "Stats - Epoch: 6 AUC-val 0.613  AUC-train 0.824\n",
            "Stats - Epoch: 7 AUC-val 0.621  AUC-train 0.842\n",
            "Stats - Epoch: 8 AUC-val 0.619  AUC-train 0.857\n",
            "Stats - Epoch: 9 AUC-val 0.603  AUC-train 0.868\n",
            "Stats - Epoch: 10 AUC-val 0.623  AUC-train 0.875\n",
            "Stats - Epoch: 11 AUC-val 0.616  AUC-train 0.889\n",
            "Stats - Epoch: 12 AUC-val 0.609  AUC-train 0.894\n",
            "Stats - Epoch: 13 AUC-val 0.624  AUC-train 0.902\n",
            "Stats - Epoch: 14 AUC-val 0.585  AUC-train 0.910\n",
            "Stats - Epoch: 15 AUC-val 0.568  AUC-train 0.913\n",
            "Stats - Epoch: 16 AUC-val 0.593  AUC-train 0.922\n",
            "Stats - Epoch: 17 AUC-val 0.614  AUC-train 0.929\n",
            "Stats - Epoch: 18 AUC-val 0.609  AUC-train 0.933\n",
            "Stats - Epoch: 19 AUC-val 0.614  AUC-train 0.935\n",
            "Stats - Epoch: 20 AUC-val 0.596  AUC-train 0.941\n",
            "Stats - Epoch: 21 AUC-val 0.591  AUC-train 0.945\n",
            "Stats - Epoch: 22 AUC-val 0.631  AUC-train 0.950\n",
            "Stats - Epoch: 23 AUC-val 0.579  AUC-train 0.953\n",
            "Stats - Epoch: 24 AUC-val 0.603  AUC-train 0.958\n",
            "Stats - Epoch: 25 AUC-val 0.630  AUC-train 0.958\n",
            "Stats - Epoch: 26 AUC-val 0.634  AUC-train 0.959\n",
            "Stats - Epoch: 27 AUC-val 0.571  AUC-train 0.963\n",
            "Stats - Epoch: 28 AUC-val 0.587  AUC-train 0.962\n",
            "Stats - Epoch: 29 AUC-val 0.659  AUC-train 0.964\n",
            "Stats - Epoch: 30 AUC-val 0.649  AUC-train 0.967\n",
            "Stats - Epoch: 31 AUC-val 0.651  AUC-train 0.968\n",
            "Stats - Epoch: 32 AUC-val 0.672  AUC-train 0.970\n",
            "Stats - Epoch: 33 AUC-val 0.600  AUC-train 0.970\n",
            "Stats - Epoch: 34 AUC-val 0.656  AUC-train 0.973\n",
            "Stats - Epoch: 35 AUC-val 0.651  AUC-train 0.973\n",
            "Stats - Epoch: 36 AUC-val 0.645  AUC-train 0.975\n",
            "Stats - Epoch: 37 AUC-val 0.640  AUC-train 0.976\n",
            "Stats - Epoch: 38 AUC-val 0.602  AUC-train 0.975\n",
            "Stats - Epoch: 39 AUC-val 0.591  AUC-train 0.975\n",
            "Stats - Epoch: 40 AUC-val 0.593  AUC-train 0.978\n",
            "Stats - Epoch: 41 AUC-val 0.614  AUC-train 0.978\n",
            "Stats - Epoch: 42 AUC-val 0.646  AUC-train 0.978\n",
            "Stats - Epoch: 43 AUC-val 0.616  AUC-train 0.975\n",
            "Stats - Epoch: 44 AUC-val 0.618  AUC-train 0.981\n",
            "Stats - Epoch: 45 AUC-val 0.647  AUC-train 0.980\n",
            "Stats - Epoch: 46 AUC-val 0.673  AUC-train 0.978\n",
            "Stats - Epoch: 47 AUC-val 0.641  AUC-train 0.981\n",
            "Stats - Epoch: 48 AUC-val 0.676  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.670  AUC-train 0.980\n",
            "Stats - Epoch: 50 AUC-val 0.618  AUC-train 0.983\n",
            "Stats - Epoch: 51 AUC-val 0.605  AUC-train 0.982\n",
            "Stats - Epoch: 52 AUC-val 0.615  AUC-train 0.982\n",
            "Stats - Epoch: 53 AUC-val 0.609  AUC-train 0.983\n",
            "Stats - Epoch: 54 AUC-val 0.649  AUC-train 0.982\n",
            "Stats - Epoch: 55 AUC-val 0.612  AUC-train 0.985\n",
            "Stats - Epoch: 56 AUC-val 0.644  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.638  AUC-train 0.985\n",
            "Stats - Epoch: 58 AUC-val 0.626  AUC-train 0.986\n",
            "Stats - Epoch: 59 AUC-val 0.613  AUC-train 0.984\n",
            "Stats - Epoch: 60 AUC-val 0.642  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.582  AUC-train 0.984\n",
            "Stats - Epoch: 62 AUC-val 0.593  AUC-train 0.984\n",
            "Stats - Epoch: 63 AUC-val 0.624  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.609  AUC-train 0.987\n",
            "Stats - Epoch: 65 AUC-val 0.660  AUC-train 0.989\n",
            "Stats - Epoch: 66 AUC-val 0.639  AUC-train 0.987\n",
            "Stats - Epoch: 67 AUC-val 0.623  AUC-train 0.989\n",
            "Stats - Epoch: 68 AUC-val 0.654  AUC-train 0.990\n",
            "Stats - Epoch: 69 AUC-val 0.662  AUC-train 0.991\n",
            "Stats - Epoch: 70 AUC-val 0.684  AUC-train 0.990\n",
            "Stats - Epoch: 71 AUC-val 0.643  AUC-train 0.991\n",
            "Stats - Epoch: 72 AUC-val 0.683  AUC-train 0.990\n",
            "Stats - Epoch: 73 AUC-val 0.671  AUC-train 0.989\n",
            "Stats - Epoch: 74 AUC-val 0.653  AUC-train 0.988\n",
            "Stats - Epoch: 75 AUC-val 0.679  AUC-train 0.991\n",
            "Stats - Epoch: 76 AUC-val 0.660  AUC-train 0.988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.648  AUC-train 0.988\n",
            "Stats - Epoch: 78 AUC-val 0.672  AUC-train 0.989\n",
            "Stats - Epoch: 79 AUC-val 0.660  AUC-train 0.990\n",
            "Stats - Epoch: 80 AUC-val 0.643  AUC-train 0.992\n",
            "Stats - Epoch: 81 AUC-val 0.667  AUC-train 0.993\n",
            "Stats - Epoch: 82 AUC-val 0.669  AUC-train 0.992\n",
            "Stats - Epoch: 83 AUC-val 0.698  AUC-train 0.993\n",
            "Stats - Epoch: 84 AUC-val 0.679  AUC-train 0.987\n",
            "Stats - Epoch: 85 AUC-val 0.698  AUC-train 0.989\n",
            "Stats - Epoch: 86 AUC-val 0.683  AUC-train 0.988\n",
            "Stats - Epoch: 87 AUC-val 0.702  AUC-train 0.992\n",
            "Stats - Epoch: 88 AUC-val 0.683  AUC-train 0.991\n",
            "Stats - Epoch: 89 AUC-val 0.693  AUC-train 0.992\n",
            "Stats - Epoch: 90 AUC-val 0.678  AUC-train 0.992\n",
            "Stats - Epoch: 91 AUC-val 0.682  AUC-train 0.992\n",
            "Stats - Epoch: 92 AUC-val 0.686  AUC-train 0.994\n",
            "Stats - Epoch: 93 AUC-val 0.694  AUC-train 0.993\n",
            "Stats - Epoch: 94 AUC-val 0.673  AUC-train 0.989\n",
            "Stats - Epoch: 95 AUC-val 0.682  AUC-train 0.992\n",
            "Stats - Epoch: 96 AUC-val 0.656  AUC-train 0.991\n",
            "Stats - Epoch: 97 AUC-val 0.691  AUC-train 0.993\n",
            "Stats - Epoch: 98 AUC-val 0.693  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.679  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.682  AUC-train 0.989\n",
            "Results 100 AUC-val 0.702 0.773 0.706 0.503 0.622 AUC-train 0.992\n",
            "Shapley [0.01331399 0.01469227 0.00962091 0.0188589  0.00618372] [0.00421324]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198681\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.267  AUC-train 0.514\n",
            "Stats - Epoch: 2 AUC-val 0.324  AUC-train 0.557\n",
            "Stats - Epoch: 3 AUC-val 0.361  AUC-train 0.602\n",
            "Stats - Epoch: 4 AUC-val 0.372  AUC-train 0.633\n",
            "Stats - Epoch: 5 AUC-val 0.397  AUC-train 0.664\n",
            "Stats - Epoch: 6 AUC-val 0.407  AUC-train 0.694\n",
            "Stats - Epoch: 7 AUC-val 0.412  AUC-train 0.711\n",
            "Stats - Epoch: 8 AUC-val 0.414  AUC-train 0.729\n",
            "Stats - Epoch: 9 AUC-val 0.422  AUC-train 0.750\n",
            "Stats - Epoch: 10 AUC-val 0.426  AUC-train 0.762\n",
            "Stats - Epoch: 11 AUC-val 0.434  AUC-train 0.770\n",
            "Stats - Epoch: 12 AUC-val 0.431  AUC-train 0.784\n",
            "Stats - Epoch: 13 AUC-val 0.433  AUC-train 0.789\n",
            "Stats - Epoch: 14 AUC-val 0.429  AUC-train 0.793\n",
            "Stats - Epoch: 15 AUC-val 0.432  AUC-train 0.804\n",
            "Stats - Epoch: 16 AUC-val 0.435  AUC-train 0.808\n",
            "Stats - Epoch: 17 AUC-val 0.450  AUC-train 0.811\n",
            "Stats - Epoch: 18 AUC-val 0.441  AUC-train 0.826\n",
            "Stats - Epoch: 19 AUC-val 0.448  AUC-train 0.827\n",
            "Stats - Epoch: 20 AUC-val 0.449  AUC-train 0.829\n",
            "Stats - Epoch: 21 AUC-val 0.444  AUC-train 0.833\n",
            "Stats - Epoch: 22 AUC-val 0.444  AUC-train 0.840\n",
            "Stats - Epoch: 23 AUC-val 0.458  AUC-train 0.842\n",
            "Stats - Epoch: 24 AUC-val 0.459  AUC-train 0.840\n",
            "Stats - Epoch: 25 AUC-val 0.451  AUC-train 0.843\n",
            "Stats - Epoch: 26 AUC-val 0.452  AUC-train 0.844\n",
            "Stats - Epoch: 27 AUC-val 0.463  AUC-train 0.845\n",
            "Stats - Epoch: 28 AUC-val 0.459  AUC-train 0.850\n",
            "Stats - Epoch: 29 AUC-val 0.466  AUC-train 0.848\n",
            "Stats - Epoch: 30 AUC-val 0.462  AUC-train 0.858\n",
            "Stats - Epoch: 31 AUC-val 0.458  AUC-train 0.857\n",
            "Stats - Epoch: 32 AUC-val 0.458  AUC-train 0.855\n",
            "Stats - Epoch: 33 AUC-val 0.466  AUC-train 0.860\n",
            "Stats - Epoch: 34 AUC-val 0.463  AUC-train 0.856\n",
            "Stats - Epoch: 35 AUC-val 0.474  AUC-train 0.856\n",
            "Stats - Epoch: 36 AUC-val 0.470  AUC-train 0.858\n",
            "Stats - Epoch: 37 AUC-val 0.469  AUC-train 0.862\n",
            "Stats - Epoch: 38 AUC-val 0.475  AUC-train 0.865\n",
            "Stats - Epoch: 39 AUC-val 0.460  AUC-train 0.862\n",
            "Stats - Epoch: 40 AUC-val 0.479  AUC-train 0.866\n",
            "Stats - Epoch: 41 AUC-val 0.481  AUC-train 0.869\n",
            "Stats - Epoch: 42 AUC-val 0.471  AUC-train 0.867\n",
            "Stats - Epoch: 43 AUC-val 0.481  AUC-train 0.860\n",
            "Stats - Epoch: 44 AUC-val 0.478  AUC-train 0.863\n",
            "Stats - Epoch: 45 AUC-val 0.476  AUC-train 0.865\n",
            "Stats - Epoch: 46 AUC-val 0.468  AUC-train 0.869\n",
            "Stats - Epoch: 47 AUC-val 0.483  AUC-train 0.871\n",
            "Stats - Epoch: 48 AUC-val 0.475  AUC-train 0.867\n",
            "Stats - Epoch: 49 AUC-val 0.467  AUC-train 0.870\n",
            "Stats - Epoch: 50 AUC-val 0.474  AUC-train 0.869\n",
            "Stats - Epoch: 51 AUC-val 0.474  AUC-train 0.869\n",
            "Stats - Epoch: 52 AUC-val 0.472  AUC-train 0.865\n",
            "Stats - Epoch: 53 AUC-val 0.485  AUC-train 0.873\n",
            "Stats - Epoch: 54 AUC-val 0.470  AUC-train 0.874\n",
            "Stats - Epoch: 55 AUC-val 0.478  AUC-train 0.874\n",
            "Stats - Epoch: 56 AUC-val 0.475  AUC-train 0.869\n",
            "Stats - Epoch: 57 AUC-val 0.472  AUC-train 0.876\n",
            "Stats - Epoch: 58 AUC-val 0.475  AUC-train 0.872\n",
            "Stats - Epoch: 59 AUC-val 0.477  AUC-train 0.872\n",
            "Stats - Epoch: 60 AUC-val 0.478  AUC-train 0.877\n",
            "Stats - Epoch: 61 AUC-val 0.470  AUC-train 0.879\n",
            "Stats - Epoch: 62 AUC-val 0.475  AUC-train 0.878\n",
            "Stats - Epoch: 63 AUC-val 0.480  AUC-train 0.881\n",
            "Stats - Epoch: 64 AUC-val 0.464  AUC-train 0.876\n",
            "Stats - Epoch: 65 AUC-val 0.485  AUC-train 0.879\n",
            "Stats - Epoch: 66 AUC-val 0.470  AUC-train 0.876\n",
            "Stats - Epoch: 67 AUC-val 0.476  AUC-train 0.878\n",
            "Stats - Epoch: 68 AUC-val 0.482  AUC-train 0.881\n",
            "Stats - Epoch: 69 AUC-val 0.475  AUC-train 0.882\n",
            "Stats - Epoch: 70 AUC-val 0.472  AUC-train 0.878\n",
            "Stats - Epoch: 71 AUC-val 0.482  AUC-train 0.880\n",
            "Stats - Epoch: 72 AUC-val 0.482  AUC-train 0.878\n",
            "Stats - Epoch: 73 AUC-val 0.476  AUC-train 0.876\n",
            "Stats - Epoch: 74 AUC-val 0.481  AUC-train 0.879\n",
            "Stats - Epoch: 75 AUC-val 0.484  AUC-train 0.882\n",
            "Stats - Epoch: 76 AUC-val 0.481  AUC-train 0.878\n",
            "Stats - Epoch: 77 AUC-val 0.489  AUC-train 0.879\n",
            "Stats - Epoch: 78 AUC-val 0.481  AUC-train 0.881\n",
            "Stats - Epoch: 79 AUC-val 0.479  AUC-train 0.880\n",
            "Stats - Epoch: 80 AUC-val 0.484  AUC-train 0.884\n",
            "Stats - Epoch: 81 AUC-val 0.474  AUC-train 0.885\n",
            "Stats - Epoch: 82 AUC-val 0.476  AUC-train 0.884\n",
            "Stats - Epoch: 83 AUC-val 0.479  AUC-train 0.886\n",
            "Stats - Epoch: 84 AUC-val 0.474  AUC-train 0.880\n",
            "Stats - Epoch: 85 AUC-val 0.482  AUC-train 0.882\n",
            "Stats - Epoch: 86 AUC-val 0.484  AUC-train 0.882\n",
            "Stats - Epoch: 87 AUC-val 0.483  AUC-train 0.882\n",
            "Stats - Epoch: 88 AUC-val 0.477  AUC-train 0.884\n",
            "Stats - Epoch: 89 AUC-val 0.483  AUC-train 0.884\n",
            "Stats - Epoch: 90 AUC-val 0.481  AUC-train 0.881\n",
            "Stats - Epoch: 91 AUC-val 0.481  AUC-train 0.886\n",
            "Stats - Epoch: 92 AUC-val 0.483  AUC-train 0.879\n",
            "Stats - Epoch: 93 AUC-val 0.474  AUC-train 0.885\n",
            "Stats - Epoch: 94 AUC-val 0.470  AUC-train 0.890\n",
            "Stats - Epoch: 95 AUC-val 0.479  AUC-train 0.884\n",
            "Stats - Epoch: 96 AUC-val 0.475  AUC-train 0.886\n",
            "Stats - Epoch: 97 AUC-val 0.481  AUC-train 0.888\n",
            "Stats - Epoch: 98 AUC-val 0.485  AUC-train 0.889\n",
            "Stats - Epoch: 99 AUC-val 0.485  AUC-train 0.882\n",
            "Stats - Epoch: 100 AUC-val 0.482  AUC-train 0.889\n",
            "Results 100 AUC-val 0.489 0.514 0.569 0.483 0.627 AUC-train 0.879\n",
            "Shapley [0.0073963  0.00788733 0.02078151 0.01208309 0.0045106 ] [0.01914159]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188312\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.173  AUC-train 0.565\n",
            "Stats - Epoch: 2 AUC-val 0.264  AUC-train 0.742\n",
            "Stats - Epoch: 3 AUC-val 0.298  AUC-train 0.822\n",
            "Stats - Epoch: 4 AUC-val 0.313  AUC-train 0.873\n",
            "Stats - Epoch: 5 AUC-val 0.330  AUC-train 0.905\n",
            "Stats - Epoch: 6 AUC-val 0.347  AUC-train 0.929\n",
            "Stats - Epoch: 7 AUC-val 0.335  AUC-train 0.945\n",
            "Stats - Epoch: 8 AUC-val 0.328  AUC-train 0.945\n",
            "Stats - Epoch: 9 AUC-val 0.347  AUC-train 0.963\n",
            "Stats - Epoch: 10 AUC-val 0.362  AUC-train 0.970\n",
            "Stats - Epoch: 11 AUC-val 0.347  AUC-train 0.971\n",
            "Stats - Epoch: 12 AUC-val 0.360  AUC-train 0.974\n",
            "Stats - Epoch: 13 AUC-val 0.363  AUC-train 0.978\n",
            "Stats - Epoch: 14 AUC-val 0.371  AUC-train 0.977\n",
            "Stats - Epoch: 15 AUC-val 0.385  AUC-train 0.979\n",
            "Stats - Epoch: 16 AUC-val 0.401  AUC-train 0.981\n",
            "Stats - Epoch: 17 AUC-val 0.385  AUC-train 0.979\n",
            "Stats - Epoch: 18 AUC-val 0.427  AUC-train 0.981\n",
            "Stats - Epoch: 19 AUC-val 0.419  AUC-train 0.983\n",
            "Stats - Epoch: 20 AUC-val 0.375  AUC-train 0.978\n",
            "Stats - Epoch: 21 AUC-val 0.413  AUC-train 0.983\n",
            "Stats - Epoch: 22 AUC-val 0.412  AUC-train 0.981\n",
            "Stats - Epoch: 23 AUC-val 0.403  AUC-train 0.985\n",
            "Stats - Epoch: 24 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 25 AUC-val 0.409  AUC-train 0.987\n",
            "Stats - Epoch: 26 AUC-val 0.431  AUC-train 0.983\n",
            "Stats - Epoch: 27 AUC-val 0.442  AUC-train 0.983\n",
            "Stats - Epoch: 28 AUC-val 0.430  AUC-train 0.983\n",
            "Stats - Epoch: 29 AUC-val 0.423  AUC-train 0.981\n",
            "Stats - Epoch: 30 AUC-val 0.433  AUC-train 0.979\n",
            "Stats - Epoch: 31 AUC-val 0.442  AUC-train 0.988\n",
            "Stats - Epoch: 32 AUC-val 0.445  AUC-train 0.987\n",
            "Stats - Epoch: 33 AUC-val 0.408  AUC-train 0.988\n",
            "Stats - Epoch: 34 AUC-val 0.430  AUC-train 0.980\n",
            "Stats - Epoch: 35 AUC-val 0.448  AUC-train 0.984\n",
            "Stats - Epoch: 36 AUC-val 0.413  AUC-train 0.982\n",
            "Stats - Epoch: 37 AUC-val 0.445  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.428  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.421  AUC-train 0.985\n",
            "Stats - Epoch: 40 AUC-val 0.450  AUC-train 0.980\n",
            "Stats - Epoch: 41 AUC-val 0.443  AUC-train 0.986\n",
            "Stats - Epoch: 42 AUC-val 0.455  AUC-train 0.982\n",
            "Stats - Epoch: 43 AUC-val 0.462  AUC-train 0.983\n",
            "Stats - Epoch: 44 AUC-val 0.438  AUC-train 0.982\n",
            "Stats - Epoch: 45 AUC-val 0.448  AUC-train 0.982\n",
            "Stats - Epoch: 46 AUC-val 0.464  AUC-train 0.983\n",
            "Stats - Epoch: 47 AUC-val 0.463  AUC-train 0.984\n",
            "Stats - Epoch: 48 AUC-val 0.467  AUC-train 0.977\n",
            "Stats - Epoch: 49 AUC-val 0.446  AUC-train 0.983\n",
            "Stats - Epoch: 50 AUC-val 0.450  AUC-train 0.982\n",
            "Stats - Epoch: 51 AUC-val 0.464  AUC-train 0.983\n",
            "Stats - Epoch: 52 AUC-val 0.431  AUC-train 0.985\n",
            "Stats - Epoch: 53 AUC-val 0.467  AUC-train 0.985\n",
            "Stats - Epoch: 54 AUC-val 0.471  AUC-train 0.984\n",
            "Stats - Epoch: 55 AUC-val 0.491  AUC-train 0.981\n",
            "Stats - Epoch: 56 AUC-val 0.467  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.460  AUC-train 0.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.477  AUC-train 0.979\n",
            "Stats - Epoch: 59 AUC-val 0.463  AUC-train 0.980\n",
            "Stats - Epoch: 60 AUC-val 0.472  AUC-train 0.982\n",
            "Stats - Epoch: 61 AUC-val 0.467  AUC-train 0.982\n",
            "Stats - Epoch: 62 AUC-val 0.448  AUC-train 0.985\n",
            "Stats - Epoch: 63 AUC-val 0.467  AUC-train 0.983\n",
            "Stats - Epoch: 64 AUC-val 0.454  AUC-train 0.972\n",
            "Stats - Epoch: 65 AUC-val 0.450  AUC-train 0.979\n",
            "Stats - Epoch: 66 AUC-val 0.442  AUC-train 0.983\n",
            "Stats - Epoch: 67 AUC-val 0.467  AUC-train 0.980\n",
            "Stats - Epoch: 68 AUC-val 0.432  AUC-train 0.983\n",
            "Stats - Epoch: 69 AUC-val 0.467  AUC-train 0.983\n",
            "Stats - Epoch: 70 AUC-val 0.444  AUC-train 0.981\n",
            "Stats - Epoch: 71 AUC-val 0.463  AUC-train 0.981\n",
            "Stats - Epoch: 72 AUC-val 0.455  AUC-train 0.980\n",
            "Stats - Epoch: 73 AUC-val 0.461  AUC-train 0.978\n",
            "Stats - Epoch: 74 AUC-val 0.462  AUC-train 0.975\n",
            "Stats - Epoch: 75 AUC-val 0.455  AUC-train 0.975\n",
            "Stats - Epoch: 76 AUC-val 0.444  AUC-train 0.977\n",
            "Stats - Epoch: 77 AUC-val 0.447  AUC-train 0.980\n",
            "Stats - Epoch: 78 AUC-val 0.448  AUC-train 0.965\n",
            "Stats - Epoch: 79 AUC-val 0.463  AUC-train 0.979\n",
            "Stats - Epoch: 80 AUC-val 0.457  AUC-train 0.979\n",
            "Stats - Epoch: 81 AUC-val 0.444  AUC-train 0.979\n",
            "Stats - Epoch: 82 AUC-val 0.441  AUC-train 0.981\n",
            "Stats - Epoch: 83 AUC-val 0.465  AUC-train 0.978\n",
            "Stats - Epoch: 84 AUC-val 0.452  AUC-train 0.978\n",
            "Stats - Epoch: 85 AUC-val 0.442  AUC-train 0.980\n",
            "Stats - Epoch: 86 AUC-val 0.454  AUC-train 0.979\n",
            "Stats - Epoch: 87 AUC-val 0.454  AUC-train 0.980\n",
            "Stats - Epoch: 88 AUC-val 0.460  AUC-train 0.978\n",
            "Stats - Epoch: 89 AUC-val 0.448  AUC-train 0.978\n",
            "Stats - Epoch: 90 AUC-val 0.420  AUC-train 0.979\n",
            "Stats - Epoch: 91 AUC-val 0.456  AUC-train 0.977\n",
            "Stats - Epoch: 92 AUC-val 0.431  AUC-train 0.975\n",
            "Stats - Epoch: 93 AUC-val 0.443  AUC-train 0.981\n",
            "Stats - Epoch: 94 AUC-val 0.440  AUC-train 0.976\n",
            "Stats - Epoch: 95 AUC-val 0.429  AUC-train 0.977\n",
            "Stats - Epoch: 96 AUC-val 0.431  AUC-train 0.976\n",
            "Stats - Epoch: 97 AUC-val 0.443  AUC-train 0.975\n",
            "Stats - Epoch: 98 AUC-val 0.434  AUC-train 0.979\n",
            "Stats - Epoch: 99 AUC-val 0.443  AUC-train 0.969\n",
            "Stats - Epoch: 100 AUC-val 0.455  AUC-train 0.975\n",
            "Results 100 AUC-val 0.491 0.445 0.299 0.168 0.532 AUC-train 0.981\n",
            "Shapley [0.02955395 0.01020512 0.01082529 0.04383114 0.01345876] [0.04400376]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.183757\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.219  AUC-train 0.575\n",
            "Stats - Epoch: 2 AUC-val 0.206  AUC-train 0.599\n",
            "Stats - Epoch: 3 AUC-val 0.194  AUC-train 0.650\n",
            "Stats - Epoch: 4 AUC-val 0.236  AUC-train 0.707\n",
            "Stats - Epoch: 5 AUC-val 0.289  AUC-train 0.749\n",
            "Stats - Epoch: 6 AUC-val 0.347  AUC-train 0.783\n",
            "Stats - Epoch: 7 AUC-val 0.403  AUC-train 0.802\n",
            "Stats - Epoch: 8 AUC-val 0.468  AUC-train 0.814\n",
            "Stats - Epoch: 9 AUC-val 0.484  AUC-train 0.822\n",
            "Stats - Epoch: 10 AUC-val 0.463  AUC-train 0.833\n",
            "Stats - Epoch: 11 AUC-val 0.481  AUC-train 0.834\n",
            "Stats - Epoch: 12 AUC-val 0.501  AUC-train 0.840\n",
            "Stats - Epoch: 13 AUC-val 0.525  AUC-train 0.846\n",
            "Stats - Epoch: 14 AUC-val 0.521  AUC-train 0.848\n",
            "Stats - Epoch: 15 AUC-val 0.541  AUC-train 0.848\n",
            "Stats - Epoch: 16 AUC-val 0.525  AUC-train 0.855\n",
            "Stats - Epoch: 17 AUC-val 0.526  AUC-train 0.861\n",
            "Stats - Epoch: 18 AUC-val 0.554  AUC-train 0.861\n",
            "Stats - Epoch: 19 AUC-val 0.553  AUC-train 0.864\n",
            "Stats - Epoch: 20 AUC-val 0.535  AUC-train 0.866\n",
            "Stats - Epoch: 21 AUC-val 0.564  AUC-train 0.870\n",
            "Stats - Epoch: 22 AUC-val 0.557  AUC-train 0.875\n",
            "Stats - Epoch: 23 AUC-val 0.564  AUC-train 0.873\n",
            "Stats - Epoch: 24 AUC-val 0.579  AUC-train 0.873\n",
            "Stats - Epoch: 25 AUC-val 0.569  AUC-train 0.875\n",
            "Stats - Epoch: 26 AUC-val 0.576  AUC-train 0.877\n",
            "Stats - Epoch: 27 AUC-val 0.567  AUC-train 0.879\n",
            "Stats - Epoch: 28 AUC-val 0.564  AUC-train 0.882\n",
            "Stats - Epoch: 29 AUC-val 0.585  AUC-train 0.881\n",
            "Stats - Epoch: 30 AUC-val 0.578  AUC-train 0.885\n",
            "Stats - Epoch: 31 AUC-val 0.573  AUC-train 0.889\n",
            "Stats - Epoch: 32 AUC-val 0.601  AUC-train 0.890\n",
            "Stats - Epoch: 33 AUC-val 0.587  AUC-train 0.888\n",
            "Stats - Epoch: 34 AUC-val 0.581  AUC-train 0.888\n",
            "Stats - Epoch: 35 AUC-val 0.570  AUC-train 0.891\n",
            "Stats - Epoch: 36 AUC-val 0.593  AUC-train 0.893\n",
            "Stats - Epoch: 37 AUC-val 0.609  AUC-train 0.893\n",
            "Stats - Epoch: 38 AUC-val 0.593  AUC-train 0.894\n",
            "Stats - Epoch: 39 AUC-val 0.594  AUC-train 0.896\n",
            "Stats - Epoch: 40 AUC-val 0.626  AUC-train 0.895\n",
            "Stats - Epoch: 41 AUC-val 0.591  AUC-train 0.901\n",
            "Stats - Epoch: 42 AUC-val 0.615  AUC-train 0.897\n",
            "Stats - Epoch: 43 AUC-val 0.589  AUC-train 0.895\n",
            "Stats - Epoch: 44 AUC-val 0.601  AUC-train 0.898\n",
            "Stats - Epoch: 45 AUC-val 0.617  AUC-train 0.898\n",
            "Stats - Epoch: 46 AUC-val 0.581  AUC-train 0.900\n",
            "Stats - Epoch: 47 AUC-val 0.625  AUC-train 0.902\n",
            "Stats - Epoch: 48 AUC-val 0.572  AUC-train 0.902\n",
            "Stats - Epoch: 49 AUC-val 0.570  AUC-train 0.906\n",
            "Stats - Epoch: 50 AUC-val 0.611  AUC-train 0.904\n",
            "Stats - Epoch: 51 AUC-val 0.598  AUC-train 0.903\n",
            "Stats - Epoch: 52 AUC-val 0.600  AUC-train 0.901\n",
            "Stats - Epoch: 53 AUC-val 0.624  AUC-train 0.901\n",
            "Stats - Epoch: 54 AUC-val 0.602  AUC-train 0.904\n",
            "Stats - Epoch: 55 AUC-val 0.613  AUC-train 0.901\n",
            "Stats - Epoch: 56 AUC-val 0.608  AUC-train 0.906\n",
            "Stats - Epoch: 57 AUC-val 0.603  AUC-train 0.907\n",
            "Stats - Epoch: 58 AUC-val 0.603  AUC-train 0.912\n",
            "Stats - Epoch: 59 AUC-val 0.595  AUC-train 0.908\n",
            "Stats - Epoch: 60 AUC-val 0.601  AUC-train 0.908\n",
            "Stats - Epoch: 61 AUC-val 0.599  AUC-train 0.908\n",
            "Stats - Epoch: 62 AUC-val 0.591  AUC-train 0.912\n",
            "Stats - Epoch: 63 AUC-val 0.592  AUC-train 0.913\n",
            "Stats - Epoch: 64 AUC-val 0.594  AUC-train 0.912\n",
            "Stats - Epoch: 65 AUC-val 0.591  AUC-train 0.918\n",
            "Stats - Epoch: 66 AUC-val 0.608  AUC-train 0.917\n",
            "Stats - Epoch: 67 AUC-val 0.619  AUC-train 0.917\n",
            "Stats - Epoch: 68 AUC-val 0.610  AUC-train 0.921\n",
            "Stats - Epoch: 69 AUC-val 0.605  AUC-train 0.922\n",
            "Stats - Epoch: 70 AUC-val 0.602  AUC-train 0.922\n",
            "Stats - Epoch: 71 AUC-val 0.610  AUC-train 0.921\n",
            "Stats - Epoch: 72 AUC-val 0.616  AUC-train 0.915\n",
            "Stats - Epoch: 73 AUC-val 0.573  AUC-train 0.913\n",
            "Stats - Epoch: 74 AUC-val 0.594  AUC-train 0.915\n",
            "Stats - Epoch: 75 AUC-val 0.592  AUC-train 0.915\n",
            "Stats - Epoch: 76 AUC-val 0.583  AUC-train 0.914\n",
            "Stats - Epoch: 77 AUC-val 0.590  AUC-train 0.914\n",
            "Stats - Epoch: 78 AUC-val 0.582  AUC-train 0.915\n",
            "Stats - Epoch: 79 AUC-val 0.595  AUC-train 0.919\n",
            "Stats - Epoch: 80 AUC-val 0.589  AUC-train 0.923\n",
            "Stats - Epoch: 81 AUC-val 0.583  AUC-train 0.925\n",
            "Stats - Epoch: 82 AUC-val 0.584  AUC-train 0.922\n",
            "Stats - Epoch: 83 AUC-val 0.582  AUC-train 0.923\n",
            "Stats - Epoch: 84 AUC-val 0.604  AUC-train 0.920\n",
            "Stats - Epoch: 85 AUC-val 0.596  AUC-train 0.924\n",
            "Stats - Epoch: 86 AUC-val 0.629  AUC-train 0.925\n",
            "Stats - Epoch: 87 AUC-val 0.595  AUC-train 0.929\n",
            "Stats - Epoch: 88 AUC-val 0.592  AUC-train 0.928\n",
            "Stats - Epoch: 89 AUC-val 0.615  AUC-train 0.933\n",
            "Stats - Epoch: 90 AUC-val 0.610  AUC-train 0.928\n",
            "Stats - Epoch: 91 AUC-val 0.590  AUC-train 0.925\n",
            "Stats - Epoch: 92 AUC-val 0.610  AUC-train 0.926\n",
            "Stats - Epoch: 93 AUC-val 0.606  AUC-train 0.929\n",
            "Stats - Epoch: 94 AUC-val 0.613  AUC-train 0.921\n",
            "Stats - Epoch: 95 AUC-val 0.581  AUC-train 0.921\n",
            "Stats - Epoch: 96 AUC-val 0.592  AUC-train 0.927\n",
            "Stats - Epoch: 97 AUC-val 0.589  AUC-train 0.930\n",
            "Stats - Epoch: 98 AUC-val 0.595  AUC-train 0.934\n",
            "Stats - Epoch: 99 AUC-val 0.605  AUC-train 0.935\n",
            "Stats - Epoch: 100 AUC-val 0.603  AUC-train 0.934\n",
            "Results 100 AUC-val 0.629 0.592 0.602 0.570 0.618 AUC-train 0.925\n",
            "Shapley [0.01660428 0.01214796 0.01814171 0.0135393  0.00548572] [0.00459056]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.190174\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.383  AUC-train 0.564\n",
            "Stats - Epoch: 2 AUC-val 0.505  AUC-train 0.702\n",
            "Stats - Epoch: 3 AUC-val 0.606  AUC-train 0.790\n",
            "Stats - Epoch: 4 AUC-val 0.633  AUC-train 0.830\n",
            "Stats - Epoch: 5 AUC-val 0.648  AUC-train 0.850\n",
            "Stats - Epoch: 6 AUC-val 0.673  AUC-train 0.869\n",
            "Stats - Epoch: 7 AUC-val 0.690  AUC-train 0.883\n",
            "Stats - Epoch: 8 AUC-val 0.721  AUC-train 0.891\n",
            "Stats - Epoch: 9 AUC-val 0.716  AUC-train 0.905\n",
            "Stats - Epoch: 10 AUC-val 0.740  AUC-train 0.916\n",
            "Stats - Epoch: 11 AUC-val 0.735  AUC-train 0.923\n",
            "Stats - Epoch: 12 AUC-val 0.744  AUC-train 0.932\n",
            "Stats - Epoch: 13 AUC-val 0.748  AUC-train 0.939\n",
            "Stats - Epoch: 14 AUC-val 0.751  AUC-train 0.941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.743  AUC-train 0.946\n",
            "Stats - Epoch: 16 AUC-val 0.749  AUC-train 0.954\n",
            "Stats - Epoch: 17 AUC-val 0.740  AUC-train 0.957\n",
            "Stats - Epoch: 18 AUC-val 0.748  AUC-train 0.961\n",
            "Stats - Epoch: 19 AUC-val 0.752  AUC-train 0.964\n",
            "Stats - Epoch: 20 AUC-val 0.744  AUC-train 0.966\n",
            "Stats - Epoch: 21 AUC-val 0.750  AUC-train 0.968\n",
            "Stats - Epoch: 22 AUC-val 0.752  AUC-train 0.975\n",
            "Stats - Epoch: 23 AUC-val 0.758  AUC-train 0.976\n",
            "Stats - Epoch: 24 AUC-val 0.743  AUC-train 0.975\n",
            "Stats - Epoch: 25 AUC-val 0.743  AUC-train 0.977\n",
            "Stats - Epoch: 26 AUC-val 0.751  AUC-train 0.979\n",
            "Stats - Epoch: 27 AUC-val 0.752  AUC-train 0.981\n",
            "Stats - Epoch: 28 AUC-val 0.736  AUC-train 0.982\n",
            "Stats - Epoch: 29 AUC-val 0.730  AUC-train 0.983\n",
            "Stats - Epoch: 30 AUC-val 0.718  AUC-train 0.985\n",
            "Stats - Epoch: 31 AUC-val 0.721  AUC-train 0.984\n",
            "Stats - Epoch: 32 AUC-val 0.691  AUC-train 0.984\n",
            "Stats - Epoch: 33 AUC-val 0.722  AUC-train 0.986\n",
            "Stats - Epoch: 34 AUC-val 0.704  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.707  AUC-train 0.986\n",
            "Stats - Epoch: 36 AUC-val 0.708  AUC-train 0.987\n",
            "Stats - Epoch: 37 AUC-val 0.705  AUC-train 0.987\n",
            "Stats - Epoch: 38 AUC-val 0.684  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.691  AUC-train 0.988\n",
            "Stats - Epoch: 40 AUC-val 0.694  AUC-train 0.988\n",
            "Stats - Epoch: 41 AUC-val 0.697  AUC-train 0.988\n",
            "Stats - Epoch: 42 AUC-val 0.714  AUC-train 0.990\n",
            "Stats - Epoch: 43 AUC-val 0.682  AUC-train 0.989\n",
            "Stats - Epoch: 44 AUC-val 0.698  AUC-train 0.989\n",
            "Stats - Epoch: 45 AUC-val 0.697  AUC-train 0.990\n",
            "Stats - Epoch: 46 AUC-val 0.688  AUC-train 0.989\n",
            "Stats - Epoch: 47 AUC-val 0.681  AUC-train 0.989\n",
            "Stats - Epoch: 48 AUC-val 0.670  AUC-train 0.990\n",
            "Stats - Epoch: 49 AUC-val 0.707  AUC-train 0.990\n",
            "Stats - Epoch: 50 AUC-val 0.672  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.681  AUC-train 0.993\n",
            "Stats - Epoch: 52 AUC-val 0.671  AUC-train 0.993\n",
            "Stats - Epoch: 53 AUC-val 0.696  AUC-train 0.993\n",
            "Stats - Epoch: 54 AUC-val 0.677  AUC-train 0.993\n",
            "Stats - Epoch: 55 AUC-val 0.690  AUC-train 0.993\n",
            "Stats - Epoch: 56 AUC-val 0.696  AUC-train 0.994\n",
            "Stats - Epoch: 57 AUC-val 0.685  AUC-train 0.993\n",
            "Stats - Epoch: 58 AUC-val 0.689  AUC-train 0.995\n",
            "Stats - Epoch: 59 AUC-val 0.680  AUC-train 0.994\n",
            "Stats - Epoch: 60 AUC-val 0.681  AUC-train 0.993\n",
            "Stats - Epoch: 61 AUC-val 0.688  AUC-train 0.989\n",
            "Stats - Epoch: 62 AUC-val 0.697  AUC-train 0.993\n",
            "Stats - Epoch: 63 AUC-val 0.681  AUC-train 0.993\n",
            "Stats - Epoch: 64 AUC-val 0.678  AUC-train 0.994\n",
            "Stats - Epoch: 65 AUC-val 0.688  AUC-train 0.994\n",
            "Stats - Epoch: 66 AUC-val 0.697  AUC-train 0.992\n",
            "Stats - Epoch: 67 AUC-val 0.705  AUC-train 0.994\n",
            "Stats - Epoch: 68 AUC-val 0.693  AUC-train 0.995\n",
            "Stats - Epoch: 69 AUC-val 0.695  AUC-train 0.995\n",
            "Stats - Epoch: 70 AUC-val 0.697  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.679  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 73 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.681  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.694  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.679  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.688  AUC-train 0.993\n",
            "Stats - Epoch: 78 AUC-val 0.692  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.686  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.704  AUC-train 0.995\n",
            "Stats - Epoch: 81 AUC-val 0.689  AUC-train 0.996\n",
            "Stats - Epoch: 82 AUC-val 0.707  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.654  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.666  AUC-train 0.996\n",
            "Stats - Epoch: 85 AUC-val 0.640  AUC-train 0.993\n",
            "Stats - Epoch: 86 AUC-val 0.677  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.667  AUC-train 0.996\n",
            "Stats - Epoch: 88 AUC-val 0.672  AUC-train 0.995\n",
            "Stats - Epoch: 89 AUC-val 0.675  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.647  AUC-train 0.990\n",
            "Stats - Epoch: 91 AUC-val 0.631  AUC-train 0.993\n",
            "Stats - Epoch: 92 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.660  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.665  AUC-train 0.989\n",
            "Stats - Epoch: 95 AUC-val 0.618  AUC-train 0.993\n",
            "Stats - Epoch: 96 AUC-val 0.685  AUC-train 0.994\n",
            "Stats - Epoch: 97 AUC-val 0.663  AUC-train 0.994\n",
            "Stats - Epoch: 98 AUC-val 0.666  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.670  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.644  AUC-train 0.995\n",
            "Results 100 AUC-val 0.758 0.631 0.537 0.501 0.598 AUC-train 0.976\n",
            "Shapley [0.01769947 0.01931266 0.01605387 0.03413863 0.01811024] [0.00938378]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.194748\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.591  AUC-train 0.464\n",
            "Stats - Epoch: 2 AUC-val 0.597  AUC-train 0.617\n",
            "Stats - Epoch: 3 AUC-val 0.612  AUC-train 0.719\n",
            "Stats - Epoch: 4 AUC-val 0.616  AUC-train 0.772\n",
            "Stats - Epoch: 5 AUC-val 0.606  AUC-train 0.807\n",
            "Stats - Epoch: 6 AUC-val 0.604  AUC-train 0.832\n",
            "Stats - Epoch: 7 AUC-val 0.597  AUC-train 0.846\n",
            "Stats - Epoch: 8 AUC-val 0.604  AUC-train 0.866\n",
            "Stats - Epoch: 9 AUC-val 0.600  AUC-train 0.878\n",
            "Stats - Epoch: 10 AUC-val 0.598  AUC-train 0.890\n",
            "Stats - Epoch: 11 AUC-val 0.593  AUC-train 0.901\n",
            "Stats - Epoch: 12 AUC-val 0.585  AUC-train 0.911\n",
            "Stats - Epoch: 13 AUC-val 0.577  AUC-train 0.918\n",
            "Stats - Epoch: 14 AUC-val 0.598  AUC-train 0.924\n",
            "Stats - Epoch: 15 AUC-val 0.552  AUC-train 0.930\n",
            "Stats - Epoch: 16 AUC-val 0.553  AUC-train 0.934\n",
            "Stats - Epoch: 17 AUC-val 0.582  AUC-train 0.944\n",
            "Stats - Epoch: 18 AUC-val 0.591  AUC-train 0.950\n",
            "Stats - Epoch: 19 AUC-val 0.589  AUC-train 0.951\n",
            "Stats - Epoch: 20 AUC-val 0.611  AUC-train 0.959\n",
            "Stats - Epoch: 21 AUC-val 0.578  AUC-train 0.963\n",
            "Stats - Epoch: 22 AUC-val 0.560  AUC-train 0.967\n",
            "Stats - Epoch: 23 AUC-val 0.572  AUC-train 0.971\n",
            "Stats - Epoch: 24 AUC-val 0.584  AUC-train 0.975\n",
            "Stats - Epoch: 25 AUC-val 0.602  AUC-train 0.977\n",
            "Stats - Epoch: 26 AUC-val 0.616  AUC-train 0.977\n",
            "Stats - Epoch: 27 AUC-val 0.613  AUC-train 0.976\n",
            "Stats - Epoch: 28 AUC-val 0.585  AUC-train 0.979\n",
            "Stats - Epoch: 29 AUC-val 0.610  AUC-train 0.983\n",
            "Stats - Epoch: 30 AUC-val 0.607  AUC-train 0.984\n",
            "Stats - Epoch: 31 AUC-val 0.611  AUC-train 0.987\n",
            "Stats - Epoch: 32 AUC-val 0.634  AUC-train 0.988\n",
            "Stats - Epoch: 33 AUC-val 0.620  AUC-train 0.984\n",
            "Stats - Epoch: 34 AUC-val 0.638  AUC-train 0.986\n",
            "Stats - Epoch: 35 AUC-val 0.629  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.616  AUC-train 0.987\n",
            "Stats - Epoch: 37 AUC-val 0.580  AUC-train 0.987\n",
            "Stats - Epoch: 38 AUC-val 0.606  AUC-train 0.991\n",
            "Stats - Epoch: 39 AUC-val 0.592  AUC-train 0.988\n",
            "Stats - Epoch: 40 AUC-val 0.666  AUC-train 0.991\n",
            "Stats - Epoch: 41 AUC-val 0.653  AUC-train 0.988\n",
            "Stats - Epoch: 42 AUC-val 0.660  AUC-train 0.991\n",
            "Stats - Epoch: 43 AUC-val 0.653  AUC-train 0.991\n",
            "Stats - Epoch: 44 AUC-val 0.656  AUC-train 0.992\n",
            "Stats - Epoch: 45 AUC-val 0.667  AUC-train 0.993\n",
            "Stats - Epoch: 46 AUC-val 0.658  AUC-train 0.992\n",
            "Stats - Epoch: 47 AUC-val 0.666  AUC-train 0.994\n",
            "Stats - Epoch: 48 AUC-val 0.654  AUC-train 0.993\n",
            "Stats - Epoch: 49 AUC-val 0.673  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.674  AUC-train 0.995\n",
            "Stats - Epoch: 51 AUC-val 0.660  AUC-train 0.996\n",
            "Stats - Epoch: 52 AUC-val 0.641  AUC-train 0.993\n",
            "Stats - Epoch: 53 AUC-val 0.670  AUC-train 0.996\n",
            "Stats - Epoch: 54 AUC-val 0.663  AUC-train 0.995\n",
            "Stats - Epoch: 55 AUC-val 0.671  AUC-train 0.995\n",
            "Stats - Epoch: 56 AUC-val 0.641  AUC-train 0.993\n",
            "Stats - Epoch: 57 AUC-val 0.622  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.614  AUC-train 0.991\n",
            "Stats - Epoch: 59 AUC-val 0.633  AUC-train 0.992\n",
            "Stats - Epoch: 60 AUC-val 0.661  AUC-train 0.992\n",
            "Stats - Epoch: 61 AUC-val 0.615  AUC-train 0.992\n",
            "Stats - Epoch: 62 AUC-val 0.624  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.638  AUC-train 0.997\n",
            "Stats - Epoch: 64 AUC-val 0.624  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.658  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.626  AUC-train 0.997\n",
            "Stats - Epoch: 67 AUC-val 0.639  AUC-train 0.993\n",
            "Stats - Epoch: 68 AUC-val 0.679  AUC-train 0.994\n",
            "Stats - Epoch: 69 AUC-val 0.657  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.645  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.654  AUC-train 0.995\n",
            "Stats - Epoch: 72 AUC-val 0.683  AUC-train 0.989\n",
            "Stats - Epoch: 73 AUC-val 0.695  AUC-train 0.990\n",
            "Stats - Epoch: 74 AUC-val 0.679  AUC-train 0.993\n",
            "Stats - Epoch: 75 AUC-val 0.666  AUC-train 0.994\n",
            "Stats - Epoch: 76 AUC-val 0.667  AUC-train 0.996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.665  AUC-train 0.994\n",
            "Stats - Epoch: 78 AUC-val 0.674  AUC-train 0.995\n",
            "Stats - Epoch: 79 AUC-val 0.665  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.717  AUC-train 0.993\n",
            "Stats - Epoch: 81 AUC-val 0.644  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.673  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.669  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.672  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.664  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.671  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.648  AUC-train 0.992\n",
            "Stats - Epoch: 88 AUC-val 0.641  AUC-train 0.992\n",
            "Stats - Epoch: 89 AUC-val 0.632  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.639  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.664  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.655  AUC-train 0.994\n",
            "Stats - Epoch: 93 AUC-val 0.660  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.668  AUC-train 0.996\n",
            "Stats - Epoch: 95 AUC-val 0.645  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.654  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.677  AUC-train 0.994\n",
            "Stats - Epoch: 98 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.667  AUC-train 0.991\n",
            "Stats - Epoch: 100 AUC-val 0.653  AUC-train 0.991\n",
            "Results 100 AUC-val 0.717 0.735 0.622 0.492 0.575 AUC-train 0.993\n",
            "Shapley [0.01313723 0.01696254 0.0089019  0.02048411 0.00765308] [0.00682933]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.200619\n",
            "         Iterations 7\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.416  AUC-train 0.496\n",
            "Stats - Epoch: 2 AUC-val 0.429  AUC-train 0.572\n",
            "Stats - Epoch: 3 AUC-val 0.416  AUC-train 0.619\n",
            "Stats - Epoch: 4 AUC-val 0.436  AUC-train 0.648\n",
            "Stats - Epoch: 5 AUC-val 0.432  AUC-train 0.674\n",
            "Stats - Epoch: 6 AUC-val 0.427  AUC-train 0.704\n",
            "Stats - Epoch: 7 AUC-val 0.427  AUC-train 0.723\n",
            "Stats - Epoch: 8 AUC-val 0.429  AUC-train 0.735\n",
            "Stats - Epoch: 9 AUC-val 0.429  AUC-train 0.753\n",
            "Stats - Epoch: 10 AUC-val 0.429  AUC-train 0.773\n",
            "Stats - Epoch: 11 AUC-val 0.429  AUC-train 0.773\n",
            "Stats - Epoch: 12 AUC-val 0.426  AUC-train 0.795\n",
            "Stats - Epoch: 13 AUC-val 0.431  AUC-train 0.797\n",
            "Stats - Epoch: 14 AUC-val 0.424  AUC-train 0.812\n",
            "Stats - Epoch: 15 AUC-val 0.423  AUC-train 0.813\n",
            "Stats - Epoch: 16 AUC-val 0.417  AUC-train 0.821\n",
            "Stats - Epoch: 17 AUC-val 0.438  AUC-train 0.816\n",
            "Stats - Epoch: 18 AUC-val 0.431  AUC-train 0.827\n",
            "Stats - Epoch: 19 AUC-val 0.439  AUC-train 0.834\n",
            "Stats - Epoch: 20 AUC-val 0.445  AUC-train 0.835\n",
            "Stats - Epoch: 21 AUC-val 0.433  AUC-train 0.840\n",
            "Stats - Epoch: 22 AUC-val 0.437  AUC-train 0.844\n",
            "Stats - Epoch: 23 AUC-val 0.452  AUC-train 0.850\n",
            "Stats - Epoch: 24 AUC-val 0.438  AUC-train 0.849\n",
            "Stats - Epoch: 25 AUC-val 0.450  AUC-train 0.848\n",
            "Stats - Epoch: 26 AUC-val 0.446  AUC-train 0.851\n",
            "Stats - Epoch: 27 AUC-val 0.448  AUC-train 0.852\n",
            "Stats - Epoch: 28 AUC-val 0.443  AUC-train 0.853\n",
            "Stats - Epoch: 29 AUC-val 0.449  AUC-train 0.849\n",
            "Stats - Epoch: 30 AUC-val 0.448  AUC-train 0.862\n",
            "Stats - Epoch: 31 AUC-val 0.445  AUC-train 0.865\n",
            "Stats - Epoch: 32 AUC-val 0.452  AUC-train 0.861\n",
            "Stats - Epoch: 33 AUC-val 0.460  AUC-train 0.865\n",
            "Stats - Epoch: 34 AUC-val 0.452  AUC-train 0.861\n",
            "Stats - Epoch: 35 AUC-val 0.463  AUC-train 0.856\n",
            "Stats - Epoch: 36 AUC-val 0.463  AUC-train 0.861\n",
            "Stats - Epoch: 37 AUC-val 0.463  AUC-train 0.867\n",
            "Stats - Epoch: 38 AUC-val 0.457  AUC-train 0.866\n",
            "Stats - Epoch: 39 AUC-val 0.452  AUC-train 0.869\n",
            "Stats - Epoch: 40 AUC-val 0.453  AUC-train 0.872\n",
            "Stats - Epoch: 41 AUC-val 0.460  AUC-train 0.874\n",
            "Stats - Epoch: 42 AUC-val 0.460  AUC-train 0.872\n",
            "Stats - Epoch: 43 AUC-val 0.463  AUC-train 0.866\n",
            "Stats - Epoch: 44 AUC-val 0.464  AUC-train 0.870\n",
            "Stats - Epoch: 45 AUC-val 0.453  AUC-train 0.869\n",
            "Stats - Epoch: 46 AUC-val 0.457  AUC-train 0.875\n",
            "Stats - Epoch: 47 AUC-val 0.460  AUC-train 0.873\n",
            "Stats - Epoch: 48 AUC-val 0.458  AUC-train 0.874\n",
            "Stats - Epoch: 49 AUC-val 0.467  AUC-train 0.875\n",
            "Stats - Epoch: 50 AUC-val 0.472  AUC-train 0.873\n",
            "Stats - Epoch: 51 AUC-val 0.466  AUC-train 0.876\n",
            "Stats - Epoch: 52 AUC-val 0.463  AUC-train 0.871\n",
            "Stats - Epoch: 53 AUC-val 0.469  AUC-train 0.879\n",
            "Stats - Epoch: 54 AUC-val 0.461  AUC-train 0.880\n",
            "Stats - Epoch: 55 AUC-val 0.465  AUC-train 0.880\n",
            "Stats - Epoch: 56 AUC-val 0.470  AUC-train 0.874\n",
            "Stats - Epoch: 57 AUC-val 0.462  AUC-train 0.880\n",
            "Stats - Epoch: 58 AUC-val 0.478  AUC-train 0.878\n",
            "Stats - Epoch: 59 AUC-val 0.463  AUC-train 0.881\n",
            "Stats - Epoch: 60 AUC-val 0.459  AUC-train 0.882\n",
            "Stats - Epoch: 61 AUC-val 0.467  AUC-train 0.885\n",
            "Stats - Epoch: 62 AUC-val 0.465  AUC-train 0.887\n",
            "Stats - Epoch: 63 AUC-val 0.470  AUC-train 0.887\n",
            "Stats - Epoch: 64 AUC-val 0.469  AUC-train 0.876\n",
            "Stats - Epoch: 65 AUC-val 0.468  AUC-train 0.883\n",
            "Stats - Epoch: 66 AUC-val 0.466  AUC-train 0.887\n",
            "Stats - Epoch: 67 AUC-val 0.477  AUC-train 0.883\n",
            "Stats - Epoch: 68 AUC-val 0.476  AUC-train 0.886\n",
            "Stats - Epoch: 69 AUC-val 0.478  AUC-train 0.887\n",
            "Stats - Epoch: 70 AUC-val 0.462  AUC-train 0.888\n",
            "Stats - Epoch: 71 AUC-val 0.474  AUC-train 0.884\n",
            "Stats - Epoch: 72 AUC-val 0.476  AUC-train 0.886\n",
            "Stats - Epoch: 73 AUC-val 0.475  AUC-train 0.885\n",
            "Stats - Epoch: 74 AUC-val 0.479  AUC-train 0.883\n",
            "Stats - Epoch: 75 AUC-val 0.470  AUC-train 0.886\n",
            "Stats - Epoch: 76 AUC-val 0.484  AUC-train 0.883\n",
            "Stats - Epoch: 77 AUC-val 0.472  AUC-train 0.888\n",
            "Stats - Epoch: 78 AUC-val 0.483  AUC-train 0.886\n",
            "Stats - Epoch: 79 AUC-val 0.481  AUC-train 0.887\n",
            "Stats - Epoch: 80 AUC-val 0.482  AUC-train 0.892\n",
            "Stats - Epoch: 81 AUC-val 0.471  AUC-train 0.890\n",
            "Stats - Epoch: 82 AUC-val 0.475  AUC-train 0.889\n",
            "Stats - Epoch: 83 AUC-val 0.476  AUC-train 0.893\n",
            "Stats - Epoch: 84 AUC-val 0.472  AUC-train 0.890\n",
            "Stats - Epoch: 85 AUC-val 0.474  AUC-train 0.889\n",
            "Stats - Epoch: 86 AUC-val 0.480  AUC-train 0.889\n",
            "Stats - Epoch: 87 AUC-val 0.482  AUC-train 0.887\n",
            "Stats - Epoch: 88 AUC-val 0.479  AUC-train 0.892\n",
            "Stats - Epoch: 89 AUC-val 0.472  AUC-train 0.892\n",
            "Stats - Epoch: 90 AUC-val 0.479  AUC-train 0.885\n",
            "Stats - Epoch: 91 AUC-val 0.475  AUC-train 0.891\n",
            "Stats - Epoch: 92 AUC-val 0.464  AUC-train 0.889\n",
            "Stats - Epoch: 93 AUC-val 0.472  AUC-train 0.891\n",
            "Stats - Epoch: 94 AUC-val 0.469  AUC-train 0.893\n",
            "Stats - Epoch: 95 AUC-val 0.485  AUC-train 0.885\n",
            "Stats - Epoch: 96 AUC-val 0.479  AUC-train 0.891\n",
            "Stats - Epoch: 97 AUC-val 0.485  AUC-train 0.890\n",
            "Stats - Epoch: 98 AUC-val 0.483  AUC-train 0.893\n",
            "Stats - Epoch: 99 AUC-val 0.485  AUC-train 0.892\n",
            "Stats - Epoch: 100 AUC-val 0.474  AUC-train 0.894\n",
            "Results 100 AUC-val 0.485 0.517 0.566 0.493 0.620 AUC-train 0.885\n",
            "Shapley [0.00761172 0.00683173 0.0187178  0.01143717 0.0036587 ] [0.0201179]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.189441\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.214  AUC-train 0.565\n",
            "Stats - Epoch: 2 AUC-val 0.275  AUC-train 0.752\n",
            "Stats - Epoch: 3 AUC-val 0.275  AUC-train 0.837\n",
            "Stats - Epoch: 4 AUC-val 0.309  AUC-train 0.885\n",
            "Stats - Epoch: 5 AUC-val 0.322  AUC-train 0.917\n",
            "Stats - Epoch: 6 AUC-val 0.322  AUC-train 0.941\n",
            "Stats - Epoch: 7 AUC-val 0.320  AUC-train 0.950\n",
            "Stats - Epoch: 8 AUC-val 0.349  AUC-train 0.952\n",
            "Stats - Epoch: 9 AUC-val 0.351  AUC-train 0.964\n",
            "Stats - Epoch: 10 AUC-val 0.359  AUC-train 0.970\n",
            "Stats - Epoch: 11 AUC-val 0.376  AUC-train 0.974\n",
            "Stats - Epoch: 12 AUC-val 0.372  AUC-train 0.981\n",
            "Stats - Epoch: 13 AUC-val 0.376  AUC-train 0.980\n",
            "Stats - Epoch: 14 AUC-val 0.397  AUC-train 0.982\n",
            "Stats - Epoch: 15 AUC-val 0.371  AUC-train 0.985\n",
            "Stats - Epoch: 16 AUC-val 0.401  AUC-train 0.986\n",
            "Stats - Epoch: 17 AUC-val 0.402  AUC-train 0.980\n",
            "Stats - Epoch: 18 AUC-val 0.400  AUC-train 0.984\n",
            "Stats - Epoch: 19 AUC-val 0.399  AUC-train 0.987\n",
            "Stats - Epoch: 20 AUC-val 0.387  AUC-train 0.984\n",
            "Stats - Epoch: 21 AUC-val 0.388  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.409  AUC-train 0.982\n",
            "Stats - Epoch: 23 AUC-val 0.389  AUC-train 0.982\n",
            "Stats - Epoch: 24 AUC-val 0.413  AUC-train 0.987\n",
            "Stats - Epoch: 25 AUC-val 0.398  AUC-train 0.985\n",
            "Stats - Epoch: 26 AUC-val 0.440  AUC-train 0.985\n",
            "Stats - Epoch: 27 AUC-val 0.431  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.409  AUC-train 0.984\n",
            "Stats - Epoch: 29 AUC-val 0.407  AUC-train 0.986\n",
            "Stats - Epoch: 30 AUC-val 0.429  AUC-train 0.987\n",
            "Stats - Epoch: 31 AUC-val 0.427  AUC-train 0.991\n",
            "Stats - Epoch: 32 AUC-val 0.421  AUC-train 0.988\n",
            "Stats - Epoch: 33 AUC-val 0.395  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.422  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.445  AUC-train 0.985\n",
            "Stats - Epoch: 36 AUC-val 0.419  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.433  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.452  AUC-train 0.986\n",
            "Stats - Epoch: 39 AUC-val 0.432  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 41 AUC-val 0.422  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.438  AUC-train 0.981\n",
            "Stats - Epoch: 43 AUC-val 0.415  AUC-train 0.977\n",
            "Stats - Epoch: 44 AUC-val 0.416  AUC-train 0.985\n",
            "Stats - Epoch: 45 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.414  AUC-train 0.986\n",
            "Stats - Epoch: 47 AUC-val 0.436  AUC-train 0.983\n",
            "Stats - Epoch: 48 AUC-val 0.462  AUC-train 0.982\n",
            "Stats - Epoch: 49 AUC-val 0.443  AUC-train 0.981\n",
            "Stats - Epoch: 50 AUC-val 0.426  AUC-train 0.981\n",
            "Stats - Epoch: 51 AUC-val 0.436  AUC-train 0.982\n",
            "Stats - Epoch: 52 AUC-val 0.419  AUC-train 0.984\n",
            "Stats - Epoch: 53 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 54 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 55 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 56 AUC-val 0.449  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.460  AUC-train 0.981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.462  AUC-train 0.984\n",
            "Stats - Epoch: 59 AUC-val 0.436  AUC-train 0.979\n",
            "Stats - Epoch: 60 AUC-val 0.434  AUC-train 0.983\n",
            "Stats - Epoch: 61 AUC-val 0.449  AUC-train 0.982\n",
            "Stats - Epoch: 62 AUC-val 0.435  AUC-train 0.985\n",
            "Stats - Epoch: 63 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 64 AUC-val 0.446  AUC-train 0.979\n",
            "Stats - Epoch: 65 AUC-val 0.456  AUC-train 0.984\n",
            "Stats - Epoch: 66 AUC-val 0.426  AUC-train 0.986\n",
            "Stats - Epoch: 67 AUC-val 0.457  AUC-train 0.980\n",
            "Stats - Epoch: 68 AUC-val 0.450  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.450  AUC-train 0.985\n",
            "Stats - Epoch: 70 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 71 AUC-val 0.445  AUC-train 0.981\n",
            "Stats - Epoch: 72 AUC-val 0.432  AUC-train 0.979\n",
            "Stats - Epoch: 73 AUC-val 0.448  AUC-train 0.982\n",
            "Stats - Epoch: 74 AUC-val 0.450  AUC-train 0.981\n",
            "Stats - Epoch: 75 AUC-val 0.450  AUC-train 0.979\n",
            "Stats - Epoch: 76 AUC-val 0.469  AUC-train 0.974\n",
            "Stats - Epoch: 77 AUC-val 0.470  AUC-train 0.979\n",
            "Stats - Epoch: 78 AUC-val 0.462  AUC-train 0.971\n",
            "Stats - Epoch: 79 AUC-val 0.435  AUC-train 0.981\n",
            "Stats - Epoch: 80 AUC-val 0.435  AUC-train 0.982\n",
            "Stats - Epoch: 81 AUC-val 0.445  AUC-train 0.983\n",
            "Stats - Epoch: 82 AUC-val 0.442  AUC-train 0.981\n",
            "Stats - Epoch: 83 AUC-val 0.467  AUC-train 0.982\n",
            "Stats - Epoch: 84 AUC-val 0.447  AUC-train 0.983\n",
            "Stats - Epoch: 85 AUC-val 0.456  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.458  AUC-train 0.983\n",
            "Stats - Epoch: 87 AUC-val 0.445  AUC-train 0.983\n",
            "Stats - Epoch: 88 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 89 AUC-val 0.445  AUC-train 0.980\n",
            "Stats - Epoch: 90 AUC-val 0.441  AUC-train 0.980\n",
            "Stats - Epoch: 91 AUC-val 0.465  AUC-train 0.981\n",
            "Stats - Epoch: 92 AUC-val 0.432  AUC-train 0.977\n",
            "Stats - Epoch: 93 AUC-val 0.447  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.474  AUC-train 0.978\n",
            "Stats - Epoch: 95 AUC-val 0.438  AUC-train 0.979\n",
            "Stats - Epoch: 96 AUC-val 0.436  AUC-train 0.977\n",
            "Stats - Epoch: 97 AUC-val 0.437  AUC-train 0.979\n",
            "Stats - Epoch: 98 AUC-val 0.440  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.434  AUC-train 0.976\n",
            "Stats - Epoch: 100 AUC-val 0.435  AUC-train 0.978\n",
            "Results 100 AUC-val 0.474 0.439 0.356 0.200 0.576 AUC-train 0.978\n",
            "Shapley [0.02639601 0.00839862 0.00984904 0.04017125 0.00713525] [0.03441029]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.177211\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.210  AUC-train 0.592\n",
            "Stats - Epoch: 2 AUC-val 0.188  AUC-train 0.618\n",
            "Stats - Epoch: 3 AUC-val 0.217  AUC-train 0.680\n",
            "Stats - Epoch: 4 AUC-val 0.245  AUC-train 0.729\n",
            "Stats - Epoch: 5 AUC-val 0.322  AUC-train 0.764\n",
            "Stats - Epoch: 6 AUC-val 0.319  AUC-train 0.788\n",
            "Stats - Epoch: 7 AUC-val 0.410  AUC-train 0.806\n",
            "Stats - Epoch: 8 AUC-val 0.452  AUC-train 0.815\n",
            "Stats - Epoch: 9 AUC-val 0.480  AUC-train 0.826\n",
            "Stats - Epoch: 10 AUC-val 0.467  AUC-train 0.838\n",
            "Stats - Epoch: 11 AUC-val 0.565  AUC-train 0.843\n",
            "Stats - Epoch: 12 AUC-val 0.505  AUC-train 0.850\n",
            "Stats - Epoch: 13 AUC-val 0.547  AUC-train 0.853\n",
            "Stats - Epoch: 14 AUC-val 0.550  AUC-train 0.859\n",
            "Stats - Epoch: 15 AUC-val 0.548  AUC-train 0.857\n",
            "Stats - Epoch: 16 AUC-val 0.569  AUC-train 0.860\n",
            "Stats - Epoch: 17 AUC-val 0.552  AUC-train 0.865\n",
            "Stats - Epoch: 18 AUC-val 0.537  AUC-train 0.868\n",
            "Stats - Epoch: 19 AUC-val 0.548  AUC-train 0.867\n",
            "Stats - Epoch: 20 AUC-val 0.566  AUC-train 0.873\n",
            "Stats - Epoch: 21 AUC-val 0.587  AUC-train 0.872\n",
            "Stats - Epoch: 22 AUC-val 0.572  AUC-train 0.874\n",
            "Stats - Epoch: 23 AUC-val 0.558  AUC-train 0.881\n",
            "Stats - Epoch: 24 AUC-val 0.573  AUC-train 0.879\n",
            "Stats - Epoch: 25 AUC-val 0.612  AUC-train 0.881\n",
            "Stats - Epoch: 26 AUC-val 0.602  AUC-train 0.885\n",
            "Stats - Epoch: 27 AUC-val 0.591  AUC-train 0.886\n",
            "Stats - Epoch: 28 AUC-val 0.597  AUC-train 0.888\n",
            "Stats - Epoch: 29 AUC-val 0.589  AUC-train 0.889\n",
            "Stats - Epoch: 30 AUC-val 0.593  AUC-train 0.885\n",
            "Stats - Epoch: 31 AUC-val 0.593  AUC-train 0.891\n",
            "Stats - Epoch: 32 AUC-val 0.614  AUC-train 0.894\n",
            "Stats - Epoch: 33 AUC-val 0.584  AUC-train 0.896\n",
            "Stats - Epoch: 34 AUC-val 0.610  AUC-train 0.896\n",
            "Stats - Epoch: 35 AUC-val 0.586  AUC-train 0.898\n",
            "Stats - Epoch: 36 AUC-val 0.586  AUC-train 0.900\n",
            "Stats - Epoch: 37 AUC-val 0.573  AUC-train 0.902\n",
            "Stats - Epoch: 38 AUC-val 0.602  AUC-train 0.903\n",
            "Stats - Epoch: 39 AUC-val 0.606  AUC-train 0.906\n",
            "Stats - Epoch: 40 AUC-val 0.591  AUC-train 0.906\n",
            "Stats - Epoch: 41 AUC-val 0.619  AUC-train 0.908\n",
            "Stats - Epoch: 42 AUC-val 0.600  AUC-train 0.915\n",
            "Stats - Epoch: 43 AUC-val 0.599  AUC-train 0.911\n",
            "Stats - Epoch: 44 AUC-val 0.594  AUC-train 0.913\n",
            "Stats - Epoch: 45 AUC-val 0.616  AUC-train 0.912\n",
            "Stats - Epoch: 46 AUC-val 0.594  AUC-train 0.914\n",
            "Stats - Epoch: 47 AUC-val 0.615  AUC-train 0.916\n",
            "Stats - Epoch: 48 AUC-val 0.599  AUC-train 0.916\n",
            "Stats - Epoch: 49 AUC-val 0.617  AUC-train 0.914\n",
            "Stats - Epoch: 50 AUC-val 0.608  AUC-train 0.911\n",
            "Stats - Epoch: 51 AUC-val 0.621  AUC-train 0.916\n",
            "Stats - Epoch: 52 AUC-val 0.612  AUC-train 0.917\n",
            "Stats - Epoch: 53 AUC-val 0.622  AUC-train 0.915\n",
            "Stats - Epoch: 54 AUC-val 0.614  AUC-train 0.916\n",
            "Stats - Epoch: 55 AUC-val 0.603  AUC-train 0.915\n",
            "Stats - Epoch: 56 AUC-val 0.617  AUC-train 0.918\n",
            "Stats - Epoch: 57 AUC-val 0.622  AUC-train 0.922\n",
            "Stats - Epoch: 58 AUC-val 0.641  AUC-train 0.922\n",
            "Stats - Epoch: 59 AUC-val 0.628  AUC-train 0.918\n",
            "Stats - Epoch: 60 AUC-val 0.606  AUC-train 0.924\n",
            "Stats - Epoch: 61 AUC-val 0.613  AUC-train 0.925\n",
            "Stats - Epoch: 62 AUC-val 0.598  AUC-train 0.924\n",
            "Stats - Epoch: 63 AUC-val 0.638  AUC-train 0.922\n",
            "Stats - Epoch: 64 AUC-val 0.640  AUC-train 0.917\n",
            "Stats - Epoch: 65 AUC-val 0.626  AUC-train 0.918\n",
            "Stats - Epoch: 66 AUC-val 0.618  AUC-train 0.920\n",
            "Stats - Epoch: 67 AUC-val 0.641  AUC-train 0.920\n",
            "Stats - Epoch: 68 AUC-val 0.651  AUC-train 0.925\n",
            "Stats - Epoch: 69 AUC-val 0.633  AUC-train 0.924\n",
            "Stats - Epoch: 70 AUC-val 0.606  AUC-train 0.924\n",
            "Stats - Epoch: 71 AUC-val 0.640  AUC-train 0.922\n",
            "Stats - Epoch: 72 AUC-val 0.624  AUC-train 0.922\n",
            "Stats - Epoch: 73 AUC-val 0.615  AUC-train 0.922\n",
            "Stats - Epoch: 74 AUC-val 0.620  AUC-train 0.924\n",
            "Stats - Epoch: 75 AUC-val 0.650  AUC-train 0.927\n",
            "Stats - Epoch: 76 AUC-val 0.622  AUC-train 0.928\n",
            "Stats - Epoch: 77 AUC-val 0.636  AUC-train 0.929\n",
            "Stats - Epoch: 78 AUC-val 0.634  AUC-train 0.930\n",
            "Stats - Epoch: 79 AUC-val 0.629  AUC-train 0.930\n",
            "Stats - Epoch: 80 AUC-val 0.598  AUC-train 0.927\n",
            "Stats - Epoch: 81 AUC-val 0.610  AUC-train 0.933\n",
            "Stats - Epoch: 82 AUC-val 0.607  AUC-train 0.934\n",
            "Stats - Epoch: 83 AUC-val 0.605  AUC-train 0.935\n",
            "Stats - Epoch: 84 AUC-val 0.604  AUC-train 0.936\n",
            "Stats - Epoch: 85 AUC-val 0.599  AUC-train 0.936\n",
            "Stats - Epoch: 86 AUC-val 0.601  AUC-train 0.938\n",
            "Stats - Epoch: 87 AUC-val 0.634  AUC-train 0.936\n",
            "Stats - Epoch: 88 AUC-val 0.633  AUC-train 0.932\n",
            "Stats - Epoch: 89 AUC-val 0.616  AUC-train 0.933\n",
            "Stats - Epoch: 90 AUC-val 0.564  AUC-train 0.939\n",
            "Stats - Epoch: 91 AUC-val 0.586  AUC-train 0.932\n",
            "Stats - Epoch: 92 AUC-val 0.590  AUC-train 0.938\n",
            "Stats - Epoch: 93 AUC-val 0.602  AUC-train 0.942\n",
            "Stats - Epoch: 94 AUC-val 0.586  AUC-train 0.939\n",
            "Stats - Epoch: 95 AUC-val 0.574  AUC-train 0.942\n",
            "Stats - Epoch: 96 AUC-val 0.605  AUC-train 0.939\n",
            "Stats - Epoch: 97 AUC-val 0.605  AUC-train 0.945\n",
            "Stats - Epoch: 98 AUC-val 0.593  AUC-train 0.940\n",
            "Stats - Epoch: 99 AUC-val 0.588  AUC-train 0.938\n",
            "Stats - Epoch: 100 AUC-val 0.582  AUC-train 0.938\n",
            "Results 100 AUC-val 0.651 0.617 0.591 0.545 0.632 AUC-train 0.925\n",
            "Shapley [0.01427282 0.0108813  0.01605212 0.01209641 0.0050925 ] [0.00446316]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199138\n",
            "         Iterations 7\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.376  AUC-train 0.574\n",
            "Stats - Epoch: 2 AUC-val 0.488  AUC-train 0.736\n",
            "Stats - Epoch: 3 AUC-val 0.603  AUC-train 0.808\n",
            "Stats - Epoch: 4 AUC-val 0.639  AUC-train 0.844\n",
            "Stats - Epoch: 5 AUC-val 0.653  AUC-train 0.867\n",
            "Stats - Epoch: 6 AUC-val 0.678  AUC-train 0.887\n",
            "Stats - Epoch: 7 AUC-val 0.690  AUC-train 0.903\n",
            "Stats - Epoch: 8 AUC-val 0.683  AUC-train 0.919\n",
            "Stats - Epoch: 9 AUC-val 0.702  AUC-train 0.930\n",
            "Stats - Epoch: 10 AUC-val 0.716  AUC-train 0.939\n",
            "Stats - Epoch: 11 AUC-val 0.719  AUC-train 0.949\n",
            "Stats - Epoch: 12 AUC-val 0.721  AUC-train 0.956\n",
            "Stats - Epoch: 13 AUC-val 0.723  AUC-train 0.964\n",
            "Stats - Epoch: 14 AUC-val 0.733  AUC-train 0.967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.721  AUC-train 0.974\n",
            "Stats - Epoch: 16 AUC-val 0.716  AUC-train 0.979\n",
            "Stats - Epoch: 17 AUC-val 0.710  AUC-train 0.982\n",
            "Stats - Epoch: 18 AUC-val 0.709  AUC-train 0.982\n",
            "Stats - Epoch: 19 AUC-val 0.686  AUC-train 0.985\n",
            "Stats - Epoch: 20 AUC-val 0.726  AUC-train 0.985\n",
            "Stats - Epoch: 21 AUC-val 0.737  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.716  AUC-train 0.990\n",
            "Stats - Epoch: 23 AUC-val 0.736  AUC-train 0.992\n",
            "Stats - Epoch: 24 AUC-val 0.731  AUC-train 0.992\n",
            "Stats - Epoch: 25 AUC-val 0.731  AUC-train 0.994\n",
            "Stats - Epoch: 26 AUC-val 0.743  AUC-train 0.995\n",
            "Stats - Epoch: 27 AUC-val 0.721  AUC-train 0.995\n",
            "Stats - Epoch: 28 AUC-val 0.726  AUC-train 0.995\n",
            "Stats - Epoch: 29 AUC-val 0.701  AUC-train 0.996\n",
            "Stats - Epoch: 30 AUC-val 0.713  AUC-train 0.997\n",
            "Stats - Epoch: 31 AUC-val 0.716  AUC-train 0.996\n",
            "Stats - Epoch: 32 AUC-val 0.722  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.716  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.708  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.709  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.728  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.699  AUC-train 0.993\n",
            "Stats - Epoch: 40 AUC-val 0.690  AUC-train 0.995\n",
            "Stats - Epoch: 41 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.723  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.706  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.723  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.701  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.700  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.733  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.717  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.695  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.690  AUC-train 0.996\n",
            "Stats - Epoch: 52 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.700  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.703  AUC-train 0.995\n",
            "Stats - Epoch: 58 AUC-val 0.695  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.707  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.740  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.708  AUC-train 0.998\n",
            "Stats - Epoch: 62 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.699  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.714  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.698  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.710  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.675  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.690  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.698  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.698  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.706  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.691  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.698  AUC-train 0.997\n",
            "Stats - Epoch: 76 AUC-val 0.683  AUC-train 0.997\n",
            "Stats - Epoch: 77 AUC-val 0.698  AUC-train 0.995\n",
            "Stats - Epoch: 78 AUC-val 0.686  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.707  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.702  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.701  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.739  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.700  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.698  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.688  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.717  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.689  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.692  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.680  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.722  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.689  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.668  AUC-train 0.994\n",
            "Stats - Epoch: 95 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.650  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.656  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.677  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.694  AUC-train 0.998\n",
            "Results 100 AUC-val 0.743 0.621 0.462 0.405 0.559 AUC-train 0.995\n",
            "Shapley [0.01931924 0.02078854 0.01428986 0.03983718 0.01800003] [0.01258376]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.194237\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.488  AUC-train 0.494\n",
            "Stats - Epoch: 2 AUC-val 0.547  AUC-train 0.666\n",
            "Stats - Epoch: 3 AUC-val 0.600  AUC-train 0.753\n",
            "Stats - Epoch: 4 AUC-val 0.603  AUC-train 0.796\n",
            "Stats - Epoch: 5 AUC-val 0.613  AUC-train 0.829\n",
            "Stats - Epoch: 6 AUC-val 0.610  AUC-train 0.848\n",
            "Stats - Epoch: 7 AUC-val 0.622  AUC-train 0.865\n",
            "Stats - Epoch: 8 AUC-val 0.594  AUC-train 0.878\n",
            "Stats - Epoch: 9 AUC-val 0.607  AUC-train 0.888\n",
            "Stats - Epoch: 10 AUC-val 0.606  AUC-train 0.900\n",
            "Stats - Epoch: 11 AUC-val 0.605  AUC-train 0.909\n",
            "Stats - Epoch: 12 AUC-val 0.600  AUC-train 0.918\n",
            "Stats - Epoch: 13 AUC-val 0.614  AUC-train 0.923\n",
            "Stats - Epoch: 14 AUC-val 0.602  AUC-train 0.930\n",
            "Stats - Epoch: 15 AUC-val 0.614  AUC-train 0.938\n",
            "Stats - Epoch: 16 AUC-val 0.598  AUC-train 0.946\n",
            "Stats - Epoch: 17 AUC-val 0.648  AUC-train 0.953\n",
            "Stats - Epoch: 18 AUC-val 0.662  AUC-train 0.954\n",
            "Stats - Epoch: 19 AUC-val 0.612  AUC-train 0.961\n",
            "Stats - Epoch: 20 AUC-val 0.636  AUC-train 0.968\n",
            "Stats - Epoch: 21 AUC-val 0.631  AUC-train 0.968\n",
            "Stats - Epoch: 22 AUC-val 0.611  AUC-train 0.972\n",
            "Stats - Epoch: 23 AUC-val 0.619  AUC-train 0.976\n",
            "Stats - Epoch: 24 AUC-val 0.603  AUC-train 0.979\n",
            "Stats - Epoch: 25 AUC-val 0.617  AUC-train 0.982\n",
            "Stats - Epoch: 26 AUC-val 0.617  AUC-train 0.983\n",
            "Stats - Epoch: 27 AUC-val 0.628  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.636  AUC-train 0.981\n",
            "Stats - Epoch: 29 AUC-val 0.608  AUC-train 0.985\n",
            "Stats - Epoch: 30 AUC-val 0.678  AUC-train 0.986\n",
            "Stats - Epoch: 31 AUC-val 0.645  AUC-train 0.987\n",
            "Stats - Epoch: 32 AUC-val 0.641  AUC-train 0.989\n",
            "Stats - Epoch: 33 AUC-val 0.655  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.650  AUC-train 0.989\n",
            "Stats - Epoch: 35 AUC-val 0.691  AUC-train 0.991\n",
            "Stats - Epoch: 36 AUC-val 0.655  AUC-train 0.992\n",
            "Stats - Epoch: 37 AUC-val 0.664  AUC-train 0.993\n",
            "Stats - Epoch: 38 AUC-val 0.676  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.693  AUC-train 0.991\n",
            "Stats - Epoch: 40 AUC-val 0.698  AUC-train 0.994\n",
            "Stats - Epoch: 41 AUC-val 0.673  AUC-train 0.992\n",
            "Stats - Epoch: 42 AUC-val 0.670  AUC-train 0.994\n",
            "Stats - Epoch: 43 AUC-val 0.685  AUC-train 0.995\n",
            "Stats - Epoch: 44 AUC-val 0.664  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.680  AUC-train 0.994\n",
            "Stats - Epoch: 46 AUC-val 0.694  AUC-train 0.995\n",
            "Stats - Epoch: 47 AUC-val 0.652  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.645  AUC-train 0.996\n",
            "Stats - Epoch: 49 AUC-val 0.656  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.666  AUC-train 0.991\n",
            "Stats - Epoch: 51 AUC-val 0.673  AUC-train 0.994\n",
            "Stats - Epoch: 52 AUC-val 0.663  AUC-train 0.992\n",
            "Stats - Epoch: 53 AUC-val 0.660  AUC-train 0.991\n",
            "Stats - Epoch: 54 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 55 AUC-val 0.701  AUC-train 0.992\n",
            "Stats - Epoch: 56 AUC-val 0.682  AUC-train 0.994\n",
            "Stats - Epoch: 57 AUC-val 0.679  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.683  AUC-train 0.993\n",
            "Stats - Epoch: 59 AUC-val 0.677  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.699  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.692  AUC-train 0.995\n",
            "Stats - Epoch: 62 AUC-val 0.703  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.713  AUC-train 0.995\n",
            "Stats - Epoch: 64 AUC-val 0.703  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.728  AUC-train 0.995\n",
            "Stats - Epoch: 66 AUC-val 0.694  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.717  AUC-train 0.992\n",
            "Stats - Epoch: 68 AUC-val 0.699  AUC-train 0.991\n",
            "Stats - Epoch: 69 AUC-val 0.734  AUC-train 0.995\n",
            "Stats - Epoch: 70 AUC-val 0.713  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.705  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.728  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.709  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.710  AUC-train 0.996\n",
            "Stats - Epoch: 75 AUC-val 0.723  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.697  AUC-train 0.993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.700  AUC-train 0.992\n",
            "Stats - Epoch: 78 AUC-val 0.648  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.705  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.684  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.684  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.705  AUC-train 0.991\n",
            "Stats - Epoch: 84 AUC-val 0.702  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.680  AUC-train 0.994\n",
            "Stats - Epoch: 86 AUC-val 0.673  AUC-train 0.992\n",
            "Stats - Epoch: 87 AUC-val 0.688  AUC-train 0.994\n",
            "Stats - Epoch: 88 AUC-val 0.702  AUC-train 0.995\n",
            "Stats - Epoch: 89 AUC-val 0.679  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.721  AUC-train 0.990\n",
            "Stats - Epoch: 91 AUC-val 0.653  AUC-train 0.993\n",
            "Stats - Epoch: 92 AUC-val 0.650  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.696  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.686  AUC-train 0.992\n",
            "Stats - Epoch: 95 AUC-val 0.716  AUC-train 0.992\n",
            "Stats - Epoch: 96 AUC-val 0.726  AUC-train 0.991\n",
            "Stats - Epoch: 97 AUC-val 0.688  AUC-train 0.993\n",
            "Stats - Epoch: 98 AUC-val 0.726  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.701  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.683  AUC-train 0.991\n",
            "Results 100 AUC-val 0.734 0.764 0.623 0.466 0.585 AUC-train 0.995\n",
            "Shapley [0.01235962 0.01416675 0.00769338 0.01743501 0.00556639] [0.004728]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.200182\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.377  AUC-train 0.492\n",
            "Stats - Epoch: 2 AUC-val 0.410  AUC-train 0.562\n",
            "Stats - Epoch: 3 AUC-val 0.403  AUC-train 0.612\n",
            "Stats - Epoch: 4 AUC-val 0.414  AUC-train 0.653\n",
            "Stats - Epoch: 5 AUC-val 0.404  AUC-train 0.680\n",
            "Stats - Epoch: 6 AUC-val 0.404  AUC-train 0.710\n",
            "Stats - Epoch: 7 AUC-val 0.413  AUC-train 0.724\n",
            "Stats - Epoch: 8 AUC-val 0.410  AUC-train 0.741\n",
            "Stats - Epoch: 9 AUC-val 0.418  AUC-train 0.755\n",
            "Stats - Epoch: 10 AUC-val 0.418  AUC-train 0.775\n",
            "Stats - Epoch: 11 AUC-val 0.416  AUC-train 0.781\n",
            "Stats - Epoch: 12 AUC-val 0.416  AUC-train 0.799\n",
            "Stats - Epoch: 13 AUC-val 0.426  AUC-train 0.805\n",
            "Stats - Epoch: 14 AUC-val 0.414  AUC-train 0.811\n",
            "Stats - Epoch: 15 AUC-val 0.417  AUC-train 0.819\n",
            "Stats - Epoch: 16 AUC-val 0.414  AUC-train 0.823\n",
            "Stats - Epoch: 17 AUC-val 0.431  AUC-train 0.819\n",
            "Stats - Epoch: 18 AUC-val 0.429  AUC-train 0.836\n",
            "Stats - Epoch: 19 AUC-val 0.429  AUC-train 0.837\n",
            "Stats - Epoch: 20 AUC-val 0.434  AUC-train 0.840\n",
            "Stats - Epoch: 21 AUC-val 0.444  AUC-train 0.847\n",
            "Stats - Epoch: 22 AUC-val 0.448  AUC-train 0.848\n",
            "Stats - Epoch: 23 AUC-val 0.443  AUC-train 0.854\n",
            "Stats - Epoch: 24 AUC-val 0.447  AUC-train 0.859\n",
            "Stats - Epoch: 25 AUC-val 0.453  AUC-train 0.855\n",
            "Stats - Epoch: 26 AUC-val 0.447  AUC-train 0.858\n",
            "Stats - Epoch: 27 AUC-val 0.449  AUC-train 0.860\n",
            "Stats - Epoch: 28 AUC-val 0.458  AUC-train 0.855\n",
            "Stats - Epoch: 29 AUC-val 0.448  AUC-train 0.855\n",
            "Stats - Epoch: 30 AUC-val 0.450  AUC-train 0.866\n",
            "Stats - Epoch: 31 AUC-val 0.453  AUC-train 0.870\n",
            "Stats - Epoch: 32 AUC-val 0.455  AUC-train 0.866\n",
            "Stats - Epoch: 33 AUC-val 0.456  AUC-train 0.867\n",
            "Stats - Epoch: 34 AUC-val 0.460  AUC-train 0.863\n",
            "Stats - Epoch: 35 AUC-val 0.457  AUC-train 0.870\n",
            "Stats - Epoch: 36 AUC-val 0.459  AUC-train 0.870\n",
            "Stats - Epoch: 37 AUC-val 0.455  AUC-train 0.872\n",
            "Stats - Epoch: 38 AUC-val 0.459  AUC-train 0.873\n",
            "Stats - Epoch: 39 AUC-val 0.459  AUC-train 0.875\n",
            "Stats - Epoch: 40 AUC-val 0.458  AUC-train 0.878\n",
            "Stats - Epoch: 41 AUC-val 0.460  AUC-train 0.876\n",
            "Stats - Epoch: 42 AUC-val 0.462  AUC-train 0.872\n",
            "Stats - Epoch: 43 AUC-val 0.464  AUC-train 0.872\n",
            "Stats - Epoch: 44 AUC-val 0.465  AUC-train 0.871\n",
            "Stats - Epoch: 45 AUC-val 0.460  AUC-train 0.878\n",
            "Stats - Epoch: 46 AUC-val 0.459  AUC-train 0.878\n",
            "Stats - Epoch: 47 AUC-val 0.472  AUC-train 0.879\n",
            "Stats - Epoch: 48 AUC-val 0.457  AUC-train 0.878\n",
            "Stats - Epoch: 49 AUC-val 0.464  AUC-train 0.877\n",
            "Stats - Epoch: 50 AUC-val 0.456  AUC-train 0.884\n",
            "Stats - Epoch: 51 AUC-val 0.454  AUC-train 0.882\n",
            "Stats - Epoch: 52 AUC-val 0.457  AUC-train 0.876\n",
            "Stats - Epoch: 53 AUC-val 0.468  AUC-train 0.885\n",
            "Stats - Epoch: 54 AUC-val 0.462  AUC-train 0.887\n",
            "Stats - Epoch: 55 AUC-val 0.450  AUC-train 0.886\n",
            "Stats - Epoch: 56 AUC-val 0.464  AUC-train 0.880\n",
            "Stats - Epoch: 57 AUC-val 0.471  AUC-train 0.888\n",
            "Stats - Epoch: 58 AUC-val 0.474  AUC-train 0.884\n",
            "Stats - Epoch: 59 AUC-val 0.464  AUC-train 0.883\n",
            "Stats - Epoch: 60 AUC-val 0.466  AUC-train 0.888\n",
            "Stats - Epoch: 61 AUC-val 0.461  AUC-train 0.889\n",
            "Stats - Epoch: 62 AUC-val 0.475  AUC-train 0.892\n",
            "Stats - Epoch: 63 AUC-val 0.473  AUC-train 0.892\n",
            "Stats - Epoch: 64 AUC-val 0.461  AUC-train 0.885\n",
            "Stats - Epoch: 65 AUC-val 0.467  AUC-train 0.894\n",
            "Stats - Epoch: 66 AUC-val 0.459  AUC-train 0.894\n",
            "Stats - Epoch: 67 AUC-val 0.471  AUC-train 0.894\n",
            "Stats - Epoch: 68 AUC-val 0.477  AUC-train 0.888\n",
            "Stats - Epoch: 69 AUC-val 0.480  AUC-train 0.894\n",
            "Stats - Epoch: 70 AUC-val 0.470  AUC-train 0.897\n",
            "Stats - Epoch: 71 AUC-val 0.480  AUC-train 0.891\n",
            "Stats - Epoch: 72 AUC-val 0.480  AUC-train 0.892\n",
            "Stats - Epoch: 73 AUC-val 0.477  AUC-train 0.885\n",
            "Stats - Epoch: 74 AUC-val 0.471  AUC-train 0.889\n",
            "Stats - Epoch: 75 AUC-val 0.475  AUC-train 0.892\n",
            "Stats - Epoch: 76 AUC-val 0.470  AUC-train 0.893\n",
            "Stats - Epoch: 77 AUC-val 0.466  AUC-train 0.894\n",
            "Stats - Epoch: 78 AUC-val 0.476  AUC-train 0.892\n",
            "Stats - Epoch: 79 AUC-val 0.462  AUC-train 0.897\n",
            "Stats - Epoch: 80 AUC-val 0.470  AUC-train 0.897\n",
            "Stats - Epoch: 81 AUC-val 0.469  AUC-train 0.898\n",
            "Stats - Epoch: 82 AUC-val 0.472  AUC-train 0.898\n",
            "Stats - Epoch: 83 AUC-val 0.467  AUC-train 0.899\n",
            "Stats - Epoch: 84 AUC-val 0.468  AUC-train 0.892\n",
            "Stats - Epoch: 85 AUC-val 0.472  AUC-train 0.894\n",
            "Stats - Epoch: 86 AUC-val 0.466  AUC-train 0.900\n",
            "Stats - Epoch: 87 AUC-val 0.479  AUC-train 0.896\n",
            "Stats - Epoch: 88 AUC-val 0.477  AUC-train 0.900\n",
            "Stats - Epoch: 89 AUC-val 0.477  AUC-train 0.903\n",
            "Stats - Epoch: 90 AUC-val 0.471  AUC-train 0.893\n",
            "Stats - Epoch: 91 AUC-val 0.470  AUC-train 0.901\n",
            "Stats - Epoch: 92 AUC-val 0.473  AUC-train 0.893\n",
            "Stats - Epoch: 93 AUC-val 0.476  AUC-train 0.900\n",
            "Stats - Epoch: 94 AUC-val 0.469  AUC-train 0.901\n",
            "Stats - Epoch: 95 AUC-val 0.486  AUC-train 0.894\n",
            "Stats - Epoch: 96 AUC-val 0.474  AUC-train 0.903\n",
            "Stats - Epoch: 97 AUC-val 0.478  AUC-train 0.900\n",
            "Stats - Epoch: 98 AUC-val 0.477  AUC-train 0.902\n",
            "Stats - Epoch: 99 AUC-val 0.483  AUC-train 0.900\n",
            "Stats - Epoch: 100 AUC-val 0.481  AUC-train 0.902\n",
            "Results 100 AUC-val 0.486 0.527 0.567 0.498 0.621 AUC-train 0.894\n",
            "Shapley [0.00757087 0.00703212 0.01756765 0.01005684 0.00361326] [0.02069161]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.190348\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.245  AUC-train 0.595\n",
            "Stats - Epoch: 2 AUC-val 0.348  AUC-train 0.775\n",
            "Stats - Epoch: 3 AUC-val 0.371  AUC-train 0.858\n",
            "Stats - Epoch: 4 AUC-val 0.375  AUC-train 0.904\n",
            "Stats - Epoch: 5 AUC-val 0.361  AUC-train 0.929\n",
            "Stats - Epoch: 6 AUC-val 0.342  AUC-train 0.950\n",
            "Stats - Epoch: 7 AUC-val 0.348  AUC-train 0.959\n",
            "Stats - Epoch: 8 AUC-val 0.329  AUC-train 0.964\n",
            "Stats - Epoch: 9 AUC-val 0.346  AUC-train 0.974\n",
            "Stats - Epoch: 10 AUC-val 0.379  AUC-train 0.973\n",
            "Stats - Epoch: 11 AUC-val 0.349  AUC-train 0.981\n",
            "Stats - Epoch: 12 AUC-val 0.365  AUC-train 0.986\n",
            "Stats - Epoch: 13 AUC-val 0.359  AUC-train 0.986\n",
            "Stats - Epoch: 14 AUC-val 0.358  AUC-train 0.986\n",
            "Stats - Epoch: 15 AUC-val 0.349  AUC-train 0.988\n",
            "Stats - Epoch: 16 AUC-val 0.363  AUC-train 0.988\n",
            "Stats - Epoch: 17 AUC-val 0.365  AUC-train 0.984\n",
            "Stats - Epoch: 18 AUC-val 0.389  AUC-train 0.982\n",
            "Stats - Epoch: 19 AUC-val 0.388  AUC-train 0.989\n",
            "Stats - Epoch: 20 AUC-val 0.362  AUC-train 0.982\n",
            "Stats - Epoch: 21 AUC-val 0.376  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.381  AUC-train 0.985\n",
            "Stats - Epoch: 23 AUC-val 0.379  AUC-train 0.988\n",
            "Stats - Epoch: 24 AUC-val 0.383  AUC-train 0.986\n",
            "Stats - Epoch: 25 AUC-val 0.394  AUC-train 0.986\n",
            "Stats - Epoch: 26 AUC-val 0.388  AUC-train 0.987\n",
            "Stats - Epoch: 27 AUC-val 0.410  AUC-train 0.988\n",
            "Stats - Epoch: 28 AUC-val 0.413  AUC-train 0.987\n",
            "Stats - Epoch: 29 AUC-val 0.397  AUC-train 0.986\n",
            "Stats - Epoch: 30 AUC-val 0.421  AUC-train 0.986\n",
            "Stats - Epoch: 31 AUC-val 0.418  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.425  AUC-train 0.990\n",
            "Stats - Epoch: 33 AUC-val 0.393  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.436  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.416  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.430  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.419  AUC-train 0.989\n",
            "Stats - Epoch: 38 AUC-val 0.426  AUC-train 0.987\n",
            "Stats - Epoch: 39 AUC-val 0.417  AUC-train 0.988\n",
            "Stats - Epoch: 40 AUC-val 0.452  AUC-train 0.985\n",
            "Stats - Epoch: 41 AUC-val 0.443  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.427  AUC-train 0.984\n",
            "Stats - Epoch: 43 AUC-val 0.444  AUC-train 0.978\n",
            "Stats - Epoch: 44 AUC-val 0.431  AUC-train 0.983\n",
            "Stats - Epoch: 45 AUC-val 0.447  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.447  AUC-train 0.987\n",
            "Stats - Epoch: 47 AUC-val 0.438  AUC-train 0.987\n",
            "Stats - Epoch: 48 AUC-val 0.456  AUC-train 0.984\n",
            "Stats - Epoch: 49 AUC-val 0.417  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.433  AUC-train 0.982\n",
            "Stats - Epoch: 51 AUC-val 0.438  AUC-train 0.984\n",
            "Stats - Epoch: 52 AUC-val 0.430  AUC-train 0.984\n",
            "Stats - Epoch: 53 AUC-val 0.429  AUC-train 0.985\n",
            "Stats - Epoch: 54 AUC-val 0.441  AUC-train 0.984\n",
            "Stats - Epoch: 55 AUC-val 0.470  AUC-train 0.984\n",
            "Stats - Epoch: 56 AUC-val 0.440  AUC-train 0.984\n",
            "Stats - Epoch: 57 AUC-val 0.451  AUC-train 0.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.442  AUC-train 0.983\n",
            "Stats - Epoch: 59 AUC-val 0.468  AUC-train 0.979\n",
            "Stats - Epoch: 60 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 61 AUC-val 0.466  AUC-train 0.982\n",
            "Stats - Epoch: 62 AUC-val 0.448  AUC-train 0.984\n",
            "Stats - Epoch: 63 AUC-val 0.444  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.436  AUC-train 0.977\n",
            "Stats - Epoch: 65 AUC-val 0.429  AUC-train 0.977\n",
            "Stats - Epoch: 66 AUC-val 0.443  AUC-train 0.981\n",
            "Stats - Epoch: 67 AUC-val 0.442  AUC-train 0.980\n",
            "Stats - Epoch: 68 AUC-val 0.440  AUC-train 0.979\n",
            "Stats - Epoch: 69 AUC-val 0.450  AUC-train 0.983\n",
            "Stats - Epoch: 70 AUC-val 0.454  AUC-train 0.983\n",
            "Stats - Epoch: 71 AUC-val 0.449  AUC-train 0.983\n",
            "Stats - Epoch: 72 AUC-val 0.443  AUC-train 0.978\n",
            "Stats - Epoch: 73 AUC-val 0.462  AUC-train 0.977\n",
            "Stats - Epoch: 74 AUC-val 0.447  AUC-train 0.978\n",
            "Stats - Epoch: 75 AUC-val 0.456  AUC-train 0.973\n",
            "Stats - Epoch: 76 AUC-val 0.466  AUC-train 0.979\n",
            "Stats - Epoch: 77 AUC-val 0.484  AUC-train 0.981\n",
            "Stats - Epoch: 78 AUC-val 0.476  AUC-train 0.980\n",
            "Stats - Epoch: 79 AUC-val 0.446  AUC-train 0.982\n",
            "Stats - Epoch: 80 AUC-val 0.444  AUC-train 0.980\n",
            "Stats - Epoch: 81 AUC-val 0.429  AUC-train 0.980\n",
            "Stats - Epoch: 82 AUC-val 0.448  AUC-train 0.981\n",
            "Stats - Epoch: 83 AUC-val 0.451  AUC-train 0.981\n",
            "Stats - Epoch: 84 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 85 AUC-val 0.467  AUC-train 0.983\n",
            "Stats - Epoch: 86 AUC-val 0.458  AUC-train 0.979\n",
            "Stats - Epoch: 87 AUC-val 0.458  AUC-train 0.982\n",
            "Stats - Epoch: 88 AUC-val 0.459  AUC-train 0.981\n",
            "Stats - Epoch: 89 AUC-val 0.433  AUC-train 0.975\n",
            "Stats - Epoch: 90 AUC-val 0.436  AUC-train 0.981\n",
            "Stats - Epoch: 91 AUC-val 0.467  AUC-train 0.981\n",
            "Stats - Epoch: 92 AUC-val 0.445  AUC-train 0.977\n",
            "Stats - Epoch: 93 AUC-val 0.449  AUC-train 0.985\n",
            "Stats - Epoch: 94 AUC-val 0.442  AUC-train 0.978\n",
            "Stats - Epoch: 95 AUC-val 0.409  AUC-train 0.978\n",
            "Stats - Epoch: 96 AUC-val 0.438  AUC-train 0.974\n",
            "Stats - Epoch: 97 AUC-val 0.431  AUC-train 0.980\n",
            "Stats - Epoch: 98 AUC-val 0.436  AUC-train 0.980\n",
            "Stats - Epoch: 99 AUC-val 0.433  AUC-train 0.970\n",
            "Stats - Epoch: 100 AUC-val 0.425  AUC-train 0.976\n",
            "Results 100 AUC-val 0.484 0.442 0.296 0.175 0.547 AUC-train 0.981\n",
            "Shapley [0.02752976 0.00907663 0.0097221  0.04056727 0.00832075] [0.03921477]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.181049\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.229  AUC-train 0.588\n",
            "Stats - Epoch: 2 AUC-val 0.192  AUC-train 0.635\n",
            "Stats - Epoch: 3 AUC-val 0.211  AUC-train 0.696\n",
            "Stats - Epoch: 4 AUC-val 0.274  AUC-train 0.741\n",
            "Stats - Epoch: 5 AUC-val 0.352  AUC-train 0.781\n",
            "Stats - Epoch: 6 AUC-val 0.382  AUC-train 0.805\n",
            "Stats - Epoch: 7 AUC-val 0.403  AUC-train 0.820\n",
            "Stats - Epoch: 8 AUC-val 0.476  AUC-train 0.835\n",
            "Stats - Epoch: 9 AUC-val 0.504  AUC-train 0.840\n",
            "Stats - Epoch: 10 AUC-val 0.519  AUC-train 0.847\n",
            "Stats - Epoch: 11 AUC-val 0.525  AUC-train 0.857\n",
            "Stats - Epoch: 12 AUC-val 0.555  AUC-train 0.860\n",
            "Stats - Epoch: 13 AUC-val 0.550  AUC-train 0.861\n",
            "Stats - Epoch: 14 AUC-val 0.545  AUC-train 0.865\n",
            "Stats - Epoch: 15 AUC-val 0.541  AUC-train 0.870\n",
            "Stats - Epoch: 16 AUC-val 0.581  AUC-train 0.874\n",
            "Stats - Epoch: 17 AUC-val 0.533  AUC-train 0.879\n",
            "Stats - Epoch: 18 AUC-val 0.566  AUC-train 0.880\n",
            "Stats - Epoch: 19 AUC-val 0.548  AUC-train 0.887\n",
            "Stats - Epoch: 20 AUC-val 0.560  AUC-train 0.889\n",
            "Stats - Epoch: 21 AUC-val 0.538  AUC-train 0.888\n",
            "Stats - Epoch: 22 AUC-val 0.559  AUC-train 0.890\n",
            "Stats - Epoch: 23 AUC-val 0.537  AUC-train 0.901\n",
            "Stats - Epoch: 24 AUC-val 0.590  AUC-train 0.899\n",
            "Stats - Epoch: 25 AUC-val 0.540  AUC-train 0.895\n",
            "Stats - Epoch: 26 AUC-val 0.542  AUC-train 0.898\n",
            "Stats - Epoch: 27 AUC-val 0.544  AUC-train 0.903\n",
            "Stats - Epoch: 28 AUC-val 0.521  AUC-train 0.903\n",
            "Stats - Epoch: 29 AUC-val 0.526  AUC-train 0.906\n",
            "Stats - Epoch: 30 AUC-val 0.557  AUC-train 0.909\n",
            "Stats - Epoch: 31 AUC-val 0.553  AUC-train 0.913\n",
            "Stats - Epoch: 32 AUC-val 0.536  AUC-train 0.915\n",
            "Stats - Epoch: 33 AUC-val 0.547  AUC-train 0.917\n",
            "Stats - Epoch: 34 AUC-val 0.558  AUC-train 0.909\n",
            "Stats - Epoch: 35 AUC-val 0.580  AUC-train 0.912\n",
            "Stats - Epoch: 36 AUC-val 0.564  AUC-train 0.913\n",
            "Stats - Epoch: 37 AUC-val 0.527  AUC-train 0.919\n",
            "Stats - Epoch: 38 AUC-val 0.569  AUC-train 0.915\n",
            "Stats - Epoch: 39 AUC-val 0.568  AUC-train 0.921\n",
            "Stats - Epoch: 40 AUC-val 0.584  AUC-train 0.925\n",
            "Stats - Epoch: 41 AUC-val 0.580  AUC-train 0.921\n",
            "Stats - Epoch: 42 AUC-val 0.576  AUC-train 0.923\n",
            "Stats - Epoch: 43 AUC-val 0.563  AUC-train 0.922\n",
            "Stats - Epoch: 44 AUC-val 0.626  AUC-train 0.920\n",
            "Stats - Epoch: 45 AUC-val 0.624  AUC-train 0.926\n",
            "Stats - Epoch: 46 AUC-val 0.621  AUC-train 0.928\n",
            "Stats - Epoch: 47 AUC-val 0.571  AUC-train 0.930\n",
            "Stats - Epoch: 48 AUC-val 0.571  AUC-train 0.933\n",
            "Stats - Epoch: 49 AUC-val 0.584  AUC-train 0.934\n",
            "Stats - Epoch: 50 AUC-val 0.530  AUC-train 0.932\n",
            "Stats - Epoch: 51 AUC-val 0.559  AUC-train 0.932\n",
            "Stats - Epoch: 52 AUC-val 0.612  AUC-train 0.934\n",
            "Stats - Epoch: 53 AUC-val 0.572  AUC-train 0.936\n",
            "Stats - Epoch: 54 AUC-val 0.631  AUC-train 0.934\n",
            "Stats - Epoch: 55 AUC-val 0.567  AUC-train 0.936\n",
            "Stats - Epoch: 56 AUC-val 0.568  AUC-train 0.932\n",
            "Stats - Epoch: 57 AUC-val 0.543  AUC-train 0.933\n",
            "Stats - Epoch: 58 AUC-val 0.572  AUC-train 0.933\n",
            "Stats - Epoch: 59 AUC-val 0.555  AUC-train 0.931\n",
            "Stats - Epoch: 60 AUC-val 0.568  AUC-train 0.940\n",
            "Stats - Epoch: 61 AUC-val 0.567  AUC-train 0.943\n",
            "Stats - Epoch: 62 AUC-val 0.559  AUC-train 0.943\n",
            "Stats - Epoch: 63 AUC-val 0.531  AUC-train 0.945\n",
            "Stats - Epoch: 64 AUC-val 0.538  AUC-train 0.938\n",
            "Stats - Epoch: 65 AUC-val 0.546  AUC-train 0.939\n",
            "Stats - Epoch: 66 AUC-val 0.546  AUC-train 0.939\n",
            "Stats - Epoch: 67 AUC-val 0.569  AUC-train 0.937\n",
            "Stats - Epoch: 68 AUC-val 0.559  AUC-train 0.942\n",
            "Stats - Epoch: 69 AUC-val 0.546  AUC-train 0.946\n",
            "Stats - Epoch: 70 AUC-val 0.557  AUC-train 0.945\n",
            "Stats - Epoch: 71 AUC-val 0.558  AUC-train 0.942\n",
            "Stats - Epoch: 72 AUC-val 0.553  AUC-train 0.941\n",
            "Stats - Epoch: 73 AUC-val 0.577  AUC-train 0.942\n",
            "Stats - Epoch: 74 AUC-val 0.555  AUC-train 0.943\n",
            "Stats - Epoch: 75 AUC-val 0.561  AUC-train 0.942\n",
            "Stats - Epoch: 76 AUC-val 0.555  AUC-train 0.939\n",
            "Stats - Epoch: 77 AUC-val 0.557  AUC-train 0.942\n",
            "Stats - Epoch: 78 AUC-val 0.575  AUC-train 0.944\n",
            "Stats - Epoch: 79 AUC-val 0.617  AUC-train 0.944\n",
            "Stats - Epoch: 80 AUC-val 0.563  AUC-train 0.948\n",
            "Stats - Epoch: 81 AUC-val 0.604  AUC-train 0.947\n",
            "Stats - Epoch: 82 AUC-val 0.578  AUC-train 0.948\n",
            "Stats - Epoch: 83 AUC-val 0.582  AUC-train 0.947\n",
            "Stats - Epoch: 84 AUC-val 0.568  AUC-train 0.949\n",
            "Stats - Epoch: 85 AUC-val 0.596  AUC-train 0.945\n",
            "Stats - Epoch: 86 AUC-val 0.601  AUC-train 0.945\n",
            "Stats - Epoch: 87 AUC-val 0.587  AUC-train 0.945\n",
            "Stats - Epoch: 88 AUC-val 0.545  AUC-train 0.943\n",
            "Stats - Epoch: 89 AUC-val 0.563  AUC-train 0.949\n",
            "Stats - Epoch: 90 AUC-val 0.555  AUC-train 0.950\n",
            "Stats - Epoch: 91 AUC-val 0.563  AUC-train 0.950\n",
            "Stats - Epoch: 92 AUC-val 0.562  AUC-train 0.952\n",
            "Stats - Epoch: 93 AUC-val 0.602  AUC-train 0.952\n",
            "Stats - Epoch: 94 AUC-val 0.588  AUC-train 0.951\n",
            "Stats - Epoch: 95 AUC-val 0.590  AUC-train 0.951\n",
            "Stats - Epoch: 96 AUC-val 0.563  AUC-train 0.949\n",
            "Stats - Epoch: 97 AUC-val 0.560  AUC-train 0.949\n",
            "Stats - Epoch: 98 AUC-val 0.567  AUC-train 0.949\n",
            "Stats - Epoch: 99 AUC-val 0.564  AUC-train 0.950\n",
            "Stats - Epoch: 100 AUC-val 0.557  AUC-train 0.949\n",
            "Results 100 AUC-val 0.631 0.665 0.625 0.578 0.684 AUC-train 0.934\n",
            "Shapley [0.01805088 0.01387136 0.01806454 0.01343745 0.00605373] [0.00384057]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.193483\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.394  AUC-train 0.611\n",
            "Stats - Epoch: 2 AUC-val 0.511  AUC-train 0.760\n",
            "Stats - Epoch: 3 AUC-val 0.593  AUC-train 0.821\n",
            "Stats - Epoch: 4 AUC-val 0.625  AUC-train 0.853\n",
            "Stats - Epoch: 5 AUC-val 0.655  AUC-train 0.876\n",
            "Stats - Epoch: 6 AUC-val 0.676  AUC-train 0.897\n",
            "Stats - Epoch: 7 AUC-val 0.698  AUC-train 0.910\n",
            "Stats - Epoch: 8 AUC-val 0.714  AUC-train 0.923\n",
            "Stats - Epoch: 9 AUC-val 0.716  AUC-train 0.937\n",
            "Stats - Epoch: 10 AUC-val 0.717  AUC-train 0.947\n",
            "Stats - Epoch: 11 AUC-val 0.708  AUC-train 0.954\n",
            "Stats - Epoch: 12 AUC-val 0.721  AUC-train 0.961\n",
            "Stats - Epoch: 13 AUC-val 0.724  AUC-train 0.970\n",
            "Stats - Epoch: 14 AUC-val 0.727  AUC-train 0.972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.737  AUC-train 0.979\n",
            "Stats - Epoch: 16 AUC-val 0.739  AUC-train 0.981\n",
            "Stats - Epoch: 17 AUC-val 0.694  AUC-train 0.984\n",
            "Stats - Epoch: 18 AUC-val 0.717  AUC-train 0.988\n",
            "Stats - Epoch: 19 AUC-val 0.716  AUC-train 0.989\n",
            "Stats - Epoch: 20 AUC-val 0.714  AUC-train 0.988\n",
            "Stats - Epoch: 21 AUC-val 0.714  AUC-train 0.991\n",
            "Stats - Epoch: 22 AUC-val 0.705  AUC-train 0.992\n",
            "Stats - Epoch: 23 AUC-val 0.677  AUC-train 0.993\n",
            "Stats - Epoch: 24 AUC-val 0.705  AUC-train 0.992\n",
            "Stats - Epoch: 25 AUC-val 0.685  AUC-train 0.992\n",
            "Stats - Epoch: 26 AUC-val 0.696  AUC-train 0.993\n",
            "Stats - Epoch: 27 AUC-val 0.704  AUC-train 0.996\n",
            "Stats - Epoch: 28 AUC-val 0.681  AUC-train 0.997\n",
            "Stats - Epoch: 29 AUC-val 0.722  AUC-train 0.996\n",
            "Stats - Epoch: 30 AUC-val 0.693  AUC-train 0.997\n",
            "Stats - Epoch: 31 AUC-val 0.654  AUC-train 0.997\n",
            "Stats - Epoch: 32 AUC-val 0.687  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.691  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.680  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.696  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.696  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.655  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 42 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.684  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.698  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.722  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.677  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.682  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.696  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.684  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.690  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.679  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.675  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.660  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 63 AUC-val 0.693  AUC-train 0.998\n",
            "Stats - Epoch: 64 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 65 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.691  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 68 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.692  AUC-train 0.998\n",
            "Stats - Epoch: 71 AUC-val 0.709  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 73 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 75 AUC-val 0.677  AUC-train 1.000\n",
            "Stats - Epoch: 76 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 77 AUC-val 0.709  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.702  AUC-train 0.996\n",
            "Stats - Epoch: 80 AUC-val 0.707  AUC-train 0.996\n",
            "Stats - Epoch: 81 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.697  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.683  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.669  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.672  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.665  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.696  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.686  AUC-train 1.000\n",
            "Stats - Epoch: 96 AUC-val 0.691  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.677  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.679  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.671  AUC-train 0.998\n",
            "Results 100 AUC-val 0.739 0.608 0.479 0.443 0.590 AUC-train 0.981\n",
            "Shapley [0.01882449 0.02006426 0.01634493 0.03028341 0.01329713] [0.01006485]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197668\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.546  AUC-train 0.516\n",
            "Stats - Epoch: 2 AUC-val 0.571  AUC-train 0.687\n",
            "Stats - Epoch: 3 AUC-val 0.576  AUC-train 0.774\n",
            "Stats - Epoch: 4 AUC-val 0.577  AUC-train 0.819\n",
            "Stats - Epoch: 5 AUC-val 0.572  AUC-train 0.844\n",
            "Stats - Epoch: 6 AUC-val 0.574  AUC-train 0.860\n",
            "Stats - Epoch: 7 AUC-val 0.566  AUC-train 0.877\n",
            "Stats - Epoch: 8 AUC-val 0.573  AUC-train 0.891\n",
            "Stats - Epoch: 9 AUC-val 0.564  AUC-train 0.901\n",
            "Stats - Epoch: 10 AUC-val 0.548  AUC-train 0.912\n",
            "Stats - Epoch: 11 AUC-val 0.558  AUC-train 0.923\n",
            "Stats - Epoch: 12 AUC-val 0.555  AUC-train 0.929\n",
            "Stats - Epoch: 13 AUC-val 0.558  AUC-train 0.938\n",
            "Stats - Epoch: 14 AUC-val 0.565  AUC-train 0.948\n",
            "Stats - Epoch: 15 AUC-val 0.540  AUC-train 0.956\n",
            "Stats - Epoch: 16 AUC-val 0.546  AUC-train 0.959\n",
            "Stats - Epoch: 17 AUC-val 0.564  AUC-train 0.963\n",
            "Stats - Epoch: 18 AUC-val 0.579  AUC-train 0.970\n",
            "Stats - Epoch: 19 AUC-val 0.554  AUC-train 0.974\n",
            "Stats - Epoch: 20 AUC-val 0.578  AUC-train 0.976\n",
            "Stats - Epoch: 21 AUC-val 0.568  AUC-train 0.977\n",
            "Stats - Epoch: 22 AUC-val 0.589  AUC-train 0.981\n",
            "Stats - Epoch: 23 AUC-val 0.572  AUC-train 0.984\n",
            "Stats - Epoch: 24 AUC-val 0.621  AUC-train 0.985\n",
            "Stats - Epoch: 25 AUC-val 0.598  AUC-train 0.986\n",
            "Stats - Epoch: 26 AUC-val 0.619  AUC-train 0.987\n",
            "Stats - Epoch: 27 AUC-val 0.609  AUC-train 0.988\n",
            "Stats - Epoch: 28 AUC-val 0.640  AUC-train 0.991\n",
            "Stats - Epoch: 29 AUC-val 0.629  AUC-train 0.993\n",
            "Stats - Epoch: 30 AUC-val 0.640  AUC-train 0.994\n",
            "Stats - Epoch: 31 AUC-val 0.647  AUC-train 0.995\n",
            "Stats - Epoch: 32 AUC-val 0.685  AUC-train 0.994\n",
            "Stats - Epoch: 33 AUC-val 0.642  AUC-train 0.995\n",
            "Stats - Epoch: 34 AUC-val 0.660  AUC-train 0.995\n",
            "Stats - Epoch: 35 AUC-val 0.638  AUC-train 0.995\n",
            "Stats - Epoch: 36 AUC-val 0.654  AUC-train 0.996\n",
            "Stats - Epoch: 37 AUC-val 0.660  AUC-train 0.996\n",
            "Stats - Epoch: 38 AUC-val 0.668  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.593  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.622  AUC-train 0.996\n",
            "Stats - Epoch: 41 AUC-val 0.632  AUC-train 0.993\n",
            "Stats - Epoch: 42 AUC-val 0.651  AUC-train 0.993\n",
            "Stats - Epoch: 43 AUC-val 0.648  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.633  AUC-train 0.995\n",
            "Stats - Epoch: 45 AUC-val 0.615  AUC-train 0.995\n",
            "Stats - Epoch: 46 AUC-val 0.634  AUC-train 0.994\n",
            "Stats - Epoch: 47 AUC-val 0.654  AUC-train 0.994\n",
            "Stats - Epoch: 48 AUC-val 0.629  AUC-train 0.994\n",
            "Stats - Epoch: 49 AUC-val 0.630  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.702  AUC-train 0.996\n",
            "Stats - Epoch: 51 AUC-val 0.659  AUC-train 0.996\n",
            "Stats - Epoch: 52 AUC-val 0.691  AUC-train 0.996\n",
            "Stats - Epoch: 53 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.683  AUC-train 0.995\n",
            "Stats - Epoch: 55 AUC-val 0.649  AUC-train 0.994\n",
            "Stats - Epoch: 56 AUC-val 0.639  AUC-train 0.992\n",
            "Stats - Epoch: 57 AUC-val 0.658  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.648  AUC-train 0.996\n",
            "Stats - Epoch: 59 AUC-val 0.621  AUC-train 0.997\n",
            "Stats - Epoch: 60 AUC-val 0.670  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.657  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.666  AUC-train 0.988\n",
            "Stats - Epoch: 64 AUC-val 0.658  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.682  AUC-train 0.994\n",
            "Stats - Epoch: 67 AUC-val 0.662  AUC-train 0.996\n",
            "Stats - Epoch: 68 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.636  AUC-train 0.998\n",
            "Stats - Epoch: 70 AUC-val 0.633  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.627  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.659  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.637  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.650  AUC-train 0.994\n",
            "Stats - Epoch: 75 AUC-val 0.638  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.634  AUC-train 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.660  AUC-train 0.994\n",
            "Stats - Epoch: 78 AUC-val 0.673  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.682  AUC-train 0.993\n",
            "Stats - Epoch: 80 AUC-val 0.648  AUC-train 0.989\n",
            "Stats - Epoch: 81 AUC-val 0.648  AUC-train 0.993\n",
            "Stats - Epoch: 82 AUC-val 0.647  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.667  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.669  AUC-train 0.992\n",
            "Stats - Epoch: 85 AUC-val 0.665  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.662  AUC-train 0.997\n",
            "Stats - Epoch: 87 AUC-val 0.658  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.645  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.665  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.639  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.652  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.664  AUC-train 0.990\n",
            "Stats - Epoch: 94 AUC-val 0.663  AUC-train 0.997\n",
            "Stats - Epoch: 95 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.667  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.672  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.671  AUC-train 0.994\n",
            "Stats - Epoch: 100 AUC-val 0.669  AUC-train 0.994\n",
            "Results 100 AUC-val 0.702 0.734 0.662 0.527 0.597 AUC-train 0.996\n",
            "Shapley [0.01331641 0.01883159 0.00954738 0.02145506 0.00726068] [0.00488549]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.202515\n",
            "         Iterations 7\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.346  AUC-train 0.496\n",
            "Stats - Epoch: 2 AUC-val 0.364  AUC-train 0.586\n",
            "Stats - Epoch: 3 AUC-val 0.403  AUC-train 0.635\n",
            "Stats - Epoch: 4 AUC-val 0.421  AUC-train 0.681\n",
            "Stats - Epoch: 5 AUC-val 0.445  AUC-train 0.698\n",
            "Stats - Epoch: 6 AUC-val 0.442  AUC-train 0.728\n",
            "Stats - Epoch: 7 AUC-val 0.427  AUC-train 0.751\n",
            "Stats - Epoch: 8 AUC-val 0.441  AUC-train 0.754\n",
            "Stats - Epoch: 9 AUC-val 0.428  AUC-train 0.767\n",
            "Stats - Epoch: 10 AUC-val 0.425  AUC-train 0.790\n",
            "Stats - Epoch: 11 AUC-val 0.436  AUC-train 0.789\n",
            "Stats - Epoch: 12 AUC-val 0.424  AUC-train 0.811\n",
            "Stats - Epoch: 13 AUC-val 0.425  AUC-train 0.814\n",
            "Stats - Epoch: 14 AUC-val 0.419  AUC-train 0.823\n",
            "Stats - Epoch: 15 AUC-val 0.431  AUC-train 0.824\n",
            "Stats - Epoch: 16 AUC-val 0.432  AUC-train 0.833\n",
            "Stats - Epoch: 17 AUC-val 0.436  AUC-train 0.830\n",
            "Stats - Epoch: 18 AUC-val 0.434  AUC-train 0.840\n",
            "Stats - Epoch: 19 AUC-val 0.436  AUC-train 0.847\n",
            "Stats - Epoch: 20 AUC-val 0.441  AUC-train 0.849\n",
            "Stats - Epoch: 21 AUC-val 0.430  AUC-train 0.852\n",
            "Stats - Epoch: 22 AUC-val 0.431  AUC-train 0.851\n",
            "Stats - Epoch: 23 AUC-val 0.449  AUC-train 0.861\n",
            "Stats - Epoch: 24 AUC-val 0.450  AUC-train 0.857\n",
            "Stats - Epoch: 25 AUC-val 0.456  AUC-train 0.861\n",
            "Stats - Epoch: 26 AUC-val 0.450  AUC-train 0.863\n",
            "Stats - Epoch: 27 AUC-val 0.441  AUC-train 0.866\n",
            "Stats - Epoch: 28 AUC-val 0.448  AUC-train 0.866\n",
            "Stats - Epoch: 29 AUC-val 0.451  AUC-train 0.861\n",
            "Stats - Epoch: 30 AUC-val 0.458  AUC-train 0.871\n",
            "Stats - Epoch: 31 AUC-val 0.453  AUC-train 0.874\n",
            "Stats - Epoch: 32 AUC-val 0.460  AUC-train 0.870\n",
            "Stats - Epoch: 33 AUC-val 0.458  AUC-train 0.875\n",
            "Stats - Epoch: 34 AUC-val 0.472  AUC-train 0.866\n",
            "Stats - Epoch: 35 AUC-val 0.462  AUC-train 0.871\n",
            "Stats - Epoch: 36 AUC-val 0.472  AUC-train 0.870\n",
            "Stats - Epoch: 37 AUC-val 0.458  AUC-train 0.876\n",
            "Stats - Epoch: 38 AUC-val 0.461  AUC-train 0.877\n",
            "Stats - Epoch: 39 AUC-val 0.457  AUC-train 0.880\n",
            "Stats - Epoch: 40 AUC-val 0.478  AUC-train 0.883\n",
            "Stats - Epoch: 41 AUC-val 0.469  AUC-train 0.885\n",
            "Stats - Epoch: 42 AUC-val 0.467  AUC-train 0.882\n",
            "Stats - Epoch: 43 AUC-val 0.473  AUC-train 0.878\n",
            "Stats - Epoch: 44 AUC-val 0.460  AUC-train 0.876\n",
            "Stats - Epoch: 45 AUC-val 0.469  AUC-train 0.882\n",
            "Stats - Epoch: 46 AUC-val 0.476  AUC-train 0.882\n",
            "Stats - Epoch: 47 AUC-val 0.474  AUC-train 0.884\n",
            "Stats - Epoch: 48 AUC-val 0.458  AUC-train 0.882\n",
            "Stats - Epoch: 49 AUC-val 0.480  AUC-train 0.882\n",
            "Stats - Epoch: 50 AUC-val 0.458  AUC-train 0.885\n",
            "Stats - Epoch: 51 AUC-val 0.461  AUC-train 0.886\n",
            "Stats - Epoch: 52 AUC-val 0.466  AUC-train 0.882\n",
            "Stats - Epoch: 53 AUC-val 0.481  AUC-train 0.885\n",
            "Stats - Epoch: 54 AUC-val 0.472  AUC-train 0.890\n",
            "Stats - Epoch: 55 AUC-val 0.476  AUC-train 0.890\n",
            "Stats - Epoch: 56 AUC-val 0.466  AUC-train 0.888\n",
            "Stats - Epoch: 57 AUC-val 0.470  AUC-train 0.887\n",
            "Stats - Epoch: 58 AUC-val 0.491  AUC-train 0.888\n",
            "Stats - Epoch: 59 AUC-val 0.475  AUC-train 0.886\n",
            "Stats - Epoch: 60 AUC-val 0.471  AUC-train 0.893\n",
            "Stats - Epoch: 61 AUC-val 0.479  AUC-train 0.891\n",
            "Stats - Epoch: 62 AUC-val 0.478  AUC-train 0.895\n",
            "Stats - Epoch: 63 AUC-val 0.483  AUC-train 0.895\n",
            "Stats - Epoch: 64 AUC-val 0.483  AUC-train 0.887\n",
            "Stats - Epoch: 65 AUC-val 0.479  AUC-train 0.893\n",
            "Stats - Epoch: 66 AUC-val 0.474  AUC-train 0.893\n",
            "Stats - Epoch: 67 AUC-val 0.481  AUC-train 0.895\n",
            "Stats - Epoch: 68 AUC-val 0.488  AUC-train 0.889\n",
            "Stats - Epoch: 69 AUC-val 0.492  AUC-train 0.895\n",
            "Stats - Epoch: 70 AUC-val 0.474  AUC-train 0.900\n",
            "Stats - Epoch: 71 AUC-val 0.488  AUC-train 0.893\n",
            "Stats - Epoch: 72 AUC-val 0.481  AUC-train 0.890\n",
            "Stats - Epoch: 73 AUC-val 0.497  AUC-train 0.893\n",
            "Stats - Epoch: 74 AUC-val 0.490  AUC-train 0.898\n",
            "Stats - Epoch: 75 AUC-val 0.498  AUC-train 0.896\n",
            "Stats - Epoch: 76 AUC-val 0.495  AUC-train 0.890\n",
            "Stats - Epoch: 77 AUC-val 0.486  AUC-train 0.897\n",
            "Stats - Epoch: 78 AUC-val 0.501  AUC-train 0.899\n",
            "Stats - Epoch: 79 AUC-val 0.497  AUC-train 0.894\n",
            "Stats - Epoch: 80 AUC-val 0.490  AUC-train 0.901\n",
            "Stats - Epoch: 81 AUC-val 0.490  AUC-train 0.901\n",
            "Stats - Epoch: 82 AUC-val 0.500  AUC-train 0.899\n",
            "Stats - Epoch: 83 AUC-val 0.495  AUC-train 0.900\n",
            "Stats - Epoch: 84 AUC-val 0.500  AUC-train 0.888\n",
            "Stats - Epoch: 85 AUC-val 0.492  AUC-train 0.896\n",
            "Stats - Epoch: 86 AUC-val 0.491  AUC-train 0.900\n",
            "Stats - Epoch: 87 AUC-val 0.500  AUC-train 0.901\n",
            "Stats - Epoch: 88 AUC-val 0.502  AUC-train 0.903\n",
            "Stats - Epoch: 89 AUC-val 0.497  AUC-train 0.902\n",
            "Stats - Epoch: 90 AUC-val 0.495  AUC-train 0.900\n",
            "Stats - Epoch: 91 AUC-val 0.495  AUC-train 0.903\n",
            "Stats - Epoch: 92 AUC-val 0.500  AUC-train 0.896\n",
            "Stats - Epoch: 93 AUC-val 0.506  AUC-train 0.900\n",
            "Stats - Epoch: 94 AUC-val 0.480  AUC-train 0.898\n",
            "Stats - Epoch: 95 AUC-val 0.503  AUC-train 0.898\n",
            "Stats - Epoch: 96 AUC-val 0.495  AUC-train 0.902\n",
            "Stats - Epoch: 97 AUC-val 0.491  AUC-train 0.904\n",
            "Stats - Epoch: 98 AUC-val 0.490  AUC-train 0.903\n",
            "Stats - Epoch: 99 AUC-val 0.498  AUC-train 0.899\n",
            "Stats - Epoch: 100 AUC-val 0.495  AUC-train 0.903\n",
            "Results 100 AUC-val 0.506 0.526 0.570 0.486 0.623 AUC-train 0.900\n",
            "Shapley [0.00849974 0.00679257 0.01892456 0.01146416 0.00378689] [0.02111471]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.190234\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.279  AUC-train 0.565\n",
            "Stats - Epoch: 2 AUC-val 0.397  AUC-train 0.765\n",
            "Stats - Epoch: 3 AUC-val 0.374  AUC-train 0.853\n",
            "Stats - Epoch: 4 AUC-val 0.350  AUC-train 0.902\n",
            "Stats - Epoch: 5 AUC-val 0.354  AUC-train 0.933\n",
            "Stats - Epoch: 6 AUC-val 0.353  AUC-train 0.954\n",
            "Stats - Epoch: 7 AUC-val 0.379  AUC-train 0.963\n",
            "Stats - Epoch: 8 AUC-val 0.343  AUC-train 0.971\n",
            "Stats - Epoch: 9 AUC-val 0.369  AUC-train 0.975\n",
            "Stats - Epoch: 10 AUC-val 0.375  AUC-train 0.976\n",
            "Stats - Epoch: 11 AUC-val 0.357  AUC-train 0.980\n",
            "Stats - Epoch: 12 AUC-val 0.372  AUC-train 0.987\n",
            "Stats - Epoch: 13 AUC-val 0.365  AUC-train 0.987\n",
            "Stats - Epoch: 14 AUC-val 0.391  AUC-train 0.987\n",
            "Stats - Epoch: 15 AUC-val 0.384  AUC-train 0.987\n",
            "Stats - Epoch: 16 AUC-val 0.437  AUC-train 0.988\n",
            "Stats - Epoch: 17 AUC-val 0.407  AUC-train 0.983\n",
            "Stats - Epoch: 18 AUC-val 0.412  AUC-train 0.986\n",
            "Stats - Epoch: 19 AUC-val 0.437  AUC-train 0.989\n",
            "Stats - Epoch: 20 AUC-val 0.388  AUC-train 0.985\n",
            "Stats - Epoch: 21 AUC-val 0.397  AUC-train 0.989\n",
            "Stats - Epoch: 22 AUC-val 0.420  AUC-train 0.984\n",
            "Stats - Epoch: 23 AUC-val 0.400  AUC-train 0.989\n",
            "Stats - Epoch: 24 AUC-val 0.444  AUC-train 0.989\n",
            "Stats - Epoch: 25 AUC-val 0.408  AUC-train 0.987\n",
            "Stats - Epoch: 26 AUC-val 0.424  AUC-train 0.988\n",
            "Stats - Epoch: 27 AUC-val 0.462  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.448  AUC-train 0.987\n",
            "Stats - Epoch: 29 AUC-val 0.443  AUC-train 0.989\n",
            "Stats - Epoch: 30 AUC-val 0.431  AUC-train 0.990\n",
            "Stats - Epoch: 31 AUC-val 0.421  AUC-train 0.990\n",
            "Stats - Epoch: 32 AUC-val 0.441  AUC-train 0.990\n",
            "Stats - Epoch: 33 AUC-val 0.417  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.413  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.446  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.417  AUC-train 0.987\n",
            "Stats - Epoch: 37 AUC-val 0.450  AUC-train 0.988\n",
            "Stats - Epoch: 38 AUC-val 0.447  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.426  AUC-train 0.988\n",
            "Stats - Epoch: 40 AUC-val 0.459  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.466  AUC-train 0.986\n",
            "Stats - Epoch: 42 AUC-val 0.468  AUC-train 0.983\n",
            "Stats - Epoch: 43 AUC-val 0.469  AUC-train 0.984\n",
            "Stats - Epoch: 44 AUC-val 0.429  AUC-train 0.986\n",
            "Stats - Epoch: 45 AUC-val 0.452  AUC-train 0.987\n",
            "Stats - Epoch: 46 AUC-val 0.445  AUC-train 0.987\n",
            "Stats - Epoch: 47 AUC-val 0.434  AUC-train 0.989\n",
            "Stats - Epoch: 48 AUC-val 0.450  AUC-train 0.986\n",
            "Stats - Epoch: 49 AUC-val 0.444  AUC-train 0.987\n",
            "Stats - Epoch: 50 AUC-val 0.452  AUC-train 0.987\n",
            "Stats - Epoch: 51 AUC-val 0.456  AUC-train 0.986\n",
            "Stats - Epoch: 52 AUC-val 0.449  AUC-train 0.987\n",
            "Stats - Epoch: 53 AUC-val 0.441  AUC-train 0.987\n",
            "Stats - Epoch: 54 AUC-val 0.441  AUC-train 0.986\n",
            "Stats - Epoch: 55 AUC-val 0.452  AUC-train 0.982\n",
            "Stats - Epoch: 56 AUC-val 0.450  AUC-train 0.986\n",
            "Stats - Epoch: 57 AUC-val 0.454  AUC-train 0.986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.463  AUC-train 0.987\n",
            "Stats - Epoch: 59 AUC-val 0.442  AUC-train 0.987\n",
            "Stats - Epoch: 60 AUC-val 0.448  AUC-train 0.986\n",
            "Stats - Epoch: 61 AUC-val 0.441  AUC-train 0.984\n",
            "Stats - Epoch: 62 AUC-val 0.434  AUC-train 0.988\n",
            "Stats - Epoch: 63 AUC-val 0.457  AUC-train 0.986\n",
            "Stats - Epoch: 64 AUC-val 0.469  AUC-train 0.978\n",
            "Stats - Epoch: 65 AUC-val 0.466  AUC-train 0.982\n",
            "Stats - Epoch: 66 AUC-val 0.439  AUC-train 0.986\n",
            "Stats - Epoch: 67 AUC-val 0.457  AUC-train 0.983\n",
            "Stats - Epoch: 68 AUC-val 0.443  AUC-train 0.983\n",
            "Stats - Epoch: 69 AUC-val 0.447  AUC-train 0.985\n",
            "Stats - Epoch: 70 AUC-val 0.468  AUC-train 0.982\n",
            "Stats - Epoch: 71 AUC-val 0.451  AUC-train 0.982\n",
            "Stats - Epoch: 72 AUC-val 0.444  AUC-train 0.984\n",
            "Stats - Epoch: 73 AUC-val 0.455  AUC-train 0.979\n",
            "Stats - Epoch: 74 AUC-val 0.472  AUC-train 0.982\n",
            "Stats - Epoch: 75 AUC-val 0.480  AUC-train 0.979\n",
            "Stats - Epoch: 76 AUC-val 0.486  AUC-train 0.978\n",
            "Stats - Epoch: 77 AUC-val 0.480  AUC-train 0.982\n",
            "Stats - Epoch: 78 AUC-val 0.465  AUC-train 0.971\n",
            "Stats - Epoch: 79 AUC-val 0.455  AUC-train 0.980\n",
            "Stats - Epoch: 80 AUC-val 0.440  AUC-train 0.982\n",
            "Stats - Epoch: 81 AUC-val 0.446  AUC-train 0.983\n",
            "Stats - Epoch: 82 AUC-val 0.451  AUC-train 0.984\n",
            "Stats - Epoch: 83 AUC-val 0.453  AUC-train 0.977\n",
            "Stats - Epoch: 84 AUC-val 0.447  AUC-train 0.983\n",
            "Stats - Epoch: 85 AUC-val 0.452  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.450  AUC-train 0.982\n",
            "Stats - Epoch: 87 AUC-val 0.444  AUC-train 0.983\n",
            "Stats - Epoch: 88 AUC-val 0.460  AUC-train 0.983\n",
            "Stats - Epoch: 89 AUC-val 0.444  AUC-train 0.980\n",
            "Stats - Epoch: 90 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 91 AUC-val 0.472  AUC-train 0.983\n",
            "Stats - Epoch: 92 AUC-val 0.428  AUC-train 0.975\n",
            "Stats - Epoch: 93 AUC-val 0.441  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.428  AUC-train 0.980\n",
            "Stats - Epoch: 95 AUC-val 0.419  AUC-train 0.979\n",
            "Stats - Epoch: 96 AUC-val 0.453  AUC-train 0.978\n",
            "Stats - Epoch: 97 AUC-val 0.448  AUC-train 0.979\n",
            "Stats - Epoch: 98 AUC-val 0.465  AUC-train 0.982\n",
            "Stats - Epoch: 99 AUC-val 0.435  AUC-train 0.976\n",
            "Stats - Epoch: 100 AUC-val 0.446  AUC-train 0.975\n",
            "Results 100 AUC-val 0.486 0.471 0.331 0.182 0.571 AUC-train 0.978\n",
            "Shapley [0.02715484 0.00885213 0.0096307  0.03964393 0.0087478 ] [0.04078129]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.180362\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.217  AUC-train 0.573\n",
            "Stats - Epoch: 2 AUC-val 0.198  AUC-train 0.640\n",
            "Stats - Epoch: 3 AUC-val 0.212  AUC-train 0.699\n",
            "Stats - Epoch: 4 AUC-val 0.296  AUC-train 0.756\n",
            "Stats - Epoch: 5 AUC-val 0.365  AUC-train 0.790\n",
            "Stats - Epoch: 6 AUC-val 0.433  AUC-train 0.816\n",
            "Stats - Epoch: 7 AUC-val 0.429  AUC-train 0.830\n",
            "Stats - Epoch: 8 AUC-val 0.480  AUC-train 0.842\n",
            "Stats - Epoch: 9 AUC-val 0.476  AUC-train 0.851\n",
            "Stats - Epoch: 10 AUC-val 0.505  AUC-train 0.855\n",
            "Stats - Epoch: 11 AUC-val 0.564  AUC-train 0.860\n",
            "Stats - Epoch: 12 AUC-val 0.559  AUC-train 0.863\n",
            "Stats - Epoch: 13 AUC-val 0.551  AUC-train 0.866\n",
            "Stats - Epoch: 14 AUC-val 0.565  AUC-train 0.872\n",
            "Stats - Epoch: 15 AUC-val 0.553  AUC-train 0.876\n",
            "Stats - Epoch: 16 AUC-val 0.547  AUC-train 0.883\n",
            "Stats - Epoch: 17 AUC-val 0.550  AUC-train 0.886\n",
            "Stats - Epoch: 18 AUC-val 0.534  AUC-train 0.886\n",
            "Stats - Epoch: 19 AUC-val 0.560  AUC-train 0.888\n",
            "Stats - Epoch: 20 AUC-val 0.547  AUC-train 0.893\n",
            "Stats - Epoch: 21 AUC-val 0.587  AUC-train 0.893\n",
            "Stats - Epoch: 22 AUC-val 0.587  AUC-train 0.891\n",
            "Stats - Epoch: 23 AUC-val 0.591  AUC-train 0.898\n",
            "Stats - Epoch: 24 AUC-val 0.563  AUC-train 0.901\n",
            "Stats - Epoch: 25 AUC-val 0.581  AUC-train 0.902\n",
            "Stats - Epoch: 26 AUC-val 0.602  AUC-train 0.898\n",
            "Stats - Epoch: 27 AUC-val 0.569  AUC-train 0.905\n",
            "Stats - Epoch: 28 AUC-val 0.587  AUC-train 0.908\n",
            "Stats - Epoch: 29 AUC-val 0.600  AUC-train 0.910\n",
            "Stats - Epoch: 30 AUC-val 0.585  AUC-train 0.915\n",
            "Stats - Epoch: 31 AUC-val 0.583  AUC-train 0.919\n",
            "Stats - Epoch: 32 AUC-val 0.585  AUC-train 0.924\n",
            "Stats - Epoch: 33 AUC-val 0.583  AUC-train 0.923\n",
            "Stats - Epoch: 34 AUC-val 0.602  AUC-train 0.922\n",
            "Stats - Epoch: 35 AUC-val 0.613  AUC-train 0.922\n",
            "Stats - Epoch: 36 AUC-val 0.617  AUC-train 0.925\n",
            "Stats - Epoch: 37 AUC-val 0.614  AUC-train 0.930\n",
            "Stats - Epoch: 38 AUC-val 0.595  AUC-train 0.932\n",
            "Stats - Epoch: 39 AUC-val 0.596  AUC-train 0.931\n",
            "Stats - Epoch: 40 AUC-val 0.623  AUC-train 0.934\n",
            "Stats - Epoch: 41 AUC-val 0.588  AUC-train 0.930\n",
            "Stats - Epoch: 42 AUC-val 0.581  AUC-train 0.929\n",
            "Stats - Epoch: 43 AUC-val 0.630  AUC-train 0.932\n",
            "Stats - Epoch: 44 AUC-val 0.615  AUC-train 0.934\n",
            "Stats - Epoch: 45 AUC-val 0.597  AUC-train 0.938\n",
            "Stats - Epoch: 46 AUC-val 0.598  AUC-train 0.939\n",
            "Stats - Epoch: 47 AUC-val 0.591  AUC-train 0.945\n",
            "Stats - Epoch: 48 AUC-val 0.605  AUC-train 0.944\n",
            "Stats - Epoch: 49 AUC-val 0.601  AUC-train 0.942\n",
            "Stats - Epoch: 50 AUC-val 0.586  AUC-train 0.944\n",
            "Stats - Epoch: 51 AUC-val 0.613  AUC-train 0.947\n",
            "Stats - Epoch: 52 AUC-val 0.608  AUC-train 0.946\n",
            "Stats - Epoch: 53 AUC-val 0.602  AUC-train 0.945\n",
            "Stats - Epoch: 54 AUC-val 0.560  AUC-train 0.947\n",
            "Stats - Epoch: 55 AUC-val 0.616  AUC-train 0.946\n",
            "Stats - Epoch: 56 AUC-val 0.603  AUC-train 0.946\n",
            "Stats - Epoch: 57 AUC-val 0.600  AUC-train 0.944\n",
            "Stats - Epoch: 58 AUC-val 0.629  AUC-train 0.947\n",
            "Stats - Epoch: 59 AUC-val 0.611  AUC-train 0.943\n",
            "Stats - Epoch: 60 AUC-val 0.619  AUC-train 0.943\n",
            "Stats - Epoch: 61 AUC-val 0.626  AUC-train 0.946\n",
            "Stats - Epoch: 62 AUC-val 0.641  AUC-train 0.950\n",
            "Stats - Epoch: 63 AUC-val 0.617  AUC-train 0.952\n",
            "Stats - Epoch: 64 AUC-val 0.588  AUC-train 0.947\n",
            "Stats - Epoch: 65 AUC-val 0.612  AUC-train 0.950\n",
            "Stats - Epoch: 66 AUC-val 0.588  AUC-train 0.953\n",
            "Stats - Epoch: 67 AUC-val 0.640  AUC-train 0.949\n",
            "Stats - Epoch: 68 AUC-val 0.653  AUC-train 0.948\n",
            "Stats - Epoch: 69 AUC-val 0.604  AUC-train 0.952\n",
            "Stats - Epoch: 70 AUC-val 0.667  AUC-train 0.952\n",
            "Stats - Epoch: 71 AUC-val 0.634  AUC-train 0.954\n",
            "Stats - Epoch: 72 AUC-val 0.620  AUC-train 0.953\n",
            "Stats - Epoch: 73 AUC-val 0.575  AUC-train 0.953\n",
            "Stats - Epoch: 74 AUC-val 0.630  AUC-train 0.952\n",
            "Stats - Epoch: 75 AUC-val 0.622  AUC-train 0.950\n",
            "Stats - Epoch: 76 AUC-val 0.597  AUC-train 0.950\n",
            "Stats - Epoch: 77 AUC-val 0.605  AUC-train 0.948\n",
            "Stats - Epoch: 78 AUC-val 0.607  AUC-train 0.949\n",
            "Stats - Epoch: 79 AUC-val 0.640  AUC-train 0.956\n",
            "Stats - Epoch: 80 AUC-val 0.604  AUC-train 0.959\n",
            "Stats - Epoch: 81 AUC-val 0.609  AUC-train 0.960\n",
            "Stats - Epoch: 82 AUC-val 0.609  AUC-train 0.961\n",
            "Stats - Epoch: 83 AUC-val 0.639  AUC-train 0.962\n",
            "Stats - Epoch: 84 AUC-val 0.612  AUC-train 0.959\n",
            "Stats - Epoch: 85 AUC-val 0.642  AUC-train 0.959\n",
            "Stats - Epoch: 86 AUC-val 0.612  AUC-train 0.959\n",
            "Stats - Epoch: 87 AUC-val 0.620  AUC-train 0.959\n",
            "Stats - Epoch: 88 AUC-val 0.619  AUC-train 0.961\n",
            "Stats - Epoch: 89 AUC-val 0.609  AUC-train 0.962\n",
            "Stats - Epoch: 90 AUC-val 0.610  AUC-train 0.963\n",
            "Stats - Epoch: 91 AUC-val 0.585  AUC-train 0.964\n",
            "Stats - Epoch: 92 AUC-val 0.575  AUC-train 0.964\n",
            "Stats - Epoch: 93 AUC-val 0.581  AUC-train 0.963\n",
            "Stats - Epoch: 94 AUC-val 0.624  AUC-train 0.965\n",
            "Stats - Epoch: 95 AUC-val 0.638  AUC-train 0.964\n",
            "Stats - Epoch: 96 AUC-val 0.671  AUC-train 0.966\n",
            "Stats - Epoch: 97 AUC-val 0.621  AUC-train 0.967\n",
            "Stats - Epoch: 98 AUC-val 0.591  AUC-train 0.959\n",
            "Stats - Epoch: 99 AUC-val 0.614  AUC-train 0.961\n",
            "Stats - Epoch: 100 AUC-val 0.587  AUC-train 0.964\n",
            "Results 100 AUC-val 0.671 0.644 0.605 0.611 0.635 AUC-train 0.966\n",
            "Shapley [0.01897779 0.01336744 0.01726334 0.01445426 0.00761383] [0.00608353]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197508\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.364  AUC-train 0.594\n",
            "Stats - Epoch: 2 AUC-val 0.554  AUC-train 0.765\n",
            "Stats - Epoch: 3 AUC-val 0.610  AUC-train 0.827\n",
            "Stats - Epoch: 4 AUC-val 0.646  AUC-train 0.858\n",
            "Stats - Epoch: 5 AUC-val 0.671  AUC-train 0.885\n",
            "Stats - Epoch: 6 AUC-val 0.681  AUC-train 0.902\n",
            "Stats - Epoch: 7 AUC-val 0.698  AUC-train 0.913\n",
            "Stats - Epoch: 8 AUC-val 0.700  AUC-train 0.926\n",
            "Stats - Epoch: 9 AUC-val 0.722  AUC-train 0.939\n",
            "Stats - Epoch: 10 AUC-val 0.720  AUC-train 0.949\n",
            "Stats - Epoch: 11 AUC-val 0.712  AUC-train 0.955\n",
            "Stats - Epoch: 12 AUC-val 0.737  AUC-train 0.962\n",
            "Stats - Epoch: 13 AUC-val 0.709  AUC-train 0.969\n",
            "Stats - Epoch: 14 AUC-val 0.709  AUC-train 0.973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.719  AUC-train 0.978\n",
            "Stats - Epoch: 16 AUC-val 0.716  AUC-train 0.981\n",
            "Stats - Epoch: 17 AUC-val 0.723  AUC-train 0.984\n",
            "Stats - Epoch: 18 AUC-val 0.711  AUC-train 0.986\n",
            "Stats - Epoch: 19 AUC-val 0.717  AUC-train 0.989\n",
            "Stats - Epoch: 20 AUC-val 0.711  AUC-train 0.991\n",
            "Stats - Epoch: 21 AUC-val 0.724  AUC-train 0.990\n",
            "Stats - Epoch: 22 AUC-val 0.713  AUC-train 0.992\n",
            "Stats - Epoch: 23 AUC-val 0.682  AUC-train 0.993\n",
            "Stats - Epoch: 24 AUC-val 0.702  AUC-train 0.995\n",
            "Stats - Epoch: 25 AUC-val 0.693  AUC-train 0.994\n",
            "Stats - Epoch: 26 AUC-val 0.682  AUC-train 0.995\n",
            "Stats - Epoch: 27 AUC-val 0.712  AUC-train 0.996\n",
            "Stats - Epoch: 28 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 29 AUC-val 0.676  AUC-train 0.997\n",
            "Stats - Epoch: 30 AUC-val 0.686  AUC-train 0.997\n",
            "Stats - Epoch: 31 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 32 AUC-val 0.677  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.670  AUC-train 0.997\n",
            "Stats - Epoch: 34 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.673  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.695  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.687  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.648  AUC-train 0.997\n",
            "Stats - Epoch: 45 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 48 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.679  AUC-train 1.000\n",
            "Stats - Epoch: 53 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.685  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.681  AUC-train 0.997\n",
            "Stats - Epoch: 58 AUC-val 0.674  AUC-train 0.996\n",
            "Stats - Epoch: 59 AUC-val 0.677  AUC-train 0.998\n",
            "Stats - Epoch: 60 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.695  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.681  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.674  AUC-train 1.000\n",
            "Stats - Epoch: 67 AUC-val 0.689  AUC-train 1.000\n",
            "Stats - Epoch: 68 AUC-val 0.708  AUC-train 1.000\n",
            "Stats - Epoch: 69 AUC-val 0.687  AUC-train 1.000\n",
            "Stats - Epoch: 70 AUC-val 0.694  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.655  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 73 AUC-val 0.691  AUC-train 0.998\n",
            "Stats - Epoch: 74 AUC-val 0.663  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.687  AUC-train 0.997\n",
            "Stats - Epoch: 76 AUC-val 0.668  AUC-train 0.998\n",
            "Stats - Epoch: 77 AUC-val 0.684  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.706  AUC-train 0.995\n",
            "Stats - Epoch: 79 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.662  AUC-train 1.000\n",
            "Stats - Epoch: 81 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.659  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.658  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.651  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.656  AUC-train 1.000\n",
            "Stats - Epoch: 86 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.649  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.669  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.689  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.681  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 98 AUC-val 0.653  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.681  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.681  AUC-train 0.998\n",
            "Results 100 AUC-val 0.737 0.611 0.492 0.429 0.582 AUC-train 0.962\n",
            "Shapley [0.01688216 0.01761332 0.01734831 0.02916778 0.01072721] [0.0178338]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199447\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.524  AUC-train 0.526\n",
            "Stats - Epoch: 2 AUC-val 0.554  AUC-train 0.695\n",
            "Stats - Epoch: 3 AUC-val 0.577  AUC-train 0.785\n",
            "Stats - Epoch: 4 AUC-val 0.572  AUC-train 0.826\n",
            "Stats - Epoch: 5 AUC-val 0.567  AUC-train 0.851\n",
            "Stats - Epoch: 6 AUC-val 0.578  AUC-train 0.874\n",
            "Stats - Epoch: 7 AUC-val 0.574  AUC-train 0.887\n",
            "Stats - Epoch: 8 AUC-val 0.588  AUC-train 0.903\n",
            "Stats - Epoch: 9 AUC-val 0.576  AUC-train 0.917\n",
            "Stats - Epoch: 10 AUC-val 0.583  AUC-train 0.929\n",
            "Stats - Epoch: 11 AUC-val 0.540  AUC-train 0.937\n",
            "Stats - Epoch: 12 AUC-val 0.558  AUC-train 0.947\n",
            "Stats - Epoch: 13 AUC-val 0.567  AUC-train 0.955\n",
            "Stats - Epoch: 14 AUC-val 0.567  AUC-train 0.961\n",
            "Stats - Epoch: 15 AUC-val 0.560  AUC-train 0.968\n",
            "Stats - Epoch: 16 AUC-val 0.599  AUC-train 0.968\n",
            "Stats - Epoch: 17 AUC-val 0.562  AUC-train 0.972\n",
            "Stats - Epoch: 18 AUC-val 0.610  AUC-train 0.976\n",
            "Stats - Epoch: 19 AUC-val 0.584  AUC-train 0.978\n",
            "Stats - Epoch: 20 AUC-val 0.616  AUC-train 0.979\n",
            "Stats - Epoch: 21 AUC-val 0.618  AUC-train 0.984\n",
            "Stats - Epoch: 22 AUC-val 0.617  AUC-train 0.986\n",
            "Stats - Epoch: 23 AUC-val 0.628  AUC-train 0.986\n",
            "Stats - Epoch: 24 AUC-val 0.611  AUC-train 0.985\n",
            "Stats - Epoch: 25 AUC-val 0.650  AUC-train 0.987\n",
            "Stats - Epoch: 26 AUC-val 0.632  AUC-train 0.988\n",
            "Stats - Epoch: 27 AUC-val 0.622  AUC-train 0.990\n",
            "Stats - Epoch: 28 AUC-val 0.615  AUC-train 0.990\n",
            "Stats - Epoch: 29 AUC-val 0.645  AUC-train 0.990\n",
            "Stats - Epoch: 30 AUC-val 0.614  AUC-train 0.991\n",
            "Stats - Epoch: 31 AUC-val 0.664  AUC-train 0.990\n",
            "Stats - Epoch: 32 AUC-val 0.637  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.678  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.645  AUC-train 0.994\n",
            "Stats - Epoch: 35 AUC-val 0.648  AUC-train 0.994\n",
            "Stats - Epoch: 36 AUC-val 0.646  AUC-train 0.992\n",
            "Stats - Epoch: 37 AUC-val 0.636  AUC-train 0.994\n",
            "Stats - Epoch: 38 AUC-val 0.675  AUC-train 0.995\n",
            "Stats - Epoch: 39 AUC-val 0.647  AUC-train 0.995\n",
            "Stats - Epoch: 40 AUC-val 0.648  AUC-train 0.993\n",
            "Stats - Epoch: 41 AUC-val 0.664  AUC-train 0.994\n",
            "Stats - Epoch: 42 AUC-val 0.704  AUC-train 0.996\n",
            "Stats - Epoch: 43 AUC-val 0.681  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.660  AUC-train 0.997\n",
            "Stats - Epoch: 45 AUC-val 0.647  AUC-train 0.996\n",
            "Stats - Epoch: 46 AUC-val 0.647  AUC-train 0.997\n",
            "Stats - Epoch: 47 AUC-val 0.631  AUC-train 0.997\n",
            "Stats - Epoch: 48 AUC-val 0.659  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.657  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 51 AUC-val 0.647  AUC-train 0.994\n",
            "Stats - Epoch: 52 AUC-val 0.647  AUC-train 0.994\n",
            "Stats - Epoch: 53 AUC-val 0.666  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 55 AUC-val 0.676  AUC-train 0.992\n",
            "Stats - Epoch: 56 AUC-val 0.668  AUC-train 0.995\n",
            "Stats - Epoch: 57 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 58 AUC-val 0.686  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.656  AUC-train 0.998\n",
            "Stats - Epoch: 60 AUC-val 0.687  AUC-train 0.997\n",
            "Stats - Epoch: 61 AUC-val 0.674  AUC-train 0.998\n",
            "Stats - Epoch: 62 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 64 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 66 AUC-val 0.651  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 68 AUC-val 0.685  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.653  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.650  AUC-train 0.995\n",
            "Stats - Epoch: 71 AUC-val 0.681  AUC-train 0.994\n",
            "Stats - Epoch: 72 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 73 AUC-val 0.697  AUC-train 0.993\n",
            "Stats - Epoch: 74 AUC-val 0.666  AUC-train 0.992\n",
            "Stats - Epoch: 75 AUC-val 0.655  AUC-train 0.989\n",
            "Stats - Epoch: 76 AUC-val 0.647  AUC-train 0.992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.683  AUC-train 0.995\n",
            "Stats - Epoch: 78 AUC-val 0.699  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.683  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.685  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.669  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.717  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.665  AUC-train 0.991\n",
            "Stats - Epoch: 85 AUC-val 0.644  AUC-train 0.993\n",
            "Stats - Epoch: 86 AUC-val 0.641  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.632  AUC-train 0.995\n",
            "Stats - Epoch: 88 AUC-val 0.647  AUC-train 0.990\n",
            "Stats - Epoch: 89 AUC-val 0.671  AUC-train 0.993\n",
            "Stats - Epoch: 90 AUC-val 0.643  AUC-train 0.995\n",
            "Stats - Epoch: 91 AUC-val 0.638  AUC-train 0.993\n",
            "Stats - Epoch: 92 AUC-val 0.681  AUC-train 0.989\n",
            "Stats - Epoch: 93 AUC-val 0.627  AUC-train 0.989\n",
            "Stats - Epoch: 94 AUC-val 0.691  AUC-train 0.992\n",
            "Stats - Epoch: 95 AUC-val 0.668  AUC-train 0.993\n",
            "Stats - Epoch: 96 AUC-val 0.676  AUC-train 0.985\n",
            "Stats - Epoch: 97 AUC-val 0.674  AUC-train 0.987\n",
            "Stats - Epoch: 98 AUC-val 0.672  AUC-train 0.990\n",
            "Stats - Epoch: 99 AUC-val 0.631  AUC-train 0.990\n",
            "Stats - Epoch: 100 AUC-val 0.625  AUC-train 0.992\n",
            "Results 100 AUC-val 0.717 0.724 0.601 0.478 0.591 AUC-train 0.995\n",
            "Shapley [0.01291562 0.01429678 0.00808515 0.01857116 0.00643149] [0.00234001]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.195086\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.362  AUC-train 0.506\n",
            "Stats - Epoch: 2 AUC-val 0.381  AUC-train 0.591\n",
            "Stats - Epoch: 3 AUC-val 0.414  AUC-train 0.645\n",
            "Stats - Epoch: 4 AUC-val 0.431  AUC-train 0.689\n",
            "Stats - Epoch: 5 AUC-val 0.433  AUC-train 0.707\n",
            "Stats - Epoch: 6 AUC-val 0.420  AUC-train 0.735\n",
            "Stats - Epoch: 7 AUC-val 0.435  AUC-train 0.752\n",
            "Stats - Epoch: 8 AUC-val 0.436  AUC-train 0.760\n",
            "Stats - Epoch: 9 AUC-val 0.437  AUC-train 0.773\n",
            "Stats - Epoch: 10 AUC-val 0.432  AUC-train 0.796\n",
            "Stats - Epoch: 11 AUC-val 0.441  AUC-train 0.794\n",
            "Stats - Epoch: 12 AUC-val 0.432  AUC-train 0.810\n",
            "Stats - Epoch: 13 AUC-val 0.433  AUC-train 0.816\n",
            "Stats - Epoch: 14 AUC-val 0.441  AUC-train 0.820\n",
            "Stats - Epoch: 15 AUC-val 0.437  AUC-train 0.829\n",
            "Stats - Epoch: 16 AUC-val 0.447  AUC-train 0.835\n",
            "Stats - Epoch: 17 AUC-val 0.434  AUC-train 0.832\n",
            "Stats - Epoch: 18 AUC-val 0.459  AUC-train 0.847\n",
            "Stats - Epoch: 19 AUC-val 0.457  AUC-train 0.848\n",
            "Stats - Epoch: 20 AUC-val 0.453  AUC-train 0.851\n",
            "Stats - Epoch: 21 AUC-val 0.448  AUC-train 0.857\n",
            "Stats - Epoch: 22 AUC-val 0.459  AUC-train 0.853\n",
            "Stats - Epoch: 23 AUC-val 0.463  AUC-train 0.858\n",
            "Stats - Epoch: 24 AUC-val 0.470  AUC-train 0.861\n",
            "Stats - Epoch: 25 AUC-val 0.469  AUC-train 0.862\n",
            "Stats - Epoch: 26 AUC-val 0.475  AUC-train 0.867\n",
            "Stats - Epoch: 27 AUC-val 0.474  AUC-train 0.869\n",
            "Stats - Epoch: 28 AUC-val 0.461  AUC-train 0.863\n",
            "Stats - Epoch: 29 AUC-val 0.469  AUC-train 0.863\n",
            "Stats - Epoch: 30 AUC-val 0.476  AUC-train 0.872\n",
            "Stats - Epoch: 31 AUC-val 0.471  AUC-train 0.875\n",
            "Stats - Epoch: 32 AUC-val 0.476  AUC-train 0.876\n",
            "Stats - Epoch: 33 AUC-val 0.469  AUC-train 0.876\n",
            "Stats - Epoch: 34 AUC-val 0.477  AUC-train 0.870\n",
            "Stats - Epoch: 35 AUC-val 0.475  AUC-train 0.871\n",
            "Stats - Epoch: 36 AUC-val 0.493  AUC-train 0.869\n",
            "Stats - Epoch: 37 AUC-val 0.474  AUC-train 0.878\n",
            "Stats - Epoch: 38 AUC-val 0.476  AUC-train 0.882\n",
            "Stats - Epoch: 39 AUC-val 0.479  AUC-train 0.879\n",
            "Stats - Epoch: 40 AUC-val 0.479  AUC-train 0.883\n",
            "Stats - Epoch: 41 AUC-val 0.489  AUC-train 0.884\n",
            "Stats - Epoch: 42 AUC-val 0.486  AUC-train 0.884\n",
            "Stats - Epoch: 43 AUC-val 0.490  AUC-train 0.880\n",
            "Stats - Epoch: 44 AUC-val 0.490  AUC-train 0.875\n",
            "Stats - Epoch: 45 AUC-val 0.491  AUC-train 0.882\n",
            "Stats - Epoch: 46 AUC-val 0.488  AUC-train 0.888\n",
            "Stats - Epoch: 47 AUC-val 0.488  AUC-train 0.883\n",
            "Stats - Epoch: 48 AUC-val 0.486  AUC-train 0.884\n",
            "Stats - Epoch: 49 AUC-val 0.497  AUC-train 0.880\n",
            "Stats - Epoch: 50 AUC-val 0.501  AUC-train 0.888\n",
            "Stats - Epoch: 51 AUC-val 0.482  AUC-train 0.889\n",
            "Stats - Epoch: 52 AUC-val 0.489  AUC-train 0.879\n",
            "Stats - Epoch: 53 AUC-val 0.497  AUC-train 0.889\n",
            "Stats - Epoch: 54 AUC-val 0.490  AUC-train 0.892\n",
            "Stats - Epoch: 55 AUC-val 0.498  AUC-train 0.892\n",
            "Stats - Epoch: 56 AUC-val 0.491  AUC-train 0.882\n",
            "Stats - Epoch: 57 AUC-val 0.502  AUC-train 0.890\n",
            "Stats - Epoch: 58 AUC-val 0.507  AUC-train 0.889\n",
            "Stats - Epoch: 59 AUC-val 0.494  AUC-train 0.887\n",
            "Stats - Epoch: 60 AUC-val 0.494  AUC-train 0.895\n",
            "Stats - Epoch: 61 AUC-val 0.496  AUC-train 0.896\n",
            "Stats - Epoch: 62 AUC-val 0.508  AUC-train 0.896\n",
            "Stats - Epoch: 63 AUC-val 0.518  AUC-train 0.896\n",
            "Stats - Epoch: 64 AUC-val 0.490  AUC-train 0.893\n",
            "Stats - Epoch: 65 AUC-val 0.504  AUC-train 0.895\n",
            "Stats - Epoch: 66 AUC-val 0.502  AUC-train 0.897\n",
            "Stats - Epoch: 67 AUC-val 0.512  AUC-train 0.897\n",
            "Stats - Epoch: 68 AUC-val 0.506  AUC-train 0.897\n",
            "Stats - Epoch: 69 AUC-val 0.506  AUC-train 0.896\n",
            "Stats - Epoch: 70 AUC-val 0.510  AUC-train 0.899\n",
            "Stats - Epoch: 71 AUC-val 0.510  AUC-train 0.896\n",
            "Stats - Epoch: 72 AUC-val 0.504  AUC-train 0.891\n",
            "Stats - Epoch: 73 AUC-val 0.507  AUC-train 0.895\n",
            "Stats - Epoch: 74 AUC-val 0.506  AUC-train 0.895\n",
            "Stats - Epoch: 75 AUC-val 0.515  AUC-train 0.898\n",
            "Stats - Epoch: 76 AUC-val 0.514  AUC-train 0.888\n",
            "Stats - Epoch: 77 AUC-val 0.512  AUC-train 0.896\n",
            "Stats - Epoch: 78 AUC-val 0.508  AUC-train 0.899\n",
            "Stats - Epoch: 79 AUC-val 0.505  AUC-train 0.899\n",
            "Stats - Epoch: 80 AUC-val 0.502  AUC-train 0.902\n",
            "Stats - Epoch: 81 AUC-val 0.504  AUC-train 0.900\n",
            "Stats - Epoch: 82 AUC-val 0.504  AUC-train 0.902\n",
            "Stats - Epoch: 83 AUC-val 0.491  AUC-train 0.901\n",
            "Stats - Epoch: 84 AUC-val 0.503  AUC-train 0.895\n",
            "Stats - Epoch: 85 AUC-val 0.510  AUC-train 0.895\n",
            "Stats - Epoch: 86 AUC-val 0.503  AUC-train 0.904\n",
            "Stats - Epoch: 87 AUC-val 0.505  AUC-train 0.900\n",
            "Stats - Epoch: 88 AUC-val 0.514  AUC-train 0.903\n",
            "Stats - Epoch: 89 AUC-val 0.504  AUC-train 0.905\n",
            "Stats - Epoch: 90 AUC-val 0.510  AUC-train 0.896\n",
            "Stats - Epoch: 91 AUC-val 0.510  AUC-train 0.903\n",
            "Stats - Epoch: 92 AUC-val 0.512  AUC-train 0.897\n",
            "Stats - Epoch: 93 AUC-val 0.509  AUC-train 0.902\n",
            "Stats - Epoch: 94 AUC-val 0.507  AUC-train 0.905\n",
            "Stats - Epoch: 95 AUC-val 0.516  AUC-train 0.897\n",
            "Stats - Epoch: 96 AUC-val 0.515  AUC-train 0.905\n",
            "Stats - Epoch: 97 AUC-val 0.513  AUC-train 0.903\n",
            "Stats - Epoch: 98 AUC-val 0.520  AUC-train 0.903\n",
            "Stats - Epoch: 99 AUC-val 0.518  AUC-train 0.902\n",
            "Stats - Epoch: 100 AUC-val 0.514  AUC-train 0.903\n",
            "Results 100 AUC-val 0.520 0.553 0.587 0.501 0.625 AUC-train 0.903\n",
            "Shapley [0.00958721 0.00856896 0.02194765 0.01441411 0.00465267] [0.02147813]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188474\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.305  AUC-train 0.627\n",
            "Stats - Epoch: 2 AUC-val 0.324  AUC-train 0.802\n",
            "Stats - Epoch: 3 AUC-val 0.369  AUC-train 0.871\n",
            "Stats - Epoch: 4 AUC-val 0.341  AUC-train 0.915\n",
            "Stats - Epoch: 5 AUC-val 0.336  AUC-train 0.943\n",
            "Stats - Epoch: 6 AUC-val 0.341  AUC-train 0.959\n",
            "Stats - Epoch: 7 AUC-val 0.331  AUC-train 0.969\n",
            "Stats - Epoch: 8 AUC-val 0.365  AUC-train 0.967\n",
            "Stats - Epoch: 9 AUC-val 0.362  AUC-train 0.977\n",
            "Stats - Epoch: 10 AUC-val 0.387  AUC-train 0.984\n",
            "Stats - Epoch: 11 AUC-val 0.359  AUC-train 0.982\n",
            "Stats - Epoch: 12 AUC-val 0.383  AUC-train 0.987\n",
            "Stats - Epoch: 13 AUC-val 0.363  AUC-train 0.988\n",
            "Stats - Epoch: 14 AUC-val 0.390  AUC-train 0.985\n",
            "Stats - Epoch: 15 AUC-val 0.386  AUC-train 0.988\n",
            "Stats - Epoch: 16 AUC-val 0.386  AUC-train 0.988\n",
            "Stats - Epoch: 17 AUC-val 0.407  AUC-train 0.989\n",
            "Stats - Epoch: 18 AUC-val 0.412  AUC-train 0.987\n",
            "Stats - Epoch: 19 AUC-val 0.409  AUC-train 0.991\n",
            "Stats - Epoch: 20 AUC-val 0.400  AUC-train 0.987\n",
            "Stats - Epoch: 21 AUC-val 0.418  AUC-train 0.991\n",
            "Stats - Epoch: 22 AUC-val 0.425  AUC-train 0.984\n",
            "Stats - Epoch: 23 AUC-val 0.407  AUC-train 0.989\n",
            "Stats - Epoch: 24 AUC-val 0.439  AUC-train 0.990\n",
            "Stats - Epoch: 25 AUC-val 0.430  AUC-train 0.987\n",
            "Stats - Epoch: 26 AUC-val 0.434  AUC-train 0.989\n",
            "Stats - Epoch: 27 AUC-val 0.437  AUC-train 0.987\n",
            "Stats - Epoch: 28 AUC-val 0.442  AUC-train 0.987\n",
            "Stats - Epoch: 29 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 30 AUC-val 0.440  AUC-train 0.989\n",
            "Stats - Epoch: 31 AUC-val 0.436  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.433  AUC-train 0.992\n",
            "Stats - Epoch: 33 AUC-val 0.404  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 35 AUC-val 0.424  AUC-train 0.989\n",
            "Stats - Epoch: 36 AUC-val 0.422  AUC-train 0.987\n",
            "Stats - Epoch: 37 AUC-val 0.427  AUC-train 0.989\n",
            "Stats - Epoch: 38 AUC-val 0.463  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.416  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.462  AUC-train 0.985\n",
            "Stats - Epoch: 41 AUC-val 0.455  AUC-train 0.988\n",
            "Stats - Epoch: 42 AUC-val 0.456  AUC-train 0.985\n",
            "Stats - Epoch: 43 AUC-val 0.444  AUC-train 0.979\n",
            "Stats - Epoch: 44 AUC-val 0.426  AUC-train 0.983\n",
            "Stats - Epoch: 45 AUC-val 0.445  AUC-train 0.985\n",
            "Stats - Epoch: 46 AUC-val 0.443  AUC-train 0.985\n",
            "Stats - Epoch: 47 AUC-val 0.458  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.445  AUC-train 0.984\n",
            "Stats - Epoch: 49 AUC-val 0.439  AUC-train 0.986\n",
            "Stats - Epoch: 50 AUC-val 0.436  AUC-train 0.984\n",
            "Stats - Epoch: 51 AUC-val 0.445  AUC-train 0.987\n",
            "Stats - Epoch: 52 AUC-val 0.440  AUC-train 0.985\n",
            "Stats - Epoch: 53 AUC-val 0.432  AUC-train 0.986\n",
            "Stats - Epoch: 54 AUC-val 0.472  AUC-train 0.984\n",
            "Stats - Epoch: 55 AUC-val 0.460  AUC-train 0.982\n",
            "Stats - Epoch: 56 AUC-val 0.447  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.450  AUC-train 0.982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.458  AUC-train 0.986\n",
            "Stats - Epoch: 59 AUC-val 0.449  AUC-train 0.985\n",
            "Stats - Epoch: 60 AUC-val 0.443  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.455  AUC-train 0.981\n",
            "Stats - Epoch: 62 AUC-val 0.444  AUC-train 0.987\n",
            "Stats - Epoch: 63 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 64 AUC-val 0.443  AUC-train 0.980\n",
            "Stats - Epoch: 65 AUC-val 0.462  AUC-train 0.983\n",
            "Stats - Epoch: 66 AUC-val 0.431  AUC-train 0.985\n",
            "Stats - Epoch: 67 AUC-val 0.441  AUC-train 0.981\n",
            "Stats - Epoch: 68 AUC-val 0.442  AUC-train 0.983\n",
            "Stats - Epoch: 69 AUC-val 0.444  AUC-train 0.987\n",
            "Stats - Epoch: 70 AUC-val 0.441  AUC-train 0.986\n",
            "Stats - Epoch: 71 AUC-val 0.451  AUC-train 0.984\n",
            "Stats - Epoch: 72 AUC-val 0.439  AUC-train 0.981\n",
            "Stats - Epoch: 73 AUC-val 0.459  AUC-train 0.983\n",
            "Stats - Epoch: 74 AUC-val 0.459  AUC-train 0.985\n",
            "Stats - Epoch: 75 AUC-val 0.462  AUC-train 0.979\n",
            "Stats - Epoch: 76 AUC-val 0.479  AUC-train 0.976\n",
            "Stats - Epoch: 77 AUC-val 0.468  AUC-train 0.981\n",
            "Stats - Epoch: 78 AUC-val 0.460  AUC-train 0.975\n",
            "Stats - Epoch: 79 AUC-val 0.431  AUC-train 0.984\n",
            "Stats - Epoch: 80 AUC-val 0.445  AUC-train 0.982\n",
            "Stats - Epoch: 81 AUC-val 0.432  AUC-train 0.980\n",
            "Stats - Epoch: 82 AUC-val 0.453  AUC-train 0.983\n",
            "Stats - Epoch: 83 AUC-val 0.453  AUC-train 0.976\n",
            "Stats - Epoch: 84 AUC-val 0.434  AUC-train 0.986\n",
            "Stats - Epoch: 85 AUC-val 0.430  AUC-train 0.986\n",
            "Stats - Epoch: 86 AUC-val 0.459  AUC-train 0.980\n",
            "Stats - Epoch: 87 AUC-val 0.460  AUC-train 0.981\n",
            "Stats - Epoch: 88 AUC-val 0.456  AUC-train 0.984\n",
            "Stats - Epoch: 89 AUC-val 0.438  AUC-train 0.982\n",
            "Stats - Epoch: 90 AUC-val 0.433  AUC-train 0.984\n",
            "Stats - Epoch: 91 AUC-val 0.447  AUC-train 0.984\n",
            "Stats - Epoch: 92 AUC-val 0.418  AUC-train 0.978\n",
            "Stats - Epoch: 93 AUC-val 0.438  AUC-train 0.983\n",
            "Stats - Epoch: 94 AUC-val 0.431  AUC-train 0.979\n",
            "Stats - Epoch: 95 AUC-val 0.434  AUC-train 0.980\n",
            "Stats - Epoch: 96 AUC-val 0.408  AUC-train 0.979\n",
            "Stats - Epoch: 97 AUC-val 0.442  AUC-train 0.982\n",
            "Stats - Epoch: 98 AUC-val 0.429  AUC-train 0.983\n",
            "Stats - Epoch: 99 AUC-val 0.428  AUC-train 0.979\n",
            "Stats - Epoch: 100 AUC-val 0.426  AUC-train 0.982\n",
            "Results 100 AUC-val 0.479 0.456 0.324 0.179 0.538 AUC-train 0.976\n",
            "Shapley [0.02590971 0.00852305 0.00975382 0.03838348 0.00834229] [0.04160505]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.182579\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.228  AUC-train 0.589\n",
            "Stats - Epoch: 2 AUC-val 0.201  AUC-train 0.649\n",
            "Stats - Epoch: 3 AUC-val 0.227  AUC-train 0.715\n",
            "Stats - Epoch: 4 AUC-val 0.264  AUC-train 0.769\n",
            "Stats - Epoch: 5 AUC-val 0.313  AUC-train 0.809\n",
            "Stats - Epoch: 6 AUC-val 0.390  AUC-train 0.826\n",
            "Stats - Epoch: 7 AUC-val 0.428  AUC-train 0.839\n",
            "Stats - Epoch: 8 AUC-val 0.456  AUC-train 0.849\n",
            "Stats - Epoch: 9 AUC-val 0.469  AUC-train 0.855\n",
            "Stats - Epoch: 10 AUC-val 0.495  AUC-train 0.864\n",
            "Stats - Epoch: 11 AUC-val 0.573  AUC-train 0.869\n",
            "Stats - Epoch: 12 AUC-val 0.479  AUC-train 0.874\n",
            "Stats - Epoch: 13 AUC-val 0.521  AUC-train 0.876\n",
            "Stats - Epoch: 14 AUC-val 0.495  AUC-train 0.879\n",
            "Stats - Epoch: 15 AUC-val 0.544  AUC-train 0.882\n",
            "Stats - Epoch: 16 AUC-val 0.556  AUC-train 0.888\n",
            "Stats - Epoch: 17 AUC-val 0.537  AUC-train 0.892\n",
            "Stats - Epoch: 18 AUC-val 0.568  AUC-train 0.897\n",
            "Stats - Epoch: 19 AUC-val 0.536  AUC-train 0.898\n",
            "Stats - Epoch: 20 AUC-val 0.570  AUC-train 0.897\n",
            "Stats - Epoch: 21 AUC-val 0.581  AUC-train 0.901\n",
            "Stats - Epoch: 22 AUC-val 0.532  AUC-train 0.906\n",
            "Stats - Epoch: 23 AUC-val 0.559  AUC-train 0.910\n",
            "Stats - Epoch: 24 AUC-val 0.558  AUC-train 0.910\n",
            "Stats - Epoch: 25 AUC-val 0.568  AUC-train 0.910\n",
            "Stats - Epoch: 26 AUC-val 0.553  AUC-train 0.911\n",
            "Stats - Epoch: 27 AUC-val 0.572  AUC-train 0.916\n",
            "Stats - Epoch: 28 AUC-val 0.566  AUC-train 0.919\n",
            "Stats - Epoch: 29 AUC-val 0.584  AUC-train 0.923\n",
            "Stats - Epoch: 30 AUC-val 0.590  AUC-train 0.925\n",
            "Stats - Epoch: 31 AUC-val 0.596  AUC-train 0.928\n",
            "Stats - Epoch: 32 AUC-val 0.585  AUC-train 0.930\n",
            "Stats - Epoch: 33 AUC-val 0.574  AUC-train 0.929\n",
            "Stats - Epoch: 34 AUC-val 0.589  AUC-train 0.929\n",
            "Stats - Epoch: 35 AUC-val 0.593  AUC-train 0.931\n",
            "Stats - Epoch: 36 AUC-val 0.594  AUC-train 0.932\n",
            "Stats - Epoch: 37 AUC-val 0.588  AUC-train 0.930\n",
            "Stats - Epoch: 38 AUC-val 0.580  AUC-train 0.934\n",
            "Stats - Epoch: 39 AUC-val 0.588  AUC-train 0.937\n",
            "Stats - Epoch: 40 AUC-val 0.592  AUC-train 0.936\n",
            "Stats - Epoch: 41 AUC-val 0.593  AUC-train 0.938\n",
            "Stats - Epoch: 42 AUC-val 0.668  AUC-train 0.938\n",
            "Stats - Epoch: 43 AUC-val 0.570  AUC-train 0.939\n",
            "Stats - Epoch: 44 AUC-val 0.620  AUC-train 0.942\n",
            "Stats - Epoch: 45 AUC-val 0.588  AUC-train 0.944\n",
            "Stats - Epoch: 46 AUC-val 0.612  AUC-train 0.944\n",
            "Stats - Epoch: 47 AUC-val 0.595  AUC-train 0.948\n",
            "Stats - Epoch: 48 AUC-val 0.576  AUC-train 0.949\n",
            "Stats - Epoch: 49 AUC-val 0.569  AUC-train 0.947\n",
            "Stats - Epoch: 50 AUC-val 0.547  AUC-train 0.946\n",
            "Stats - Epoch: 51 AUC-val 0.575  AUC-train 0.947\n",
            "Stats - Epoch: 52 AUC-val 0.545  AUC-train 0.952\n",
            "Stats - Epoch: 53 AUC-val 0.561  AUC-train 0.955\n",
            "Stats - Epoch: 54 AUC-val 0.538  AUC-train 0.956\n",
            "Stats - Epoch: 55 AUC-val 0.593  AUC-train 0.953\n",
            "Stats - Epoch: 56 AUC-val 0.564  AUC-train 0.953\n",
            "Stats - Epoch: 57 AUC-val 0.562  AUC-train 0.957\n",
            "Stats - Epoch: 58 AUC-val 0.559  AUC-train 0.958\n",
            "Stats - Epoch: 59 AUC-val 0.573  AUC-train 0.958\n",
            "Stats - Epoch: 60 AUC-val 0.569  AUC-train 0.960\n",
            "Stats - Epoch: 61 AUC-val 0.562  AUC-train 0.960\n",
            "Stats - Epoch: 62 AUC-val 0.583  AUC-train 0.962\n",
            "Stats - Epoch: 63 AUC-val 0.601  AUC-train 0.964\n",
            "Stats - Epoch: 64 AUC-val 0.565  AUC-train 0.958\n",
            "Stats - Epoch: 65 AUC-val 0.574  AUC-train 0.961\n",
            "Stats - Epoch: 66 AUC-val 0.586  AUC-train 0.961\n",
            "Stats - Epoch: 67 AUC-val 0.587  AUC-train 0.962\n",
            "Stats - Epoch: 68 AUC-val 0.575  AUC-train 0.963\n",
            "Stats - Epoch: 69 AUC-val 0.594  AUC-train 0.963\n",
            "Stats - Epoch: 70 AUC-val 0.591  AUC-train 0.964\n",
            "Stats - Epoch: 71 AUC-val 0.576  AUC-train 0.963\n",
            "Stats - Epoch: 72 AUC-val 0.580  AUC-train 0.960\n",
            "Stats - Epoch: 73 AUC-val 0.572  AUC-train 0.964\n",
            "Stats - Epoch: 74 AUC-val 0.574  AUC-train 0.965\n",
            "Stats - Epoch: 75 AUC-val 0.578  AUC-train 0.961\n",
            "Stats - Epoch: 76 AUC-val 0.584  AUC-train 0.964\n",
            "Stats - Epoch: 77 AUC-val 0.563  AUC-train 0.960\n",
            "Stats - Epoch: 78 AUC-val 0.563  AUC-train 0.964\n",
            "Stats - Epoch: 79 AUC-val 0.564  AUC-train 0.967\n",
            "Stats - Epoch: 80 AUC-val 0.557  AUC-train 0.970\n",
            "Stats - Epoch: 81 AUC-val 0.563  AUC-train 0.970\n",
            "Stats - Epoch: 82 AUC-val 0.588  AUC-train 0.968\n",
            "Stats - Epoch: 83 AUC-val 0.548  AUC-train 0.971\n",
            "Stats - Epoch: 84 AUC-val 0.550  AUC-train 0.971\n",
            "Stats - Epoch: 85 AUC-val 0.567  AUC-train 0.969\n",
            "Stats - Epoch: 86 AUC-val 0.567  AUC-train 0.971\n",
            "Stats - Epoch: 87 AUC-val 0.578  AUC-train 0.970\n",
            "Stats - Epoch: 88 AUC-val 0.564  AUC-train 0.974\n",
            "Stats - Epoch: 89 AUC-val 0.573  AUC-train 0.973\n",
            "Stats - Epoch: 90 AUC-val 0.559  AUC-train 0.977\n",
            "Stats - Epoch: 91 AUC-val 0.600  AUC-train 0.975\n",
            "Stats - Epoch: 92 AUC-val 0.664  AUC-train 0.975\n",
            "Stats - Epoch: 93 AUC-val 0.586  AUC-train 0.978\n",
            "Stats - Epoch: 94 AUC-val 0.647  AUC-train 0.976\n",
            "Stats - Epoch: 95 AUC-val 0.697  AUC-train 0.976\n",
            "Stats - Epoch: 96 AUC-val 0.628  AUC-train 0.975\n",
            "Stats - Epoch: 97 AUC-val 0.591  AUC-train 0.975\n",
            "Stats - Epoch: 98 AUC-val 0.603  AUC-train 0.974\n",
            "Stats - Epoch: 99 AUC-val 0.598  AUC-train 0.976\n",
            "Stats - Epoch: 100 AUC-val 0.602  AUC-train 0.972\n",
            "Results 100 AUC-val 0.697 0.637 0.557 0.525 0.615 AUC-train 0.976\n",
            "Shapley [0.01905104 0.01184682 0.01674019 0.01577785 0.00701443] [0.00300863]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196538\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.398  AUC-train 0.612\n",
            "Stats - Epoch: 2 AUC-val 0.549  AUC-train 0.767\n",
            "Stats - Epoch: 3 AUC-val 0.611  AUC-train 0.824\n",
            "Stats - Epoch: 4 AUC-val 0.649  AUC-train 0.854\n",
            "Stats - Epoch: 5 AUC-val 0.669  AUC-train 0.882\n",
            "Stats - Epoch: 6 AUC-val 0.690  AUC-train 0.902\n",
            "Stats - Epoch: 7 AUC-val 0.717  AUC-train 0.921\n",
            "Stats - Epoch: 8 AUC-val 0.710  AUC-train 0.936\n",
            "Stats - Epoch: 9 AUC-val 0.728  AUC-train 0.947\n",
            "Stats - Epoch: 10 AUC-val 0.715  AUC-train 0.956\n",
            "Stats - Epoch: 11 AUC-val 0.743  AUC-train 0.966\n",
            "Stats - Epoch: 12 AUC-val 0.734  AUC-train 0.972\n",
            "Stats - Epoch: 13 AUC-val 0.735  AUC-train 0.977\n",
            "Stats - Epoch: 14 AUC-val 0.725  AUC-train 0.981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.726  AUC-train 0.984\n",
            "Stats - Epoch: 16 AUC-val 0.719  AUC-train 0.989\n",
            "Stats - Epoch: 17 AUC-val 0.696  AUC-train 0.989\n",
            "Stats - Epoch: 18 AUC-val 0.726  AUC-train 0.993\n",
            "Stats - Epoch: 19 AUC-val 0.692  AUC-train 0.993\n",
            "Stats - Epoch: 20 AUC-val 0.694  AUC-train 0.993\n",
            "Stats - Epoch: 21 AUC-val 0.688  AUC-train 0.995\n",
            "Stats - Epoch: 22 AUC-val 0.674  AUC-train 0.995\n",
            "Stats - Epoch: 23 AUC-val 0.708  AUC-train 0.996\n",
            "Stats - Epoch: 24 AUC-val 0.709  AUC-train 0.995\n",
            "Stats - Epoch: 25 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 26 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 27 AUC-val 0.684  AUC-train 0.998\n",
            "Stats - Epoch: 28 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 29 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.694  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.650  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.633  AUC-train 0.996\n",
            "Stats - Epoch: 37 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.650  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.696  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 48 AUC-val 0.692  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.663  AUC-train 1.000\n",
            "Stats - Epoch: 52 AUC-val 0.652  AUC-train 0.997\n",
            "Stats - Epoch: 53 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.705  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.653  AUC-train 0.993\n",
            "Stats - Epoch: 56 AUC-val 0.634  AUC-train 0.992\n",
            "Stats - Epoch: 57 AUC-val 0.650  AUC-train 0.996\n",
            "Stats - Epoch: 58 AUC-val 0.650  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.653  AUC-train 0.997\n",
            "Stats - Epoch: 60 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.672  AUC-train 0.997\n",
            "Stats - Epoch: 64 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.657  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.659  AUC-train 0.997\n",
            "Stats - Epoch: 67 AUC-val 0.695  AUC-train 0.997\n",
            "Stats - Epoch: 68 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.680  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.675  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 73 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 75 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 77 AUC-val 0.640  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.650  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.664  AUC-train 0.996\n",
            "Stats - Epoch: 80 AUC-val 0.693  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.630  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.698  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.665  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.673  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.663  AUC-train 0.996\n",
            "Stats - Epoch: 88 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.667  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.682  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.659  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.669  AUC-train 1.000\n",
            "Stats - Epoch: 96 AUC-val 0.696  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.695  AUC-train 0.999\n",
            "Stats - Epoch: 98 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.663  AUC-train 0.999\n",
            "Results 100 AUC-val 0.743 0.619 0.480 0.413 0.573 AUC-train 0.966\n",
            "Shapley [0.01717258 0.01955793 0.01516532 0.03089707 0.0128765 ] [0.01568398]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197521\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.565  AUC-train 0.529\n",
            "Stats - Epoch: 2 AUC-val 0.591  AUC-train 0.708\n",
            "Stats - Epoch: 3 AUC-val 0.614  AUC-train 0.790\n",
            "Stats - Epoch: 4 AUC-val 0.593  AUC-train 0.835\n",
            "Stats - Epoch: 5 AUC-val 0.612  AUC-train 0.859\n",
            "Stats - Epoch: 6 AUC-val 0.607  AUC-train 0.882\n",
            "Stats - Epoch: 7 AUC-val 0.596  AUC-train 0.899\n",
            "Stats - Epoch: 8 AUC-val 0.588  AUC-train 0.914\n",
            "Stats - Epoch: 9 AUC-val 0.602  AUC-train 0.929\n",
            "Stats - Epoch: 10 AUC-val 0.579  AUC-train 0.940\n",
            "Stats - Epoch: 11 AUC-val 0.590  AUC-train 0.949\n",
            "Stats - Epoch: 12 AUC-val 0.581  AUC-train 0.958\n",
            "Stats - Epoch: 13 AUC-val 0.586  AUC-train 0.963\n",
            "Stats - Epoch: 14 AUC-val 0.618  AUC-train 0.969\n",
            "Stats - Epoch: 15 AUC-val 0.622  AUC-train 0.974\n",
            "Stats - Epoch: 16 AUC-val 0.622  AUC-train 0.980\n",
            "Stats - Epoch: 17 AUC-val 0.592  AUC-train 0.983\n",
            "Stats - Epoch: 18 AUC-val 0.662  AUC-train 0.982\n",
            "Stats - Epoch: 19 AUC-val 0.603  AUC-train 0.987\n",
            "Stats - Epoch: 20 AUC-val 0.676  AUC-train 0.989\n",
            "Stats - Epoch: 21 AUC-val 0.645  AUC-train 0.991\n",
            "Stats - Epoch: 22 AUC-val 0.636  AUC-train 0.993\n",
            "Stats - Epoch: 23 AUC-val 0.645  AUC-train 0.994\n",
            "Stats - Epoch: 24 AUC-val 0.647  AUC-train 0.993\n",
            "Stats - Epoch: 25 AUC-val 0.656  AUC-train 0.995\n",
            "Stats - Epoch: 26 AUC-val 0.658  AUC-train 0.993\n",
            "Stats - Epoch: 27 AUC-val 0.634  AUC-train 0.995\n",
            "Stats - Epoch: 28 AUC-val 0.644  AUC-train 0.995\n",
            "Stats - Epoch: 29 AUC-val 0.676  AUC-train 0.997\n",
            "Stats - Epoch: 30 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 31 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 32 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 33 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.677  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.681  AUC-train 0.996\n",
            "Stats - Epoch: 36 AUC-val 0.703  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.691  AUC-train 0.996\n",
            "Stats - Epoch: 38 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 39 AUC-val 0.693  AUC-train 0.995\n",
            "Stats - Epoch: 40 AUC-val 0.704  AUC-train 0.995\n",
            "Stats - Epoch: 41 AUC-val 0.672  AUC-train 0.997\n",
            "Stats - Epoch: 42 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.651  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.675  AUC-train 0.995\n",
            "Stats - Epoch: 45 AUC-val 0.667  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.669  AUC-train 0.994\n",
            "Stats - Epoch: 47 AUC-val 0.658  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.675  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 52 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.689  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.660  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.641  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.643  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.673  AUC-train 0.998\n",
            "Stats - Epoch: 60 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 61 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.691  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.655  AUC-train 0.996\n",
            "Stats - Epoch: 64 AUC-val 0.655  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.667  AUC-train 0.993\n",
            "Stats - Epoch: 66 AUC-val 0.692  AUC-train 0.998\n",
            "Stats - Epoch: 67 AUC-val 0.654  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.671  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.680  AUC-train 0.995\n",
            "Stats - Epoch: 70 AUC-val 0.688  AUC-train 0.991\n",
            "Stats - Epoch: 71 AUC-val 0.663  AUC-train 0.994\n",
            "Stats - Epoch: 72 AUC-val 0.707  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.712  AUC-train 0.992\n",
            "Stats - Epoch: 74 AUC-val 0.704  AUC-train 0.993\n",
            "Stats - Epoch: 75 AUC-val 0.707  AUC-train 0.994\n",
            "Stats - Epoch: 76 AUC-val 0.704  AUC-train 0.998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.712  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.711  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.721  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.717  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.706  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.702  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.687  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.712  AUC-train 0.994\n",
            "Stats - Epoch: 87 AUC-val 0.731  AUC-train 0.993\n",
            "Stats - Epoch: 88 AUC-val 0.726  AUC-train 0.993\n",
            "Stats - Epoch: 89 AUC-val 0.698  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.680  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.687  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.674  AUC-train 0.995\n",
            "Stats - Epoch: 95 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.676  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.679  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 100 AUC-val 0.650  AUC-train 0.997\n",
            "Results 100 AUC-val 0.731 0.704 0.617 0.431 0.581 AUC-train 0.993\n",
            "Shapley [0.01410927 0.01264225 0.00915751 0.01824451 0.00614697] [0.00384242]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.190512\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.376  AUC-train 0.521\n",
            "Stats - Epoch: 2 AUC-val 0.377  AUC-train 0.604\n",
            "Stats - Epoch: 3 AUC-val 0.394  AUC-train 0.647\n",
            "Stats - Epoch: 4 AUC-val 0.415  AUC-train 0.692\n",
            "Stats - Epoch: 5 AUC-val 0.422  AUC-train 0.705\n",
            "Stats - Epoch: 6 AUC-val 0.423  AUC-train 0.730\n",
            "Stats - Epoch: 7 AUC-val 0.423  AUC-train 0.749\n",
            "Stats - Epoch: 8 AUC-val 0.422  AUC-train 0.758\n",
            "Stats - Epoch: 9 AUC-val 0.425  AUC-train 0.771\n",
            "Stats - Epoch: 10 AUC-val 0.424  AUC-train 0.792\n",
            "Stats - Epoch: 11 AUC-val 0.421  AUC-train 0.789\n",
            "Stats - Epoch: 12 AUC-val 0.421  AUC-train 0.815\n",
            "Stats - Epoch: 13 AUC-val 0.409  AUC-train 0.819\n",
            "Stats - Epoch: 14 AUC-val 0.415  AUC-train 0.825\n",
            "Stats - Epoch: 15 AUC-val 0.423  AUC-train 0.831\n",
            "Stats - Epoch: 16 AUC-val 0.425  AUC-train 0.841\n",
            "Stats - Epoch: 17 AUC-val 0.424  AUC-train 0.832\n",
            "Stats - Epoch: 18 AUC-val 0.424  AUC-train 0.849\n",
            "Stats - Epoch: 19 AUC-val 0.431  AUC-train 0.854\n",
            "Stats - Epoch: 20 AUC-val 0.438  AUC-train 0.857\n",
            "Stats - Epoch: 21 AUC-val 0.431  AUC-train 0.860\n",
            "Stats - Epoch: 22 AUC-val 0.444  AUC-train 0.863\n",
            "Stats - Epoch: 23 AUC-val 0.455  AUC-train 0.866\n",
            "Stats - Epoch: 24 AUC-val 0.453  AUC-train 0.864\n",
            "Stats - Epoch: 25 AUC-val 0.453  AUC-train 0.869\n",
            "Stats - Epoch: 26 AUC-val 0.452  AUC-train 0.870\n",
            "Stats - Epoch: 27 AUC-val 0.449  AUC-train 0.870\n",
            "Stats - Epoch: 28 AUC-val 0.457  AUC-train 0.868\n",
            "Stats - Epoch: 29 AUC-val 0.455  AUC-train 0.868\n",
            "Stats - Epoch: 30 AUC-val 0.457  AUC-train 0.876\n",
            "Stats - Epoch: 31 AUC-val 0.455  AUC-train 0.882\n",
            "Stats - Epoch: 32 AUC-val 0.462  AUC-train 0.883\n",
            "Stats - Epoch: 33 AUC-val 0.466  AUC-train 0.881\n",
            "Stats - Epoch: 34 AUC-val 0.458  AUC-train 0.877\n",
            "Stats - Epoch: 35 AUC-val 0.461  AUC-train 0.879\n",
            "Stats - Epoch: 36 AUC-val 0.472  AUC-train 0.876\n",
            "Stats - Epoch: 37 AUC-val 0.455  AUC-train 0.879\n",
            "Stats - Epoch: 38 AUC-val 0.466  AUC-train 0.884\n",
            "Stats - Epoch: 39 AUC-val 0.468  AUC-train 0.883\n",
            "Stats - Epoch: 40 AUC-val 0.472  AUC-train 0.890\n",
            "Stats - Epoch: 41 AUC-val 0.461  AUC-train 0.889\n",
            "Stats - Epoch: 42 AUC-val 0.466  AUC-train 0.886\n",
            "Stats - Epoch: 43 AUC-val 0.460  AUC-train 0.881\n",
            "Stats - Epoch: 44 AUC-val 0.472  AUC-train 0.875\n",
            "Stats - Epoch: 45 AUC-val 0.472  AUC-train 0.885\n",
            "Stats - Epoch: 46 AUC-val 0.470  AUC-train 0.890\n",
            "Stats - Epoch: 47 AUC-val 0.488  AUC-train 0.889\n",
            "Stats - Epoch: 48 AUC-val 0.472  AUC-train 0.887\n",
            "Stats - Epoch: 49 AUC-val 0.481  AUC-train 0.879\n",
            "Stats - Epoch: 50 AUC-val 0.465  AUC-train 0.891\n",
            "Stats - Epoch: 51 AUC-val 0.471  AUC-train 0.885\n",
            "Stats - Epoch: 52 AUC-val 0.479  AUC-train 0.889\n",
            "Stats - Epoch: 53 AUC-val 0.485  AUC-train 0.890\n",
            "Stats - Epoch: 54 AUC-val 0.483  AUC-train 0.891\n",
            "Stats - Epoch: 55 AUC-val 0.478  AUC-train 0.894\n",
            "Stats - Epoch: 56 AUC-val 0.485  AUC-train 0.887\n",
            "Stats - Epoch: 57 AUC-val 0.484  AUC-train 0.889\n",
            "Stats - Epoch: 58 AUC-val 0.486  AUC-train 0.893\n",
            "Stats - Epoch: 59 AUC-val 0.497  AUC-train 0.889\n",
            "Stats - Epoch: 60 AUC-val 0.477  AUC-train 0.896\n",
            "Stats - Epoch: 61 AUC-val 0.484  AUC-train 0.894\n",
            "Stats - Epoch: 62 AUC-val 0.492  AUC-train 0.901\n",
            "Stats - Epoch: 63 AUC-val 0.492  AUC-train 0.897\n",
            "Stats - Epoch: 64 AUC-val 0.483  AUC-train 0.894\n",
            "Stats - Epoch: 65 AUC-val 0.491  AUC-train 0.898\n",
            "Stats - Epoch: 66 AUC-val 0.482  AUC-train 0.897\n",
            "Stats - Epoch: 67 AUC-val 0.491  AUC-train 0.899\n",
            "Stats - Epoch: 68 AUC-val 0.492  AUC-train 0.892\n",
            "Stats - Epoch: 69 AUC-val 0.498  AUC-train 0.900\n",
            "Stats - Epoch: 70 AUC-val 0.479  AUC-train 0.903\n",
            "Stats - Epoch: 71 AUC-val 0.490  AUC-train 0.895\n",
            "Stats - Epoch: 72 AUC-val 0.489  AUC-train 0.892\n",
            "Stats - Epoch: 73 AUC-val 0.504  AUC-train 0.895\n",
            "Stats - Epoch: 74 AUC-val 0.494  AUC-train 0.900\n",
            "Stats - Epoch: 75 AUC-val 0.484  AUC-train 0.900\n",
            "Stats - Epoch: 76 AUC-val 0.488  AUC-train 0.894\n",
            "Stats - Epoch: 77 AUC-val 0.487  AUC-train 0.900\n",
            "Stats - Epoch: 78 AUC-val 0.497  AUC-train 0.900\n",
            "Stats - Epoch: 79 AUC-val 0.492  AUC-train 0.903\n",
            "Stats - Epoch: 80 AUC-val 0.488  AUC-train 0.905\n",
            "Stats - Epoch: 81 AUC-val 0.488  AUC-train 0.904\n",
            "Stats - Epoch: 82 AUC-val 0.492  AUC-train 0.906\n",
            "Stats - Epoch: 83 AUC-val 0.491  AUC-train 0.905\n",
            "Stats - Epoch: 84 AUC-val 0.490  AUC-train 0.900\n",
            "Stats - Epoch: 85 AUC-val 0.493  AUC-train 0.900\n",
            "Stats - Epoch: 86 AUC-val 0.486  AUC-train 0.903\n",
            "Stats - Epoch: 87 AUC-val 0.496  AUC-train 0.904\n",
            "Stats - Epoch: 88 AUC-val 0.490  AUC-train 0.904\n",
            "Stats - Epoch: 89 AUC-val 0.491  AUC-train 0.906\n",
            "Stats - Epoch: 90 AUC-val 0.493  AUC-train 0.902\n",
            "Stats - Epoch: 91 AUC-val 0.502  AUC-train 0.907\n",
            "Stats - Epoch: 92 AUC-val 0.488  AUC-train 0.896\n",
            "Stats - Epoch: 93 AUC-val 0.501  AUC-train 0.904\n",
            "Stats - Epoch: 94 AUC-val 0.486  AUC-train 0.907\n",
            "Stats - Epoch: 95 AUC-val 0.498  AUC-train 0.896\n",
            "Stats - Epoch: 96 AUC-val 0.494  AUC-train 0.906\n",
            "Stats - Epoch: 97 AUC-val 0.492  AUC-train 0.906\n",
            "Stats - Epoch: 98 AUC-val 0.486  AUC-train 0.908\n",
            "Stats - Epoch: 99 AUC-val 0.509  AUC-train 0.907\n",
            "Stats - Epoch: 100 AUC-val 0.497  AUC-train 0.907\n",
            "Results 100 AUC-val 0.509 0.537 0.576 0.501 0.619 AUC-train 0.907\n",
            "Shapley [0.00932832 0.00725217 0.02113013 0.01396123 0.00467237] [0.02097021]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187920\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.282  AUC-train 0.633\n",
            "Stats - Epoch: 2 AUC-val 0.424  AUC-train 0.814\n",
            "Stats - Epoch: 3 AUC-val 0.355  AUC-train 0.882\n",
            "Stats - Epoch: 4 AUC-val 0.357  AUC-train 0.922\n",
            "Stats - Epoch: 5 AUC-val 0.339  AUC-train 0.949\n",
            "Stats - Epoch: 6 AUC-val 0.355  AUC-train 0.960\n",
            "Stats - Epoch: 7 AUC-val 0.354  AUC-train 0.972\n",
            "Stats - Epoch: 8 AUC-val 0.342  AUC-train 0.974\n",
            "Stats - Epoch: 9 AUC-val 0.325  AUC-train 0.980\n",
            "Stats - Epoch: 10 AUC-val 0.363  AUC-train 0.985\n",
            "Stats - Epoch: 11 AUC-val 0.362  AUC-train 0.987\n",
            "Stats - Epoch: 12 AUC-val 0.364  AUC-train 0.991\n",
            "Stats - Epoch: 13 AUC-val 0.358  AUC-train 0.986\n",
            "Stats - Epoch: 14 AUC-val 0.379  AUC-train 0.986\n",
            "Stats - Epoch: 15 AUC-val 0.364  AUC-train 0.990\n",
            "Stats - Epoch: 16 AUC-val 0.398  AUC-train 0.990\n",
            "Stats - Epoch: 17 AUC-val 0.397  AUC-train 0.991\n",
            "Stats - Epoch: 18 AUC-val 0.410  AUC-train 0.986\n",
            "Stats - Epoch: 19 AUC-val 0.423  AUC-train 0.992\n",
            "Stats - Epoch: 20 AUC-val 0.411  AUC-train 0.989\n",
            "Stats - Epoch: 21 AUC-val 0.388  AUC-train 0.990\n",
            "Stats - Epoch: 22 AUC-val 0.417  AUC-train 0.984\n",
            "Stats - Epoch: 23 AUC-val 0.409  AUC-train 0.989\n",
            "Stats - Epoch: 24 AUC-val 0.426  AUC-train 0.992\n",
            "Stats - Epoch: 25 AUC-val 0.424  AUC-train 0.989\n",
            "Stats - Epoch: 26 AUC-val 0.425  AUC-train 0.988\n",
            "Stats - Epoch: 27 AUC-val 0.445  AUC-train 0.989\n",
            "Stats - Epoch: 28 AUC-val 0.413  AUC-train 0.989\n",
            "Stats - Epoch: 29 AUC-val 0.409  AUC-train 0.989\n",
            "Stats - Epoch: 30 AUC-val 0.421  AUC-train 0.989\n",
            "Stats - Epoch: 31 AUC-val 0.440  AUC-train 0.993\n",
            "Stats - Epoch: 32 AUC-val 0.438  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.396  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.440  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.442  AUC-train 0.988\n",
            "Stats - Epoch: 36 AUC-val 0.417  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.442  AUC-train 0.987\n",
            "Stats - Epoch: 38 AUC-val 0.440  AUC-train 0.987\n",
            "Stats - Epoch: 39 AUC-val 0.435  AUC-train 0.988\n",
            "Stats - Epoch: 40 AUC-val 0.456  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.455  AUC-train 0.989\n",
            "Stats - Epoch: 42 AUC-val 0.443  AUC-train 0.984\n",
            "Stats - Epoch: 43 AUC-val 0.444  AUC-train 0.985\n",
            "Stats - Epoch: 44 AUC-val 0.417  AUC-train 0.987\n",
            "Stats - Epoch: 45 AUC-val 0.446  AUC-train 0.985\n",
            "Stats - Epoch: 46 AUC-val 0.449  AUC-train 0.988\n",
            "Stats - Epoch: 47 AUC-val 0.437  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.444  AUC-train 0.984\n",
            "Stats - Epoch: 49 AUC-val 0.430  AUC-train 0.988\n",
            "Stats - Epoch: 50 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 51 AUC-val 0.449  AUC-train 0.986\n",
            "Stats - Epoch: 52 AUC-val 0.447  AUC-train 0.986\n",
            "Stats - Epoch: 53 AUC-val 0.437  AUC-train 0.987\n",
            "Stats - Epoch: 54 AUC-val 0.455  AUC-train 0.987\n",
            "Stats - Epoch: 55 AUC-val 0.460  AUC-train 0.984\n",
            "Stats - Epoch: 56 AUC-val 0.453  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.449  AUC-train 0.981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.466  AUC-train 0.987\n",
            "Stats - Epoch: 59 AUC-val 0.444  AUC-train 0.981\n",
            "Stats - Epoch: 60 AUC-val 0.447  AUC-train 0.983\n",
            "Stats - Epoch: 61 AUC-val 0.456  AUC-train 0.986\n",
            "Stats - Epoch: 62 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 63 AUC-val 0.443  AUC-train 0.986\n",
            "Stats - Epoch: 64 AUC-val 0.460  AUC-train 0.977\n",
            "Stats - Epoch: 65 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 66 AUC-val 0.429  AUC-train 0.986\n",
            "Stats - Epoch: 67 AUC-val 0.438  AUC-train 0.986\n",
            "Stats - Epoch: 68 AUC-val 0.444  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.448  AUC-train 0.986\n",
            "Stats - Epoch: 70 AUC-val 0.462  AUC-train 0.983\n",
            "Stats - Epoch: 71 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 72 AUC-val 0.439  AUC-train 0.978\n",
            "Stats - Epoch: 73 AUC-val 0.448  AUC-train 0.979\n",
            "Stats - Epoch: 74 AUC-val 0.450  AUC-train 0.980\n",
            "Stats - Epoch: 75 AUC-val 0.455  AUC-train 0.981\n",
            "Stats - Epoch: 76 AUC-val 0.479  AUC-train 0.979\n",
            "Stats - Epoch: 77 AUC-val 0.482  AUC-train 0.984\n",
            "Stats - Epoch: 78 AUC-val 0.465  AUC-train 0.970\n",
            "Stats - Epoch: 79 AUC-val 0.462  AUC-train 0.980\n",
            "Stats - Epoch: 80 AUC-val 0.439  AUC-train 0.982\n",
            "Stats - Epoch: 81 AUC-val 0.446  AUC-train 0.981\n",
            "Stats - Epoch: 82 AUC-val 0.440  AUC-train 0.985\n",
            "Stats - Epoch: 83 AUC-val 0.445  AUC-train 0.981\n",
            "Stats - Epoch: 84 AUC-val 0.457  AUC-train 0.982\n",
            "Stats - Epoch: 85 AUC-val 0.439  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.452  AUC-train 0.980\n",
            "Stats - Epoch: 87 AUC-val 0.451  AUC-train 0.984\n",
            "Stats - Epoch: 88 AUC-val 0.460  AUC-train 0.984\n",
            "Stats - Epoch: 89 AUC-val 0.441  AUC-train 0.981\n",
            "Stats - Epoch: 90 AUC-val 0.431  AUC-train 0.980\n",
            "Stats - Epoch: 91 AUC-val 0.461  AUC-train 0.984\n",
            "Stats - Epoch: 92 AUC-val 0.438  AUC-train 0.981\n",
            "Stats - Epoch: 93 AUC-val 0.431  AUC-train 0.987\n",
            "Stats - Epoch: 94 AUC-val 0.438  AUC-train 0.980\n",
            "Stats - Epoch: 95 AUC-val 0.448  AUC-train 0.983\n",
            "Stats - Epoch: 96 AUC-val 0.429  AUC-train 0.978\n",
            "Stats - Epoch: 97 AUC-val 0.428  AUC-train 0.983\n",
            "Stats - Epoch: 98 AUC-val 0.439  AUC-train 0.983\n",
            "Stats - Epoch: 99 AUC-val 0.430  AUC-train 0.975\n",
            "Stats - Epoch: 100 AUC-val 0.421  AUC-train 0.980\n",
            "Results 100 AUC-val 0.482 0.448 0.302 0.181 0.568 AUC-train 0.984\n",
            "Shapley [0.02829803 0.00875492 0.01031144 0.04032201 0.008629  ] [0.03895496]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.180791\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.201  AUC-train 0.578\n",
            "Stats - Epoch: 2 AUC-val 0.190  AUC-train 0.638\n",
            "Stats - Epoch: 3 AUC-val 0.249  AUC-train 0.718\n",
            "Stats - Epoch: 4 AUC-val 0.325  AUC-train 0.771\n",
            "Stats - Epoch: 5 AUC-val 0.412  AUC-train 0.801\n",
            "Stats - Epoch: 6 AUC-val 0.470  AUC-train 0.822\n",
            "Stats - Epoch: 7 AUC-val 0.475  AUC-train 0.837\n",
            "Stats - Epoch: 8 AUC-val 0.528  AUC-train 0.847\n",
            "Stats - Epoch: 9 AUC-val 0.534  AUC-train 0.853\n",
            "Stats - Epoch: 10 AUC-val 0.564  AUC-train 0.856\n",
            "Stats - Epoch: 11 AUC-val 0.552  AUC-train 0.867\n",
            "Stats - Epoch: 12 AUC-val 0.558  AUC-train 0.868\n",
            "Stats - Epoch: 13 AUC-val 0.529  AUC-train 0.873\n",
            "Stats - Epoch: 14 AUC-val 0.543  AUC-train 0.881\n",
            "Stats - Epoch: 15 AUC-val 0.539  AUC-train 0.881\n",
            "Stats - Epoch: 16 AUC-val 0.567  AUC-train 0.887\n",
            "Stats - Epoch: 17 AUC-val 0.589  AUC-train 0.887\n",
            "Stats - Epoch: 18 AUC-val 0.579  AUC-train 0.894\n",
            "Stats - Epoch: 19 AUC-val 0.555  AUC-train 0.897\n",
            "Stats - Epoch: 20 AUC-val 0.581  AUC-train 0.898\n",
            "Stats - Epoch: 21 AUC-val 0.589  AUC-train 0.902\n",
            "Stats - Epoch: 22 AUC-val 0.588  AUC-train 0.908\n",
            "Stats - Epoch: 23 AUC-val 0.560  AUC-train 0.911\n",
            "Stats - Epoch: 24 AUC-val 0.552  AUC-train 0.913\n",
            "Stats - Epoch: 25 AUC-val 0.550  AUC-train 0.916\n",
            "Stats - Epoch: 26 AUC-val 0.572  AUC-train 0.911\n",
            "Stats - Epoch: 27 AUC-val 0.555  AUC-train 0.918\n",
            "Stats - Epoch: 28 AUC-val 0.547  AUC-train 0.919\n",
            "Stats - Epoch: 29 AUC-val 0.558  AUC-train 0.925\n",
            "Stats - Epoch: 30 AUC-val 0.576  AUC-train 0.929\n",
            "Stats - Epoch: 31 AUC-val 0.571  AUC-train 0.931\n",
            "Stats - Epoch: 32 AUC-val 0.541  AUC-train 0.935\n",
            "Stats - Epoch: 33 AUC-val 0.560  AUC-train 0.936\n",
            "Stats - Epoch: 34 AUC-val 0.567  AUC-train 0.936\n",
            "Stats - Epoch: 35 AUC-val 0.563  AUC-train 0.941\n",
            "Stats - Epoch: 36 AUC-val 0.583  AUC-train 0.938\n",
            "Stats - Epoch: 37 AUC-val 0.573  AUC-train 0.938\n",
            "Stats - Epoch: 38 AUC-val 0.557  AUC-train 0.941\n",
            "Stats - Epoch: 39 AUC-val 0.558  AUC-train 0.945\n",
            "Stats - Epoch: 40 AUC-val 0.603  AUC-train 0.944\n",
            "Stats - Epoch: 41 AUC-val 0.582  AUC-train 0.946\n",
            "Stats - Epoch: 42 AUC-val 0.583  AUC-train 0.948\n",
            "Stats - Epoch: 43 AUC-val 0.541  AUC-train 0.949\n",
            "Stats - Epoch: 44 AUC-val 0.550  AUC-train 0.950\n",
            "Stats - Epoch: 45 AUC-val 0.577  AUC-train 0.954\n",
            "Stats - Epoch: 46 AUC-val 0.570  AUC-train 0.954\n",
            "Stats - Epoch: 47 AUC-val 0.598  AUC-train 0.954\n",
            "Stats - Epoch: 48 AUC-val 0.619  AUC-train 0.949\n",
            "Stats - Epoch: 49 AUC-val 0.603  AUC-train 0.952\n",
            "Stats - Epoch: 50 AUC-val 0.594  AUC-train 0.954\n",
            "Stats - Epoch: 51 AUC-val 0.594  AUC-train 0.956\n",
            "Stats - Epoch: 52 AUC-val 0.563  AUC-train 0.959\n",
            "Stats - Epoch: 53 AUC-val 0.584  AUC-train 0.959\n",
            "Stats - Epoch: 54 AUC-val 0.566  AUC-train 0.958\n",
            "Stats - Epoch: 55 AUC-val 0.610  AUC-train 0.956\n",
            "Stats - Epoch: 56 AUC-val 0.553  AUC-train 0.956\n",
            "Stats - Epoch: 57 AUC-val 0.576  AUC-train 0.957\n",
            "Stats - Epoch: 58 AUC-val 0.588  AUC-train 0.956\n",
            "Stats - Epoch: 59 AUC-val 0.594  AUC-train 0.961\n",
            "Stats - Epoch: 60 AUC-val 0.597  AUC-train 0.965\n",
            "Stats - Epoch: 61 AUC-val 0.565  AUC-train 0.964\n",
            "Stats - Epoch: 62 AUC-val 0.605  AUC-train 0.966\n",
            "Stats - Epoch: 63 AUC-val 0.595  AUC-train 0.966\n",
            "Stats - Epoch: 64 AUC-val 0.569  AUC-train 0.967\n",
            "Stats - Epoch: 65 AUC-val 0.607  AUC-train 0.965\n",
            "Stats - Epoch: 66 AUC-val 0.647  AUC-train 0.966\n",
            "Stats - Epoch: 67 AUC-val 0.588  AUC-train 0.961\n",
            "Stats - Epoch: 68 AUC-val 0.562  AUC-train 0.965\n",
            "Stats - Epoch: 69 AUC-val 0.570  AUC-train 0.965\n",
            "Stats - Epoch: 70 AUC-val 0.575  AUC-train 0.966\n",
            "Stats - Epoch: 71 AUC-val 0.584  AUC-train 0.967\n",
            "Stats - Epoch: 72 AUC-val 0.583  AUC-train 0.970\n",
            "Stats - Epoch: 73 AUC-val 0.581  AUC-train 0.970\n",
            "Stats - Epoch: 74 AUC-val 0.616  AUC-train 0.972\n",
            "Stats - Epoch: 75 AUC-val 0.607  AUC-train 0.974\n",
            "Stats - Epoch: 76 AUC-val 0.593  AUC-train 0.971\n",
            "Stats - Epoch: 77 AUC-val 0.611  AUC-train 0.968\n",
            "Stats - Epoch: 78 AUC-val 0.636  AUC-train 0.963\n",
            "Stats - Epoch: 79 AUC-val 0.637  AUC-train 0.965\n",
            "Stats - Epoch: 80 AUC-val 0.619  AUC-train 0.967\n",
            "Stats - Epoch: 81 AUC-val 0.608  AUC-train 0.968\n",
            "Stats - Epoch: 82 AUC-val 0.659  AUC-train 0.966\n",
            "Stats - Epoch: 83 AUC-val 0.628  AUC-train 0.957\n",
            "Stats - Epoch: 84 AUC-val 0.589  AUC-train 0.953\n",
            "Stats - Epoch: 85 AUC-val 0.595  AUC-train 0.956\n",
            "Stats - Epoch: 86 AUC-val 0.581  AUC-train 0.959\n",
            "Stats - Epoch: 87 AUC-val 0.598  AUC-train 0.963\n",
            "Stats - Epoch: 88 AUC-val 0.618  AUC-train 0.963\n",
            "Stats - Epoch: 89 AUC-val 0.655  AUC-train 0.967\n",
            "Stats - Epoch: 90 AUC-val 0.600  AUC-train 0.968\n",
            "Stats - Epoch: 91 AUC-val 0.590  AUC-train 0.971\n",
            "Stats - Epoch: 92 AUC-val 0.596  AUC-train 0.973\n",
            "Stats - Epoch: 93 AUC-val 0.576  AUC-train 0.973\n",
            "Stats - Epoch: 94 AUC-val 0.563  AUC-train 0.971\n",
            "Stats - Epoch: 95 AUC-val 0.621  AUC-train 0.966\n",
            "Stats - Epoch: 96 AUC-val 0.614  AUC-train 0.969\n",
            "Stats - Epoch: 97 AUC-val 0.597  AUC-train 0.970\n",
            "Stats - Epoch: 98 AUC-val 0.611  AUC-train 0.972\n",
            "Stats - Epoch: 99 AUC-val 0.620  AUC-train 0.968\n",
            "Stats - Epoch: 100 AUC-val 0.614  AUC-train 0.969\n",
            "Results 100 AUC-val 0.659 0.571 0.561 0.571 0.641 AUC-train 0.966\n",
            "Shapley [0.01895312 0.0115463  0.01824845 0.01509867 0.0070512 ] [0.00591205]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197424\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.383  AUC-train 0.621\n",
            "Stats - Epoch: 2 AUC-val 0.536  AUC-train 0.782\n",
            "Stats - Epoch: 3 AUC-val 0.592  AUC-train 0.838\n",
            "Stats - Epoch: 4 AUC-val 0.638  AUC-train 0.871\n",
            "Stats - Epoch: 5 AUC-val 0.646  AUC-train 0.895\n",
            "Stats - Epoch: 6 AUC-val 0.673  AUC-train 0.916\n",
            "Stats - Epoch: 7 AUC-val 0.680  AUC-train 0.931\n",
            "Stats - Epoch: 8 AUC-val 0.699  AUC-train 0.948\n",
            "Stats - Epoch: 9 AUC-val 0.680  AUC-train 0.956\n",
            "Stats - Epoch: 10 AUC-val 0.694  AUC-train 0.966\n",
            "Stats - Epoch: 11 AUC-val 0.678  AUC-train 0.973\n",
            "Stats - Epoch: 12 AUC-val 0.674  AUC-train 0.978\n",
            "Stats - Epoch: 13 AUC-val 0.687  AUC-train 0.984\n",
            "Stats - Epoch: 14 AUC-val 0.697  AUC-train 0.987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.693  AUC-train 0.990\n",
            "Stats - Epoch: 16 AUC-val 0.664  AUC-train 0.991\n",
            "Stats - Epoch: 17 AUC-val 0.694  AUC-train 0.994\n",
            "Stats - Epoch: 18 AUC-val 0.691  AUC-train 0.995\n",
            "Stats - Epoch: 19 AUC-val 0.681  AUC-train 0.995\n",
            "Stats - Epoch: 20 AUC-val 0.663  AUC-train 0.997\n",
            "Stats - Epoch: 21 AUC-val 0.693  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.634  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.673  AUC-train 0.996\n",
            "Stats - Epoch: 24 AUC-val 0.655  AUC-train 0.996\n",
            "Stats - Epoch: 25 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.638  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.679  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.653  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.657  AUC-train 1.000\n",
            "Stats - Epoch: 32 AUC-val 0.654  AUC-train 1.000\n",
            "Stats - Epoch: 33 AUC-val 0.677  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.657  AUC-train 1.000\n",
            "Stats - Epoch: 35 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.679  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.647  AUC-train 1.000\n",
            "Stats - Epoch: 39 AUC-val 0.638  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.640  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.657  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.666  AUC-train 1.000\n",
            "Stats - Epoch: 44 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.657  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.638  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.633  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.655  AUC-train 0.994\n",
            "Stats - Epoch: 51 AUC-val 0.650  AUC-train 0.996\n",
            "Stats - Epoch: 52 AUC-val 0.662  AUC-train 0.997\n",
            "Stats - Epoch: 53 AUC-val 0.677  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.647  AUC-train 0.997\n",
            "Stats - Epoch: 55 AUC-val 0.647  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.676  AUC-train 0.997\n",
            "Stats - Epoch: 57 AUC-val 0.657  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.645  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.646  AUC-train 0.994\n",
            "Stats - Epoch: 61 AUC-val 0.646  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.650  AUC-train 0.993\n",
            "Stats - Epoch: 63 AUC-val 0.627  AUC-train 0.998\n",
            "Stats - Epoch: 64 AUC-val 0.649  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.638  AUC-train 0.998\n",
            "Stats - Epoch: 66 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 67 AUC-val 0.666  AUC-train 0.993\n",
            "Stats - Epoch: 68 AUC-val 0.669  AUC-train 0.994\n",
            "Stats - Epoch: 69 AUC-val 0.655  AUC-train 0.996\n",
            "Stats - Epoch: 70 AUC-val 0.644  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.650  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.660  AUC-train 1.000\n",
            "Stats - Epoch: 75 AUC-val 0.623  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.647  AUC-train 0.998\n",
            "Stats - Epoch: 77 AUC-val 0.632  AUC-train 0.997\n",
            "Stats - Epoch: 78 AUC-val 0.627  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.625  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.662  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.627  AUC-train 0.996\n",
            "Stats - Epoch: 82 AUC-val 0.640  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 84 AUC-val 0.632  AUC-train 0.996\n",
            "Stats - Epoch: 85 AUC-val 0.648  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.637  AUC-train 1.000\n",
            "Stats - Epoch: 87 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.616  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.670  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.674  AUC-train 1.000\n",
            "Stats - Epoch: 92 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.643  AUC-train 1.000\n",
            "Stats - Epoch: 96 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.656  AUC-train 1.000\n",
            "Stats - Epoch: 98 AUC-val 0.669  AUC-train 0.996\n",
            "Stats - Epoch: 99 AUC-val 0.676  AUC-train 0.995\n",
            "Stats - Epoch: 100 AUC-val 0.658  AUC-train 0.998\n",
            "Results 100 AUC-val 0.699 0.581 0.466 0.421 0.579 AUC-train 0.948\n",
            "Shapley [0.01404762 0.01615901 0.0160835  0.02856804 0.01209754] [0.01592998]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.197833\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.551  AUC-train 0.533\n",
            "Stats - Epoch: 2 AUC-val 0.589  AUC-train 0.718\n",
            "Stats - Epoch: 3 AUC-val 0.601  AUC-train 0.805\n",
            "Stats - Epoch: 4 AUC-val 0.605  AUC-train 0.847\n",
            "Stats - Epoch: 5 AUC-val 0.607  AUC-train 0.872\n",
            "Stats - Epoch: 6 AUC-val 0.603  AUC-train 0.891\n",
            "Stats - Epoch: 7 AUC-val 0.575  AUC-train 0.910\n",
            "Stats - Epoch: 8 AUC-val 0.566  AUC-train 0.926\n",
            "Stats - Epoch: 9 AUC-val 0.583  AUC-train 0.942\n",
            "Stats - Epoch: 10 AUC-val 0.557  AUC-train 0.950\n",
            "Stats - Epoch: 11 AUC-val 0.572  AUC-train 0.961\n",
            "Stats - Epoch: 12 AUC-val 0.578  AUC-train 0.969\n",
            "Stats - Epoch: 13 AUC-val 0.572  AUC-train 0.975\n",
            "Stats - Epoch: 14 AUC-val 0.557  AUC-train 0.980\n",
            "Stats - Epoch: 15 AUC-val 0.579  AUC-train 0.982\n",
            "Stats - Epoch: 16 AUC-val 0.593  AUC-train 0.984\n",
            "Stats - Epoch: 17 AUC-val 0.595  AUC-train 0.991\n",
            "Stats - Epoch: 18 AUC-val 0.582  AUC-train 0.991\n",
            "Stats - Epoch: 19 AUC-val 0.610  AUC-train 0.993\n",
            "Stats - Epoch: 20 AUC-val 0.578  AUC-train 0.992\n",
            "Stats - Epoch: 21 AUC-val 0.584  AUC-train 0.995\n",
            "Stats - Epoch: 22 AUC-val 0.608  AUC-train 0.995\n",
            "Stats - Epoch: 23 AUC-val 0.614  AUC-train 0.994\n",
            "Stats - Epoch: 24 AUC-val 0.638  AUC-train 0.997\n",
            "Stats - Epoch: 25 AUC-val 0.598  AUC-train 0.996\n",
            "Stats - Epoch: 26 AUC-val 0.604  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.617  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.633  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.605  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.666  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.642  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.649  AUC-train 1.000\n",
            "Stats - Epoch: 33 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.629  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.626  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.653  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.643  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.643  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.642  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.633  AUC-train 0.993\n",
            "Stats - Epoch: 42 AUC-val 0.634  AUC-train 0.995\n",
            "Stats - Epoch: 43 AUC-val 0.673  AUC-train 0.992\n",
            "Stats - Epoch: 44 AUC-val 0.625  AUC-train 0.996\n",
            "Stats - Epoch: 45 AUC-val 0.664  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.633  AUC-train 0.997\n",
            "Stats - Epoch: 47 AUC-val 0.656  AUC-train 0.998\n",
            "Stats - Epoch: 48 AUC-val 0.660  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.680  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 52 AUC-val 0.631  AUC-train 0.997\n",
            "Stats - Epoch: 53 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.660  AUC-train 1.000\n",
            "Stats - Epoch: 55 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.662  AUC-train 0.997\n",
            "Stats - Epoch: 57 AUC-val 0.638  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.671  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.682  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 65 AUC-val 0.650  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.641  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.655  AUC-train 0.997\n",
            "Stats - Epoch: 68 AUC-val 0.648  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.645  AUC-train 0.998\n",
            "Stats - Epoch: 70 AUC-val 0.657  AUC-train 0.995\n",
            "Stats - Epoch: 71 AUC-val 0.610  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.643  AUC-train 0.992\n",
            "Stats - Epoch: 73 AUC-val 0.645  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.656  AUC-train 0.993\n",
            "Stats - Epoch: 75 AUC-val 0.638  AUC-train 0.997\n",
            "Stats - Epoch: 76 AUC-val 0.635  AUC-train 0.994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.673  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.688  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.664  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.648  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.630  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.646  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.667  AUC-train 0.995\n",
            "Stats - Epoch: 85 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.698  AUC-train 0.993\n",
            "Stats - Epoch: 87 AUC-val 0.702  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.648  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.656  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.640  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.616  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.625  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.627  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 98 AUC-val 0.668  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.692  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.655  AUC-train 1.000\n",
            "Results 100 AUC-val 0.702 0.688 0.619 0.491 0.580 AUC-train 0.997\n",
            "Shapley [0.01236478 0.01344127 0.00768464 0.01770619 0.0059593 ] [0.00214496]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199318\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.404  AUC-train 0.510\n",
            "Stats - Epoch: 2 AUC-val 0.381  AUC-train 0.605\n",
            "Stats - Epoch: 3 AUC-val 0.390  AUC-train 0.654\n",
            "Stats - Epoch: 4 AUC-val 0.418  AUC-train 0.691\n",
            "Stats - Epoch: 5 AUC-val 0.419  AUC-train 0.713\n",
            "Stats - Epoch: 6 AUC-val 0.415  AUC-train 0.736\n",
            "Stats - Epoch: 7 AUC-val 0.419  AUC-train 0.751\n",
            "Stats - Epoch: 8 AUC-val 0.424  AUC-train 0.763\n",
            "Stats - Epoch: 9 AUC-val 0.421  AUC-train 0.781\n",
            "Stats - Epoch: 10 AUC-val 0.417  AUC-train 0.802\n",
            "Stats - Epoch: 11 AUC-val 0.414  AUC-train 0.792\n",
            "Stats - Epoch: 12 AUC-val 0.416  AUC-train 0.820\n",
            "Stats - Epoch: 13 AUC-val 0.417  AUC-train 0.825\n",
            "Stats - Epoch: 14 AUC-val 0.428  AUC-train 0.831\n",
            "Stats - Epoch: 15 AUC-val 0.422  AUC-train 0.832\n",
            "Stats - Epoch: 16 AUC-val 0.412  AUC-train 0.849\n",
            "Stats - Epoch: 17 AUC-val 0.421  AUC-train 0.837\n",
            "Stats - Epoch: 18 AUC-val 0.435  AUC-train 0.849\n",
            "Stats - Epoch: 19 AUC-val 0.429  AUC-train 0.855\n",
            "Stats - Epoch: 20 AUC-val 0.440  AUC-train 0.856\n",
            "Stats - Epoch: 21 AUC-val 0.445  AUC-train 0.859\n",
            "Stats - Epoch: 22 AUC-val 0.443  AUC-train 0.851\n",
            "Stats - Epoch: 23 AUC-val 0.439  AUC-train 0.865\n",
            "Stats - Epoch: 24 AUC-val 0.445  AUC-train 0.869\n",
            "Stats - Epoch: 25 AUC-val 0.457  AUC-train 0.863\n",
            "Stats - Epoch: 26 AUC-val 0.449  AUC-train 0.868\n",
            "Stats - Epoch: 27 AUC-val 0.445  AUC-train 0.873\n",
            "Stats - Epoch: 28 AUC-val 0.457  AUC-train 0.870\n",
            "Stats - Epoch: 29 AUC-val 0.443  AUC-train 0.870\n",
            "Stats - Epoch: 30 AUC-val 0.468  AUC-train 0.875\n",
            "Stats - Epoch: 31 AUC-val 0.455  AUC-train 0.879\n",
            "Stats - Epoch: 32 AUC-val 0.456  AUC-train 0.876\n",
            "Stats - Epoch: 33 AUC-val 0.459  AUC-train 0.883\n",
            "Stats - Epoch: 34 AUC-val 0.478  AUC-train 0.876\n",
            "Stats - Epoch: 35 AUC-val 0.452  AUC-train 0.876\n",
            "Stats - Epoch: 36 AUC-val 0.468  AUC-train 0.875\n",
            "Stats - Epoch: 37 AUC-val 0.459  AUC-train 0.879\n",
            "Stats - Epoch: 38 AUC-val 0.468  AUC-train 0.883\n",
            "Stats - Epoch: 39 AUC-val 0.473  AUC-train 0.880\n",
            "Stats - Epoch: 40 AUC-val 0.466  AUC-train 0.889\n",
            "Stats - Epoch: 41 AUC-val 0.469  AUC-train 0.889\n",
            "Stats - Epoch: 42 AUC-val 0.457  AUC-train 0.890\n",
            "Stats - Epoch: 43 AUC-val 0.462  AUC-train 0.881\n",
            "Stats - Epoch: 44 AUC-val 0.467  AUC-train 0.878\n",
            "Stats - Epoch: 45 AUC-val 0.478  AUC-train 0.889\n",
            "Stats - Epoch: 46 AUC-val 0.471  AUC-train 0.892\n",
            "Stats - Epoch: 47 AUC-val 0.452  AUC-train 0.888\n",
            "Stats - Epoch: 48 AUC-val 0.450  AUC-train 0.886\n",
            "Stats - Epoch: 49 AUC-val 0.466  AUC-train 0.879\n",
            "Stats - Epoch: 50 AUC-val 0.466  AUC-train 0.891\n",
            "Stats - Epoch: 51 AUC-val 0.456  AUC-train 0.887\n",
            "Stats - Epoch: 52 AUC-val 0.462  AUC-train 0.888\n",
            "Stats - Epoch: 53 AUC-val 0.461  AUC-train 0.895\n",
            "Stats - Epoch: 54 AUC-val 0.470  AUC-train 0.895\n",
            "Stats - Epoch: 55 AUC-val 0.471  AUC-train 0.896\n",
            "Stats - Epoch: 56 AUC-val 0.460  AUC-train 0.891\n",
            "Stats - Epoch: 57 AUC-val 0.467  AUC-train 0.893\n",
            "Stats - Epoch: 58 AUC-val 0.468  AUC-train 0.892\n",
            "Stats - Epoch: 59 AUC-val 0.478  AUC-train 0.886\n",
            "Stats - Epoch: 60 AUC-val 0.473  AUC-train 0.898\n",
            "Stats - Epoch: 61 AUC-val 0.464  AUC-train 0.896\n",
            "Stats - Epoch: 62 AUC-val 0.464  AUC-train 0.903\n",
            "Stats - Epoch: 63 AUC-val 0.481  AUC-train 0.899\n",
            "Stats - Epoch: 64 AUC-val 0.467  AUC-train 0.898\n",
            "Stats - Epoch: 65 AUC-val 0.477  AUC-train 0.898\n",
            "Stats - Epoch: 66 AUC-val 0.475  AUC-train 0.898\n",
            "Stats - Epoch: 67 AUC-val 0.480  AUC-train 0.899\n",
            "Stats - Epoch: 68 AUC-val 0.481  AUC-train 0.899\n",
            "Stats - Epoch: 69 AUC-val 0.483  AUC-train 0.897\n",
            "Stats - Epoch: 70 AUC-val 0.472  AUC-train 0.905\n",
            "Stats - Epoch: 71 AUC-val 0.469  AUC-train 0.903\n",
            "Stats - Epoch: 72 AUC-val 0.480  AUC-train 0.899\n",
            "Stats - Epoch: 73 AUC-val 0.480  AUC-train 0.894\n",
            "Stats - Epoch: 74 AUC-val 0.470  AUC-train 0.901\n",
            "Stats - Epoch: 75 AUC-val 0.476  AUC-train 0.898\n",
            "Stats - Epoch: 76 AUC-val 0.479  AUC-train 0.900\n",
            "Stats - Epoch: 77 AUC-val 0.467  AUC-train 0.903\n",
            "Stats - Epoch: 78 AUC-val 0.484  AUC-train 0.899\n",
            "Stats - Epoch: 79 AUC-val 0.475  AUC-train 0.905\n",
            "Stats - Epoch: 80 AUC-val 0.466  AUC-train 0.905\n",
            "Stats - Epoch: 81 AUC-val 0.478  AUC-train 0.906\n",
            "Stats - Epoch: 82 AUC-val 0.477  AUC-train 0.910\n",
            "Stats - Epoch: 83 AUC-val 0.472  AUC-train 0.909\n",
            "Stats - Epoch: 84 AUC-val 0.459  AUC-train 0.899\n",
            "Stats - Epoch: 85 AUC-val 0.472  AUC-train 0.904\n",
            "Stats - Epoch: 86 AUC-val 0.470  AUC-train 0.904\n",
            "Stats - Epoch: 87 AUC-val 0.478  AUC-train 0.904\n",
            "Stats - Epoch: 88 AUC-val 0.471  AUC-train 0.906\n",
            "Stats - Epoch: 89 AUC-val 0.479  AUC-train 0.908\n",
            "Stats - Epoch: 90 AUC-val 0.474  AUC-train 0.902\n",
            "Stats - Epoch: 91 AUC-val 0.482  AUC-train 0.907\n",
            "Stats - Epoch: 92 AUC-val 0.483  AUC-train 0.898\n",
            "Stats - Epoch: 93 AUC-val 0.483  AUC-train 0.905\n",
            "Stats - Epoch: 94 AUC-val 0.468  AUC-train 0.908\n",
            "Stats - Epoch: 95 AUC-val 0.482  AUC-train 0.902\n",
            "Stats - Epoch: 96 AUC-val 0.484  AUC-train 0.908\n",
            "Stats - Epoch: 97 AUC-val 0.479  AUC-train 0.907\n",
            "Stats - Epoch: 98 AUC-val 0.478  AUC-train 0.908\n",
            "Stats - Epoch: 99 AUC-val 0.478  AUC-train 0.906\n",
            "Stats - Epoch: 100 AUC-val 0.472  AUC-train 0.908\n",
            "Results 100 AUC-val 0.484 0.515 0.555 0.488 0.621 AUC-train 0.908\n",
            "Shapley [0.00853037 0.00666843 0.01886612 0.01318388 0.0045387 ] [0.01982078]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187609\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.303  AUC-train 0.637\n",
            "Stats - Epoch: 2 AUC-val 0.358  AUC-train 0.817\n",
            "Stats - Epoch: 3 AUC-val 0.368  AUC-train 0.897\n",
            "Stats - Epoch: 4 AUC-val 0.376  AUC-train 0.934\n",
            "Stats - Epoch: 5 AUC-val 0.353  AUC-train 0.958\n",
            "Stats - Epoch: 6 AUC-val 0.379  AUC-train 0.971\n",
            "Stats - Epoch: 7 AUC-val 0.377  AUC-train 0.979\n",
            "Stats - Epoch: 8 AUC-val 0.355  AUC-train 0.981\n",
            "Stats - Epoch: 9 AUC-val 0.372  AUC-train 0.984\n",
            "Stats - Epoch: 10 AUC-val 0.397  AUC-train 0.986\n",
            "Stats - Epoch: 11 AUC-val 0.371  AUC-train 0.987\n",
            "Stats - Epoch: 12 AUC-val 0.381  AUC-train 0.989\n",
            "Stats - Epoch: 13 AUC-val 0.403  AUC-train 0.987\n",
            "Stats - Epoch: 14 AUC-val 0.410  AUC-train 0.992\n",
            "Stats - Epoch: 15 AUC-val 0.410  AUC-train 0.990\n",
            "Stats - Epoch: 16 AUC-val 0.422  AUC-train 0.987\n",
            "Stats - Epoch: 17 AUC-val 0.403  AUC-train 0.989\n",
            "Stats - Epoch: 18 AUC-val 0.415  AUC-train 0.985\n",
            "Stats - Epoch: 19 AUC-val 0.405  AUC-train 0.991\n",
            "Stats - Epoch: 20 AUC-val 0.407  AUC-train 0.989\n",
            "Stats - Epoch: 21 AUC-val 0.413  AUC-train 0.991\n",
            "Stats - Epoch: 22 AUC-val 0.411  AUC-train 0.985\n",
            "Stats - Epoch: 23 AUC-val 0.407  AUC-train 0.990\n",
            "Stats - Epoch: 24 AUC-val 0.417  AUC-train 0.989\n",
            "Stats - Epoch: 25 AUC-val 0.417  AUC-train 0.989\n",
            "Stats - Epoch: 26 AUC-val 0.414  AUC-train 0.988\n",
            "Stats - Epoch: 27 AUC-val 0.450  AUC-train 0.986\n",
            "Stats - Epoch: 28 AUC-val 0.431  AUC-train 0.990\n",
            "Stats - Epoch: 29 AUC-val 0.435  AUC-train 0.986\n",
            "Stats - Epoch: 30 AUC-val 0.433  AUC-train 0.985\n",
            "Stats - Epoch: 31 AUC-val 0.456  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.432  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.424  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.431  AUC-train 0.983\n",
            "Stats - Epoch: 35 AUC-val 0.453  AUC-train 0.984\n",
            "Stats - Epoch: 36 AUC-val 0.434  AUC-train 0.986\n",
            "Stats - Epoch: 37 AUC-val 0.434  AUC-train 0.985\n",
            "Stats - Epoch: 38 AUC-val 0.445  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.434  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.460  AUC-train 0.986\n",
            "Stats - Epoch: 41 AUC-val 0.446  AUC-train 0.989\n",
            "Stats - Epoch: 42 AUC-val 0.447  AUC-train 0.986\n",
            "Stats - Epoch: 43 AUC-val 0.460  AUC-train 0.983\n",
            "Stats - Epoch: 44 AUC-val 0.440  AUC-train 0.985\n",
            "Stats - Epoch: 45 AUC-val 0.458  AUC-train 0.982\n",
            "Stats - Epoch: 46 AUC-val 0.443  AUC-train 0.983\n",
            "Stats - Epoch: 47 AUC-val 0.452  AUC-train 0.987\n",
            "Stats - Epoch: 48 AUC-val 0.448  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.440  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.423  AUC-train 0.986\n",
            "Stats - Epoch: 51 AUC-val 0.434  AUC-train 0.988\n",
            "Stats - Epoch: 52 AUC-val 0.434  AUC-train 0.985\n",
            "Stats - Epoch: 53 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 54 AUC-val 0.438  AUC-train 0.984\n",
            "Stats - Epoch: 55 AUC-val 0.480  AUC-train 0.982\n",
            "Stats - Epoch: 56 AUC-val 0.444  AUC-train 0.986\n",
            "Stats - Epoch: 57 AUC-val 0.440  AUC-train 0.985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.468  AUC-train 0.983\n",
            "Stats - Epoch: 59 AUC-val 0.454  AUC-train 0.986\n",
            "Stats - Epoch: 60 AUC-val 0.437  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.452  AUC-train 0.981\n",
            "Stats - Epoch: 62 AUC-val 0.442  AUC-train 0.987\n",
            "Stats - Epoch: 63 AUC-val 0.450  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.461  AUC-train 0.974\n",
            "Stats - Epoch: 65 AUC-val 0.472  AUC-train 0.981\n",
            "Stats - Epoch: 66 AUC-val 0.434  AUC-train 0.982\n",
            "Stats - Epoch: 67 AUC-val 0.443  AUC-train 0.980\n",
            "Stats - Epoch: 68 AUC-val 0.454  AUC-train 0.980\n",
            "Stats - Epoch: 69 AUC-val 0.445  AUC-train 0.985\n",
            "Stats - Epoch: 70 AUC-val 0.436  AUC-train 0.982\n",
            "Stats - Epoch: 71 AUC-val 0.455  AUC-train 0.982\n",
            "Stats - Epoch: 72 AUC-val 0.431  AUC-train 0.981\n",
            "Stats - Epoch: 73 AUC-val 0.459  AUC-train 0.982\n",
            "Stats - Epoch: 74 AUC-val 0.439  AUC-train 0.982\n",
            "Stats - Epoch: 75 AUC-val 0.456  AUC-train 0.981\n",
            "Stats - Epoch: 76 AUC-val 0.458  AUC-train 0.979\n",
            "Stats - Epoch: 77 AUC-val 0.464  AUC-train 0.983\n",
            "Stats - Epoch: 78 AUC-val 0.467  AUC-train 0.977\n",
            "Stats - Epoch: 79 AUC-val 0.441  AUC-train 0.982\n",
            "Stats - Epoch: 80 AUC-val 0.429  AUC-train 0.980\n",
            "Stats - Epoch: 81 AUC-val 0.417  AUC-train 0.982\n",
            "Stats - Epoch: 82 AUC-val 0.429  AUC-train 0.983\n",
            "Stats - Epoch: 83 AUC-val 0.454  AUC-train 0.981\n",
            "Stats - Epoch: 84 AUC-val 0.452  AUC-train 0.981\n",
            "Stats - Epoch: 85 AUC-val 0.440  AUC-train 0.981\n",
            "Stats - Epoch: 86 AUC-val 0.440  AUC-train 0.980\n",
            "Stats - Epoch: 87 AUC-val 0.438  AUC-train 0.983\n",
            "Stats - Epoch: 88 AUC-val 0.450  AUC-train 0.983\n",
            "Stats - Epoch: 89 AUC-val 0.457  AUC-train 0.978\n",
            "Stats - Epoch: 90 AUC-val 0.431  AUC-train 0.982\n",
            "Stats - Epoch: 91 AUC-val 0.463  AUC-train 0.983\n",
            "Stats - Epoch: 92 AUC-val 0.429  AUC-train 0.981\n",
            "Stats - Epoch: 93 AUC-val 0.434  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.418  AUC-train 0.980\n",
            "Stats - Epoch: 95 AUC-val 0.424  AUC-train 0.981\n",
            "Stats - Epoch: 96 AUC-val 0.431  AUC-train 0.976\n",
            "Stats - Epoch: 97 AUC-val 0.433  AUC-train 0.980\n",
            "Stats - Epoch: 98 AUC-val 0.433  AUC-train 0.982\n",
            "Stats - Epoch: 99 AUC-val 0.434  AUC-train 0.979\n",
            "Stats - Epoch: 100 AUC-val 0.426  AUC-train 0.979\n",
            "Results 100 AUC-val 0.480 0.434 0.286 0.149 0.525 AUC-train 0.982\n",
            "Shapley [0.0305522  0.00943152 0.01211986 0.04740813 0.01178041] [0.04943282]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186530\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.204  AUC-train 0.612\n",
            "Stats - Epoch: 2 AUC-val 0.207  AUC-train 0.678\n",
            "Stats - Epoch: 3 AUC-val 0.272  AUC-train 0.750\n",
            "Stats - Epoch: 4 AUC-val 0.325  AUC-train 0.800\n",
            "Stats - Epoch: 5 AUC-val 0.430  AUC-train 0.828\n",
            "Stats - Epoch: 6 AUC-val 0.431  AUC-train 0.841\n",
            "Stats - Epoch: 7 AUC-val 0.461  AUC-train 0.857\n",
            "Stats - Epoch: 8 AUC-val 0.495  AUC-train 0.864\n",
            "Stats - Epoch: 9 AUC-val 0.521  AUC-train 0.870\n",
            "Stats - Epoch: 10 AUC-val 0.521  AUC-train 0.880\n",
            "Stats - Epoch: 11 AUC-val 0.509  AUC-train 0.885\n",
            "Stats - Epoch: 12 AUC-val 0.500  AUC-train 0.890\n",
            "Stats - Epoch: 13 AUC-val 0.575  AUC-train 0.890\n",
            "Stats - Epoch: 14 AUC-val 0.496  AUC-train 0.900\n",
            "Stats - Epoch: 15 AUC-val 0.517  AUC-train 0.899\n",
            "Stats - Epoch: 16 AUC-val 0.512  AUC-train 0.906\n",
            "Stats - Epoch: 17 AUC-val 0.546  AUC-train 0.907\n",
            "Stats - Epoch: 18 AUC-val 0.540  AUC-train 0.909\n",
            "Stats - Epoch: 19 AUC-val 0.547  AUC-train 0.911\n",
            "Stats - Epoch: 20 AUC-val 0.547  AUC-train 0.917\n",
            "Stats - Epoch: 21 AUC-val 0.580  AUC-train 0.916\n",
            "Stats - Epoch: 22 AUC-val 0.597  AUC-train 0.920\n",
            "Stats - Epoch: 23 AUC-val 0.576  AUC-train 0.922\n",
            "Stats - Epoch: 24 AUC-val 0.619  AUC-train 0.916\n",
            "Stats - Epoch: 25 AUC-val 0.607  AUC-train 0.922\n",
            "Stats - Epoch: 26 AUC-val 0.611  AUC-train 0.925\n",
            "Stats - Epoch: 27 AUC-val 0.564  AUC-train 0.927\n",
            "Stats - Epoch: 28 AUC-val 0.561  AUC-train 0.932\n",
            "Stats - Epoch: 29 AUC-val 0.588  AUC-train 0.935\n",
            "Stats - Epoch: 30 AUC-val 0.590  AUC-train 0.937\n",
            "Stats - Epoch: 31 AUC-val 0.589  AUC-train 0.939\n",
            "Stats - Epoch: 32 AUC-val 0.556  AUC-train 0.944\n",
            "Stats - Epoch: 33 AUC-val 0.614  AUC-train 0.943\n",
            "Stats - Epoch: 34 AUC-val 0.593  AUC-train 0.945\n",
            "Stats - Epoch: 35 AUC-val 0.574  AUC-train 0.950\n",
            "Stats - Epoch: 36 AUC-val 0.595  AUC-train 0.948\n",
            "Stats - Epoch: 37 AUC-val 0.604  AUC-train 0.951\n",
            "Stats - Epoch: 38 AUC-val 0.574  AUC-train 0.951\n",
            "Stats - Epoch: 39 AUC-val 0.574  AUC-train 0.953\n",
            "Stats - Epoch: 40 AUC-val 0.622  AUC-train 0.952\n",
            "Stats - Epoch: 41 AUC-val 0.583  AUC-train 0.952\n",
            "Stats - Epoch: 42 AUC-val 0.577  AUC-train 0.951\n",
            "Stats - Epoch: 43 AUC-val 0.580  AUC-train 0.950\n",
            "Stats - Epoch: 44 AUC-val 0.617  AUC-train 0.953\n",
            "Stats - Epoch: 45 AUC-val 0.617  AUC-train 0.956\n",
            "Stats - Epoch: 46 AUC-val 0.606  AUC-train 0.959\n",
            "Stats - Epoch: 47 AUC-val 0.621  AUC-train 0.958\n",
            "Stats - Epoch: 48 AUC-val 0.594  AUC-train 0.958\n",
            "Stats - Epoch: 49 AUC-val 0.600  AUC-train 0.962\n",
            "Stats - Epoch: 50 AUC-val 0.596  AUC-train 0.964\n",
            "Stats - Epoch: 51 AUC-val 0.572  AUC-train 0.963\n",
            "Stats - Epoch: 52 AUC-val 0.620  AUC-train 0.965\n",
            "Stats - Epoch: 53 AUC-val 0.605  AUC-train 0.966\n",
            "Stats - Epoch: 54 AUC-val 0.584  AUC-train 0.963\n",
            "Stats - Epoch: 55 AUC-val 0.605  AUC-train 0.966\n",
            "Stats - Epoch: 56 AUC-val 0.610  AUC-train 0.961\n",
            "Stats - Epoch: 57 AUC-val 0.581  AUC-train 0.969\n",
            "Stats - Epoch: 58 AUC-val 0.586  AUC-train 0.964\n",
            "Stats - Epoch: 59 AUC-val 0.692  AUC-train 0.968\n",
            "Stats - Epoch: 60 AUC-val 0.563  AUC-train 0.970\n",
            "Stats - Epoch: 61 AUC-val 0.660  AUC-train 0.971\n",
            "Stats - Epoch: 62 AUC-val 0.616  AUC-train 0.969\n",
            "Stats - Epoch: 63 AUC-val 0.596  AUC-train 0.968\n",
            "Stats - Epoch: 64 AUC-val 0.659  AUC-train 0.970\n",
            "Stats - Epoch: 65 AUC-val 0.664  AUC-train 0.967\n",
            "Stats - Epoch: 66 AUC-val 0.637  AUC-train 0.969\n",
            "Stats - Epoch: 67 AUC-val 0.609  AUC-train 0.967\n",
            "Stats - Epoch: 68 AUC-val 0.606  AUC-train 0.969\n",
            "Stats - Epoch: 69 AUC-val 0.675  AUC-train 0.969\n",
            "Stats - Epoch: 70 AUC-val 0.545  AUC-train 0.966\n",
            "Stats - Epoch: 71 AUC-val 0.588  AUC-train 0.969\n",
            "Stats - Epoch: 72 AUC-val 0.585  AUC-train 0.969\n",
            "Stats - Epoch: 73 AUC-val 0.558  AUC-train 0.971\n",
            "Stats - Epoch: 74 AUC-val 0.576  AUC-train 0.973\n",
            "Stats - Epoch: 75 AUC-val 0.598  AUC-train 0.970\n",
            "Stats - Epoch: 76 AUC-val 0.600  AUC-train 0.969\n",
            "Stats - Epoch: 77 AUC-val 0.602  AUC-train 0.968\n",
            "Stats - Epoch: 78 AUC-val 0.616  AUC-train 0.974\n",
            "Stats - Epoch: 79 AUC-val 0.598  AUC-train 0.974\n",
            "Stats - Epoch: 80 AUC-val 0.590  AUC-train 0.970\n",
            "Stats - Epoch: 81 AUC-val 0.609  AUC-train 0.971\n",
            "Stats - Epoch: 82 AUC-val 0.616  AUC-train 0.972\n",
            "Stats - Epoch: 83 AUC-val 0.629  AUC-train 0.972\n",
            "Stats - Epoch: 84 AUC-val 0.594  AUC-train 0.969\n",
            "Stats - Epoch: 85 AUC-val 0.557  AUC-train 0.971\n",
            "Stats - Epoch: 86 AUC-val 0.632  AUC-train 0.974\n",
            "Stats - Epoch: 87 AUC-val 0.580  AUC-train 0.976\n",
            "Stats - Epoch: 88 AUC-val 0.572  AUC-train 0.975\n",
            "Stats - Epoch: 89 AUC-val 0.551  AUC-train 0.974\n",
            "Stats - Epoch: 90 AUC-val 0.586  AUC-train 0.976\n",
            "Stats - Epoch: 91 AUC-val 0.579  AUC-train 0.980\n",
            "Stats - Epoch: 92 AUC-val 0.600  AUC-train 0.975\n",
            "Stats - Epoch: 93 AUC-val 0.570  AUC-train 0.979\n",
            "Stats - Epoch: 94 AUC-val 0.617  AUC-train 0.979\n",
            "Stats - Epoch: 95 AUC-val 0.647  AUC-train 0.976\n",
            "Stats - Epoch: 96 AUC-val 0.550  AUC-train 0.982\n",
            "Stats - Epoch: 97 AUC-val 0.574  AUC-train 0.980\n",
            "Stats - Epoch: 98 AUC-val 0.600  AUC-train 0.976\n",
            "Stats - Epoch: 99 AUC-val 0.587  AUC-train 0.979\n",
            "Stats - Epoch: 100 AUC-val 0.583  AUC-train 0.982\n",
            "Results 100 AUC-val 0.692 0.622 0.593 0.567 0.655 AUC-train 0.968\n",
            "Shapley [0.01686865 0.0134553  0.01195802 0.01631939 0.00826471] [0.01790231]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199627\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.407  AUC-train 0.662\n",
            "Stats - Epoch: 2 AUC-val 0.573  AUC-train 0.798\n",
            "Stats - Epoch: 3 AUC-val 0.619  AUC-train 0.847\n",
            "Stats - Epoch: 4 AUC-val 0.664  AUC-train 0.878\n",
            "Stats - Epoch: 5 AUC-val 0.663  AUC-train 0.899\n",
            "Stats - Epoch: 6 AUC-val 0.676  AUC-train 0.917\n",
            "Stats - Epoch: 7 AUC-val 0.683  AUC-train 0.935\n",
            "Stats - Epoch: 8 AUC-val 0.685  AUC-train 0.951\n",
            "Stats - Epoch: 9 AUC-val 0.694  AUC-train 0.961\n",
            "Stats - Epoch: 10 AUC-val 0.705  AUC-train 0.971\n",
            "Stats - Epoch: 11 AUC-val 0.702  AUC-train 0.979\n",
            "Stats - Epoch: 12 AUC-val 0.691  AUC-train 0.981\n",
            "Stats - Epoch: 13 AUC-val 0.694  AUC-train 0.988\n",
            "Stats - Epoch: 14 AUC-val 0.697  AUC-train 0.990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.680  AUC-train 0.992\n",
            "Stats - Epoch: 16 AUC-val 0.664  AUC-train 0.994\n",
            "Stats - Epoch: 17 AUC-val 0.679  AUC-train 0.996\n",
            "Stats - Epoch: 18 AUC-val 0.694  AUC-train 0.995\n",
            "Stats - Epoch: 19 AUC-val 0.665  AUC-train 0.997\n",
            "Stats - Epoch: 20 AUC-val 0.680  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.663  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.646  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.634  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.664  AUC-train 0.997\n",
            "Stats - Epoch: 25 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.635  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.662  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.619  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.626  AUC-train 1.000\n",
            "Stats - Epoch: 34 AUC-val 0.643  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.637  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.647  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.635  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.651  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.695  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 42 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.696  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.692  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.665  AUC-train 1.000\n",
            "Stats - Epoch: 46 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.679  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.646  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.657  AUC-train 0.997\n",
            "Stats - Epoch: 52 AUC-val 0.658  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.677  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.695  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.689  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.714  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.690  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.684  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.702  AUC-train 0.995\n",
            "Stats - Epoch: 63 AUC-val 0.697  AUC-train 0.995\n",
            "Stats - Epoch: 64 AUC-val 0.721  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.726  AUC-train 0.997\n",
            "Stats - Epoch: 66 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 67 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 68 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.662  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.628  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.679  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.696  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.674  AUC-train 1.000\n",
            "Stats - Epoch: 77 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.695  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.687  AUC-train 1.000\n",
            "Stats - Epoch: 80 AUC-val 0.702  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.708  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.688  AUC-train 1.000\n",
            "Stats - Epoch: 83 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 84 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 86 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.670  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.672  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.689  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.691  AUC-train 1.000\n",
            "Stats - Epoch: 94 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 97 AUC-val 0.682  AUC-train 1.000\n",
            "Stats - Epoch: 98 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.688  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.649  AUC-train 0.998\n",
            "Results 100 AUC-val 0.726 0.614 0.432 0.457 0.596 AUC-train 0.997\n",
            "Shapley [0.01843548 0.02219807 0.01308919 0.04320125 0.02346349] [0.01353554]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.183221\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.567  AUC-train 0.547\n",
            "Stats - Epoch: 2 AUC-val 0.590  AUC-train 0.737\n",
            "Stats - Epoch: 3 AUC-val 0.586  AUC-train 0.813\n",
            "Stats - Epoch: 4 AUC-val 0.593  AUC-train 0.849\n",
            "Stats - Epoch: 5 AUC-val 0.588  AUC-train 0.874\n",
            "Stats - Epoch: 6 AUC-val 0.585  AUC-train 0.893\n",
            "Stats - Epoch: 7 AUC-val 0.590  AUC-train 0.912\n",
            "Stats - Epoch: 8 AUC-val 0.582  AUC-train 0.928\n",
            "Stats - Epoch: 9 AUC-val 0.559  AUC-train 0.943\n",
            "Stats - Epoch: 10 AUC-val 0.544  AUC-train 0.949\n",
            "Stats - Epoch: 11 AUC-val 0.548  AUC-train 0.957\n",
            "Stats - Epoch: 12 AUC-val 0.555  AUC-train 0.965\n",
            "Stats - Epoch: 13 AUC-val 0.559  AUC-train 0.971\n",
            "Stats - Epoch: 14 AUC-val 0.550  AUC-train 0.976\n",
            "Stats - Epoch: 15 AUC-val 0.522  AUC-train 0.982\n",
            "Stats - Epoch: 16 AUC-val 0.570  AUC-train 0.985\n",
            "Stats - Epoch: 17 AUC-val 0.574  AUC-train 0.987\n",
            "Stats - Epoch: 18 AUC-val 0.582  AUC-train 0.989\n",
            "Stats - Epoch: 19 AUC-val 0.607  AUC-train 0.992\n",
            "Stats - Epoch: 20 AUC-val 0.616  AUC-train 0.990\n",
            "Stats - Epoch: 21 AUC-val 0.590  AUC-train 0.993\n",
            "Stats - Epoch: 22 AUC-val 0.605  AUC-train 0.994\n",
            "Stats - Epoch: 23 AUC-val 0.615  AUC-train 0.995\n",
            "Stats - Epoch: 24 AUC-val 0.604  AUC-train 0.995\n",
            "Stats - Epoch: 25 AUC-val 0.608  AUC-train 0.993\n",
            "Stats - Epoch: 26 AUC-val 0.657  AUC-train 0.994\n",
            "Stats - Epoch: 27 AUC-val 0.603  AUC-train 0.997\n",
            "Stats - Epoch: 28 AUC-val 0.650  AUC-train 0.996\n",
            "Stats - Epoch: 29 AUC-val 0.647  AUC-train 0.997\n",
            "Stats - Epoch: 30 AUC-val 0.645  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.643  AUC-train 0.998\n",
            "Stats - Epoch: 32 AUC-val 0.624  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.609  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.662  AUC-train 0.996\n",
            "Stats - Epoch: 35 AUC-val 0.682  AUC-train 0.996\n",
            "Stats - Epoch: 36 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.647  AUC-train 0.997\n",
            "Stats - Epoch: 38 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.632  AUC-train 0.997\n",
            "Stats - Epoch: 41 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.695  AUC-train 0.995\n",
            "Stats - Epoch: 44 AUC-val 0.662  AUC-train 0.996\n",
            "Stats - Epoch: 45 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 47 AUC-val 0.705  AUC-train 0.990\n",
            "Stats - Epoch: 48 AUC-val 0.705  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.703  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.721  AUC-train 0.996\n",
            "Stats - Epoch: 51 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 52 AUC-val 0.712  AUC-train 0.996\n",
            "Stats - Epoch: 53 AUC-val 0.718  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.710  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.705  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.714  AUC-train 0.995\n",
            "Stats - Epoch: 57 AUC-val 0.676  AUC-train 0.995\n",
            "Stats - Epoch: 58 AUC-val 0.700  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.713  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.726  AUC-train 0.998\n",
            "Stats - Epoch: 61 AUC-val 0.720  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.727  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.724  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.705  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.709  AUC-train 0.996\n",
            "Stats - Epoch: 68 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.695  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.699  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 72 AUC-val 0.689  AUC-train 0.993\n",
            "Stats - Epoch: 73 AUC-val 0.650  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 75 AUC-val 0.661  AUC-train 1.000\n",
            "Stats - Epoch: 76 AUC-val 0.665  AUC-train 0.999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 78 AUC-val 0.684  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.678  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.633  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.679  AUC-train 0.999\n",
            "Stats - Epoch: 86 AUC-val 0.674  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.743  AUC-train 0.992\n",
            "Stats - Epoch: 88 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.674  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.696  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.700  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.697  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.701  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.699  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.684  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.705  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.693  AUC-train 0.996\n",
            "Stats - Epoch: 99 AUC-val 0.672  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.721  AUC-train 0.995\n",
            "Results 100 AUC-val 0.743 0.619 0.419 0.396 0.599 AUC-train 0.992\n",
            "Shapley [0.01675695 0.01567781 0.0113431  0.02405303 0.00619107] [0.00429534]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196804\n",
            "         Iterations 7\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.378  AUC-train 0.524\n",
            "Stats - Epoch: 2 AUC-val 0.423  AUC-train 0.610\n",
            "Stats - Epoch: 3 AUC-val 0.428  AUC-train 0.650\n",
            "Stats - Epoch: 4 AUC-val 0.429  AUC-train 0.702\n",
            "Stats - Epoch: 5 AUC-val 0.426  AUC-train 0.718\n",
            "Stats - Epoch: 6 AUC-val 0.426  AUC-train 0.747\n",
            "Stats - Epoch: 7 AUC-val 0.429  AUC-train 0.761\n",
            "Stats - Epoch: 8 AUC-val 0.421  AUC-train 0.775\n",
            "Stats - Epoch: 9 AUC-val 0.422  AUC-train 0.792\n",
            "Stats - Epoch: 10 AUC-val 0.426  AUC-train 0.810\n",
            "Stats - Epoch: 11 AUC-val 0.430  AUC-train 0.802\n",
            "Stats - Epoch: 12 AUC-val 0.430  AUC-train 0.828\n",
            "Stats - Epoch: 13 AUC-val 0.424  AUC-train 0.830\n",
            "Stats - Epoch: 14 AUC-val 0.420  AUC-train 0.834\n",
            "Stats - Epoch: 15 AUC-val 0.426  AUC-train 0.841\n",
            "Stats - Epoch: 16 AUC-val 0.437  AUC-train 0.851\n",
            "Stats - Epoch: 17 AUC-val 0.431  AUC-train 0.845\n",
            "Stats - Epoch: 18 AUC-val 0.427  AUC-train 0.860\n",
            "Stats - Epoch: 19 AUC-val 0.428  AUC-train 0.861\n",
            "Stats - Epoch: 20 AUC-val 0.437  AUC-train 0.861\n",
            "Stats - Epoch: 21 AUC-val 0.440  AUC-train 0.867\n",
            "Stats - Epoch: 22 AUC-val 0.446  AUC-train 0.868\n",
            "Stats - Epoch: 23 AUC-val 0.448  AUC-train 0.871\n",
            "Stats - Epoch: 24 AUC-val 0.451  AUC-train 0.872\n",
            "Stats - Epoch: 25 AUC-val 0.451  AUC-train 0.868\n",
            "Stats - Epoch: 26 AUC-val 0.448  AUC-train 0.873\n",
            "Stats - Epoch: 27 AUC-val 0.456  AUC-train 0.874\n",
            "Stats - Epoch: 28 AUC-val 0.446  AUC-train 0.867\n",
            "Stats - Epoch: 29 AUC-val 0.449  AUC-train 0.869\n",
            "Stats - Epoch: 30 AUC-val 0.452  AUC-train 0.880\n",
            "Stats - Epoch: 31 AUC-val 0.460  AUC-train 0.882\n",
            "Stats - Epoch: 32 AUC-val 0.457  AUC-train 0.881\n",
            "Stats - Epoch: 33 AUC-val 0.466  AUC-train 0.885\n",
            "Stats - Epoch: 34 AUC-val 0.459  AUC-train 0.875\n",
            "Stats - Epoch: 35 AUC-val 0.459  AUC-train 0.880\n",
            "Stats - Epoch: 36 AUC-val 0.475  AUC-train 0.882\n",
            "Stats - Epoch: 37 AUC-val 0.458  AUC-train 0.884\n",
            "Stats - Epoch: 38 AUC-val 0.469  AUC-train 0.887\n",
            "Stats - Epoch: 39 AUC-val 0.464  AUC-train 0.886\n",
            "Stats - Epoch: 40 AUC-val 0.470  AUC-train 0.890\n",
            "Stats - Epoch: 41 AUC-val 0.468  AUC-train 0.888\n",
            "Stats - Epoch: 42 AUC-val 0.478  AUC-train 0.889\n",
            "Stats - Epoch: 43 AUC-val 0.464  AUC-train 0.888\n",
            "Stats - Epoch: 44 AUC-val 0.474  AUC-train 0.883\n",
            "Stats - Epoch: 45 AUC-val 0.473  AUC-train 0.888\n",
            "Stats - Epoch: 46 AUC-val 0.473  AUC-train 0.893\n",
            "Stats - Epoch: 47 AUC-val 0.472  AUC-train 0.893\n",
            "Stats - Epoch: 48 AUC-val 0.466  AUC-train 0.885\n",
            "Stats - Epoch: 49 AUC-val 0.471  AUC-train 0.884\n",
            "Stats - Epoch: 50 AUC-val 0.466  AUC-train 0.888\n",
            "Stats - Epoch: 51 AUC-val 0.468  AUC-train 0.887\n",
            "Stats - Epoch: 52 AUC-val 0.463  AUC-train 0.888\n",
            "Stats - Epoch: 53 AUC-val 0.483  AUC-train 0.891\n",
            "Stats - Epoch: 54 AUC-val 0.467  AUC-train 0.895\n",
            "Stats - Epoch: 55 AUC-val 0.469  AUC-train 0.895\n",
            "Stats - Epoch: 56 AUC-val 0.470  AUC-train 0.889\n",
            "Stats - Epoch: 57 AUC-val 0.485  AUC-train 0.892\n",
            "Stats - Epoch: 58 AUC-val 0.483  AUC-train 0.891\n",
            "Stats - Epoch: 59 AUC-val 0.480  AUC-train 0.892\n",
            "Stats - Epoch: 60 AUC-val 0.471  AUC-train 0.899\n",
            "Stats - Epoch: 61 AUC-val 0.478  AUC-train 0.897\n",
            "Stats - Epoch: 62 AUC-val 0.471  AUC-train 0.902\n",
            "Stats - Epoch: 63 AUC-val 0.486  AUC-train 0.900\n",
            "Stats - Epoch: 64 AUC-val 0.472  AUC-train 0.895\n",
            "Stats - Epoch: 65 AUC-val 0.471  AUC-train 0.896\n",
            "Stats - Epoch: 66 AUC-val 0.464  AUC-train 0.897\n",
            "Stats - Epoch: 67 AUC-val 0.472  AUC-train 0.898\n",
            "Stats - Epoch: 68 AUC-val 0.481  AUC-train 0.899\n",
            "Stats - Epoch: 69 AUC-val 0.477  AUC-train 0.901\n",
            "Stats - Epoch: 70 AUC-val 0.466  AUC-train 0.904\n",
            "Stats - Epoch: 71 AUC-val 0.486  AUC-train 0.901\n",
            "Stats - Epoch: 72 AUC-val 0.476  AUC-train 0.898\n",
            "Stats - Epoch: 73 AUC-val 0.491  AUC-train 0.896\n",
            "Stats - Epoch: 74 AUC-val 0.482  AUC-train 0.898\n",
            "Stats - Epoch: 75 AUC-val 0.488  AUC-train 0.900\n",
            "Stats - Epoch: 76 AUC-val 0.484  AUC-train 0.894\n",
            "Stats - Epoch: 77 AUC-val 0.478  AUC-train 0.902\n",
            "Stats - Epoch: 78 AUC-val 0.485  AUC-train 0.900\n",
            "Stats - Epoch: 79 AUC-val 0.486  AUC-train 0.903\n",
            "Stats - Epoch: 80 AUC-val 0.478  AUC-train 0.907\n",
            "Stats - Epoch: 81 AUC-val 0.486  AUC-train 0.909\n",
            "Stats - Epoch: 82 AUC-val 0.483  AUC-train 0.910\n",
            "Stats - Epoch: 83 AUC-val 0.481  AUC-train 0.906\n",
            "Stats - Epoch: 84 AUC-val 0.478  AUC-train 0.897\n",
            "Stats - Epoch: 85 AUC-val 0.483  AUC-train 0.904\n",
            "Stats - Epoch: 86 AUC-val 0.484  AUC-train 0.908\n",
            "Stats - Epoch: 87 AUC-val 0.487  AUC-train 0.909\n",
            "Stats - Epoch: 88 AUC-val 0.481  AUC-train 0.908\n",
            "Stats - Epoch: 89 AUC-val 0.493  AUC-train 0.909\n",
            "Stats - Epoch: 90 AUC-val 0.484  AUC-train 0.901\n",
            "Stats - Epoch: 91 AUC-val 0.491  AUC-train 0.909\n",
            "Stats - Epoch: 92 AUC-val 0.485  AUC-train 0.903\n",
            "Stats - Epoch: 93 AUC-val 0.487  AUC-train 0.908\n",
            "Stats - Epoch: 94 AUC-val 0.484  AUC-train 0.909\n",
            "Stats - Epoch: 95 AUC-val 0.494  AUC-train 0.897\n",
            "Stats - Epoch: 96 AUC-val 0.488  AUC-train 0.906\n",
            "Stats - Epoch: 97 AUC-val 0.484  AUC-train 0.911\n",
            "Stats - Epoch: 98 AUC-val 0.494  AUC-train 0.908\n",
            "Stats - Epoch: 99 AUC-val 0.493  AUC-train 0.909\n",
            "Stats - Epoch: 100 AUC-val 0.485  AUC-train 0.908\n",
            "Results 100 AUC-val 0.494 0.533 0.574 0.511 0.631 AUC-train 0.897\n",
            "Shapley [0.00913315 0.00778549 0.0188169  0.01206766 0.00438077] [0.02185935]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188027\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.324  AUC-train 0.626\n",
            "Stats - Epoch: 2 AUC-val 0.349  AUC-train 0.819\n",
            "Stats - Epoch: 3 AUC-val 0.328  AUC-train 0.895\n",
            "Stats - Epoch: 4 AUC-val 0.335  AUC-train 0.933\n",
            "Stats - Epoch: 5 AUC-val 0.345  AUC-train 0.957\n",
            "Stats - Epoch: 6 AUC-val 0.353  AUC-train 0.971\n",
            "Stats - Epoch: 7 AUC-val 0.355  AUC-train 0.974\n",
            "Stats - Epoch: 8 AUC-val 0.342  AUC-train 0.975\n",
            "Stats - Epoch: 9 AUC-val 0.378  AUC-train 0.982\n",
            "Stats - Epoch: 10 AUC-val 0.389  AUC-train 0.988\n",
            "Stats - Epoch: 11 AUC-val 0.368  AUC-train 0.988\n",
            "Stats - Epoch: 12 AUC-val 0.395  AUC-train 0.989\n",
            "Stats - Epoch: 13 AUC-val 0.404  AUC-train 0.992\n",
            "Stats - Epoch: 14 AUC-val 0.391  AUC-train 0.991\n",
            "Stats - Epoch: 15 AUC-val 0.406  AUC-train 0.992\n",
            "Stats - Epoch: 16 AUC-val 0.407  AUC-train 0.990\n",
            "Stats - Epoch: 17 AUC-val 0.417  AUC-train 0.986\n",
            "Stats - Epoch: 18 AUC-val 0.432  AUC-train 0.984\n",
            "Stats - Epoch: 19 AUC-val 0.415  AUC-train 0.991\n",
            "Stats - Epoch: 20 AUC-val 0.409  AUC-train 0.986\n",
            "Stats - Epoch: 21 AUC-val 0.421  AUC-train 0.992\n",
            "Stats - Epoch: 22 AUC-val 0.417  AUC-train 0.987\n",
            "Stats - Epoch: 23 AUC-val 0.408  AUC-train 0.988\n",
            "Stats - Epoch: 24 AUC-val 0.424  AUC-train 0.990\n",
            "Stats - Epoch: 25 AUC-val 0.411  AUC-train 0.987\n",
            "Stats - Epoch: 26 AUC-val 0.437  AUC-train 0.989\n",
            "Stats - Epoch: 27 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 28 AUC-val 0.417  AUC-train 0.988\n",
            "Stats - Epoch: 29 AUC-val 0.427  AUC-train 0.985\n",
            "Stats - Epoch: 30 AUC-val 0.429  AUC-train 0.984\n",
            "Stats - Epoch: 31 AUC-val 0.426  AUC-train 0.991\n",
            "Stats - Epoch: 32 AUC-val 0.438  AUC-train 0.992\n",
            "Stats - Epoch: 33 AUC-val 0.414  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.430  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.435  AUC-train 0.986\n",
            "Stats - Epoch: 36 AUC-val 0.414  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.445  AUC-train 0.985\n",
            "Stats - Epoch: 38 AUC-val 0.435  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.445  AUC-train 0.986\n",
            "Stats - Epoch: 40 AUC-val 0.463  AUC-train 0.985\n",
            "Stats - Epoch: 41 AUC-val 0.475  AUC-train 0.985\n",
            "Stats - Epoch: 42 AUC-val 0.457  AUC-train 0.983\n",
            "Stats - Epoch: 43 AUC-val 0.442  AUC-train 0.982\n",
            "Stats - Epoch: 44 AUC-val 0.420  AUC-train 0.984\n",
            "Stats - Epoch: 45 AUC-val 0.459  AUC-train 0.985\n",
            "Stats - Epoch: 46 AUC-val 0.452  AUC-train 0.988\n",
            "Stats - Epoch: 47 AUC-val 0.444  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.413  AUC-train 0.986\n",
            "Stats - Epoch: 50 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 51 AUC-val 0.433  AUC-train 0.984\n",
            "Stats - Epoch: 52 AUC-val 0.424  AUC-train 0.987\n",
            "Stats - Epoch: 53 AUC-val 0.426  AUC-train 0.988\n",
            "Stats - Epoch: 54 AUC-val 0.448  AUC-train 0.985\n",
            "Stats - Epoch: 55 AUC-val 0.453  AUC-train 0.985\n",
            "Stats - Epoch: 56 AUC-val 0.428  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.451  AUC-train 0.984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.459  AUC-train 0.984\n",
            "Stats - Epoch: 59 AUC-val 0.434  AUC-train 0.981\n",
            "Stats - Epoch: 60 AUC-val 0.438  AUC-train 0.982\n",
            "Stats - Epoch: 61 AUC-val 0.447  AUC-train 0.985\n",
            "Stats - Epoch: 62 AUC-val 0.423  AUC-train 0.987\n",
            "Stats - Epoch: 63 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 64 AUC-val 0.451  AUC-train 0.979\n",
            "Stats - Epoch: 65 AUC-val 0.453  AUC-train 0.983\n",
            "Stats - Epoch: 66 AUC-val 0.441  AUC-train 0.985\n",
            "Stats - Epoch: 67 AUC-val 0.452  AUC-train 0.984\n",
            "Stats - Epoch: 68 AUC-val 0.449  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.453  AUC-train 0.986\n",
            "Stats - Epoch: 70 AUC-val 0.456  AUC-train 0.983\n",
            "Stats - Epoch: 71 AUC-val 0.443  AUC-train 0.983\n",
            "Stats - Epoch: 72 AUC-val 0.433  AUC-train 0.973\n",
            "Stats - Epoch: 73 AUC-val 0.453  AUC-train 0.979\n",
            "Stats - Epoch: 74 AUC-val 0.452  AUC-train 0.981\n",
            "Stats - Epoch: 75 AUC-val 0.456  AUC-train 0.977\n",
            "Stats - Epoch: 76 AUC-val 0.456  AUC-train 0.976\n",
            "Stats - Epoch: 77 AUC-val 0.464  AUC-train 0.981\n",
            "Stats - Epoch: 78 AUC-val 0.443  AUC-train 0.975\n",
            "Stats - Epoch: 79 AUC-val 0.439  AUC-train 0.980\n",
            "Stats - Epoch: 80 AUC-val 0.434  AUC-train 0.981\n",
            "Stats - Epoch: 81 AUC-val 0.422  AUC-train 0.982\n",
            "Stats - Epoch: 82 AUC-val 0.424  AUC-train 0.984\n",
            "Stats - Epoch: 83 AUC-val 0.464  AUC-train 0.983\n",
            "Stats - Epoch: 84 AUC-val 0.431  AUC-train 0.980\n",
            "Stats - Epoch: 85 AUC-val 0.422  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.443  AUC-train 0.983\n",
            "Stats - Epoch: 87 AUC-val 0.437  AUC-train 0.982\n",
            "Stats - Epoch: 88 AUC-val 0.437  AUC-train 0.982\n",
            "Stats - Epoch: 89 AUC-val 0.427  AUC-train 0.978\n",
            "Stats - Epoch: 90 AUC-val 0.429  AUC-train 0.982\n",
            "Stats - Epoch: 91 AUC-val 0.460  AUC-train 0.981\n",
            "Stats - Epoch: 92 AUC-val 0.416  AUC-train 0.977\n",
            "Stats - Epoch: 93 AUC-val 0.433  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.436  AUC-train 0.980\n",
            "Stats - Epoch: 95 AUC-val 0.439  AUC-train 0.980\n",
            "Stats - Epoch: 96 AUC-val 0.421  AUC-train 0.977\n",
            "Stats - Epoch: 97 AUC-val 0.438  AUC-train 0.980\n",
            "Stats - Epoch: 98 AUC-val 0.409  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.409  AUC-train 0.977\n",
            "Stats - Epoch: 100 AUC-val 0.431  AUC-train 0.977\n",
            "Results 100 AUC-val 0.475 0.462 0.302 0.145 0.536 AUC-train 0.985\n",
            "Shapley [0.03160458 0.0102437  0.01392746 0.0518496  0.01506546] [0.05357325]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187143\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.203  AUC-train 0.605\n",
            "Stats - Epoch: 2 AUC-val 0.202  AUC-train 0.679\n",
            "Stats - Epoch: 3 AUC-val 0.264  AUC-train 0.756\n",
            "Stats - Epoch: 4 AUC-val 0.333  AUC-train 0.804\n",
            "Stats - Epoch: 5 AUC-val 0.422  AUC-train 0.833\n",
            "Stats - Epoch: 6 AUC-val 0.480  AUC-train 0.854\n",
            "Stats - Epoch: 7 AUC-val 0.491  AUC-train 0.866\n",
            "Stats - Epoch: 8 AUC-val 0.551  AUC-train 0.871\n",
            "Stats - Epoch: 9 AUC-val 0.540  AUC-train 0.879\n",
            "Stats - Epoch: 10 AUC-val 0.575  AUC-train 0.886\n",
            "Stats - Epoch: 11 AUC-val 0.578  AUC-train 0.892\n",
            "Stats - Epoch: 12 AUC-val 0.556  AUC-train 0.897\n",
            "Stats - Epoch: 13 AUC-val 0.572  AUC-train 0.896\n",
            "Stats - Epoch: 14 AUC-val 0.568  AUC-train 0.905\n",
            "Stats - Epoch: 15 AUC-val 0.583  AUC-train 0.906\n",
            "Stats - Epoch: 16 AUC-val 0.574  AUC-train 0.911\n",
            "Stats - Epoch: 17 AUC-val 0.591  AUC-train 0.916\n",
            "Stats - Epoch: 18 AUC-val 0.578  AUC-train 0.924\n",
            "Stats - Epoch: 19 AUC-val 0.582  AUC-train 0.921\n",
            "Stats - Epoch: 20 AUC-val 0.606  AUC-train 0.924\n",
            "Stats - Epoch: 21 AUC-val 0.588  AUC-train 0.927\n",
            "Stats - Epoch: 22 AUC-val 0.599  AUC-train 0.931\n",
            "Stats - Epoch: 23 AUC-val 0.594  AUC-train 0.930\n",
            "Stats - Epoch: 24 AUC-val 0.605  AUC-train 0.930\n",
            "Stats - Epoch: 25 AUC-val 0.574  AUC-train 0.934\n",
            "Stats - Epoch: 26 AUC-val 0.571  AUC-train 0.935\n",
            "Stats - Epoch: 27 AUC-val 0.546  AUC-train 0.937\n",
            "Stats - Epoch: 28 AUC-val 0.603  AUC-train 0.942\n",
            "Stats - Epoch: 29 AUC-val 0.645  AUC-train 0.946\n",
            "Stats - Epoch: 30 AUC-val 0.596  AUC-train 0.948\n",
            "Stats - Epoch: 31 AUC-val 0.573  AUC-train 0.955\n",
            "Stats - Epoch: 32 AUC-val 0.614  AUC-train 0.956\n",
            "Stats - Epoch: 33 AUC-val 0.589  AUC-train 0.953\n",
            "Stats - Epoch: 34 AUC-val 0.581  AUC-train 0.958\n",
            "Stats - Epoch: 35 AUC-val 0.640  AUC-train 0.958\n",
            "Stats - Epoch: 36 AUC-val 0.582  AUC-train 0.957\n",
            "Stats - Epoch: 37 AUC-val 0.546  AUC-train 0.961\n",
            "Stats - Epoch: 38 AUC-val 0.603  AUC-train 0.958\n",
            "Stats - Epoch: 39 AUC-val 0.579  AUC-train 0.964\n",
            "Stats - Epoch: 40 AUC-val 0.619  AUC-train 0.959\n",
            "Stats - Epoch: 41 AUC-val 0.590  AUC-train 0.963\n",
            "Stats - Epoch: 42 AUC-val 0.553  AUC-train 0.966\n",
            "Stats - Epoch: 43 AUC-val 0.603  AUC-train 0.967\n",
            "Stats - Epoch: 44 AUC-val 0.601  AUC-train 0.969\n",
            "Stats - Epoch: 45 AUC-val 0.579  AUC-train 0.970\n",
            "Stats - Epoch: 46 AUC-val 0.604  AUC-train 0.972\n",
            "Stats - Epoch: 47 AUC-val 0.584  AUC-train 0.971\n",
            "Stats - Epoch: 48 AUC-val 0.579  AUC-train 0.973\n",
            "Stats - Epoch: 49 AUC-val 0.577  AUC-train 0.973\n",
            "Stats - Epoch: 50 AUC-val 0.602  AUC-train 0.973\n",
            "Stats - Epoch: 51 AUC-val 0.565  AUC-train 0.974\n",
            "Stats - Epoch: 52 AUC-val 0.588  AUC-train 0.977\n",
            "Stats - Epoch: 53 AUC-val 0.590  AUC-train 0.975\n",
            "Stats - Epoch: 54 AUC-val 0.622  AUC-train 0.974\n",
            "Stats - Epoch: 55 AUC-val 0.557  AUC-train 0.971\n",
            "Stats - Epoch: 56 AUC-val 0.550  AUC-train 0.977\n",
            "Stats - Epoch: 57 AUC-val 0.604  AUC-train 0.978\n",
            "Stats - Epoch: 58 AUC-val 0.589  AUC-train 0.979\n",
            "Stats - Epoch: 59 AUC-val 0.552  AUC-train 0.980\n",
            "Stats - Epoch: 60 AUC-val 0.555  AUC-train 0.981\n",
            "Stats - Epoch: 61 AUC-val 0.558  AUC-train 0.982\n",
            "Stats - Epoch: 62 AUC-val 0.575  AUC-train 0.981\n",
            "Stats - Epoch: 63 AUC-val 0.565  AUC-train 0.977\n",
            "Stats - Epoch: 64 AUC-val 0.582  AUC-train 0.979\n",
            "Stats - Epoch: 65 AUC-val 0.560  AUC-train 0.976\n",
            "Stats - Epoch: 66 AUC-val 0.587  AUC-train 0.978\n",
            "Stats - Epoch: 67 AUC-val 0.614  AUC-train 0.976\n",
            "Stats - Epoch: 68 AUC-val 0.615  AUC-train 0.977\n",
            "Stats - Epoch: 69 AUC-val 0.564  AUC-train 0.980\n",
            "Stats - Epoch: 70 AUC-val 0.555  AUC-train 0.980\n",
            "Stats - Epoch: 71 AUC-val 0.624  AUC-train 0.979\n",
            "Stats - Epoch: 72 AUC-val 0.578  AUC-train 0.978\n",
            "Stats - Epoch: 73 AUC-val 0.590  AUC-train 0.978\n",
            "Stats - Epoch: 74 AUC-val 0.562  AUC-train 0.981\n",
            "Stats - Epoch: 75 AUC-val 0.547  AUC-train 0.982\n",
            "Stats - Epoch: 76 AUC-val 0.539  AUC-train 0.977\n",
            "Stats - Epoch: 77 AUC-val 0.622  AUC-train 0.975\n",
            "Stats - Epoch: 78 AUC-val 0.574  AUC-train 0.976\n",
            "Stats - Epoch: 79 AUC-val 0.537  AUC-train 0.978\n",
            "Stats - Epoch: 80 AUC-val 0.519  AUC-train 0.980\n",
            "Stats - Epoch: 81 AUC-val 0.569  AUC-train 0.982\n",
            "Stats - Epoch: 82 AUC-val 0.575  AUC-train 0.985\n",
            "Stats - Epoch: 83 AUC-val 0.524  AUC-train 0.977\n",
            "Stats - Epoch: 84 AUC-val 0.569  AUC-train 0.980\n",
            "Stats - Epoch: 85 AUC-val 0.549  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.560  AUC-train 0.980\n",
            "Stats - Epoch: 87 AUC-val 0.588  AUC-train 0.979\n",
            "Stats - Epoch: 88 AUC-val 0.520  AUC-train 0.975\n",
            "Stats - Epoch: 89 AUC-val 0.556  AUC-train 0.977\n",
            "Stats - Epoch: 90 AUC-val 0.571  AUC-train 0.974\n",
            "Stats - Epoch: 91 AUC-val 0.610  AUC-train 0.979\n",
            "Stats - Epoch: 92 AUC-val 0.602  AUC-train 0.982\n",
            "Stats - Epoch: 93 AUC-val 0.578  AUC-train 0.983\n",
            "Stats - Epoch: 94 AUC-val 0.570  AUC-train 0.983\n",
            "Stats - Epoch: 95 AUC-val 0.576  AUC-train 0.984\n",
            "Stats - Epoch: 96 AUC-val 0.567  AUC-train 0.986\n",
            "Stats - Epoch: 97 AUC-val 0.587  AUC-train 0.986\n",
            "Stats - Epoch: 98 AUC-val 0.581  AUC-train 0.982\n",
            "Stats - Epoch: 99 AUC-val 0.593  AUC-train 0.983\n",
            "Stats - Epoch: 100 AUC-val 0.571  AUC-train 0.981\n",
            "Results 100 AUC-val 0.645 0.583 0.502 0.484 0.622 AUC-train 0.946\n",
            "Shapley [0.01403938 0.01207783 0.01670181 0.01588757 0.00935438] [0.00316613]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.195658\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.431  AUC-train 0.656\n",
            "Stats - Epoch: 2 AUC-val 0.561  AUC-train 0.799\n",
            "Stats - Epoch: 3 AUC-val 0.610  AUC-train 0.845\n",
            "Stats - Epoch: 4 AUC-val 0.634  AUC-train 0.873\n",
            "Stats - Epoch: 5 AUC-val 0.655  AUC-train 0.893\n",
            "Stats - Epoch: 6 AUC-val 0.660  AUC-train 0.917\n",
            "Stats - Epoch: 7 AUC-val 0.690  AUC-train 0.934\n",
            "Stats - Epoch: 8 AUC-val 0.691  AUC-train 0.948\n",
            "Stats - Epoch: 9 AUC-val 0.710  AUC-train 0.960\n",
            "Stats - Epoch: 10 AUC-val 0.704  AUC-train 0.967\n",
            "Stats - Epoch: 11 AUC-val 0.710  AUC-train 0.975\n",
            "Stats - Epoch: 12 AUC-val 0.700  AUC-train 0.982\n",
            "Stats - Epoch: 13 AUC-val 0.691  AUC-train 0.986\n",
            "Stats - Epoch: 14 AUC-val 0.696  AUC-train 0.991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.705  AUC-train 0.992\n",
            "Stats - Epoch: 16 AUC-val 0.692  AUC-train 0.993\n",
            "Stats - Epoch: 17 AUC-val 0.664  AUC-train 0.994\n",
            "Stats - Epoch: 18 AUC-val 0.708  AUC-train 0.995\n",
            "Stats - Epoch: 19 AUC-val 0.679  AUC-train 0.993\n",
            "Stats - Epoch: 20 AUC-val 0.698  AUC-train 0.996\n",
            "Stats - Epoch: 21 AUC-val 0.689  AUC-train 0.996\n",
            "Stats - Epoch: 22 AUC-val 0.699  AUC-train 0.996\n",
            "Stats - Epoch: 23 AUC-val 0.670  AUC-train 0.997\n",
            "Stats - Epoch: 24 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 25 AUC-val 0.686  AUC-train 0.997\n",
            "Stats - Epoch: 26 AUC-val 0.684  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.685  AUC-train 0.998\n",
            "Stats - Epoch: 28 AUC-val 0.689  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.700  AUC-train 0.998\n",
            "Stats - Epoch: 30 AUC-val 0.680  AUC-train 0.996\n",
            "Stats - Epoch: 31 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.708  AUC-train 0.998\n",
            "Stats - Epoch: 33 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.688  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 38 AUC-val 0.673  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.645  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.677  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 52 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.690  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.657  AUC-train 1.000\n",
            "Stats - Epoch: 57 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.670  AUC-train 0.997\n",
            "Stats - Epoch: 60 AUC-val 0.683  AUC-train 0.997\n",
            "Stats - Epoch: 61 AUC-val 0.674  AUC-train 0.998\n",
            "Stats - Epoch: 62 AUC-val 0.689  AUC-train 0.993\n",
            "Stats - Epoch: 63 AUC-val 0.646  AUC-train 0.995\n",
            "Stats - Epoch: 64 AUC-val 0.700  AUC-train 0.994\n",
            "Stats - Epoch: 65 AUC-val 0.675  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.691  AUC-train 0.997\n",
            "Stats - Epoch: 67 AUC-val 0.674  AUC-train 0.995\n",
            "Stats - Epoch: 68 AUC-val 0.660  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 70 AUC-val 0.679  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 72 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.646  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.647  AUC-train 0.997\n",
            "Stats - Epoch: 76 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.686  AUC-train 1.000\n",
            "Stats - Epoch: 78 AUC-val 0.694  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.645  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 83 AUC-val 0.664  AUC-train 1.000\n",
            "Stats - Epoch: 84 AUC-val 0.633  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 86 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.669  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.669  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.656  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.633  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.668  AUC-train 0.996\n",
            "Stats - Epoch: 95 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 97 AUC-val 0.678  AUC-train 0.992\n",
            "Stats - Epoch: 98 AUC-val 0.668  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.682  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.683  AUC-train 0.999\n",
            "Results 100 AUC-val 0.710 0.627 0.493 0.426 0.557 AUC-train 0.975\n",
            "Shapley [0.01941636 0.01866417 0.01587942 0.03319304 0.01490291] [0.01059471]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199012\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.542  AUC-train 0.565\n",
            "Stats - Epoch: 2 AUC-val 0.598  AUC-train 0.758\n",
            "Stats - Epoch: 3 AUC-val 0.593  AUC-train 0.830\n",
            "Stats - Epoch: 4 AUC-val 0.585  AUC-train 0.862\n",
            "Stats - Epoch: 5 AUC-val 0.580  AUC-train 0.886\n",
            "Stats - Epoch: 6 AUC-val 0.581  AUC-train 0.904\n",
            "Stats - Epoch: 7 AUC-val 0.562  AUC-train 0.926\n",
            "Stats - Epoch: 8 AUC-val 0.550  AUC-train 0.940\n",
            "Stats - Epoch: 9 AUC-val 0.574  AUC-train 0.956\n",
            "Stats - Epoch: 10 AUC-val 0.552  AUC-train 0.965\n",
            "Stats - Epoch: 11 AUC-val 0.586  AUC-train 0.975\n",
            "Stats - Epoch: 12 AUC-val 0.567  AUC-train 0.978\n",
            "Stats - Epoch: 13 AUC-val 0.542  AUC-train 0.985\n",
            "Stats - Epoch: 14 AUC-val 0.582  AUC-train 0.989\n",
            "Stats - Epoch: 15 AUC-val 0.548  AUC-train 0.990\n",
            "Stats - Epoch: 16 AUC-val 0.578  AUC-train 0.992\n",
            "Stats - Epoch: 17 AUC-val 0.617  AUC-train 0.994\n",
            "Stats - Epoch: 18 AUC-val 0.600  AUC-train 0.996\n",
            "Stats - Epoch: 19 AUC-val 0.628  AUC-train 0.996\n",
            "Stats - Epoch: 20 AUC-val 0.655  AUC-train 0.996\n",
            "Stats - Epoch: 21 AUC-val 0.638  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.660  AUC-train 0.997\n",
            "Stats - Epoch: 23 AUC-val 0.620  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 25 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.641  AUC-train 0.998\n",
            "Stats - Epoch: 27 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.617  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.654  AUC-train 0.997\n",
            "Stats - Epoch: 30 AUC-val 0.648  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.664  AUC-train 0.997\n",
            "Stats - Epoch: 32 AUC-val 0.629  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.707  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.684  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 38 AUC-val 0.700  AUC-train 0.999\n",
            "Stats - Epoch: 39 AUC-val 0.707  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.675  AUC-train 0.996\n",
            "Stats - Epoch: 41 AUC-val 0.690  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.695  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.700  AUC-train 0.997\n",
            "Stats - Epoch: 44 AUC-val 0.688  AUC-train 0.996\n",
            "Stats - Epoch: 45 AUC-val 0.672  AUC-train 0.995\n",
            "Stats - Epoch: 46 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.669  AUC-train 0.997\n",
            "Stats - Epoch: 49 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.698  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.723  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.664  AUC-train 0.996\n",
            "Stats - Epoch: 57 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.695  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.713  AUC-train 0.998\n",
            "Stats - Epoch: 61 AUC-val 0.694  AUC-train 0.991\n",
            "Stats - Epoch: 62 AUC-val 0.691  AUC-train 0.992\n",
            "Stats - Epoch: 63 AUC-val 0.729  AUC-train 0.992\n",
            "Stats - Epoch: 64 AUC-val 0.683  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.697  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.695  AUC-train 0.993\n",
            "Stats - Epoch: 67 AUC-val 0.710  AUC-train 0.995\n",
            "Stats - Epoch: 68 AUC-val 0.693  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.697  AUC-train 0.996\n",
            "Stats - Epoch: 70 AUC-val 0.687  AUC-train 0.994\n",
            "Stats - Epoch: 71 AUC-val 0.687  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.687  AUC-train 0.998\n",
            "Stats - Epoch: 74 AUC-val 0.676  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.705  AUC-train 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.731  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.680  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.734  AUC-train 0.992\n",
            "Stats - Epoch: 81 AUC-val 0.676  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.689  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.703  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.712  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.700  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.694  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.702  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.669  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.657  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.635  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.695  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.673  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.691  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.690  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.692  AUC-train 0.993\n",
            "Results 100 AUC-val 0.734 0.686 0.558 0.476 0.642 AUC-train 0.992\n",
            "Shapley [0.01405042 0.01350862 0.00782929 0.01752397 0.00494754] [0.002363]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196541\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.355  AUC-train 0.530\n",
            "Stats - Epoch: 2 AUC-val 0.390  AUC-train 0.627\n",
            "Stats - Epoch: 3 AUC-val 0.389  AUC-train 0.671\n",
            "Stats - Epoch: 4 AUC-val 0.408  AUC-train 0.712\n",
            "Stats - Epoch: 5 AUC-val 0.416  AUC-train 0.721\n",
            "Stats - Epoch: 6 AUC-val 0.427  AUC-train 0.750\n",
            "Stats - Epoch: 7 AUC-val 0.427  AUC-train 0.768\n",
            "Stats - Epoch: 8 AUC-val 0.426  AUC-train 0.773\n",
            "Stats - Epoch: 9 AUC-val 0.422  AUC-train 0.792\n",
            "Stats - Epoch: 10 AUC-val 0.421  AUC-train 0.815\n",
            "Stats - Epoch: 11 AUC-val 0.427  AUC-train 0.800\n",
            "Stats - Epoch: 12 AUC-val 0.423  AUC-train 0.827\n",
            "Stats - Epoch: 13 AUC-val 0.422  AUC-train 0.832\n",
            "Stats - Epoch: 14 AUC-val 0.429  AUC-train 0.834\n",
            "Stats - Epoch: 15 AUC-val 0.424  AUC-train 0.834\n",
            "Stats - Epoch: 16 AUC-val 0.434  AUC-train 0.851\n",
            "Stats - Epoch: 17 AUC-val 0.433  AUC-train 0.844\n",
            "Stats - Epoch: 18 AUC-val 0.443  AUC-train 0.858\n",
            "Stats - Epoch: 19 AUC-val 0.437  AUC-train 0.860\n",
            "Stats - Epoch: 20 AUC-val 0.450  AUC-train 0.861\n",
            "Stats - Epoch: 21 AUC-val 0.443  AUC-train 0.863\n",
            "Stats - Epoch: 22 AUC-val 0.450  AUC-train 0.865\n",
            "Stats - Epoch: 23 AUC-val 0.452  AUC-train 0.867\n",
            "Stats - Epoch: 24 AUC-val 0.457  AUC-train 0.872\n",
            "Stats - Epoch: 25 AUC-val 0.454  AUC-train 0.858\n",
            "Stats - Epoch: 26 AUC-val 0.460  AUC-train 0.873\n",
            "Stats - Epoch: 27 AUC-val 0.456  AUC-train 0.874\n",
            "Stats - Epoch: 28 AUC-val 0.453  AUC-train 0.875\n",
            "Stats - Epoch: 29 AUC-val 0.459  AUC-train 0.873\n",
            "Stats - Epoch: 30 AUC-val 0.464  AUC-train 0.882\n",
            "Stats - Epoch: 31 AUC-val 0.457  AUC-train 0.883\n",
            "Stats - Epoch: 32 AUC-val 0.454  AUC-train 0.878\n",
            "Stats - Epoch: 33 AUC-val 0.464  AUC-train 0.885\n",
            "Stats - Epoch: 34 AUC-val 0.465  AUC-train 0.878\n",
            "Stats - Epoch: 35 AUC-val 0.467  AUC-train 0.885\n",
            "Stats - Epoch: 36 AUC-val 0.474  AUC-train 0.880\n",
            "Stats - Epoch: 37 AUC-val 0.466  AUC-train 0.881\n",
            "Stats - Epoch: 38 AUC-val 0.467  AUC-train 0.888\n",
            "Stats - Epoch: 39 AUC-val 0.472  AUC-train 0.887\n",
            "Stats - Epoch: 40 AUC-val 0.481  AUC-train 0.892\n",
            "Stats - Epoch: 41 AUC-val 0.475  AUC-train 0.894\n",
            "Stats - Epoch: 42 AUC-val 0.479  AUC-train 0.894\n",
            "Stats - Epoch: 43 AUC-val 0.482  AUC-train 0.888\n",
            "Stats - Epoch: 44 AUC-val 0.486  AUC-train 0.885\n",
            "Stats - Epoch: 45 AUC-val 0.484  AUC-train 0.892\n",
            "Stats - Epoch: 46 AUC-val 0.486  AUC-train 0.894\n",
            "Stats - Epoch: 47 AUC-val 0.481  AUC-train 0.892\n",
            "Stats - Epoch: 48 AUC-val 0.472  AUC-train 0.891\n",
            "Stats - Epoch: 49 AUC-val 0.487  AUC-train 0.887\n",
            "Stats - Epoch: 50 AUC-val 0.482  AUC-train 0.887\n",
            "Stats - Epoch: 51 AUC-val 0.473  AUC-train 0.892\n",
            "Stats - Epoch: 52 AUC-val 0.475  AUC-train 0.889\n",
            "Stats - Epoch: 53 AUC-val 0.486  AUC-train 0.892\n",
            "Stats - Epoch: 54 AUC-val 0.481  AUC-train 0.894\n",
            "Stats - Epoch: 55 AUC-val 0.484  AUC-train 0.898\n",
            "Stats - Epoch: 56 AUC-val 0.488  AUC-train 0.887\n",
            "Stats - Epoch: 57 AUC-val 0.486  AUC-train 0.894\n",
            "Stats - Epoch: 58 AUC-val 0.492  AUC-train 0.892\n",
            "Stats - Epoch: 59 AUC-val 0.491  AUC-train 0.891\n",
            "Stats - Epoch: 60 AUC-val 0.483  AUC-train 0.899\n",
            "Stats - Epoch: 61 AUC-val 0.479  AUC-train 0.898\n",
            "Stats - Epoch: 62 AUC-val 0.491  AUC-train 0.905\n",
            "Stats - Epoch: 63 AUC-val 0.485  AUC-train 0.903\n",
            "Stats - Epoch: 64 AUC-val 0.486  AUC-train 0.894\n",
            "Stats - Epoch: 65 AUC-val 0.477  AUC-train 0.901\n",
            "Stats - Epoch: 66 AUC-val 0.472  AUC-train 0.900\n",
            "Stats - Epoch: 67 AUC-val 0.480  AUC-train 0.899\n",
            "Stats - Epoch: 68 AUC-val 0.487  AUC-train 0.899\n",
            "Stats - Epoch: 69 AUC-val 0.483  AUC-train 0.904\n",
            "Stats - Epoch: 70 AUC-val 0.479  AUC-train 0.906\n",
            "Stats - Epoch: 71 AUC-val 0.485  AUC-train 0.897\n",
            "Stats - Epoch: 72 AUC-val 0.484  AUC-train 0.895\n",
            "Stats - Epoch: 73 AUC-val 0.493  AUC-train 0.897\n",
            "Stats - Epoch: 74 AUC-val 0.480  AUC-train 0.901\n",
            "Stats - Epoch: 75 AUC-val 0.493  AUC-train 0.904\n",
            "Stats - Epoch: 76 AUC-val 0.490  AUC-train 0.896\n",
            "Stats - Epoch: 77 AUC-val 0.484  AUC-train 0.901\n",
            "Stats - Epoch: 78 AUC-val 0.493  AUC-train 0.899\n",
            "Stats - Epoch: 79 AUC-val 0.481  AUC-train 0.905\n",
            "Stats - Epoch: 80 AUC-val 0.481  AUC-train 0.909\n",
            "Stats - Epoch: 81 AUC-val 0.484  AUC-train 0.907\n",
            "Stats - Epoch: 82 AUC-val 0.482  AUC-train 0.906\n",
            "Stats - Epoch: 83 AUC-val 0.486  AUC-train 0.906\n",
            "Stats - Epoch: 84 AUC-val 0.478  AUC-train 0.896\n",
            "Stats - Epoch: 85 AUC-val 0.497  AUC-train 0.906\n",
            "Stats - Epoch: 86 AUC-val 0.486  AUC-train 0.906\n",
            "Stats - Epoch: 87 AUC-val 0.483  AUC-train 0.906\n",
            "Stats - Epoch: 88 AUC-val 0.490  AUC-train 0.906\n",
            "Stats - Epoch: 89 AUC-val 0.497  AUC-train 0.909\n",
            "Stats - Epoch: 90 AUC-val 0.487  AUC-train 0.903\n",
            "Stats - Epoch: 91 AUC-val 0.498  AUC-train 0.910\n",
            "Stats - Epoch: 92 AUC-val 0.499  AUC-train 0.906\n",
            "Stats - Epoch: 93 AUC-val 0.485  AUC-train 0.905\n",
            "Stats - Epoch: 94 AUC-val 0.488  AUC-train 0.910\n",
            "Stats - Epoch: 95 AUC-val 0.496  AUC-train 0.903\n",
            "Stats - Epoch: 96 AUC-val 0.484  AUC-train 0.910\n",
            "Stats - Epoch: 97 AUC-val 0.494  AUC-train 0.910\n",
            "Stats - Epoch: 98 AUC-val 0.489  AUC-train 0.910\n",
            "Stats - Epoch: 99 AUC-val 0.493  AUC-train 0.908\n",
            "Stats - Epoch: 100 AUC-val 0.495  AUC-train 0.908\n",
            "Results 100 AUC-val 0.499 0.542 0.582 0.509 0.625 AUC-train 0.906\n",
            "Shapley [0.00905305 0.00739813 0.01919249 0.0127208  0.00470186] [0.02241537]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.189356\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.352  AUC-train 0.626\n",
            "Stats - Epoch: 2 AUC-val 0.467  AUC-train 0.827\n",
            "Stats - Epoch: 3 AUC-val 0.433  AUC-train 0.895\n",
            "Stats - Epoch: 4 AUC-val 0.440  AUC-train 0.939\n",
            "Stats - Epoch: 5 AUC-val 0.419  AUC-train 0.962\n",
            "Stats - Epoch: 6 AUC-val 0.437  AUC-train 0.969\n",
            "Stats - Epoch: 7 AUC-val 0.393  AUC-train 0.976\n",
            "Stats - Epoch: 8 AUC-val 0.415  AUC-train 0.976\n",
            "Stats - Epoch: 9 AUC-val 0.392  AUC-train 0.985\n",
            "Stats - Epoch: 10 AUC-val 0.432  AUC-train 0.989\n",
            "Stats - Epoch: 11 AUC-val 0.400  AUC-train 0.983\n",
            "Stats - Epoch: 12 AUC-val 0.399  AUC-train 0.989\n",
            "Stats - Epoch: 13 AUC-val 0.428  AUC-train 0.991\n",
            "Stats - Epoch: 14 AUC-val 0.414  AUC-train 0.990\n",
            "Stats - Epoch: 15 AUC-val 0.397  AUC-train 0.991\n",
            "Stats - Epoch: 16 AUC-val 0.432  AUC-train 0.990\n",
            "Stats - Epoch: 17 AUC-val 0.407  AUC-train 0.990\n",
            "Stats - Epoch: 18 AUC-val 0.423  AUC-train 0.985\n",
            "Stats - Epoch: 19 AUC-val 0.410  AUC-train 0.991\n",
            "Stats - Epoch: 20 AUC-val 0.412  AUC-train 0.989\n",
            "Stats - Epoch: 21 AUC-val 0.416  AUC-train 0.988\n",
            "Stats - Epoch: 22 AUC-val 0.429  AUC-train 0.982\n",
            "Stats - Epoch: 23 AUC-val 0.421  AUC-train 0.988\n",
            "Stats - Epoch: 24 AUC-val 0.438  AUC-train 0.991\n",
            "Stats - Epoch: 25 AUC-val 0.417  AUC-train 0.989\n",
            "Stats - Epoch: 26 AUC-val 0.422  AUC-train 0.990\n",
            "Stats - Epoch: 27 AUC-val 0.431  AUC-train 0.989\n",
            "Stats - Epoch: 28 AUC-val 0.428  AUC-train 0.987\n",
            "Stats - Epoch: 29 AUC-val 0.428  AUC-train 0.987\n",
            "Stats - Epoch: 30 AUC-val 0.444  AUC-train 0.987\n",
            "Stats - Epoch: 31 AUC-val 0.422  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.443  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.403  AUC-train 0.991\n",
            "Stats - Epoch: 34 AUC-val 0.428  AUC-train 0.983\n",
            "Stats - Epoch: 35 AUC-val 0.434  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.438  AUC-train 0.988\n",
            "Stats - Epoch: 37 AUC-val 0.449  AUC-train 0.987\n",
            "Stats - Epoch: 38 AUC-val 0.442  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.437  AUC-train 0.985\n",
            "Stats - Epoch: 40 AUC-val 0.448  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.447  AUC-train 0.988\n",
            "Stats - Epoch: 42 AUC-val 0.433  AUC-train 0.986\n",
            "Stats - Epoch: 43 AUC-val 0.448  AUC-train 0.983\n",
            "Stats - Epoch: 44 AUC-val 0.443  AUC-train 0.986\n",
            "Stats - Epoch: 45 AUC-val 0.446  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.450  AUC-train 0.985\n",
            "Stats - Epoch: 47 AUC-val 0.445  AUC-train 0.987\n",
            "Stats - Epoch: 48 AUC-val 0.466  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.446  AUC-train 0.982\n",
            "Stats - Epoch: 50 AUC-val 0.456  AUC-train 0.982\n",
            "Stats - Epoch: 51 AUC-val 0.446  AUC-train 0.985\n",
            "Stats - Epoch: 52 AUC-val 0.442  AUC-train 0.983\n",
            "Stats - Epoch: 53 AUC-val 0.459  AUC-train 0.986\n",
            "Stats - Epoch: 54 AUC-val 0.453  AUC-train 0.985\n",
            "Stats - Epoch: 55 AUC-val 0.447  AUC-train 0.982\n",
            "Stats - Epoch: 56 AUC-val 0.447  AUC-train 0.986\n",
            "Stats - Epoch: 57 AUC-val 0.455  AUC-train 0.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.466  AUC-train 0.983\n",
            "Stats - Epoch: 59 AUC-val 0.440  AUC-train 0.982\n",
            "Stats - Epoch: 60 AUC-val 0.441  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.456  AUC-train 0.984\n",
            "Stats - Epoch: 62 AUC-val 0.438  AUC-train 0.985\n",
            "Stats - Epoch: 63 AUC-val 0.440  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.462  AUC-train 0.977\n",
            "Stats - Epoch: 65 AUC-val 0.460  AUC-train 0.980\n",
            "Stats - Epoch: 66 AUC-val 0.433  AUC-train 0.983\n",
            "Stats - Epoch: 67 AUC-val 0.449  AUC-train 0.981\n",
            "Stats - Epoch: 68 AUC-val 0.445  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.440  AUC-train 0.987\n",
            "Stats - Epoch: 70 AUC-val 0.463  AUC-train 0.984\n",
            "Stats - Epoch: 71 AUC-val 0.454  AUC-train 0.983\n",
            "Stats - Epoch: 72 AUC-val 0.439  AUC-train 0.982\n",
            "Stats - Epoch: 73 AUC-val 0.459  AUC-train 0.982\n",
            "Stats - Epoch: 74 AUC-val 0.447  AUC-train 0.982\n",
            "Stats - Epoch: 75 AUC-val 0.441  AUC-train 0.975\n",
            "Stats - Epoch: 76 AUC-val 0.440  AUC-train 0.978\n",
            "Stats - Epoch: 77 AUC-val 0.469  AUC-train 0.980\n",
            "Stats - Epoch: 78 AUC-val 0.462  AUC-train 0.970\n",
            "Stats - Epoch: 79 AUC-val 0.447  AUC-train 0.981\n",
            "Stats - Epoch: 80 AUC-val 0.440  AUC-train 0.978\n",
            "Stats - Epoch: 81 AUC-val 0.425  AUC-train 0.980\n",
            "Stats - Epoch: 82 AUC-val 0.438  AUC-train 0.983\n",
            "Stats - Epoch: 83 AUC-val 0.439  AUC-train 0.982\n",
            "Stats - Epoch: 84 AUC-val 0.429  AUC-train 0.983\n",
            "Stats - Epoch: 85 AUC-val 0.425  AUC-train 0.983\n",
            "Stats - Epoch: 86 AUC-val 0.445  AUC-train 0.982\n",
            "Stats - Epoch: 87 AUC-val 0.436  AUC-train 0.981\n",
            "Stats - Epoch: 88 AUC-val 0.440  AUC-train 0.983\n",
            "Stats - Epoch: 89 AUC-val 0.440  AUC-train 0.978\n",
            "Stats - Epoch: 90 AUC-val 0.417  AUC-train 0.983\n",
            "Stats - Epoch: 91 AUC-val 0.447  AUC-train 0.982\n",
            "Stats - Epoch: 92 AUC-val 0.421  AUC-train 0.975\n",
            "Stats - Epoch: 93 AUC-val 0.417  AUC-train 0.982\n",
            "Stats - Epoch: 94 AUC-val 0.442  AUC-train 0.977\n",
            "Stats - Epoch: 95 AUC-val 0.421  AUC-train 0.977\n",
            "Stats - Epoch: 96 AUC-val 0.422  AUC-train 0.974\n",
            "Stats - Epoch: 97 AUC-val 0.422  AUC-train 0.982\n",
            "Stats - Epoch: 98 AUC-val 0.421  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.431  AUC-train 0.978\n",
            "Stats - Epoch: 100 AUC-val 0.447  AUC-train 0.978\n",
            "Results 100 AUC-val 0.469 0.444 0.325 0.180 0.533 AUC-train 0.980\n",
            "Shapley [0.02668809 0.00794024 0.01001748 0.03779057 0.00814526] [0.03882466]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.183171\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.199  AUC-train 0.596\n",
            "Stats - Epoch: 2 AUC-val 0.196  AUC-train 0.682\n",
            "Stats - Epoch: 3 AUC-val 0.262  AUC-train 0.754\n",
            "Stats - Epoch: 4 AUC-val 0.342  AUC-train 0.796\n",
            "Stats - Epoch: 5 AUC-val 0.363  AUC-train 0.829\n",
            "Stats - Epoch: 6 AUC-val 0.419  AUC-train 0.843\n",
            "Stats - Epoch: 7 AUC-val 0.500  AUC-train 0.856\n",
            "Stats - Epoch: 8 AUC-val 0.484  AUC-train 0.866\n",
            "Stats - Epoch: 9 AUC-val 0.569  AUC-train 0.873\n",
            "Stats - Epoch: 10 AUC-val 0.551  AUC-train 0.877\n",
            "Stats - Epoch: 11 AUC-val 0.577  AUC-train 0.884\n",
            "Stats - Epoch: 12 AUC-val 0.582  AUC-train 0.887\n",
            "Stats - Epoch: 13 AUC-val 0.515  AUC-train 0.897\n",
            "Stats - Epoch: 14 AUC-val 0.522  AUC-train 0.901\n",
            "Stats - Epoch: 15 AUC-val 0.547  AUC-train 0.903\n",
            "Stats - Epoch: 16 AUC-val 0.618  AUC-train 0.908\n",
            "Stats - Epoch: 17 AUC-val 0.550  AUC-train 0.914\n",
            "Stats - Epoch: 18 AUC-val 0.582  AUC-train 0.918\n",
            "Stats - Epoch: 19 AUC-val 0.557  AUC-train 0.921\n",
            "Stats - Epoch: 20 AUC-val 0.584  AUC-train 0.924\n",
            "Stats - Epoch: 21 AUC-val 0.560  AUC-train 0.927\n",
            "Stats - Epoch: 22 AUC-val 0.557  AUC-train 0.930\n",
            "Stats - Epoch: 23 AUC-val 0.553  AUC-train 0.932\n",
            "Stats - Epoch: 24 AUC-val 0.567  AUC-train 0.934\n",
            "Stats - Epoch: 25 AUC-val 0.522  AUC-train 0.936\n",
            "Stats - Epoch: 26 AUC-val 0.573  AUC-train 0.940\n",
            "Stats - Epoch: 27 AUC-val 0.571  AUC-train 0.939\n",
            "Stats - Epoch: 28 AUC-val 0.584  AUC-train 0.943\n",
            "Stats - Epoch: 29 AUC-val 0.549  AUC-train 0.947\n",
            "Stats - Epoch: 30 AUC-val 0.558  AUC-train 0.953\n",
            "Stats - Epoch: 31 AUC-val 0.560  AUC-train 0.952\n",
            "Stats - Epoch: 32 AUC-val 0.549  AUC-train 0.959\n",
            "Stats - Epoch: 33 AUC-val 0.598  AUC-train 0.952\n",
            "Stats - Epoch: 34 AUC-val 0.565  AUC-train 0.952\n",
            "Stats - Epoch: 35 AUC-val 0.561  AUC-train 0.955\n",
            "Stats - Epoch: 36 AUC-val 0.556  AUC-train 0.960\n",
            "Stats - Epoch: 37 AUC-val 0.536  AUC-train 0.958\n",
            "Stats - Epoch: 38 AUC-val 0.535  AUC-train 0.960\n",
            "Stats - Epoch: 39 AUC-val 0.538  AUC-train 0.962\n",
            "Stats - Epoch: 40 AUC-val 0.580  AUC-train 0.959\n",
            "Stats - Epoch: 41 AUC-val 0.526  AUC-train 0.960\n",
            "Stats - Epoch: 42 AUC-val 0.523  AUC-train 0.961\n",
            "Stats - Epoch: 43 AUC-val 0.550  AUC-train 0.965\n",
            "Stats - Epoch: 44 AUC-val 0.547  AUC-train 0.963\n",
            "Stats - Epoch: 45 AUC-val 0.520  AUC-train 0.967\n",
            "Stats - Epoch: 46 AUC-val 0.572  AUC-train 0.966\n",
            "Stats - Epoch: 47 AUC-val 0.531  AUC-train 0.970\n",
            "Stats - Epoch: 48 AUC-val 0.491  AUC-train 0.970\n",
            "Stats - Epoch: 49 AUC-val 0.533  AUC-train 0.969\n",
            "Stats - Epoch: 50 AUC-val 0.525  AUC-train 0.972\n",
            "Stats - Epoch: 51 AUC-val 0.563  AUC-train 0.975\n",
            "Stats - Epoch: 52 AUC-val 0.549  AUC-train 0.976\n",
            "Stats - Epoch: 53 AUC-val 0.548  AUC-train 0.979\n",
            "Stats - Epoch: 54 AUC-val 0.557  AUC-train 0.976\n",
            "Stats - Epoch: 55 AUC-val 0.559  AUC-train 0.977\n",
            "Stats - Epoch: 56 AUC-val 0.531  AUC-train 0.975\n",
            "Stats - Epoch: 57 AUC-val 0.541  AUC-train 0.976\n",
            "Stats - Epoch: 58 AUC-val 0.590  AUC-train 0.974\n",
            "Stats - Epoch: 59 AUC-val 0.531  AUC-train 0.978\n",
            "Stats - Epoch: 60 AUC-val 0.591  AUC-train 0.979\n",
            "Stats - Epoch: 61 AUC-val 0.603  AUC-train 0.980\n",
            "Stats - Epoch: 62 AUC-val 0.570  AUC-train 0.983\n",
            "Stats - Epoch: 63 AUC-val 0.549  AUC-train 0.982\n",
            "Stats - Epoch: 64 AUC-val 0.555  AUC-train 0.980\n",
            "Stats - Epoch: 65 AUC-val 0.598  AUC-train 0.982\n",
            "Stats - Epoch: 66 AUC-val 0.639  AUC-train 0.980\n",
            "Stats - Epoch: 67 AUC-val 0.630  AUC-train 0.983\n",
            "Stats - Epoch: 68 AUC-val 0.622  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.619  AUC-train 0.980\n",
            "Stats - Epoch: 70 AUC-val 0.576  AUC-train 0.981\n",
            "Stats - Epoch: 71 AUC-val 0.612  AUC-train 0.974\n",
            "Stats - Epoch: 72 AUC-val 0.577  AUC-train 0.976\n",
            "Stats - Epoch: 73 AUC-val 0.570  AUC-train 0.974\n",
            "Stats - Epoch: 74 AUC-val 0.561  AUC-train 0.972\n",
            "Stats - Epoch: 75 AUC-val 0.557  AUC-train 0.976\n",
            "Stats - Epoch: 76 AUC-val 0.553  AUC-train 0.976\n",
            "Stats - Epoch: 77 AUC-val 0.524  AUC-train 0.977\n",
            "Stats - Epoch: 78 AUC-val 0.569  AUC-train 0.979\n",
            "Stats - Epoch: 79 AUC-val 0.558  AUC-train 0.982\n",
            "Stats - Epoch: 80 AUC-val 0.538  AUC-train 0.986\n",
            "Stats - Epoch: 81 AUC-val 0.601  AUC-train 0.984\n",
            "Stats - Epoch: 82 AUC-val 0.554  AUC-train 0.989\n",
            "Stats - Epoch: 83 AUC-val 0.557  AUC-train 0.987\n",
            "Stats - Epoch: 84 AUC-val 0.551  AUC-train 0.984\n",
            "Stats - Epoch: 85 AUC-val 0.577  AUC-train 0.983\n",
            "Stats - Epoch: 86 AUC-val 0.619  AUC-train 0.977\n",
            "Stats - Epoch: 87 AUC-val 0.600  AUC-train 0.984\n",
            "Stats - Epoch: 88 AUC-val 0.589  AUC-train 0.985\n",
            "Stats - Epoch: 89 AUC-val 0.589  AUC-train 0.976\n",
            "Stats - Epoch: 90 AUC-val 0.611  AUC-train 0.977\n",
            "Stats - Epoch: 91 AUC-val 0.612  AUC-train 0.981\n",
            "Stats - Epoch: 92 AUC-val 0.541  AUC-train 0.981\n",
            "Stats - Epoch: 93 AUC-val 0.581  AUC-train 0.981\n",
            "Stats - Epoch: 94 AUC-val 0.570  AUC-train 0.976\n",
            "Stats - Epoch: 95 AUC-val 0.546  AUC-train 0.982\n",
            "Stats - Epoch: 96 AUC-val 0.553  AUC-train 0.981\n",
            "Stats - Epoch: 97 AUC-val 0.568  AUC-train 0.984\n",
            "Stats - Epoch: 98 AUC-val 0.543  AUC-train 0.984\n",
            "Stats - Epoch: 99 AUC-val 0.582  AUC-train 0.982\n",
            "Stats - Epoch: 100 AUC-val 0.552  AUC-train 0.986\n",
            "Results 100 AUC-val 0.639 0.540 0.477 0.516 0.629 AUC-train 0.980\n",
            "Shapley [0.01569136 0.0111696  0.01305198 0.0163338  0.0083046 ] [0.0026614]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.195881\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.421  AUC-train 0.665\n",
            "Stats - Epoch: 2 AUC-val 0.575  AUC-train 0.807\n",
            "Stats - Epoch: 3 AUC-val 0.626  AUC-train 0.848\n",
            "Stats - Epoch: 4 AUC-val 0.653  AUC-train 0.881\n",
            "Stats - Epoch: 5 AUC-val 0.679  AUC-train 0.909\n",
            "Stats - Epoch: 6 AUC-val 0.666  AUC-train 0.931\n",
            "Stats - Epoch: 7 AUC-val 0.688  AUC-train 0.948\n",
            "Stats - Epoch: 8 AUC-val 0.691  AUC-train 0.960\n",
            "Stats - Epoch: 9 AUC-val 0.679  AUC-train 0.968\n",
            "Stats - Epoch: 10 AUC-val 0.726  AUC-train 0.977\n",
            "Stats - Epoch: 11 AUC-val 0.706  AUC-train 0.982\n",
            "Stats - Epoch: 12 AUC-val 0.676  AUC-train 0.988\n",
            "Stats - Epoch: 13 AUC-val 0.698  AUC-train 0.990\n",
            "Stats - Epoch: 14 AUC-val 0.688  AUC-train 0.993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.679  AUC-train 0.992\n",
            "Stats - Epoch: 16 AUC-val 0.671  AUC-train 0.996\n",
            "Stats - Epoch: 17 AUC-val 0.692  AUC-train 0.996\n",
            "Stats - Epoch: 18 AUC-val 0.664  AUC-train 0.997\n",
            "Stats - Epoch: 19 AUC-val 0.680  AUC-train 0.998\n",
            "Stats - Epoch: 20 AUC-val 0.661  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.675  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.646  AUC-train 0.999\n",
            "Stats - Epoch: 28 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.654  AUC-train 0.995\n",
            "Stats - Epoch: 31 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.688  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.689  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.675  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.636  AUC-train 0.997\n",
            "Stats - Epoch: 39 AUC-val 0.641  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.687  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.651  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.651  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.680  AUC-train 1.000\n",
            "Stats - Epoch: 47 AUC-val 0.670  AUC-train 1.000\n",
            "Stats - Epoch: 48 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.648  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.617  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.645  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.629  AUC-train 0.997\n",
            "Stats - Epoch: 58 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.647  AUC-train 0.994\n",
            "Stats - Epoch: 60 AUC-val 0.653  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.648  AUC-train 0.994\n",
            "Stats - Epoch: 62 AUC-val 0.688  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.696  AUC-train 0.998\n",
            "Stats - Epoch: 64 AUC-val 0.716  AUC-train 0.999\n",
            "Stats - Epoch: 65 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.664  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.671  AUC-train 1.000\n",
            "Stats - Epoch: 70 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.676  AUC-train 0.995\n",
            "Stats - Epoch: 72 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.681  AUC-train 0.996\n",
            "Stats - Epoch: 74 AUC-val 0.676  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.659  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.703  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.677  AUC-train 1.000\n",
            "Stats - Epoch: 79 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.645  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.685  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.669  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.706  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.700  AUC-train 0.999\n",
            "Stats - Epoch: 86 AUC-val 0.689  AUC-train 1.000\n",
            "Stats - Epoch: 87 AUC-val 0.690  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.688  AUC-train 0.994\n",
            "Stats - Epoch: 93 AUC-val 0.678  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.697  AUC-train 0.997\n",
            "Stats - Epoch: 95 AUC-val 0.646  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.690  AUC-train 1.000\n",
            "Stats - Epoch: 97 AUC-val 0.664  AUC-train 1.000\n",
            "Stats - Epoch: 98 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.669  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.649  AUC-train 0.999\n",
            "Results 100 AUC-val 0.726 0.610 0.498 0.419 0.549 AUC-train 0.977\n",
            "Shapley [0.01717534 0.01911474 0.0136812  0.03082984 0.01347514] [0.01097854]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199151\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.545  AUC-train 0.594\n",
            "Stats - Epoch: 2 AUC-val 0.566  AUC-train 0.773\n",
            "Stats - Epoch: 3 AUC-val 0.592  AUC-train 0.837\n",
            "Stats - Epoch: 4 AUC-val 0.574  AUC-train 0.873\n",
            "Stats - Epoch: 5 AUC-val 0.567  AUC-train 0.898\n",
            "Stats - Epoch: 6 AUC-val 0.552  AUC-train 0.922\n",
            "Stats - Epoch: 7 AUC-val 0.521  AUC-train 0.938\n",
            "Stats - Epoch: 8 AUC-val 0.576  AUC-train 0.951\n",
            "Stats - Epoch: 9 AUC-val 0.532  AUC-train 0.963\n",
            "Stats - Epoch: 10 AUC-val 0.552  AUC-train 0.971\n",
            "Stats - Epoch: 11 AUC-val 0.538  AUC-train 0.981\n",
            "Stats - Epoch: 12 AUC-val 0.527  AUC-train 0.986\n",
            "Stats - Epoch: 13 AUC-val 0.579  AUC-train 0.991\n",
            "Stats - Epoch: 14 AUC-val 0.583  AUC-train 0.994\n",
            "Stats - Epoch: 15 AUC-val 0.586  AUC-train 0.994\n",
            "Stats - Epoch: 16 AUC-val 0.603  AUC-train 0.996\n",
            "Stats - Epoch: 17 AUC-val 0.651  AUC-train 0.996\n",
            "Stats - Epoch: 18 AUC-val 0.588  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.612  AUC-train 0.997\n",
            "Stats - Epoch: 20 AUC-val 0.622  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.639  AUC-train 0.998\n",
            "Stats - Epoch: 22 AUC-val 0.615  AUC-train 0.997\n",
            "Stats - Epoch: 23 AUC-val 0.614  AUC-train 0.996\n",
            "Stats - Epoch: 24 AUC-val 0.618  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.644  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.612  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.634  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.638  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.674  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.653  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.650  AUC-train 0.997\n",
            "Stats - Epoch: 32 AUC-val 0.641  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.641  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.647  AUC-train 1.000\n",
            "Stats - Epoch: 39 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.632  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.626  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.653  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.629  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.665  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.658  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.681  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.674  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.646  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 57 AUC-val 0.638  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.669  AUC-train 1.000\n",
            "Stats - Epoch: 60 AUC-val 0.668  AUC-train 1.000\n",
            "Stats - Epoch: 61 AUC-val 0.650  AUC-train 1.000\n",
            "Stats - Epoch: 62 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 63 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.666  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.678  AUC-train 1.000\n",
            "Stats - Epoch: 66 AUC-val 0.685  AUC-train 0.994\n",
            "Stats - Epoch: 67 AUC-val 0.667  AUC-train 0.993\n",
            "Stats - Epoch: 68 AUC-val 0.650  AUC-train 0.991\n",
            "Stats - Epoch: 69 AUC-val 0.660  AUC-train 0.992\n",
            "Stats - Epoch: 70 AUC-val 0.672  AUC-train 0.993\n",
            "Stats - Epoch: 71 AUC-val 0.671  AUC-train 0.995\n",
            "Stats - Epoch: 72 AUC-val 0.660  AUC-train 0.995\n",
            "Stats - Epoch: 73 AUC-val 0.684  AUC-train 0.992\n",
            "Stats - Epoch: 74 AUC-val 0.673  AUC-train 0.992\n",
            "Stats - Epoch: 75 AUC-val 0.676  AUC-train 0.992\n",
            "Stats - Epoch: 76 AUC-val 0.683  AUC-train 0.995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.670  AUC-train 0.994\n",
            "Stats - Epoch: 78 AUC-val 0.666  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.700  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.656  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.660  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.630  AUC-train 0.995\n",
            "Stats - Epoch: 85 AUC-val 0.645  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.629  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.649  AUC-train 0.994\n",
            "Stats - Epoch: 88 AUC-val 0.671  AUC-train 0.995\n",
            "Stats - Epoch: 89 AUC-val 0.669  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.657  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.669  AUC-train 0.989\n",
            "Stats - Epoch: 92 AUC-val 0.679  AUC-train 0.987\n",
            "Stats - Epoch: 93 AUC-val 0.671  AUC-train 0.994\n",
            "Stats - Epoch: 94 AUC-val 0.658  AUC-train 0.996\n",
            "Stats - Epoch: 95 AUC-val 0.648  AUC-train 0.993\n",
            "Stats - Epoch: 96 AUC-val 0.659  AUC-train 0.993\n",
            "Stats - Epoch: 97 AUC-val 0.656  AUC-train 0.995\n",
            "Stats - Epoch: 98 AUC-val 0.688  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.655  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.691  AUC-train 0.992\n",
            "Results 100 AUC-val 0.700 0.669 0.540 0.435 0.571 AUC-train 0.994\n",
            "Shapley [0.01568947 0.01384403 0.00924498 0.01928262 0.006615  ] [0.00272966]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.201437\n",
            "         Iterations 7\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.453  AUC-train 0.516\n",
            "Stats - Epoch: 2 AUC-val 0.433  AUC-train 0.615\n",
            "Stats - Epoch: 3 AUC-val 0.433  AUC-train 0.661\n",
            "Stats - Epoch: 4 AUC-val 0.437  AUC-train 0.713\n",
            "Stats - Epoch: 5 AUC-val 0.433  AUC-train 0.723\n",
            "Stats - Epoch: 6 AUC-val 0.430  AUC-train 0.752\n",
            "Stats - Epoch: 7 AUC-val 0.436  AUC-train 0.770\n",
            "Stats - Epoch: 8 AUC-val 0.428  AUC-train 0.779\n",
            "Stats - Epoch: 9 AUC-val 0.431  AUC-train 0.794\n",
            "Stats - Epoch: 10 AUC-val 0.420  AUC-train 0.816\n",
            "Stats - Epoch: 11 AUC-val 0.426  AUC-train 0.813\n",
            "Stats - Epoch: 12 AUC-val 0.432  AUC-train 0.833\n",
            "Stats - Epoch: 13 AUC-val 0.429  AUC-train 0.836\n",
            "Stats - Epoch: 14 AUC-val 0.426  AUC-train 0.843\n",
            "Stats - Epoch: 15 AUC-val 0.423  AUC-train 0.843\n",
            "Stats - Epoch: 16 AUC-val 0.436  AUC-train 0.856\n",
            "Stats - Epoch: 17 AUC-val 0.441  AUC-train 0.852\n",
            "Stats - Epoch: 18 AUC-val 0.434  AUC-train 0.863\n",
            "Stats - Epoch: 19 AUC-val 0.454  AUC-train 0.866\n",
            "Stats - Epoch: 20 AUC-val 0.449  AUC-train 0.866\n",
            "Stats - Epoch: 21 AUC-val 0.436  AUC-train 0.868\n",
            "Stats - Epoch: 22 AUC-val 0.445  AUC-train 0.868\n",
            "Stats - Epoch: 23 AUC-val 0.453  AUC-train 0.879\n",
            "Stats - Epoch: 24 AUC-val 0.457  AUC-train 0.873\n",
            "Stats - Epoch: 25 AUC-val 0.449  AUC-train 0.875\n",
            "Stats - Epoch: 26 AUC-val 0.454  AUC-train 0.878\n",
            "Stats - Epoch: 27 AUC-val 0.453  AUC-train 0.881\n",
            "Stats - Epoch: 28 AUC-val 0.466  AUC-train 0.878\n",
            "Stats - Epoch: 29 AUC-val 0.458  AUC-train 0.876\n",
            "Stats - Epoch: 30 AUC-val 0.453  AUC-train 0.890\n",
            "Stats - Epoch: 31 AUC-val 0.455  AUC-train 0.885\n",
            "Stats - Epoch: 32 AUC-val 0.457  AUC-train 0.887\n",
            "Stats - Epoch: 33 AUC-val 0.467  AUC-train 0.893\n",
            "Stats - Epoch: 34 AUC-val 0.469  AUC-train 0.880\n",
            "Stats - Epoch: 35 AUC-val 0.471  AUC-train 0.878\n",
            "Stats - Epoch: 36 AUC-val 0.486  AUC-train 0.886\n",
            "Stats - Epoch: 37 AUC-val 0.462  AUC-train 0.887\n",
            "Stats - Epoch: 38 AUC-val 0.472  AUC-train 0.894\n",
            "Stats - Epoch: 39 AUC-val 0.479  AUC-train 0.890\n",
            "Stats - Epoch: 40 AUC-val 0.471  AUC-train 0.898\n",
            "Stats - Epoch: 41 AUC-val 0.466  AUC-train 0.898\n",
            "Stats - Epoch: 42 AUC-val 0.467  AUC-train 0.896\n",
            "Stats - Epoch: 43 AUC-val 0.489  AUC-train 0.890\n",
            "Stats - Epoch: 44 AUC-val 0.480  AUC-train 0.886\n",
            "Stats - Epoch: 45 AUC-val 0.474  AUC-train 0.891\n",
            "Stats - Epoch: 46 AUC-val 0.487  AUC-train 0.897\n",
            "Stats - Epoch: 47 AUC-val 0.483  AUC-train 0.899\n",
            "Stats - Epoch: 48 AUC-val 0.479  AUC-train 0.898\n",
            "Stats - Epoch: 49 AUC-val 0.481  AUC-train 0.892\n",
            "Stats - Epoch: 50 AUC-val 0.478  AUC-train 0.900\n",
            "Stats - Epoch: 51 AUC-val 0.476  AUC-train 0.900\n",
            "Stats - Epoch: 52 AUC-val 0.472  AUC-train 0.890\n",
            "Stats - Epoch: 53 AUC-val 0.492  AUC-train 0.899\n",
            "Stats - Epoch: 54 AUC-val 0.479  AUC-train 0.902\n",
            "Stats - Epoch: 55 AUC-val 0.477  AUC-train 0.903\n",
            "Stats - Epoch: 56 AUC-val 0.473  AUC-train 0.891\n",
            "Stats - Epoch: 57 AUC-val 0.490  AUC-train 0.901\n",
            "Stats - Epoch: 58 AUC-val 0.485  AUC-train 0.896\n",
            "Stats - Epoch: 59 AUC-val 0.490  AUC-train 0.896\n",
            "Stats - Epoch: 60 AUC-val 0.486  AUC-train 0.905\n",
            "Stats - Epoch: 61 AUC-val 0.479  AUC-train 0.907\n",
            "Stats - Epoch: 62 AUC-val 0.498  AUC-train 0.911\n",
            "Stats - Epoch: 63 AUC-val 0.500  AUC-train 0.912\n",
            "Stats - Epoch: 64 AUC-val 0.481  AUC-train 0.901\n",
            "Stats - Epoch: 65 AUC-val 0.488  AUC-train 0.906\n",
            "Stats - Epoch: 66 AUC-val 0.476  AUC-train 0.904\n",
            "Stats - Epoch: 67 AUC-val 0.494  AUC-train 0.908\n",
            "Stats - Epoch: 68 AUC-val 0.483  AUC-train 0.905\n",
            "Stats - Epoch: 69 AUC-val 0.489  AUC-train 0.910\n",
            "Stats - Epoch: 70 AUC-val 0.485  AUC-train 0.911\n",
            "Stats - Epoch: 71 AUC-val 0.489  AUC-train 0.907\n",
            "Stats - Epoch: 72 AUC-val 0.490  AUC-train 0.901\n",
            "Stats - Epoch: 73 AUC-val 0.494  AUC-train 0.902\n",
            "Stats - Epoch: 74 AUC-val 0.495  AUC-train 0.907\n",
            "Stats - Epoch: 75 AUC-val 0.486  AUC-train 0.910\n",
            "Stats - Epoch: 76 AUC-val 0.485  AUC-train 0.902\n",
            "Stats - Epoch: 77 AUC-val 0.495  AUC-train 0.907\n",
            "Stats - Epoch: 78 AUC-val 0.507  AUC-train 0.905\n",
            "Stats - Epoch: 79 AUC-val 0.497  AUC-train 0.909\n",
            "Stats - Epoch: 80 AUC-val 0.495  AUC-train 0.913\n",
            "Stats - Epoch: 81 AUC-val 0.487  AUC-train 0.913\n",
            "Stats - Epoch: 82 AUC-val 0.497  AUC-train 0.913\n",
            "Stats - Epoch: 83 AUC-val 0.492  AUC-train 0.915\n",
            "Stats - Epoch: 84 AUC-val 0.491  AUC-train 0.902\n",
            "Stats - Epoch: 85 AUC-val 0.488  AUC-train 0.913\n",
            "Stats - Epoch: 86 AUC-val 0.494  AUC-train 0.915\n",
            "Stats - Epoch: 87 AUC-val 0.496  AUC-train 0.912\n",
            "Stats - Epoch: 88 AUC-val 0.491  AUC-train 0.912\n",
            "Stats - Epoch: 89 AUC-val 0.494  AUC-train 0.914\n",
            "Stats - Epoch: 90 AUC-val 0.495  AUC-train 0.908\n",
            "Stats - Epoch: 91 AUC-val 0.502  AUC-train 0.917\n",
            "Stats - Epoch: 92 AUC-val 0.507  AUC-train 0.910\n",
            "Stats - Epoch: 93 AUC-val 0.505  AUC-train 0.912\n",
            "Stats - Epoch: 94 AUC-val 0.495  AUC-train 0.917\n",
            "Stats - Epoch: 95 AUC-val 0.507  AUC-train 0.908\n",
            "Stats - Epoch: 96 AUC-val 0.491  AUC-train 0.914\n",
            "Stats - Epoch: 97 AUC-val 0.499  AUC-train 0.917\n",
            "Stats - Epoch: 98 AUC-val 0.495  AUC-train 0.916\n",
            "Stats - Epoch: 99 AUC-val 0.506  AUC-train 0.913\n",
            "Stats - Epoch: 100 AUC-val 0.493  AUC-train 0.917\n",
            "Results 100 AUC-val 0.507 0.532 0.572 0.497 0.629 AUC-train 0.910\n",
            "Shapley [0.00865479 0.00648366 0.01886242 0.01284838 0.00454847] [0.0213548]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.188057\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.326  AUC-train 0.665\n",
            "Stats - Epoch: 2 AUC-val 0.422  AUC-train 0.834\n",
            "Stats - Epoch: 3 AUC-val 0.401  AUC-train 0.908\n",
            "Stats - Epoch: 4 AUC-val 0.396  AUC-train 0.941\n",
            "Stats - Epoch: 5 AUC-val 0.375  AUC-train 0.964\n",
            "Stats - Epoch: 6 AUC-val 0.381  AUC-train 0.970\n",
            "Stats - Epoch: 7 AUC-val 0.374  AUC-train 0.979\n",
            "Stats - Epoch: 8 AUC-val 0.353  AUC-train 0.983\n",
            "Stats - Epoch: 9 AUC-val 0.364  AUC-train 0.984\n",
            "Stats - Epoch: 10 AUC-val 0.398  AUC-train 0.986\n",
            "Stats - Epoch: 11 AUC-val 0.379  AUC-train 0.985\n",
            "Stats - Epoch: 12 AUC-val 0.392  AUC-train 0.991\n",
            "Stats - Epoch: 13 AUC-val 0.384  AUC-train 0.989\n",
            "Stats - Epoch: 14 AUC-val 0.392  AUC-train 0.991\n",
            "Stats - Epoch: 15 AUC-val 0.407  AUC-train 0.992\n",
            "Stats - Epoch: 16 AUC-val 0.409  AUC-train 0.989\n",
            "Stats - Epoch: 17 AUC-val 0.401  AUC-train 0.989\n",
            "Stats - Epoch: 18 AUC-val 0.407  AUC-train 0.982\n",
            "Stats - Epoch: 19 AUC-val 0.416  AUC-train 0.991\n",
            "Stats - Epoch: 20 AUC-val 0.406  AUC-train 0.986\n",
            "Stats - Epoch: 21 AUC-val 0.407  AUC-train 0.988\n",
            "Stats - Epoch: 22 AUC-val 0.421  AUC-train 0.986\n",
            "Stats - Epoch: 23 AUC-val 0.417  AUC-train 0.988\n",
            "Stats - Epoch: 24 AUC-val 0.430  AUC-train 0.987\n",
            "Stats - Epoch: 25 AUC-val 0.423  AUC-train 0.991\n",
            "Stats - Epoch: 26 AUC-val 0.410  AUC-train 0.991\n",
            "Stats - Epoch: 27 AUC-val 0.446  AUC-train 0.987\n",
            "Stats - Epoch: 28 AUC-val 0.425  AUC-train 0.986\n",
            "Stats - Epoch: 29 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 30 AUC-val 0.436  AUC-train 0.989\n",
            "Stats - Epoch: 31 AUC-val 0.419  AUC-train 0.992\n",
            "Stats - Epoch: 32 AUC-val 0.426  AUC-train 0.991\n",
            "Stats - Epoch: 33 AUC-val 0.405  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.433  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.448  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.426  AUC-train 0.989\n",
            "Stats - Epoch: 37 AUC-val 0.438  AUC-train 0.989\n",
            "Stats - Epoch: 38 AUC-val 0.447  AUC-train 0.991\n",
            "Stats - Epoch: 39 AUC-val 0.437  AUC-train 0.986\n",
            "Stats - Epoch: 40 AUC-val 0.454  AUC-train 0.987\n",
            "Stats - Epoch: 41 AUC-val 0.464  AUC-train 0.987\n",
            "Stats - Epoch: 42 AUC-val 0.457  AUC-train 0.982\n",
            "Stats - Epoch: 43 AUC-val 0.452  AUC-train 0.981\n",
            "Stats - Epoch: 44 AUC-val 0.425  AUC-train 0.984\n",
            "Stats - Epoch: 45 AUC-val 0.441  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.447  AUC-train 0.987\n",
            "Stats - Epoch: 47 AUC-val 0.434  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.450  AUC-train 0.984\n",
            "Stats - Epoch: 49 AUC-val 0.403  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.440  AUC-train 0.981\n",
            "Stats - Epoch: 51 AUC-val 0.450  AUC-train 0.984\n",
            "Stats - Epoch: 52 AUC-val 0.424  AUC-train 0.983\n",
            "Stats - Epoch: 53 AUC-val 0.438  AUC-train 0.984\n",
            "Stats - Epoch: 54 AUC-val 0.427  AUC-train 0.985\n",
            "Stats - Epoch: 55 AUC-val 0.429  AUC-train 0.982\n",
            "Stats - Epoch: 56 AUC-val 0.430  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.441  AUC-train 0.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.459  AUC-train 0.985\n",
            "Stats - Epoch: 59 AUC-val 0.445  AUC-train 0.983\n",
            "Stats - Epoch: 60 AUC-val 0.436  AUC-train 0.984\n",
            "Stats - Epoch: 61 AUC-val 0.456  AUC-train 0.985\n",
            "Stats - Epoch: 62 AUC-val 0.446  AUC-train 0.987\n",
            "Stats - Epoch: 63 AUC-val 0.445  AUC-train 0.986\n",
            "Stats - Epoch: 64 AUC-val 0.465  AUC-train 0.976\n",
            "Stats - Epoch: 65 AUC-val 0.444  AUC-train 0.984\n",
            "Stats - Epoch: 66 AUC-val 0.436  AUC-train 0.984\n",
            "Stats - Epoch: 67 AUC-val 0.459  AUC-train 0.983\n",
            "Stats - Epoch: 68 AUC-val 0.453  AUC-train 0.981\n",
            "Stats - Epoch: 69 AUC-val 0.444  AUC-train 0.985\n",
            "Stats - Epoch: 70 AUC-val 0.446  AUC-train 0.982\n",
            "Stats - Epoch: 71 AUC-val 0.445  AUC-train 0.982\n",
            "Stats - Epoch: 72 AUC-val 0.458  AUC-train 0.975\n",
            "Stats - Epoch: 73 AUC-val 0.455  AUC-train 0.981\n",
            "Stats - Epoch: 74 AUC-val 0.457  AUC-train 0.982\n",
            "Stats - Epoch: 75 AUC-val 0.459  AUC-train 0.980\n",
            "Stats - Epoch: 76 AUC-val 0.466  AUC-train 0.977\n",
            "Stats - Epoch: 77 AUC-val 0.463  AUC-train 0.983\n",
            "Stats - Epoch: 78 AUC-val 0.448  AUC-train 0.968\n",
            "Stats - Epoch: 79 AUC-val 0.466  AUC-train 0.982\n",
            "Stats - Epoch: 80 AUC-val 0.453  AUC-train 0.980\n",
            "Stats - Epoch: 81 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 82 AUC-val 0.445  AUC-train 0.984\n",
            "Stats - Epoch: 83 AUC-val 0.433  AUC-train 0.981\n",
            "Stats - Epoch: 84 AUC-val 0.432  AUC-train 0.985\n",
            "Stats - Epoch: 85 AUC-val 0.441  AUC-train 0.983\n",
            "Stats - Epoch: 86 AUC-val 0.445  AUC-train 0.983\n",
            "Stats - Epoch: 87 AUC-val 0.447  AUC-train 0.981\n",
            "Stats - Epoch: 88 AUC-val 0.451  AUC-train 0.984\n",
            "Stats - Epoch: 89 AUC-val 0.406  AUC-train 0.975\n",
            "Stats - Epoch: 90 AUC-val 0.448  AUC-train 0.984\n",
            "Stats - Epoch: 91 AUC-val 0.461  AUC-train 0.983\n",
            "Stats - Epoch: 92 AUC-val 0.413  AUC-train 0.978\n",
            "Stats - Epoch: 93 AUC-val 0.433  AUC-train 0.986\n",
            "Stats - Epoch: 94 AUC-val 0.423  AUC-train 0.981\n",
            "Stats - Epoch: 95 AUC-val 0.422  AUC-train 0.979\n",
            "Stats - Epoch: 96 AUC-val 0.428  AUC-train 0.979\n",
            "Stats - Epoch: 97 AUC-val 0.429  AUC-train 0.981\n",
            "Stats - Epoch: 98 AUC-val 0.424  AUC-train 0.982\n",
            "Stats - Epoch: 99 AUC-val 0.430  AUC-train 0.981\n",
            "Stats - Epoch: 100 AUC-val 0.432  AUC-train 0.979\n",
            "Results 100 AUC-val 0.466 0.451 0.372 0.204 0.568 AUC-train 0.977\n",
            "Shapley [0.02702178 0.00903695 0.01083316 0.04109937 0.00835689] [0.04205416]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.180776\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.203  AUC-train 0.614\n",
            "Stats - Epoch: 2 AUC-val 0.208  AUC-train 0.693\n",
            "Stats - Epoch: 3 AUC-val 0.290  AUC-train 0.775\n",
            "Stats - Epoch: 4 AUC-val 0.376  AUC-train 0.816\n",
            "Stats - Epoch: 5 AUC-val 0.460  AUC-train 0.840\n",
            "Stats - Epoch: 6 AUC-val 0.462  AUC-train 0.858\n",
            "Stats - Epoch: 7 AUC-val 0.496  AUC-train 0.869\n",
            "Stats - Epoch: 8 AUC-val 0.524  AUC-train 0.876\n",
            "Stats - Epoch: 9 AUC-val 0.547  AUC-train 0.884\n",
            "Stats - Epoch: 10 AUC-val 0.574  AUC-train 0.892\n",
            "Stats - Epoch: 11 AUC-val 0.530  AUC-train 0.901\n",
            "Stats - Epoch: 12 AUC-val 0.538  AUC-train 0.904\n",
            "Stats - Epoch: 13 AUC-val 0.537  AUC-train 0.907\n",
            "Stats - Epoch: 14 AUC-val 0.552  AUC-train 0.910\n",
            "Stats - Epoch: 15 AUC-val 0.555  AUC-train 0.916\n",
            "Stats - Epoch: 16 AUC-val 0.534  AUC-train 0.919\n",
            "Stats - Epoch: 17 AUC-val 0.560  AUC-train 0.921\n",
            "Stats - Epoch: 18 AUC-val 0.542  AUC-train 0.923\n",
            "Stats - Epoch: 19 AUC-val 0.528  AUC-train 0.927\n",
            "Stats - Epoch: 20 AUC-val 0.578  AUC-train 0.932\n",
            "Stats - Epoch: 21 AUC-val 0.555  AUC-train 0.936\n",
            "Stats - Epoch: 22 AUC-val 0.541  AUC-train 0.943\n",
            "Stats - Epoch: 23 AUC-val 0.557  AUC-train 0.946\n",
            "Stats - Epoch: 24 AUC-val 0.552  AUC-train 0.947\n",
            "Stats - Epoch: 25 AUC-val 0.572  AUC-train 0.949\n",
            "Stats - Epoch: 26 AUC-val 0.546  AUC-train 0.950\n",
            "Stats - Epoch: 27 AUC-val 0.520  AUC-train 0.953\n",
            "Stats - Epoch: 28 AUC-val 0.554  AUC-train 0.956\n",
            "Stats - Epoch: 29 AUC-val 0.569  AUC-train 0.955\n",
            "Stats - Epoch: 30 AUC-val 0.562  AUC-train 0.956\n",
            "Stats - Epoch: 31 AUC-val 0.552  AUC-train 0.959\n",
            "Stats - Epoch: 32 AUC-val 0.547  AUC-train 0.963\n",
            "Stats - Epoch: 33 AUC-val 0.576  AUC-train 0.960\n",
            "Stats - Epoch: 34 AUC-val 0.569  AUC-train 0.960\n",
            "Stats - Epoch: 35 AUC-val 0.573  AUC-train 0.957\n",
            "Stats - Epoch: 36 AUC-val 0.543  AUC-train 0.964\n",
            "Stats - Epoch: 37 AUC-val 0.586  AUC-train 0.967\n",
            "Stats - Epoch: 38 AUC-val 0.543  AUC-train 0.968\n",
            "Stats - Epoch: 39 AUC-val 0.567  AUC-train 0.971\n",
            "Stats - Epoch: 40 AUC-val 0.573  AUC-train 0.969\n",
            "Stats - Epoch: 41 AUC-val 0.570  AUC-train 0.969\n",
            "Stats - Epoch: 42 AUC-val 0.592  AUC-train 0.973\n",
            "Stats - Epoch: 43 AUC-val 0.574  AUC-train 0.975\n",
            "Stats - Epoch: 44 AUC-val 0.626  AUC-train 0.976\n",
            "Stats - Epoch: 45 AUC-val 0.590  AUC-train 0.974\n",
            "Stats - Epoch: 46 AUC-val 0.588  AUC-train 0.980\n",
            "Stats - Epoch: 47 AUC-val 0.593  AUC-train 0.981\n",
            "Stats - Epoch: 48 AUC-val 0.584  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.579  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.575  AUC-train 0.984\n",
            "Stats - Epoch: 51 AUC-val 0.559  AUC-train 0.982\n",
            "Stats - Epoch: 52 AUC-val 0.565  AUC-train 0.979\n",
            "Stats - Epoch: 53 AUC-val 0.526  AUC-train 0.976\n",
            "Stats - Epoch: 54 AUC-val 0.607  AUC-train 0.975\n",
            "Stats - Epoch: 55 AUC-val 0.595  AUC-train 0.975\n",
            "Stats - Epoch: 56 AUC-val 0.571  AUC-train 0.977\n",
            "Stats - Epoch: 57 AUC-val 0.584  AUC-train 0.973\n",
            "Stats - Epoch: 58 AUC-val 0.579  AUC-train 0.975\n",
            "Stats - Epoch: 59 AUC-val 0.645  AUC-train 0.982\n",
            "Stats - Epoch: 60 AUC-val 0.588  AUC-train 0.984\n",
            "Stats - Epoch: 61 AUC-val 0.605  AUC-train 0.986\n",
            "Stats - Epoch: 62 AUC-val 0.614  AUC-train 0.986\n",
            "Stats - Epoch: 63 AUC-val 0.625  AUC-train 0.982\n",
            "Stats - Epoch: 64 AUC-val 0.590  AUC-train 0.981\n",
            "Stats - Epoch: 65 AUC-val 0.640  AUC-train 0.985\n",
            "Stats - Epoch: 66 AUC-val 0.542  AUC-train 0.986\n",
            "Stats - Epoch: 67 AUC-val 0.602  AUC-train 0.987\n",
            "Stats - Epoch: 68 AUC-val 0.585  AUC-train 0.989\n",
            "Stats - Epoch: 69 AUC-val 0.536  AUC-train 0.992\n",
            "Stats - Epoch: 70 AUC-val 0.608  AUC-train 0.990\n",
            "Stats - Epoch: 71 AUC-val 0.594  AUC-train 0.983\n",
            "Stats - Epoch: 72 AUC-val 0.571  AUC-train 0.984\n",
            "Stats - Epoch: 73 AUC-val 0.607  AUC-train 0.984\n",
            "Stats - Epoch: 74 AUC-val 0.620  AUC-train 0.985\n",
            "Stats - Epoch: 75 AUC-val 0.590  AUC-train 0.985\n",
            "Stats - Epoch: 76 AUC-val 0.609  AUC-train 0.984\n",
            "Stats - Epoch: 77 AUC-val 0.569  AUC-train 0.984\n",
            "Stats - Epoch: 78 AUC-val 0.618  AUC-train 0.983\n",
            "Stats - Epoch: 79 AUC-val 0.592  AUC-train 0.983\n",
            "Stats - Epoch: 80 AUC-val 0.569  AUC-train 0.983\n",
            "Stats - Epoch: 81 AUC-val 0.604  AUC-train 0.978\n",
            "Stats - Epoch: 82 AUC-val 0.610  AUC-train 0.987\n",
            "Stats - Epoch: 83 AUC-val 0.644  AUC-train 0.985\n",
            "Stats - Epoch: 84 AUC-val 0.579  AUC-train 0.987\n",
            "Stats - Epoch: 85 AUC-val 0.603  AUC-train 0.989\n",
            "Stats - Epoch: 86 AUC-val 0.567  AUC-train 0.986\n",
            "Stats - Epoch: 87 AUC-val 0.564  AUC-train 0.989\n",
            "Stats - Epoch: 88 AUC-val 0.556  AUC-train 0.991\n",
            "Stats - Epoch: 89 AUC-val 0.604  AUC-train 0.991\n",
            "Stats - Epoch: 90 AUC-val 0.586  AUC-train 0.991\n",
            "Stats - Epoch: 91 AUC-val 0.590  AUC-train 0.986\n",
            "Stats - Epoch: 92 AUC-val 0.597  AUC-train 0.989\n",
            "Stats - Epoch: 93 AUC-val 0.603  AUC-train 0.991\n",
            "Stats - Epoch: 94 AUC-val 0.548  AUC-train 0.989\n",
            "Stats - Epoch: 95 AUC-val 0.572  AUC-train 0.985\n",
            "Stats - Epoch: 96 AUC-val 0.554  AUC-train 0.991\n",
            "Stats - Epoch: 97 AUC-val 0.574  AUC-train 0.987\n",
            "Stats - Epoch: 98 AUC-val 0.638  AUC-train 0.989\n",
            "Stats - Epoch: 99 AUC-val 0.609  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.557  AUC-train 0.992\n",
            "Results 100 AUC-val 0.645 0.590 0.544 0.555 0.668 AUC-train 0.982\n",
            "Shapley [0.01437606 0.01071293 0.01270859 0.01356001 0.00686955] [0.00263037]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198024\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.406  AUC-train 0.664\n",
            "Stats - Epoch: 2 AUC-val 0.557  AUC-train 0.799\n",
            "Stats - Epoch: 3 AUC-val 0.620  AUC-train 0.841\n",
            "Stats - Epoch: 4 AUC-val 0.653  AUC-train 0.877\n",
            "Stats - Epoch: 5 AUC-val 0.664  AUC-train 0.900\n",
            "Stats - Epoch: 6 AUC-val 0.678  AUC-train 0.926\n",
            "Stats - Epoch: 7 AUC-val 0.683  AUC-train 0.943\n",
            "Stats - Epoch: 8 AUC-val 0.695  AUC-train 0.958\n",
            "Stats - Epoch: 9 AUC-val 0.688  AUC-train 0.969\n",
            "Stats - Epoch: 10 AUC-val 0.690  AUC-train 0.979\n",
            "Stats - Epoch: 11 AUC-val 0.705  AUC-train 0.985\n",
            "Stats - Epoch: 12 AUC-val 0.674  AUC-train 0.990\n",
            "Stats - Epoch: 13 AUC-val 0.707  AUC-train 0.992\n",
            "Stats - Epoch: 14 AUC-val 0.680  AUC-train 0.995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.673  AUC-train 0.996\n",
            "Stats - Epoch: 16 AUC-val 0.683  AUC-train 0.997\n",
            "Stats - Epoch: 17 AUC-val 0.698  AUC-train 0.997\n",
            "Stats - Epoch: 18 AUC-val 0.680  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 22 AUC-val 0.673  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.639  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.677  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.673  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.698  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.688  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.650  AUC-train 1.000\n",
            "Stats - Epoch: 37 AUC-val 0.664  AUC-train 0.996\n",
            "Stats - Epoch: 38 AUC-val 0.652  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.705  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 44 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.697  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.644  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 52 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 53 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.653  AUC-train 1.000\n",
            "Stats - Epoch: 55 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 61 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 62 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.662  AUC-train 1.000\n",
            "Stats - Epoch: 64 AUC-val 0.666  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.670  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.684  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 71 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 72 AUC-val 0.652  AUC-train 1.000\n",
            "Stats - Epoch: 73 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.647  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.694  AUC-train 0.999\n",
            "Stats - Epoch: 77 AUC-val 0.668  AUC-train 1.000\n",
            "Stats - Epoch: 78 AUC-val 0.699  AUC-train 1.000\n",
            "Stats - Epoch: 79 AUC-val 0.674  AUC-train 0.998\n",
            "Stats - Epoch: 80 AUC-val 0.641  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.655  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.693  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.656  AUC-train 0.998\n",
            "Stats - Epoch: 84 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.668  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.631  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.690  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.689  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.620  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.613  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.648  AUC-train 0.995\n",
            "Stats - Epoch: 95 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.637  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.630  AUC-train 0.999\n",
            "Stats - Epoch: 98 AUC-val 0.658  AUC-train 0.999\n",
            "Stats - Epoch: 99 AUC-val 0.675  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.643  AUC-train 0.996\n",
            "Results 100 AUC-val 0.707 0.600 0.469 0.439 0.586 AUC-train 0.992\n",
            "Shapley [0.01844623 0.01791519 0.01267894 0.03349193 0.01753519] [0.00737481]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196339\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.511  AUC-train 0.628\n",
            "Stats - Epoch: 2 AUC-val 0.549  AUC-train 0.788\n",
            "Stats - Epoch: 3 AUC-val 0.578  AUC-train 0.842\n",
            "Stats - Epoch: 4 AUC-val 0.589  AUC-train 0.877\n",
            "Stats - Epoch: 5 AUC-val 0.569  AUC-train 0.900\n",
            "Stats - Epoch: 6 AUC-val 0.569  AUC-train 0.926\n",
            "Stats - Epoch: 7 AUC-val 0.587  AUC-train 0.943\n",
            "Stats - Epoch: 8 AUC-val 0.524  AUC-train 0.959\n",
            "Stats - Epoch: 9 AUC-val 0.565  AUC-train 0.968\n",
            "Stats - Epoch: 10 AUC-val 0.583  AUC-train 0.977\n",
            "Stats - Epoch: 11 AUC-val 0.565  AUC-train 0.985\n",
            "Stats - Epoch: 12 AUC-val 0.578  AUC-train 0.988\n",
            "Stats - Epoch: 13 AUC-val 0.597  AUC-train 0.993\n",
            "Stats - Epoch: 14 AUC-val 0.583  AUC-train 0.995\n",
            "Stats - Epoch: 15 AUC-val 0.604  AUC-train 0.996\n",
            "Stats - Epoch: 16 AUC-val 0.601  AUC-train 0.995\n",
            "Stats - Epoch: 17 AUC-val 0.609  AUC-train 0.998\n",
            "Stats - Epoch: 18 AUC-val 0.643  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.665  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.684  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.684  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.658  AUC-train 1.000\n",
            "Stats - Epoch: 31 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.697  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.674  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.692  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.696  AUC-train 0.996\n",
            "Stats - Epoch: 39 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 40 AUC-val 0.689  AUC-train 0.996\n",
            "Stats - Epoch: 41 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 43 AUC-val 0.698  AUC-train 0.996\n",
            "Stats - Epoch: 44 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 45 AUC-val 0.689  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.695  AUC-train 0.993\n",
            "Stats - Epoch: 47 AUC-val 0.711  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.695  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.690  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.726  AUC-train 0.997\n",
            "Stats - Epoch: 51 AUC-val 0.697  AUC-train 0.995\n",
            "Stats - Epoch: 52 AUC-val 0.732  AUC-train 0.997\n",
            "Stats - Epoch: 53 AUC-val 0.673  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.681  AUC-train 0.997\n",
            "Stats - Epoch: 55 AUC-val 0.668  AUC-train 0.996\n",
            "Stats - Epoch: 56 AUC-val 0.642  AUC-train 0.996\n",
            "Stats - Epoch: 57 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.658  AUC-train 0.998\n",
            "Stats - Epoch: 59 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.644  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 65 AUC-val 0.696  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.655  AUC-train 1.000\n",
            "Stats - Epoch: 67 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.698  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 73 AUC-val 0.655  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.665  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.660  AUC-train 0.995\n",
            "Stats - Epoch: 76 AUC-val 0.650  AUC-train 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.681  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.677  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.672  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.702  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.672  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.688  AUC-train 0.990\n",
            "Stats - Epoch: 86 AUC-val 0.691  AUC-train 0.993\n",
            "Stats - Epoch: 87 AUC-val 0.673  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.680  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.702  AUC-train 0.999\n",
            "Stats - Epoch: 91 AUC-val 0.684  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.690  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.681  AUC-train 0.997\n",
            "Stats - Epoch: 95 AUC-val 0.687  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.675  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.678  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.651  AUC-train 0.994\n",
            "Results 100 AUC-val 0.732 0.622 0.519 0.462 0.616 AUC-train 0.997\n",
            "Shapley [0.01413578 0.01377167 0.00862196 0.01953185 0.00698041] [0.00349689]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.194340\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.380  AUC-train 0.527\n",
            "Stats - Epoch: 2 AUC-val 0.414  AUC-train 0.625\n",
            "Stats - Epoch: 3 AUC-val 0.412  AUC-train 0.661\n",
            "Stats - Epoch: 4 AUC-val 0.409  AUC-train 0.714\n",
            "Stats - Epoch: 5 AUC-val 0.409  AUC-train 0.723\n",
            "Stats - Epoch: 6 AUC-val 0.418  AUC-train 0.749\n",
            "Stats - Epoch: 7 AUC-val 0.420  AUC-train 0.773\n",
            "Stats - Epoch: 8 AUC-val 0.423  AUC-train 0.774\n",
            "Stats - Epoch: 9 AUC-val 0.414  AUC-train 0.802\n",
            "Stats - Epoch: 10 AUC-val 0.415  AUC-train 0.820\n",
            "Stats - Epoch: 11 AUC-val 0.425  AUC-train 0.814\n",
            "Stats - Epoch: 12 AUC-val 0.426  AUC-train 0.832\n",
            "Stats - Epoch: 13 AUC-val 0.425  AUC-train 0.840\n",
            "Stats - Epoch: 14 AUC-val 0.428  AUC-train 0.845\n",
            "Stats - Epoch: 15 AUC-val 0.429  AUC-train 0.848\n",
            "Stats - Epoch: 16 AUC-val 0.429  AUC-train 0.857\n",
            "Stats - Epoch: 17 AUC-val 0.433  AUC-train 0.854\n",
            "Stats - Epoch: 18 AUC-val 0.429  AUC-train 0.862\n",
            "Stats - Epoch: 19 AUC-val 0.440  AUC-train 0.862\n",
            "Stats - Epoch: 20 AUC-val 0.452  AUC-train 0.868\n",
            "Stats - Epoch: 21 AUC-val 0.426  AUC-train 0.870\n",
            "Stats - Epoch: 22 AUC-val 0.448  AUC-train 0.873\n",
            "Stats - Epoch: 23 AUC-val 0.450  AUC-train 0.878\n",
            "Stats - Epoch: 24 AUC-val 0.452  AUC-train 0.879\n",
            "Stats - Epoch: 25 AUC-val 0.441  AUC-train 0.872\n",
            "Stats - Epoch: 26 AUC-val 0.447  AUC-train 0.881\n",
            "Stats - Epoch: 27 AUC-val 0.452  AUC-train 0.882\n",
            "Stats - Epoch: 28 AUC-val 0.453  AUC-train 0.878\n",
            "Stats - Epoch: 29 AUC-val 0.456  AUC-train 0.880\n",
            "Stats - Epoch: 30 AUC-val 0.459  AUC-train 0.889\n",
            "Stats - Epoch: 31 AUC-val 0.454  AUC-train 0.885\n",
            "Stats - Epoch: 32 AUC-val 0.456  AUC-train 0.886\n",
            "Stats - Epoch: 33 AUC-val 0.463  AUC-train 0.895\n",
            "Stats - Epoch: 34 AUC-val 0.466  AUC-train 0.883\n",
            "Stats - Epoch: 35 AUC-val 0.464  AUC-train 0.882\n",
            "Stats - Epoch: 36 AUC-val 0.474  AUC-train 0.882\n",
            "Stats - Epoch: 37 AUC-val 0.472  AUC-train 0.888\n",
            "Stats - Epoch: 38 AUC-val 0.471  AUC-train 0.894\n",
            "Stats - Epoch: 39 AUC-val 0.473  AUC-train 0.896\n",
            "Stats - Epoch: 40 AUC-val 0.484  AUC-train 0.896\n",
            "Stats - Epoch: 41 AUC-val 0.476  AUC-train 0.900\n",
            "Stats - Epoch: 42 AUC-val 0.474  AUC-train 0.892\n",
            "Stats - Epoch: 43 AUC-val 0.479  AUC-train 0.888\n",
            "Stats - Epoch: 44 AUC-val 0.483  AUC-train 0.888\n",
            "Stats - Epoch: 45 AUC-val 0.474  AUC-train 0.894\n",
            "Stats - Epoch: 46 AUC-val 0.483  AUC-train 0.900\n",
            "Stats - Epoch: 47 AUC-val 0.486  AUC-train 0.897\n",
            "Stats - Epoch: 48 AUC-val 0.480  AUC-train 0.890\n",
            "Stats - Epoch: 49 AUC-val 0.483  AUC-train 0.898\n",
            "Stats - Epoch: 50 AUC-val 0.481  AUC-train 0.898\n",
            "Stats - Epoch: 51 AUC-val 0.478  AUC-train 0.893\n",
            "Stats - Epoch: 52 AUC-val 0.470  AUC-train 0.888\n",
            "Stats - Epoch: 53 AUC-val 0.477  AUC-train 0.898\n",
            "Stats - Epoch: 54 AUC-val 0.474  AUC-train 0.896\n",
            "Stats - Epoch: 55 AUC-val 0.468  AUC-train 0.901\n",
            "Stats - Epoch: 56 AUC-val 0.469  AUC-train 0.892\n",
            "Stats - Epoch: 57 AUC-val 0.477  AUC-train 0.899\n",
            "Stats - Epoch: 58 AUC-val 0.480  AUC-train 0.892\n",
            "Stats - Epoch: 59 AUC-val 0.479  AUC-train 0.892\n",
            "Stats - Epoch: 60 AUC-val 0.484  AUC-train 0.902\n",
            "Stats - Epoch: 61 AUC-val 0.474  AUC-train 0.902\n",
            "Stats - Epoch: 62 AUC-val 0.478  AUC-train 0.907\n",
            "Stats - Epoch: 63 AUC-val 0.482  AUC-train 0.907\n",
            "Stats - Epoch: 64 AUC-val 0.485  AUC-train 0.899\n",
            "Stats - Epoch: 65 AUC-val 0.478  AUC-train 0.905\n",
            "Stats - Epoch: 66 AUC-val 0.479  AUC-train 0.906\n",
            "Stats - Epoch: 67 AUC-val 0.491  AUC-train 0.909\n",
            "Stats - Epoch: 68 AUC-val 0.483  AUC-train 0.907\n",
            "Stats - Epoch: 69 AUC-val 0.481  AUC-train 0.909\n",
            "Stats - Epoch: 70 AUC-val 0.484  AUC-train 0.909\n",
            "Stats - Epoch: 71 AUC-val 0.488  AUC-train 0.905\n",
            "Stats - Epoch: 72 AUC-val 0.487  AUC-train 0.905\n",
            "Stats - Epoch: 73 AUC-val 0.493  AUC-train 0.902\n",
            "Stats - Epoch: 74 AUC-val 0.488  AUC-train 0.907\n",
            "Stats - Epoch: 75 AUC-val 0.482  AUC-train 0.907\n",
            "Stats - Epoch: 76 AUC-val 0.484  AUC-train 0.901\n",
            "Stats - Epoch: 77 AUC-val 0.485  AUC-train 0.906\n",
            "Stats - Epoch: 78 AUC-val 0.488  AUC-train 0.909\n",
            "Stats - Epoch: 79 AUC-val 0.488  AUC-train 0.909\n",
            "Stats - Epoch: 80 AUC-val 0.499  AUC-train 0.910\n",
            "Stats - Epoch: 81 AUC-val 0.489  AUC-train 0.913\n",
            "Stats - Epoch: 82 AUC-val 0.482  AUC-train 0.910\n",
            "Stats - Epoch: 83 AUC-val 0.494  AUC-train 0.912\n",
            "Stats - Epoch: 84 AUC-val 0.477  AUC-train 0.904\n",
            "Stats - Epoch: 85 AUC-val 0.496  AUC-train 0.911\n",
            "Stats - Epoch: 86 AUC-val 0.494  AUC-train 0.912\n",
            "Stats - Epoch: 87 AUC-val 0.489  AUC-train 0.908\n",
            "Stats - Epoch: 88 AUC-val 0.493  AUC-train 0.915\n",
            "Stats - Epoch: 89 AUC-val 0.494  AUC-train 0.913\n",
            "Stats - Epoch: 90 AUC-val 0.486  AUC-train 0.907\n",
            "Stats - Epoch: 91 AUC-val 0.503  AUC-train 0.914\n",
            "Stats - Epoch: 92 AUC-val 0.497  AUC-train 0.905\n",
            "Stats - Epoch: 93 AUC-val 0.495  AUC-train 0.910\n",
            "Stats - Epoch: 94 AUC-val 0.492  AUC-train 0.911\n",
            "Stats - Epoch: 95 AUC-val 0.499  AUC-train 0.904\n",
            "Stats - Epoch: 96 AUC-val 0.485  AUC-train 0.912\n",
            "Stats - Epoch: 97 AUC-val 0.487  AUC-train 0.914\n",
            "Stats - Epoch: 98 AUC-val 0.489  AUC-train 0.912\n",
            "Stats - Epoch: 99 AUC-val 0.505  AUC-train 0.908\n",
            "Stats - Epoch: 100 AUC-val 0.498  AUC-train 0.911\n",
            "Results 100 AUC-val 0.505 0.534 0.571 0.502 0.628 AUC-train 0.908\n",
            "Shapley [0.00924949 0.00731373 0.01980567 0.01432353 0.00448004] [0.02008696]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187425\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.376  AUC-train 0.661\n",
            "Stats - Epoch: 2 AUC-val 0.409  AUC-train 0.839\n",
            "Stats - Epoch: 3 AUC-val 0.397  AUC-train 0.901\n",
            "Stats - Epoch: 4 AUC-val 0.384  AUC-train 0.945\n",
            "Stats - Epoch: 5 AUC-val 0.391  AUC-train 0.960\n",
            "Stats - Epoch: 6 AUC-val 0.413  AUC-train 0.972\n",
            "Stats - Epoch: 7 AUC-val 0.388  AUC-train 0.979\n",
            "Stats - Epoch: 8 AUC-val 0.391  AUC-train 0.973\n",
            "Stats - Epoch: 9 AUC-val 0.400  AUC-train 0.982\n",
            "Stats - Epoch: 10 AUC-val 0.441  AUC-train 0.989\n",
            "Stats - Epoch: 11 AUC-val 0.403  AUC-train 0.987\n",
            "Stats - Epoch: 12 AUC-val 0.422  AUC-train 0.990\n",
            "Stats - Epoch: 13 AUC-val 0.401  AUC-train 0.992\n",
            "Stats - Epoch: 14 AUC-val 0.436  AUC-train 0.989\n",
            "Stats - Epoch: 15 AUC-val 0.423  AUC-train 0.991\n",
            "Stats - Epoch: 16 AUC-val 0.428  AUC-train 0.987\n",
            "Stats - Epoch: 17 AUC-val 0.422  AUC-train 0.990\n",
            "Stats - Epoch: 18 AUC-val 0.431  AUC-train 0.983\n",
            "Stats - Epoch: 19 AUC-val 0.423  AUC-train 0.988\n",
            "Stats - Epoch: 20 AUC-val 0.422  AUC-train 0.983\n",
            "Stats - Epoch: 21 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 22 AUC-val 0.436  AUC-train 0.984\n",
            "Stats - Epoch: 23 AUC-val 0.431  AUC-train 0.988\n",
            "Stats - Epoch: 24 AUC-val 0.440  AUC-train 0.988\n",
            "Stats - Epoch: 25 AUC-val 0.435  AUC-train 0.989\n",
            "Stats - Epoch: 26 AUC-val 0.437  AUC-train 0.988\n",
            "Stats - Epoch: 27 AUC-val 0.461  AUC-train 0.985\n",
            "Stats - Epoch: 28 AUC-val 0.450  AUC-train 0.984\n",
            "Stats - Epoch: 29 AUC-val 0.437  AUC-train 0.986\n",
            "Stats - Epoch: 30 AUC-val 0.431  AUC-train 0.990\n",
            "Stats - Epoch: 31 AUC-val 0.446  AUC-train 0.991\n",
            "Stats - Epoch: 32 AUC-val 0.446  AUC-train 0.990\n",
            "Stats - Epoch: 33 AUC-val 0.410  AUC-train 0.991\n",
            "Stats - Epoch: 34 AUC-val 0.450  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.451  AUC-train 0.989\n",
            "Stats - Epoch: 36 AUC-val 0.435  AUC-train 0.989\n",
            "Stats - Epoch: 37 AUC-val 0.452  AUC-train 0.987\n",
            "Stats - Epoch: 38 AUC-val 0.463  AUC-train 0.989\n",
            "Stats - Epoch: 39 AUC-val 0.433  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.472  AUC-train 0.987\n",
            "Stats - Epoch: 41 AUC-val 0.471  AUC-train 0.986\n",
            "Stats - Epoch: 42 AUC-val 0.459  AUC-train 0.983\n",
            "Stats - Epoch: 43 AUC-val 0.459  AUC-train 0.983\n",
            "Stats - Epoch: 44 AUC-val 0.433  AUC-train 0.988\n",
            "Stats - Epoch: 45 AUC-val 0.463  AUC-train 0.987\n",
            "Stats - Epoch: 46 AUC-val 0.455  AUC-train 0.987\n",
            "Stats - Epoch: 47 AUC-val 0.479  AUC-train 0.985\n",
            "Stats - Epoch: 48 AUC-val 0.449  AUC-train 0.984\n",
            "Stats - Epoch: 49 AUC-val 0.448  AUC-train 0.986\n",
            "Stats - Epoch: 50 AUC-val 0.456  AUC-train 0.979\n",
            "Stats - Epoch: 51 AUC-val 0.459  AUC-train 0.983\n",
            "Stats - Epoch: 52 AUC-val 0.447  AUC-train 0.986\n",
            "Stats - Epoch: 53 AUC-val 0.447  AUC-train 0.988\n",
            "Stats - Epoch: 54 AUC-val 0.456  AUC-train 0.987\n",
            "Stats - Epoch: 55 AUC-val 0.456  AUC-train 0.981\n",
            "Stats - Epoch: 56 AUC-val 0.448  AUC-train 0.986\n",
            "Stats - Epoch: 57 AUC-val 0.449  AUC-train 0.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.477  AUC-train 0.984\n",
            "Stats - Epoch: 59 AUC-val 0.450  AUC-train 0.981\n",
            "Stats - Epoch: 60 AUC-val 0.441  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 62 AUC-val 0.451  AUC-train 0.986\n",
            "Stats - Epoch: 63 AUC-val 0.448  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.460  AUC-train 0.977\n",
            "Stats - Epoch: 65 AUC-val 0.461  AUC-train 0.982\n",
            "Stats - Epoch: 66 AUC-val 0.444  AUC-train 0.985\n",
            "Stats - Epoch: 67 AUC-val 0.451  AUC-train 0.983\n",
            "Stats - Epoch: 68 AUC-val 0.438  AUC-train 0.983\n",
            "Stats - Epoch: 69 AUC-val 0.453  AUC-train 0.987\n",
            "Stats - Epoch: 70 AUC-val 0.434  AUC-train 0.983\n",
            "Stats - Epoch: 71 AUC-val 0.471  AUC-train 0.983\n",
            "Stats - Epoch: 72 AUC-val 0.448  AUC-train 0.979\n",
            "Stats - Epoch: 73 AUC-val 0.471  AUC-train 0.982\n",
            "Stats - Epoch: 74 AUC-val 0.453  AUC-train 0.982\n",
            "Stats - Epoch: 75 AUC-val 0.486  AUC-train 0.980\n",
            "Stats - Epoch: 76 AUC-val 0.482  AUC-train 0.978\n",
            "Stats - Epoch: 77 AUC-val 0.456  AUC-train 0.982\n",
            "Stats - Epoch: 78 AUC-val 0.471  AUC-train 0.975\n",
            "Stats - Epoch: 79 AUC-val 0.468  AUC-train 0.982\n",
            "Stats - Epoch: 80 AUC-val 0.445  AUC-train 0.982\n",
            "Stats - Epoch: 81 AUC-val 0.429  AUC-train 0.981\n",
            "Stats - Epoch: 82 AUC-val 0.445  AUC-train 0.983\n",
            "Stats - Epoch: 83 AUC-val 0.464  AUC-train 0.982\n",
            "Stats - Epoch: 84 AUC-val 0.474  AUC-train 0.982\n",
            "Stats - Epoch: 85 AUC-val 0.439  AUC-train 0.985\n",
            "Stats - Epoch: 86 AUC-val 0.462  AUC-train 0.982\n",
            "Stats - Epoch: 87 AUC-val 0.478  AUC-train 0.983\n",
            "Stats - Epoch: 88 AUC-val 0.447  AUC-train 0.983\n",
            "Stats - Epoch: 89 AUC-val 0.451  AUC-train 0.977\n",
            "Stats - Epoch: 90 AUC-val 0.439  AUC-train 0.982\n",
            "Stats - Epoch: 91 AUC-val 0.492  AUC-train 0.983\n",
            "Stats - Epoch: 92 AUC-val 0.464  AUC-train 0.978\n",
            "Stats - Epoch: 93 AUC-val 0.453  AUC-train 0.985\n",
            "Stats - Epoch: 94 AUC-val 0.432  AUC-train 0.978\n",
            "Stats - Epoch: 95 AUC-val 0.448  AUC-train 0.979\n",
            "Stats - Epoch: 96 AUC-val 0.438  AUC-train 0.979\n",
            "Stats - Epoch: 97 AUC-val 0.447  AUC-train 0.982\n",
            "Stats - Epoch: 98 AUC-val 0.444  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.430  AUC-train 0.976\n",
            "Stats - Epoch: 100 AUC-val 0.457  AUC-train 0.978\n",
            "Results 100 AUC-val 0.492 0.470 0.332 0.184 0.577 AUC-train 0.983\n",
            "Shapley [0.02686009 0.00892899 0.01026637 0.03862485 0.00728382] [0.03600385]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.178444\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.221  AUC-train 0.613\n",
            "Stats - Epoch: 2 AUC-val 0.228  AUC-train 0.714\n",
            "Stats - Epoch: 3 AUC-val 0.307  AUC-train 0.780\n",
            "Stats - Epoch: 4 AUC-val 0.410  AUC-train 0.823\n",
            "Stats - Epoch: 5 AUC-val 0.435  AUC-train 0.843\n",
            "Stats - Epoch: 6 AUC-val 0.539  AUC-train 0.858\n",
            "Stats - Epoch: 7 AUC-val 0.540  AUC-train 0.868\n",
            "Stats - Epoch: 8 AUC-val 0.547  AUC-train 0.875\n",
            "Stats - Epoch: 9 AUC-val 0.567  AUC-train 0.882\n",
            "Stats - Epoch: 10 AUC-val 0.555  AUC-train 0.887\n",
            "Stats - Epoch: 11 AUC-val 0.548  AUC-train 0.895\n",
            "Stats - Epoch: 12 AUC-val 0.563  AUC-train 0.899\n",
            "Stats - Epoch: 13 AUC-val 0.544  AUC-train 0.908\n",
            "Stats - Epoch: 14 AUC-val 0.569  AUC-train 0.910\n",
            "Stats - Epoch: 15 AUC-val 0.548  AUC-train 0.913\n",
            "Stats - Epoch: 16 AUC-val 0.561  AUC-train 0.918\n",
            "Stats - Epoch: 17 AUC-val 0.560  AUC-train 0.924\n",
            "Stats - Epoch: 18 AUC-val 0.591  AUC-train 0.926\n",
            "Stats - Epoch: 19 AUC-val 0.556  AUC-train 0.928\n",
            "Stats - Epoch: 20 AUC-val 0.568  AUC-train 0.935\n",
            "Stats - Epoch: 21 AUC-val 0.566  AUC-train 0.935\n",
            "Stats - Epoch: 22 AUC-val 0.540  AUC-train 0.942\n",
            "Stats - Epoch: 23 AUC-val 0.527  AUC-train 0.949\n",
            "Stats - Epoch: 24 AUC-val 0.566  AUC-train 0.948\n",
            "Stats - Epoch: 25 AUC-val 0.536  AUC-train 0.950\n",
            "Stats - Epoch: 26 AUC-val 0.552  AUC-train 0.947\n",
            "Stats - Epoch: 27 AUC-val 0.565  AUC-train 0.951\n",
            "Stats - Epoch: 28 AUC-val 0.557  AUC-train 0.953\n",
            "Stats - Epoch: 29 AUC-val 0.563  AUC-train 0.960\n",
            "Stats - Epoch: 30 AUC-val 0.527  AUC-train 0.961\n",
            "Stats - Epoch: 31 AUC-val 0.565  AUC-train 0.962\n",
            "Stats - Epoch: 32 AUC-val 0.539  AUC-train 0.964\n",
            "Stats - Epoch: 33 AUC-val 0.554  AUC-train 0.966\n",
            "Stats - Epoch: 34 AUC-val 0.540  AUC-train 0.967\n",
            "Stats - Epoch: 35 AUC-val 0.548  AUC-train 0.971\n",
            "Stats - Epoch: 36 AUC-val 0.533  AUC-train 0.975\n",
            "Stats - Epoch: 37 AUC-val 0.570  AUC-train 0.974\n",
            "Stats - Epoch: 38 AUC-val 0.516  AUC-train 0.976\n",
            "Stats - Epoch: 39 AUC-val 0.545  AUC-train 0.973\n",
            "Stats - Epoch: 40 AUC-val 0.570  AUC-train 0.975\n",
            "Stats - Epoch: 41 AUC-val 0.555  AUC-train 0.977\n",
            "Stats - Epoch: 42 AUC-val 0.556  AUC-train 0.977\n",
            "Stats - Epoch: 43 AUC-val 0.519  AUC-train 0.981\n",
            "Stats - Epoch: 44 AUC-val 0.596  AUC-train 0.980\n",
            "Stats - Epoch: 45 AUC-val 0.585  AUC-train 0.979\n",
            "Stats - Epoch: 46 AUC-val 0.536  AUC-train 0.981\n",
            "Stats - Epoch: 47 AUC-val 0.543  AUC-train 0.981\n",
            "Stats - Epoch: 48 AUC-val 0.600  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.542  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.579  AUC-train 0.983\n",
            "Stats - Epoch: 51 AUC-val 0.546  AUC-train 0.978\n",
            "Stats - Epoch: 52 AUC-val 0.540  AUC-train 0.975\n",
            "Stats - Epoch: 53 AUC-val 0.550  AUC-train 0.978\n",
            "Stats - Epoch: 54 AUC-val 0.585  AUC-train 0.976\n",
            "Stats - Epoch: 55 AUC-val 0.511  AUC-train 0.981\n",
            "Stats - Epoch: 56 AUC-val 0.550  AUC-train 0.983\n",
            "Stats - Epoch: 57 AUC-val 0.579  AUC-train 0.985\n",
            "Stats - Epoch: 58 AUC-val 0.577  AUC-train 0.985\n",
            "Stats - Epoch: 59 AUC-val 0.538  AUC-train 0.983\n",
            "Stats - Epoch: 60 AUC-val 0.507  AUC-train 0.986\n",
            "Stats - Epoch: 61 AUC-val 0.524  AUC-train 0.987\n",
            "Stats - Epoch: 62 AUC-val 0.558  AUC-train 0.988\n",
            "Stats - Epoch: 63 AUC-val 0.556  AUC-train 0.983\n",
            "Stats - Epoch: 64 AUC-val 0.598  AUC-train 0.988\n",
            "Stats - Epoch: 65 AUC-val 0.526  AUC-train 0.988\n",
            "Stats - Epoch: 66 AUC-val 0.575  AUC-train 0.985\n",
            "Stats - Epoch: 67 AUC-val 0.567  AUC-train 0.989\n",
            "Stats - Epoch: 68 AUC-val 0.512  AUC-train 0.990\n",
            "Stats - Epoch: 69 AUC-val 0.525  AUC-train 0.987\n",
            "Stats - Epoch: 70 AUC-val 0.516  AUC-train 0.987\n",
            "Stats - Epoch: 71 AUC-val 0.528  AUC-train 0.987\n",
            "Stats - Epoch: 72 AUC-val 0.528  AUC-train 0.986\n",
            "Stats - Epoch: 73 AUC-val 0.532  AUC-train 0.983\n",
            "Stats - Epoch: 74 AUC-val 0.500  AUC-train 0.980\n",
            "Stats - Epoch: 75 AUC-val 0.503  AUC-train 0.981\n",
            "Stats - Epoch: 76 AUC-val 0.546  AUC-train 0.985\n",
            "Stats - Epoch: 77 AUC-val 0.519  AUC-train 0.989\n",
            "Stats - Epoch: 78 AUC-val 0.550  AUC-train 0.991\n",
            "Stats - Epoch: 79 AUC-val 0.512  AUC-train 0.990\n",
            "Stats - Epoch: 80 AUC-val 0.519  AUC-train 0.989\n",
            "Stats - Epoch: 81 AUC-val 0.489  AUC-train 0.990\n",
            "Stats - Epoch: 82 AUC-val 0.547  AUC-train 0.992\n",
            "Stats - Epoch: 83 AUC-val 0.533  AUC-train 0.990\n",
            "Stats - Epoch: 84 AUC-val 0.531  AUC-train 0.992\n",
            "Stats - Epoch: 85 AUC-val 0.525  AUC-train 0.990\n",
            "Stats - Epoch: 86 AUC-val 0.504  AUC-train 0.991\n",
            "Stats - Epoch: 87 AUC-val 0.510  AUC-train 0.991\n",
            "Stats - Epoch: 88 AUC-val 0.507  AUC-train 0.989\n",
            "Stats - Epoch: 89 AUC-val 0.507  AUC-train 0.991\n",
            "Stats - Epoch: 90 AUC-val 0.504  AUC-train 0.988\n",
            "Stats - Epoch: 91 AUC-val 0.484  AUC-train 0.983\n",
            "Stats - Epoch: 92 AUC-val 0.535  AUC-train 0.986\n",
            "Stats - Epoch: 93 AUC-val 0.521  AUC-train 0.980\n",
            "Stats - Epoch: 94 AUC-val 0.503  AUC-train 0.983\n",
            "Stats - Epoch: 95 AUC-val 0.451  AUC-train 0.981\n",
            "Stats - Epoch: 96 AUC-val 0.514  AUC-train 0.981\n",
            "Stats - Epoch: 97 AUC-val 0.455  AUC-train 0.980\n",
            "Stats - Epoch: 98 AUC-val 0.549  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.516  AUC-train 0.983\n",
            "Stats - Epoch: 100 AUC-val 0.498  AUC-train 0.979\n",
            "Results 100 AUC-val 0.600 0.472 0.482 0.579 0.683 AUC-train 0.983\n",
            "Shapley [0.01547881 0.01212061 0.01407519 0.01591747 0.00839495] [0.00260489]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.193612\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.428  AUC-train 0.679\n",
            "Stats - Epoch: 2 AUC-val 0.558  AUC-train 0.807\n",
            "Stats - Epoch: 3 AUC-val 0.627  AUC-train 0.852\n",
            "Stats - Epoch: 4 AUC-val 0.641  AUC-train 0.889\n",
            "Stats - Epoch: 5 AUC-val 0.661  AUC-train 0.914\n",
            "Stats - Epoch: 6 AUC-val 0.673  AUC-train 0.938\n",
            "Stats - Epoch: 7 AUC-val 0.683  AUC-train 0.956\n",
            "Stats - Epoch: 8 AUC-val 0.684  AUC-train 0.967\n",
            "Stats - Epoch: 9 AUC-val 0.695  AUC-train 0.977\n",
            "Stats - Epoch: 10 AUC-val 0.674  AUC-train 0.984\n",
            "Stats - Epoch: 11 AUC-val 0.712  AUC-train 0.989\n",
            "Stats - Epoch: 12 AUC-val 0.682  AUC-train 0.992\n",
            "Stats - Epoch: 13 AUC-val 0.660  AUC-train 0.995\n",
            "Stats - Epoch: 14 AUC-val 0.695  AUC-train 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.697  AUC-train 0.998\n",
            "Stats - Epoch: 16 AUC-val 0.671  AUC-train 0.995\n",
            "Stats - Epoch: 17 AUC-val 0.683  AUC-train 0.997\n",
            "Stats - Epoch: 18 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 20 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.669  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 24 AUC-val 0.673  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.667  AUC-train 1.000\n",
            "Stats - Epoch: 26 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.676  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.650  AUC-train 1.000\n",
            "Stats - Epoch: 30 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 31 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.702  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 34 AUC-val 0.659  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 36 AUC-val 0.658  AUC-train 0.998\n",
            "Stats - Epoch: 37 AUC-val 0.681  AUC-train 0.995\n",
            "Stats - Epoch: 38 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.684  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.694  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.683  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.684  AUC-train 0.998\n",
            "Stats - Epoch: 46 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.647  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 50 AUC-val 0.670  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.684  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.672  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 54 AUC-val 0.689  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 56 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.671  AUC-train 1.000\n",
            "Stats - Epoch: 58 AUC-val 0.663  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.658  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.668  AUC-train 0.998\n",
            "Stats - Epoch: 61 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.688  AUC-train 0.999\n",
            "Stats - Epoch: 63 AUC-val 0.671  AUC-train 0.999\n",
            "Stats - Epoch: 64 AUC-val 0.718  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.694  AUC-train 0.998\n",
            "Stats - Epoch: 66 AUC-val 0.702  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.668  AUC-train 0.999\n",
            "Stats - Epoch: 68 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.672  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.690  AUC-train 0.998\n",
            "Stats - Epoch: 71 AUC-val 0.678  AUC-train 0.999\n",
            "Stats - Epoch: 72 AUC-val 0.687  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.692  AUC-train 0.999\n",
            "Stats - Epoch: 74 AUC-val 0.669  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 76 AUC-val 0.661  AUC-train 1.000\n",
            "Stats - Epoch: 77 AUC-val 0.680  AUC-train 1.000\n",
            "Stats - Epoch: 78 AUC-val 0.651  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.681  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.658  AUC-train 0.994\n",
            "Stats - Epoch: 84 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.673  AUC-train 0.999\n",
            "Stats - Epoch: 86 AUC-val 0.694  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.637  AUC-train 0.995\n",
            "Stats - Epoch: 88 AUC-val 0.655  AUC-train 0.998\n",
            "Stats - Epoch: 89 AUC-val 0.641  AUC-train 0.999\n",
            "Stats - Epoch: 90 AUC-val 0.644  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.630  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 94 AUC-val 0.667  AUC-train 0.999\n",
            "Stats - Epoch: 95 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 96 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 98 AUC-val 0.675  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.661  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.672  AUC-train 0.998\n",
            "Results 100 AUC-val 0.718 0.553 0.401 0.452 0.607 AUC-train 0.996\n",
            "Shapley [0.01696265 0.01548622 0.0100776  0.03212524 0.01544661] [0.00302096]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.182897\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.564  AUC-train 0.618\n",
            "Stats - Epoch: 2 AUC-val 0.565  AUC-train 0.787\n",
            "Stats - Epoch: 3 AUC-val 0.574  AUC-train 0.841\n",
            "Stats - Epoch: 4 AUC-val 0.567  AUC-train 0.873\n",
            "Stats - Epoch: 5 AUC-val 0.576  AUC-train 0.900\n",
            "Stats - Epoch: 6 AUC-val 0.566  AUC-train 0.925\n",
            "Stats - Epoch: 7 AUC-val 0.560  AUC-train 0.945\n",
            "Stats - Epoch: 8 AUC-val 0.555  AUC-train 0.959\n",
            "Stats - Epoch: 9 AUC-val 0.570  AUC-train 0.969\n",
            "Stats - Epoch: 10 AUC-val 0.573  AUC-train 0.979\n",
            "Stats - Epoch: 11 AUC-val 0.586  AUC-train 0.983\n",
            "Stats - Epoch: 12 AUC-val 0.605  AUC-train 0.987\n",
            "Stats - Epoch: 13 AUC-val 0.604  AUC-train 0.991\n",
            "Stats - Epoch: 14 AUC-val 0.651  AUC-train 0.993\n",
            "Stats - Epoch: 15 AUC-val 0.654  AUC-train 0.995\n",
            "Stats - Epoch: 16 AUC-val 0.628  AUC-train 0.997\n",
            "Stats - Epoch: 17 AUC-val 0.630  AUC-train 0.997\n",
            "Stats - Epoch: 18 AUC-val 0.626  AUC-train 0.996\n",
            "Stats - Epoch: 19 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 20 AUC-val 0.633  AUC-train 0.998\n",
            "Stats - Epoch: 21 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.646  AUC-train 1.000\n",
            "Stats - Epoch: 23 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 25 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 26 AUC-val 0.686  AUC-train 0.999\n",
            "Stats - Epoch: 27 AUC-val 0.681  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.687  AUC-train 0.999\n",
            "Stats - Epoch: 29 AUC-val 0.660  AUC-train 0.998\n",
            "Stats - Epoch: 30 AUC-val 0.679  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 34 AUC-val 0.662  AUC-train 0.997\n",
            "Stats - Epoch: 35 AUC-val 0.662  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.695  AUC-train 1.000\n",
            "Stats - Epoch: 38 AUC-val 0.678  AUC-train 0.997\n",
            "Stats - Epoch: 39 AUC-val 0.690  AUC-train 0.998\n",
            "Stats - Epoch: 40 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 41 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 42 AUC-val 0.682  AUC-train 1.000\n",
            "Stats - Epoch: 43 AUC-val 0.712  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.710  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.713  AUC-train 0.998\n",
            "Stats - Epoch: 47 AUC-val 0.703  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.714  AUC-train 0.999\n",
            "Stats - Epoch: 49 AUC-val 0.719  AUC-train 0.999\n",
            "Stats - Epoch: 50 AUC-val 0.711  AUC-train 0.998\n",
            "Stats - Epoch: 51 AUC-val 0.703  AUC-train 0.993\n",
            "Stats - Epoch: 52 AUC-val 0.723  AUC-train 0.995\n",
            "Stats - Epoch: 53 AUC-val 0.655  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.688  AUC-train 0.997\n",
            "Stats - Epoch: 55 AUC-val 0.689  AUC-train 0.996\n",
            "Stats - Epoch: 56 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.687  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 59 AUC-val 0.664  AUC-train 0.996\n",
            "Stats - Epoch: 60 AUC-val 0.702  AUC-train 0.998\n",
            "Stats - Epoch: 61 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.683  AUC-train 0.993\n",
            "Stats - Epoch: 63 AUC-val 0.684  AUC-train 0.997\n",
            "Stats - Epoch: 64 AUC-val 0.682  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.686  AUC-train 0.998\n",
            "Stats - Epoch: 66 AUC-val 0.713  AUC-train 0.998\n",
            "Stats - Epoch: 67 AUC-val 0.705  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.695  AUC-train 0.999\n",
            "Stats - Epoch: 69 AUC-val 0.683  AUC-train 0.996\n",
            "Stats - Epoch: 70 AUC-val 0.664  AUC-train 0.995\n",
            "Stats - Epoch: 71 AUC-val 0.649  AUC-train 0.994\n",
            "Stats - Epoch: 72 AUC-val 0.658  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.651  AUC-train 0.996\n",
            "Stats - Epoch: 74 AUC-val 0.703  AUC-train 0.994\n",
            "Stats - Epoch: 75 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 76 AUC-val 0.676  AUC-train 0.996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.669  AUC-train 0.995\n",
            "Stats - Epoch: 78 AUC-val 0.700  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.661  AUC-train 0.999\n",
            "Stats - Epoch: 80 AUC-val 0.621  AUC-train 0.999\n",
            "Stats - Epoch: 81 AUC-val 0.663  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.647  AUC-train 0.999\n",
            "Stats - Epoch: 83 AUC-val 0.684  AUC-train 0.999\n",
            "Stats - Epoch: 84 AUC-val 0.676  AUC-train 0.999\n",
            "Stats - Epoch: 85 AUC-val 0.691  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 87 AUC-val 0.669  AUC-train 0.996\n",
            "Stats - Epoch: 88 AUC-val 0.672  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.668  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.689  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.642  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.662  AUC-train 0.992\n",
            "Stats - Epoch: 93 AUC-val 0.697  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 95 AUC-val 0.686  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.681  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.692  AUC-train 0.993\n",
            "Stats - Epoch: 98 AUC-val 0.657  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.683  AUC-train 0.992\n",
            "Stats - Epoch: 100 AUC-val 0.687  AUC-train 0.992\n",
            "Results 100 AUC-val 0.723 0.675 0.502 0.410 0.546 AUC-train 0.995\n",
            "Shapley [0.01696328 0.01472231 0.01041366 0.0229645  0.0081611 ] [0.00498179]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196463\n",
            "         Iterations 8\n",
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.535  AUC-train 0.796\n",
            "Results 1 AUC-val 0.535 0.487 0.537 0.435 0.619 AUC-train 0.796\n",
            "Shapley [0.00636812 0.00366348 0.01797677 0.01009084 0.00289773] [0.01485846]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184694\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.374  AUC-train 0.916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.374 0.354 0.323 0.538 0.696 AUC-train 0.916\n",
            "Shapley [0.03177418 0.00681214 0.01127988 0.0344528  0.01801459] [0.00274397]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186882\n",
            "         Iterations 13\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.401  AUC-train 0.537\n",
            "Stats - Epoch: 2 AUC-val 0.435  AUC-train 0.630\n",
            "Stats - Epoch: 3 AUC-val 0.431  AUC-train 0.667\n",
            "Stats - Epoch: 4 AUC-val 0.440  AUC-train 0.714\n",
            "Stats - Epoch: 5 AUC-val 0.431  AUC-train 0.723\n",
            "Stats - Epoch: 6 AUC-val 0.438  AUC-train 0.759\n",
            "Stats - Epoch: 7 AUC-val 0.440  AUC-train 0.775\n",
            "Stats - Epoch: 8 AUC-val 0.436  AUC-train 0.779\n",
            "Stats - Epoch: 9 AUC-val 0.437  AUC-train 0.800\n",
            "Stats - Epoch: 10 AUC-val 0.441  AUC-train 0.819\n",
            "Stats - Epoch: 11 AUC-val 0.441  AUC-train 0.818\n",
            "Stats - Epoch: 12 AUC-val 0.438  AUC-train 0.841\n",
            "Stats - Epoch: 13 AUC-val 0.439  AUC-train 0.840\n",
            "Stats - Epoch: 14 AUC-val 0.433  AUC-train 0.848\n",
            "Stats - Epoch: 15 AUC-val 0.435  AUC-train 0.849\n",
            "Stats - Epoch: 16 AUC-val 0.443  AUC-train 0.859\n",
            "Stats - Epoch: 17 AUC-val 0.456  AUC-train 0.853\n",
            "Stats - Epoch: 18 AUC-val 0.447  AUC-train 0.860\n",
            "Stats - Epoch: 19 AUC-val 0.458  AUC-train 0.867\n",
            "Stats - Epoch: 20 AUC-val 0.463  AUC-train 0.871\n",
            "Stats - Epoch: 21 AUC-val 0.438  AUC-train 0.871\n",
            "Stats - Epoch: 22 AUC-val 0.453  AUC-train 0.872\n",
            "Stats - Epoch: 23 AUC-val 0.465  AUC-train 0.877\n",
            "Stats - Epoch: 24 AUC-val 0.473  AUC-train 0.877\n",
            "Stats - Epoch: 25 AUC-val 0.463  AUC-train 0.876\n",
            "Stats - Epoch: 26 AUC-val 0.473  AUC-train 0.879\n",
            "Stats - Epoch: 27 AUC-val 0.457  AUC-train 0.883\n",
            "Stats - Epoch: 28 AUC-val 0.464  AUC-train 0.877\n",
            "Stats - Epoch: 29 AUC-val 0.465  AUC-train 0.879\n",
            "Stats - Epoch: 30 AUC-val 0.468  AUC-train 0.889\n",
            "Stats - Epoch: 31 AUC-val 0.467  AUC-train 0.889\n",
            "Stats - Epoch: 32 AUC-val 0.468  AUC-train 0.887\n",
            "Stats - Epoch: 33 AUC-val 0.490  AUC-train 0.894\n",
            "Stats - Epoch: 34 AUC-val 0.484  AUC-train 0.884\n",
            "Stats - Epoch: 35 AUC-val 0.474  AUC-train 0.881\n",
            "Stats - Epoch: 36 AUC-val 0.491  AUC-train 0.881\n",
            "Stats - Epoch: 37 AUC-val 0.472  AUC-train 0.893\n",
            "Stats - Epoch: 38 AUC-val 0.487  AUC-train 0.890\n",
            "Stats - Epoch: 39 AUC-val 0.476  AUC-train 0.897\n",
            "Stats - Epoch: 40 AUC-val 0.483  AUC-train 0.897\n",
            "Stats - Epoch: 41 AUC-val 0.488  AUC-train 0.899\n",
            "Stats - Epoch: 42 AUC-val 0.478  AUC-train 0.894\n",
            "Stats - Epoch: 43 AUC-val 0.490  AUC-train 0.889\n",
            "Stats - Epoch: 44 AUC-val 0.488  AUC-train 0.891\n",
            "Stats - Epoch: 45 AUC-val 0.483  AUC-train 0.897\n",
            "Stats - Epoch: 46 AUC-val 0.485  AUC-train 0.897\n",
            "Stats - Epoch: 47 AUC-val 0.486  AUC-train 0.903\n",
            "Stats - Epoch: 48 AUC-val 0.493  AUC-train 0.895\n",
            "Stats - Epoch: 49 AUC-val 0.483  AUC-train 0.899\n",
            "Stats - Epoch: 50 AUC-val 0.480  AUC-train 0.899\n",
            "Stats - Epoch: 51 AUC-val 0.471  AUC-train 0.901\n",
            "Stats - Epoch: 52 AUC-val 0.478  AUC-train 0.883\n",
            "Stats - Epoch: 53 AUC-val 0.495  AUC-train 0.901\n",
            "Stats - Epoch: 54 AUC-val 0.485  AUC-train 0.903\n",
            "Stats - Epoch: 55 AUC-val 0.479  AUC-train 0.902\n",
            "Stats - Epoch: 56 AUC-val 0.476  AUC-train 0.895\n",
            "Stats - Epoch: 57 AUC-val 0.490  AUC-train 0.900\n",
            "Stats - Epoch: 58 AUC-val 0.501  AUC-train 0.902\n",
            "Stats - Epoch: 59 AUC-val 0.479  AUC-train 0.900\n",
            "Stats - Epoch: 60 AUC-val 0.481  AUC-train 0.906\n",
            "Stats - Epoch: 61 AUC-val 0.474  AUC-train 0.911\n",
            "Stats - Epoch: 62 AUC-val 0.490  AUC-train 0.908\n",
            "Stats - Epoch: 63 AUC-val 0.500  AUC-train 0.911\n",
            "Stats - Epoch: 64 AUC-val 0.476  AUC-train 0.902\n",
            "Stats - Epoch: 65 AUC-val 0.478  AUC-train 0.908\n",
            "Stats - Epoch: 66 AUC-val 0.477  AUC-train 0.910\n",
            "Stats - Epoch: 67 AUC-val 0.488  AUC-train 0.908\n",
            "Stats - Epoch: 68 AUC-val 0.480  AUC-train 0.909\n",
            "Stats - Epoch: 69 AUC-val 0.490  AUC-train 0.910\n",
            "Stats - Epoch: 70 AUC-val 0.481  AUC-train 0.911\n",
            "Stats - Epoch: 71 AUC-val 0.491  AUC-train 0.907\n",
            "Stats - Epoch: 72 AUC-val 0.485  AUC-train 0.903\n",
            "Stats - Epoch: 73 AUC-val 0.491  AUC-train 0.904\n",
            "Stats - Epoch: 74 AUC-val 0.491  AUC-train 0.909\n",
            "Stats - Epoch: 75 AUC-val 0.488  AUC-train 0.911\n",
            "Stats - Epoch: 76 AUC-val 0.500  AUC-train 0.905\n",
            "Stats - Epoch: 77 AUC-val 0.487  AUC-train 0.909\n",
            "Stats - Epoch: 78 AUC-val 0.495  AUC-train 0.911\n",
            "Stats - Epoch: 79 AUC-val 0.497  AUC-train 0.911\n",
            "Stats - Epoch: 80 AUC-val 0.484  AUC-train 0.915\n",
            "Stats - Epoch: 81 AUC-val 0.491  AUC-train 0.918\n",
            "Stats - Epoch: 82 AUC-val 0.491  AUC-train 0.916\n",
            "Stats - Epoch: 83 AUC-val 0.487  AUC-train 0.915\n",
            "Stats - Epoch: 84 AUC-val 0.488  AUC-train 0.907\n",
            "Stats - Epoch: 85 AUC-val 0.489  AUC-train 0.911\n",
            "Stats - Epoch: 86 AUC-val 0.494  AUC-train 0.916\n",
            "Stats - Epoch: 87 AUC-val 0.491  AUC-train 0.911\n",
            "Stats - Epoch: 88 AUC-val 0.491  AUC-train 0.915\n",
            "Stats - Epoch: 89 AUC-val 0.492  AUC-train 0.917\n",
            "Stats - Epoch: 90 AUC-val 0.489  AUC-train 0.911\n",
            "Stats - Epoch: 91 AUC-val 0.502  AUC-train 0.919\n",
            "Stats - Epoch: 92 AUC-val 0.489  AUC-train 0.909\n",
            "Stats - Epoch: 93 AUC-val 0.495  AUC-train 0.913\n",
            "Stats - Epoch: 94 AUC-val 0.484  AUC-train 0.917\n",
            "Stats - Epoch: 95 AUC-val 0.495  AUC-train 0.912\n",
            "Stats - Epoch: 96 AUC-val 0.481  AUC-train 0.919\n",
            "Stats - Epoch: 97 AUC-val 0.496  AUC-train 0.919\n",
            "Stats - Epoch: 98 AUC-val 0.478  AUC-train 0.918\n",
            "Stats - Epoch: 99 AUC-val 0.488  AUC-train 0.914\n",
            "Stats - Epoch: 100 AUC-val 0.493  AUC-train 0.916\n",
            "Results 100 AUC-val 0.502 0.537 0.578 0.499 0.628 AUC-train 0.919\n",
            "Shapley [0.01036026 0.00775296 0.02090398 0.0162182  0.00503436] [0.02175454]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.186807\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.351  AUC-train 0.689\n",
            "Stats - Epoch: 2 AUC-val 0.367  AUC-train 0.856\n",
            "Stats - Epoch: 3 AUC-val 0.431  AUC-train 0.921\n",
            "Stats - Epoch: 4 AUC-val 0.370  AUC-train 0.952\n",
            "Stats - Epoch: 5 AUC-val 0.388  AUC-train 0.969\n",
            "Stats - Epoch: 6 AUC-val 0.361  AUC-train 0.973\n",
            "Stats - Epoch: 7 AUC-val 0.360  AUC-train 0.981\n",
            "Stats - Epoch: 8 AUC-val 0.369  AUC-train 0.982\n",
            "Stats - Epoch: 9 AUC-val 0.393  AUC-train 0.982\n",
            "Stats - Epoch: 10 AUC-val 0.395  AUC-train 0.987\n",
            "Stats - Epoch: 11 AUC-val 0.374  AUC-train 0.985\n",
            "Stats - Epoch: 12 AUC-val 0.387  AUC-train 0.991\n",
            "Stats - Epoch: 13 AUC-val 0.363  AUC-train 0.990\n",
            "Stats - Epoch: 14 AUC-val 0.400  AUC-train 0.988\n",
            "Stats - Epoch: 15 AUC-val 0.411  AUC-train 0.992\n",
            "Stats - Epoch: 16 AUC-val 0.418  AUC-train 0.991\n",
            "Stats - Epoch: 17 AUC-val 0.397  AUC-train 0.988\n",
            "Stats - Epoch: 18 AUC-val 0.424  AUC-train 0.987\n",
            "Stats - Epoch: 19 AUC-val 0.412  AUC-train 0.992\n",
            "Stats - Epoch: 20 AUC-val 0.424  AUC-train 0.983\n",
            "Stats - Epoch: 21 AUC-val 0.434  AUC-train 0.987\n",
            "Stats - Epoch: 22 AUC-val 0.424  AUC-train 0.985\n",
            "Stats - Epoch: 23 AUC-val 0.430  AUC-train 0.988\n",
            "Stats - Epoch: 24 AUC-val 0.443  AUC-train 0.986\n",
            "Stats - Epoch: 25 AUC-val 0.434  AUC-train 0.985\n",
            "Stats - Epoch: 26 AUC-val 0.436  AUC-train 0.989\n",
            "Stats - Epoch: 27 AUC-val 0.444  AUC-train 0.987\n",
            "Stats - Epoch: 28 AUC-val 0.416  AUC-train 0.982\n",
            "Stats - Epoch: 29 AUC-val 0.424  AUC-train 0.984\n",
            "Stats - Epoch: 30 AUC-val 0.434  AUC-train 0.983\n",
            "Stats - Epoch: 31 AUC-val 0.421  AUC-train 0.990\n",
            "Stats - Epoch: 32 AUC-val 0.433  AUC-train 0.990\n",
            "Stats - Epoch: 33 AUC-val 0.410  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.427  AUC-train 0.982\n",
            "Stats - Epoch: 35 AUC-val 0.436  AUC-train 0.984\n",
            "Stats - Epoch: 36 AUC-val 0.442  AUC-train 0.986\n",
            "Stats - Epoch: 37 AUC-val 0.417  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.450  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.438  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.442  AUC-train 0.987\n",
            "Stats - Epoch: 41 AUC-val 0.430  AUC-train 0.986\n",
            "Stats - Epoch: 42 AUC-val 0.451  AUC-train 0.982\n",
            "Stats - Epoch: 43 AUC-val 0.460  AUC-train 0.983\n",
            "Stats - Epoch: 44 AUC-val 0.448  AUC-train 0.984\n",
            "Stats - Epoch: 45 AUC-val 0.445  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.445  AUC-train 0.986\n",
            "Stats - Epoch: 47 AUC-val 0.452  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.450  AUC-train 0.983\n",
            "Stats - Epoch: 49 AUC-val 0.441  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.445  AUC-train 0.981\n",
            "Stats - Epoch: 51 AUC-val 0.465  AUC-train 0.983\n",
            "Stats - Epoch: 52 AUC-val 0.433  AUC-train 0.985\n",
            "Stats - Epoch: 53 AUC-val 0.445  AUC-train 0.987\n",
            "Stats - Epoch: 54 AUC-val 0.434  AUC-train 0.985\n",
            "Stats - Epoch: 55 AUC-val 0.457  AUC-train 0.982\n",
            "Stats - Epoch: 56 AUC-val 0.431  AUC-train 0.986\n",
            "Stats - Epoch: 57 AUC-val 0.446  AUC-train 0.984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 58 AUC-val 0.458  AUC-train 0.985\n",
            "Stats - Epoch: 59 AUC-val 0.452  AUC-train 0.983\n",
            "Stats - Epoch: 60 AUC-val 0.428  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.461  AUC-train 0.983\n",
            "Stats - Epoch: 62 AUC-val 0.423  AUC-train 0.986\n",
            "Stats - Epoch: 63 AUC-val 0.438  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.461  AUC-train 0.975\n",
            "Stats - Epoch: 65 AUC-val 0.458  AUC-train 0.980\n",
            "Stats - Epoch: 66 AUC-val 0.428  AUC-train 0.984\n",
            "Stats - Epoch: 67 AUC-val 0.432  AUC-train 0.983\n",
            "Stats - Epoch: 68 AUC-val 0.428  AUC-train 0.982\n",
            "Stats - Epoch: 69 AUC-val 0.432  AUC-train 0.987\n",
            "Stats - Epoch: 70 AUC-val 0.431  AUC-train 0.984\n",
            "Stats - Epoch: 71 AUC-val 0.441  AUC-train 0.981\n",
            "Stats - Epoch: 72 AUC-val 0.432  AUC-train 0.981\n",
            "Stats - Epoch: 73 AUC-val 0.447  AUC-train 0.979\n",
            "Stats - Epoch: 74 AUC-val 0.446  AUC-train 0.981\n",
            "Stats - Epoch: 75 AUC-val 0.463  AUC-train 0.980\n",
            "Stats - Epoch: 76 AUC-val 0.458  AUC-train 0.980\n",
            "Stats - Epoch: 77 AUC-val 0.469  AUC-train 0.982\n",
            "Stats - Epoch: 78 AUC-val 0.462  AUC-train 0.974\n",
            "Stats - Epoch: 79 AUC-val 0.434  AUC-train 0.982\n",
            "Stats - Epoch: 80 AUC-val 0.444  AUC-train 0.980\n",
            "Stats - Epoch: 81 AUC-val 0.443  AUC-train 0.980\n",
            "Stats - Epoch: 82 AUC-val 0.452  AUC-train 0.983\n",
            "Stats - Epoch: 83 AUC-val 0.447  AUC-train 0.981\n",
            "Stats - Epoch: 84 AUC-val 0.452  AUC-train 0.982\n",
            "Stats - Epoch: 85 AUC-val 0.443  AUC-train 0.981\n",
            "Stats - Epoch: 86 AUC-val 0.445  AUC-train 0.980\n",
            "Stats - Epoch: 87 AUC-val 0.441  AUC-train 0.981\n",
            "Stats - Epoch: 88 AUC-val 0.449  AUC-train 0.981\n",
            "Stats - Epoch: 89 AUC-val 0.437  AUC-train 0.973\n",
            "Stats - Epoch: 90 AUC-val 0.431  AUC-train 0.979\n",
            "Stats - Epoch: 91 AUC-val 0.459  AUC-train 0.981\n",
            "Stats - Epoch: 92 AUC-val 0.420  AUC-train 0.979\n",
            "Stats - Epoch: 93 AUC-val 0.435  AUC-train 0.985\n",
            "Stats - Epoch: 94 AUC-val 0.471  AUC-train 0.980\n",
            "Stats - Epoch: 95 AUC-val 0.439  AUC-train 0.981\n",
            "Stats - Epoch: 96 AUC-val 0.424  AUC-train 0.978\n",
            "Stats - Epoch: 97 AUC-val 0.440  AUC-train 0.979\n",
            "Stats - Epoch: 98 AUC-val 0.414  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.411  AUC-train 0.981\n",
            "Stats - Epoch: 100 AUC-val 0.434  AUC-train 0.982\n",
            "Results 100 AUC-val 0.471 0.465 0.392 0.204 0.583 AUC-train 0.980\n",
            "Shapley [0.0275181  0.00846948 0.00994291 0.04194652 0.00677952] [0.0388835]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.179702\n",
            "         Iterations 10\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.201  AUC-train 0.601\n",
            "Stats - Epoch: 2 AUC-val 0.238  AUC-train 0.709\n",
            "Stats - Epoch: 3 AUC-val 0.318  AUC-train 0.784\n",
            "Stats - Epoch: 4 AUC-val 0.389  AUC-train 0.826\n",
            "Stats - Epoch: 5 AUC-val 0.404  AUC-train 0.851\n",
            "Stats - Epoch: 6 AUC-val 0.509  AUC-train 0.867\n",
            "Stats - Epoch: 7 AUC-val 0.491  AUC-train 0.879\n",
            "Stats - Epoch: 8 AUC-val 0.517  AUC-train 0.882\n",
            "Stats - Epoch: 9 AUC-val 0.514  AUC-train 0.888\n",
            "Stats - Epoch: 10 AUC-val 0.503  AUC-train 0.900\n",
            "Stats - Epoch: 11 AUC-val 0.514  AUC-train 0.905\n",
            "Stats - Epoch: 12 AUC-val 0.518  AUC-train 0.913\n",
            "Stats - Epoch: 13 AUC-val 0.529  AUC-train 0.916\n",
            "Stats - Epoch: 14 AUC-val 0.557  AUC-train 0.923\n",
            "Stats - Epoch: 15 AUC-val 0.571  AUC-train 0.926\n",
            "Stats - Epoch: 16 AUC-val 0.553  AUC-train 0.931\n",
            "Stats - Epoch: 17 AUC-val 0.595  AUC-train 0.931\n",
            "Stats - Epoch: 18 AUC-val 0.497  AUC-train 0.938\n",
            "Stats - Epoch: 19 AUC-val 0.562  AUC-train 0.941\n",
            "Stats - Epoch: 20 AUC-val 0.531  AUC-train 0.946\n",
            "Stats - Epoch: 21 AUC-val 0.564  AUC-train 0.946\n",
            "Stats - Epoch: 22 AUC-val 0.548  AUC-train 0.951\n",
            "Stats - Epoch: 23 AUC-val 0.529  AUC-train 0.952\n",
            "Stats - Epoch: 24 AUC-val 0.543  AUC-train 0.954\n",
            "Stats - Epoch: 25 AUC-val 0.517  AUC-train 0.959\n",
            "Stats - Epoch: 26 AUC-val 0.607  AUC-train 0.958\n",
            "Stats - Epoch: 27 AUC-val 0.541  AUC-train 0.959\n",
            "Stats - Epoch: 28 AUC-val 0.557  AUC-train 0.963\n",
            "Stats - Epoch: 29 AUC-val 0.566  AUC-train 0.968\n",
            "Stats - Epoch: 30 AUC-val 0.555  AUC-train 0.973\n",
            "Stats - Epoch: 31 AUC-val 0.562  AUC-train 0.972\n",
            "Stats - Epoch: 32 AUC-val 0.555  AUC-train 0.969\n",
            "Stats - Epoch: 33 AUC-val 0.518  AUC-train 0.970\n",
            "Stats - Epoch: 34 AUC-val 0.571  AUC-train 0.966\n",
            "Stats - Epoch: 35 AUC-val 0.510  AUC-train 0.968\n",
            "Stats - Epoch: 36 AUC-val 0.544  AUC-train 0.974\n",
            "Stats - Epoch: 37 AUC-val 0.511  AUC-train 0.972\n",
            "Stats - Epoch: 38 AUC-val 0.552  AUC-train 0.974\n",
            "Stats - Epoch: 39 AUC-val 0.521  AUC-train 0.981\n",
            "Stats - Epoch: 40 AUC-val 0.531  AUC-train 0.981\n",
            "Stats - Epoch: 41 AUC-val 0.593  AUC-train 0.976\n",
            "Stats - Epoch: 42 AUC-val 0.541  AUC-train 0.979\n",
            "Stats - Epoch: 43 AUC-val 0.558  AUC-train 0.982\n",
            "Stats - Epoch: 44 AUC-val 0.619  AUC-train 0.982\n",
            "Stats - Epoch: 45 AUC-val 0.538  AUC-train 0.984\n",
            "Stats - Epoch: 46 AUC-val 0.566  AUC-train 0.981\n",
            "Stats - Epoch: 47 AUC-val 0.597  AUC-train 0.985\n",
            "Stats - Epoch: 48 AUC-val 0.569  AUC-train 0.986\n",
            "Stats - Epoch: 49 AUC-val 0.545  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.553  AUC-train 0.983\n",
            "Stats - Epoch: 51 AUC-val 0.578  AUC-train 0.986\n",
            "Stats - Epoch: 52 AUC-val 0.614  AUC-train 0.987\n",
            "Stats - Epoch: 53 AUC-val 0.602  AUC-train 0.987\n",
            "Stats - Epoch: 54 AUC-val 0.586  AUC-train 0.987\n",
            "Stats - Epoch: 55 AUC-val 0.606  AUC-train 0.988\n",
            "Stats - Epoch: 56 AUC-val 0.603  AUC-train 0.985\n",
            "Stats - Epoch: 57 AUC-val 0.544  AUC-train 0.987\n",
            "Stats - Epoch: 58 AUC-val 0.575  AUC-train 0.990\n",
            "Stats - Epoch: 59 AUC-val 0.557  AUC-train 0.989\n",
            "Stats - Epoch: 60 AUC-val 0.541  AUC-train 0.992\n",
            "Stats - Epoch: 61 AUC-val 0.548  AUC-train 0.993\n",
            "Stats - Epoch: 62 AUC-val 0.587  AUC-train 0.991\n",
            "Stats - Epoch: 63 AUC-val 0.584  AUC-train 0.991\n",
            "Stats - Epoch: 64 AUC-val 0.614  AUC-train 0.992\n",
            "Stats - Epoch: 65 AUC-val 0.582  AUC-train 0.993\n",
            "Stats - Epoch: 66 AUC-val 0.607  AUC-train 0.993\n",
            "Stats - Epoch: 67 AUC-val 0.610  AUC-train 0.988\n",
            "Stats - Epoch: 68 AUC-val 0.607  AUC-train 0.992\n",
            "Stats - Epoch: 69 AUC-val 0.603  AUC-train 0.992\n",
            "Stats - Epoch: 70 AUC-val 0.609  AUC-train 0.993\n",
            "Stats - Epoch: 71 AUC-val 0.637  AUC-train 0.991\n",
            "Stats - Epoch: 72 AUC-val 0.608  AUC-train 0.991\n",
            "Stats - Epoch: 73 AUC-val 0.591  AUC-train 0.992\n",
            "Stats - Epoch: 74 AUC-val 0.587  AUC-train 0.987\n",
            "Stats - Epoch: 75 AUC-val 0.578  AUC-train 0.987\n",
            "Stats - Epoch: 76 AUC-val 0.576  AUC-train 0.987\n",
            "Stats - Epoch: 77 AUC-val 0.618  AUC-train 0.985\n",
            "Stats - Epoch: 78 AUC-val 0.626  AUC-train 0.990\n",
            "Stats - Epoch: 79 AUC-val 0.551  AUC-train 0.990\n",
            "Stats - Epoch: 80 AUC-val 0.580  AUC-train 0.987\n",
            "Stats - Epoch: 81 AUC-val 0.572  AUC-train 0.983\n",
            "Stats - Epoch: 82 AUC-val 0.574  AUC-train 0.988\n",
            "Stats - Epoch: 83 AUC-val 0.571  AUC-train 0.988\n",
            "Stats - Epoch: 84 AUC-val 0.546  AUC-train 0.985\n",
            "Stats - Epoch: 85 AUC-val 0.526  AUC-train 0.990\n",
            "Stats - Epoch: 86 AUC-val 0.577  AUC-train 0.992\n",
            "Stats - Epoch: 87 AUC-val 0.555  AUC-train 0.992\n",
            "Stats - Epoch: 88 AUC-val 0.512  AUC-train 0.984\n",
            "Stats - Epoch: 89 AUC-val 0.572  AUC-train 0.990\n",
            "Stats - Epoch: 90 AUC-val 0.523  AUC-train 0.992\n",
            "Stats - Epoch: 91 AUC-val 0.532  AUC-train 0.992\n",
            "Stats - Epoch: 92 AUC-val 0.521  AUC-train 0.991\n",
            "Stats - Epoch: 93 AUC-val 0.670  AUC-train 0.983\n",
            "Stats - Epoch: 94 AUC-val 0.566  AUC-train 0.986\n",
            "Stats - Epoch: 95 AUC-val 0.621  AUC-train 0.989\n",
            "Stats - Epoch: 96 AUC-val 0.664  AUC-train 0.989\n",
            "Stats - Epoch: 97 AUC-val 0.593  AUC-train 0.987\n",
            "Stats - Epoch: 98 AUC-val 0.639  AUC-train 0.990\n",
            "Stats - Epoch: 99 AUC-val 0.628  AUC-train 0.991\n",
            "Stats - Epoch: 100 AUC-val 0.617  AUC-train 0.985\n",
            "Results 100 AUC-val 0.670 0.534 0.502 0.433 0.597 AUC-train 0.983\n",
            "Shapley [0.01435658 0.01131744 0.01146969 0.01524479 0.00878637] [0.00133342]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196002\n",
            "         Iterations 8\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.430  AUC-train 0.666\n",
            "Stats - Epoch: 2 AUC-val 0.588  AUC-train 0.813\n",
            "Stats - Epoch: 3 AUC-val 0.630  AUC-train 0.861\n",
            "Stats - Epoch: 4 AUC-val 0.651  AUC-train 0.897\n",
            "Stats - Epoch: 5 AUC-val 0.676  AUC-train 0.926\n",
            "Stats - Epoch: 6 AUC-val 0.676  AUC-train 0.945\n",
            "Stats - Epoch: 7 AUC-val 0.690  AUC-train 0.957\n",
            "Stats - Epoch: 8 AUC-val 0.673  AUC-train 0.968\n",
            "Stats - Epoch: 9 AUC-val 0.668  AUC-train 0.978\n",
            "Stats - Epoch: 10 AUC-val 0.681  AUC-train 0.983\n",
            "Stats - Epoch: 11 AUC-val 0.688  AUC-train 0.989\n",
            "Stats - Epoch: 12 AUC-val 0.671  AUC-train 0.992\n",
            "Stats - Epoch: 13 AUC-val 0.667  AUC-train 0.994\n",
            "Stats - Epoch: 14 AUC-val 0.669  AUC-train 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 15 AUC-val 0.670  AUC-train 0.998\n",
            "Stats - Epoch: 16 AUC-val 0.659  AUC-train 0.997\n",
            "Stats - Epoch: 17 AUC-val 0.670  AUC-train 0.999\n",
            "Stats - Epoch: 18 AUC-val 0.674  AUC-train 0.998\n",
            "Stats - Epoch: 19 AUC-val 0.635  AUC-train 0.998\n",
            "Stats - Epoch: 20 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 21 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 23 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.666  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.651  AUC-train 1.000\n",
            "Stats - Epoch: 26 AUC-val 0.653  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.631  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.669  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.679  AUC-train 0.999\n",
            "Stats - Epoch: 30 AUC-val 0.653  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 32 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 33 AUC-val 0.668  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.667  AUC-train 0.998\n",
            "Stats - Epoch: 35 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 36 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.649  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.648  AUC-train 0.999\n",
            "Stats - Epoch: 40 AUC-val 0.644  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.657  AUC-train 1.000\n",
            "Stats - Epoch: 42 AUC-val 0.653  AUC-train 0.998\n",
            "Stats - Epoch: 43 AUC-val 0.656  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 45 AUC-val 0.653  AUC-train 0.999\n",
            "Stats - Epoch: 46 AUC-val 0.665  AUC-train 1.000\n",
            "Stats - Epoch: 47 AUC-val 0.670  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 49 AUC-val 0.666  AUC-train 0.998\n",
            "Stats - Epoch: 50 AUC-val 0.679  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.631  AUC-train 0.998\n",
            "Stats - Epoch: 52 AUC-val 0.644  AUC-train 0.997\n",
            "Stats - Epoch: 53 AUC-val 0.691  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.665  AUC-train 0.999\n",
            "Stats - Epoch: 55 AUC-val 0.666  AUC-train 0.999\n",
            "Stats - Epoch: 56 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 57 AUC-val 0.654  AUC-train 0.998\n",
            "Stats - Epoch: 58 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 59 AUC-val 0.621  AUC-train 0.999\n",
            "Stats - Epoch: 60 AUC-val 0.671  AUC-train 0.997\n",
            "Stats - Epoch: 61 AUC-val 0.638  AUC-train 0.999\n",
            "Stats - Epoch: 62 AUC-val 0.688  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.650  AUC-train 1.000\n",
            "Stats - Epoch: 64 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 65 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 66 AUC-val 0.672  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.616  AUC-train 0.998\n",
            "Stats - Epoch: 68 AUC-val 0.651  AUC-train 0.998\n",
            "Stats - Epoch: 69 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 70 AUC-val 0.678  AUC-train 0.994\n",
            "Stats - Epoch: 71 AUC-val 0.671  AUC-train 0.995\n",
            "Stats - Epoch: 72 AUC-val 0.643  AUC-train 0.990\n",
            "Stats - Epoch: 73 AUC-val 0.676  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.661  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.636  AUC-train 0.998\n",
            "Stats - Epoch: 76 AUC-val 0.649  AUC-train 0.997\n",
            "Stats - Epoch: 77 AUC-val 0.655  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.664  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.647  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.637  AUC-train 1.000\n",
            "Stats - Epoch: 81 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 82 AUC-val 0.648  AUC-train 0.999\n",
            "Stats - Epoch: 83 AUC-val 0.660  AUC-train 1.000\n",
            "Stats - Epoch: 84 AUC-val 0.662  AUC-train 1.000\n",
            "Stats - Epoch: 85 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.651  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 88 AUC-val 0.650  AUC-train 0.999\n",
            "Stats - Epoch: 89 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.662  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 92 AUC-val 0.659  AUC-train 0.999\n",
            "Stats - Epoch: 93 AUC-val 0.663  AUC-train 1.000\n",
            "Stats - Epoch: 94 AUC-val 0.654  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.675  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.640  AUC-train 0.994\n",
            "Stats - Epoch: 97 AUC-val 0.658  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.632  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.615  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.641  AUC-train 0.998\n",
            "Results 100 AUC-val 0.691 0.568 0.455 0.471 0.639 AUC-train 0.999\n",
            "Shapley [0.01613002 0.01950358 0.01074458 0.03939435 0.0236921 ] [0.00710623]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.184232\n",
            "         Iterations 9\n",
            "Crises train:12\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.575  AUC-train 0.615\n",
            "Stats - Epoch: 2 AUC-val 0.585  AUC-train 0.789\n",
            "Stats - Epoch: 3 AUC-val 0.595  AUC-train 0.850\n",
            "Stats - Epoch: 4 AUC-val 0.585  AUC-train 0.882\n",
            "Stats - Epoch: 5 AUC-val 0.575  AUC-train 0.912\n",
            "Stats - Epoch: 6 AUC-val 0.576  AUC-train 0.936\n",
            "Stats - Epoch: 7 AUC-val 0.533  AUC-train 0.952\n",
            "Stats - Epoch: 8 AUC-val 0.531  AUC-train 0.966\n",
            "Stats - Epoch: 9 AUC-val 0.558  AUC-train 0.975\n",
            "Stats - Epoch: 10 AUC-val 0.539  AUC-train 0.984\n",
            "Stats - Epoch: 11 AUC-val 0.550  AUC-train 0.989\n",
            "Stats - Epoch: 12 AUC-val 0.584  AUC-train 0.992\n",
            "Stats - Epoch: 13 AUC-val 0.568  AUC-train 0.996\n",
            "Stats - Epoch: 14 AUC-val 0.570  AUC-train 0.996\n",
            "Stats - Epoch: 15 AUC-val 0.614  AUC-train 0.996\n",
            "Stats - Epoch: 16 AUC-val 0.626  AUC-train 0.998\n",
            "Stats - Epoch: 17 AUC-val 0.621  AUC-train 0.999\n",
            "Stats - Epoch: 18 AUC-val 0.642  AUC-train 0.999\n",
            "Stats - Epoch: 19 AUC-val 0.640  AUC-train 1.000\n",
            "Stats - Epoch: 20 AUC-val 0.617  AUC-train 1.000\n",
            "Stats - Epoch: 21 AUC-val 0.674  AUC-train 0.999\n",
            "Stats - Epoch: 22 AUC-val 0.658  AUC-train 0.998\n",
            "Stats - Epoch: 23 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 24 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 25 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 26 AUC-val 0.706  AUC-train 1.000\n",
            "Stats - Epoch: 27 AUC-val 0.672  AUC-train 1.000\n",
            "Stats - Epoch: 28 AUC-val 0.665  AUC-train 1.000\n",
            "Stats - Epoch: 29 AUC-val 0.648  AUC-train 0.998\n",
            "Stats - Epoch: 30 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 31 AUC-val 0.676  AUC-train 0.996\n",
            "Stats - Epoch: 32 AUC-val 0.704  AUC-train 0.997\n",
            "Stats - Epoch: 33 AUC-val 0.687  AUC-train 0.998\n",
            "Stats - Epoch: 34 AUC-val 0.664  AUC-train 0.999\n",
            "Stats - Epoch: 35 AUC-val 0.642  AUC-train 0.996\n",
            "Stats - Epoch: 36 AUC-val 0.657  AUC-train 0.999\n",
            "Stats - Epoch: 37 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 38 AUC-val 0.680  AUC-train 0.998\n",
            "Stats - Epoch: 39 AUC-val 0.683  AUC-train 1.000\n",
            "Stats - Epoch: 40 AUC-val 0.718  AUC-train 0.999\n",
            "Stats - Epoch: 41 AUC-val 0.700  AUC-train 0.998\n",
            "Stats - Epoch: 42 AUC-val 0.687  AUC-train 0.999\n",
            "Stats - Epoch: 43 AUC-val 0.645  AUC-train 0.999\n",
            "Stats - Epoch: 44 AUC-val 0.671  AUC-train 1.000\n",
            "Stats - Epoch: 45 AUC-val 0.655  AUC-train 0.997\n",
            "Stats - Epoch: 46 AUC-val 0.639  AUC-train 0.999\n",
            "Stats - Epoch: 47 AUC-val 0.632  AUC-train 0.999\n",
            "Stats - Epoch: 48 AUC-val 0.664  AUC-train 1.000\n",
            "Stats - Epoch: 49 AUC-val 0.673  AUC-train 1.000\n",
            "Stats - Epoch: 50 AUC-val 0.675  AUC-train 0.999\n",
            "Stats - Epoch: 51 AUC-val 0.693  AUC-train 0.999\n",
            "Stats - Epoch: 52 AUC-val 0.662  AUC-train 0.998\n",
            "Stats - Epoch: 53 AUC-val 0.685  AUC-train 0.999\n",
            "Stats - Epoch: 54 AUC-val 0.676  AUC-train 0.998\n",
            "Stats - Epoch: 55 AUC-val 0.677  AUC-train 0.997\n",
            "Stats - Epoch: 56 AUC-val 0.664  AUC-train 0.997\n",
            "Stats - Epoch: 57 AUC-val 0.660  AUC-train 0.999\n",
            "Stats - Epoch: 58 AUC-val 0.666  AUC-train 1.000\n",
            "Stats - Epoch: 59 AUC-val 0.693  AUC-train 0.997\n",
            "Stats - Epoch: 60 AUC-val 0.654  AUC-train 0.998\n",
            "Stats - Epoch: 61 AUC-val 0.672  AUC-train 0.997\n",
            "Stats - Epoch: 62 AUC-val 0.648  AUC-train 0.998\n",
            "Stats - Epoch: 63 AUC-val 0.649  AUC-train 0.998\n",
            "Stats - Epoch: 64 AUC-val 0.617  AUC-train 0.997\n",
            "Stats - Epoch: 65 AUC-val 0.644  AUC-train 0.998\n",
            "Stats - Epoch: 66 AUC-val 0.680  AUC-train 0.999\n",
            "Stats - Epoch: 67 AUC-val 0.662  AUC-train 0.996\n",
            "Stats - Epoch: 68 AUC-val 0.604  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.662  AUC-train 0.993\n",
            "Stats - Epoch: 70 AUC-val 0.633  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.639  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.625  AUC-train 0.998\n",
            "Stats - Epoch: 73 AUC-val 0.686  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.649  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.660  AUC-train 0.995\n",
            "Stats - Epoch: 76 AUC-val 0.651  AUC-train 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 77 AUC-val 0.652  AUC-train 0.999\n",
            "Stats - Epoch: 78 AUC-val 0.654  AUC-train 0.999\n",
            "Stats - Epoch: 79 AUC-val 0.653  AUC-train 0.998\n",
            "Stats - Epoch: 80 AUC-val 0.652  AUC-train 0.998\n",
            "Stats - Epoch: 81 AUC-val 0.661  AUC-train 0.996\n",
            "Stats - Epoch: 82 AUC-val 0.670  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.706  AUC-train 0.993\n",
            "Stats - Epoch: 84 AUC-val 0.662  AUC-train 0.994\n",
            "Stats - Epoch: 85 AUC-val 0.659  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.656  AUC-train 0.997\n",
            "Stats - Epoch: 87 AUC-val 0.646  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.632  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.659  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.662  AUC-train 0.995\n",
            "Stats - Epoch: 91 AUC-val 0.638  AUC-train 0.994\n",
            "Stats - Epoch: 92 AUC-val 0.648  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.645  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.647  AUC-train 0.995\n",
            "Stats - Epoch: 95 AUC-val 0.681  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.669  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.611  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.670  AUC-train 0.994\n",
            "Stats - Epoch: 99 AUC-val 0.635  AUC-train 0.995\n",
            "Stats - Epoch: 100 AUC-val 0.649  AUC-train 0.997\n",
            "Results 100 AUC-val 0.718 0.727 0.559 0.470 0.559 AUC-train 0.999\n",
            "Shapley [0.01457268 0.01371211 0.01000319 0.01939641 0.00711563] [0.00140092]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.194612\n",
            "         Iterations 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC1DgA4utap0"
      },
      "source": [
        "    # Simulation params\n",
        "    filename = 'C:/Users/eerot/Desktop/NNCALC/seq_logit2_doshap_' + str(train_start_year) + '_' +  str(train_end_year) + \"_\" + str(epochs) + '.csv';    \n",
        "    f=open(filename, \"w\")\n",
        "    epochs = 20;\n",
        "    for dates in [[1970,1999,2000,2016],[1950,1999,2000,2016],[1950,1989,1990,2016],[1870,1914,1920,1939]]: #[1970,2016]\n",
        "        train_end_year=dates[1];\n",
        "        train_start_year=dates[0];\n",
        "        test_start_year=dates[2]; # Define test set\n",
        "        test_end_year=dates[3];\n",
        "        \n",
        "    \n",
        "        all_predictors = ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g','cpi_g','debtgdp_g','rtloans_g','rtmort_g','rthh_g','rtbus_g','ltrate','stir'];    \n",
        "        df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "\n",
        "        t = time.time();\n",
        "              \n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=1,nlags=1,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "        f.write(sequential_evaluation(test_start_year=test_start_year,test_end_year=test_end_year,train_start_year=train_start_year,train_end_year=train_end_year,mm=1,nlags=5,df=df3,fcast_horizon=1,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=False));\n",
        "        f.write(\"\\n\");f.flush();elapsed = time.time() - t;print(elapsed);\n",
        "\n",
        "    \n",
        "    f.close()\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epa6w_A_tap0"
      },
      "source": [
        "# Few variables sequential for generic model mm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC3121LMtap0",
        "outputId": "087a1423-db14-4495-d079-7afd2fbabbf2"
      },
      "source": [
        "# LSTM with 1-variable and 2-variable\n",
        "mm=4;\n",
        "reps=50;\n",
        "# Cross-validation:\n",
        "filename = 'C:/Users/eerot/Desktop/NNCALC/fewvar_seq_lstm_fc3_rep50.csv';    \n",
        "f=open(filename, \"w\")\n",
        "predictors=['tloansgdp_g','rsp_g','rhp_g','ca/gdp','rgdp_g'];\n",
        "for fcast_horizon in [3]:\n",
        "  train_start_year=1970;\n",
        "  train_end_year=1999;\n",
        "  test_start_year=2000;\n",
        "  test_end_year=2016;\n",
        "  epochs = 100;\n",
        "  reg_weight=[0.0]\n",
        "  df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "  \n",
        "  for pp in range(0,5):\n",
        "    bs=[0,0,0,0,0,0,0,0];\n",
        "    bs[3+pp]=1;\n",
        "    S = np.packbits(bs, axis=0)[0];\n",
        "    all_predictors = [predictors[pp]];\n",
        "    print(all_predictors);\n",
        "    f.write(predictors[pp] + \";\" + sequential_evaluation(reps=reps,d2cgraph=True,Nf=1,mm=mm,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,train_start_year=train_start_year,train_end_year=train_end_year,test_start_year=test_start_year,test_end_year=test_end_year,do_shapley=True,code=S));\n",
        "    f.write(\"\\n\");f.flush();\n",
        "  \n",
        "  \n",
        "  for pp in range(0,5):\n",
        "    for pp2 in range(0,5):\n",
        "      if(pp2>pp):\n",
        "        bs=[0,0,0,0,0,0,0,0];\n",
        "        bs[3+pp]=1;\n",
        "        bs[3+pp2]=1;\n",
        "        S = np.packbits(bs, axis=0)[0];\n",
        "        all_predictors = [predictors[pp],predictors[pp2]];\n",
        "        print(all_predictors);\n",
        "        f.write(predictors[pp] + \";\" + predictors[pp2] + \";\" + sequential_evaluation(reps=reps,d2cgraph=True,Nf=2,mm=mm,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,train_start_year=train_start_year,train_end_year=train_end_year,test_start_year=test_start_year,test_end_year=test_end_year,do_shapley=True,code=S));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "   \n",
        "  for pp in range(0,5):\n",
        "    for pp2 in range(0,5):\n",
        "        for pp3 in range(0,5):\n",
        "          if(pp2>pp and pp3>pp2):\n",
        "            bs=[0,0,0,0,0,0,0,0];\n",
        "            bs[3+pp]=1;\n",
        "            bs[3+pp2]=1;\n",
        "            bs[3+pp3]=1;\n",
        "            S = np.packbits(bs, axis=0)[0];\n",
        "            all_predictors = [predictors[pp],predictors[pp2],predictors[pp3]];\n",
        "            print(all_predictors);\n",
        "            f.write(predictors[pp] + \";\" + predictors[pp2] + \";\" + predictors[pp3] + \";\" + sequential_evaluation(reps=reps,d2cgraph=True,Nf=3,mm=mm,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,train_start_year=train_start_year,train_end_year=train_end_year,test_start_year=test_start_year,test_end_year=test_end_year,do_shapley=True,code=S));\n",
        "            f.write(\"\\n\");f.flush();\n",
        "\n",
        "  for pp in range(0,5):\n",
        "    for pp2 in range(0,5):\n",
        "        for pp3 in range(0,5):\n",
        "            for pp4 in range(0,5):\n",
        "              if(pp2>pp and pp3>pp2 and pp4>pp3):\n",
        "                bs=[0,0,0,0,0,0,0,0];\n",
        "                bs[3+pp]=1;\n",
        "                bs[3+pp2]=1;\n",
        "                bs[3+pp3]=1;\n",
        "                bs[3+pp4]=1;\n",
        "                S = np.packbits(bs, axis=0)[0];\n",
        "                all_predictors = [predictors[pp],predictors[pp2],predictors[pp3],predictors[pp4]];\n",
        "                print(all_predictors);\n",
        "                f.write(predictors[pp] + \";\" + predictors[pp2] + \";\" + predictors[pp3] + \";\" + predictors[pp4] + \";\" + sequential_evaluation(reps=reps,d2cgraph=True,Nf=4,mm=mm,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,train_start_year=train_start_year,train_end_year=train_end_year,test_start_year=test_start_year,test_end_year=test_end_year,do_shapley=True,code=S));\n",
        "                f.write(\"\\n\");f.flush();\n",
        "  all_predictors=['tloansgdp_g','rsp_g','rhp_g','ca/gdp','rgdp_g']\n",
        "  f.write(\"all;\" + sequential_evaluation(reps=reps,d2cgraph=True,Nf=5,mm=mm,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,train_start_year=train_start_year,train_end_year=train_end_year,test_start_year=test_start_year,test_end_year=test_end_year,do_shapley=True,code=31));\n",
        "  f.write(\"\\n\");f.flush();\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "['tloansgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.507  AUC-train 0.602\n",
            "Stats - Epoch: 2 AUC-val 0.546  AUC-train 0.694\n",
            "Stats - Epoch: 3 AUC-val 0.576  AUC-train 0.716\n",
            "Stats - Epoch: 4 AUC-val 0.572  AUC-train 0.726\n",
            "Stats - Epoch: 5 AUC-val 0.567  AUC-train 0.732\n",
            "Stats - Epoch: 6 AUC-val 0.562  AUC-train 0.737\n",
            "Stats - Epoch: 7 AUC-val 0.553  AUC-train 0.741\n",
            "Stats - Epoch: 8 AUC-val 0.546  AUC-train 0.742\n",
            "Stats - Epoch: 9 AUC-val 0.543  AUC-train 0.744\n",
            "Stats - Epoch: 10 AUC-val 0.543  AUC-train 0.746\n",
            "Stats - Epoch: 11 AUC-val 0.540  AUC-train 0.747\n",
            "Stats - Epoch: 12 AUC-val 0.534  AUC-train 0.748\n",
            "Stats - Epoch: 13 AUC-val 0.535  AUC-train 0.748\n",
            "Stats - Epoch: 14 AUC-val 0.529  AUC-train 0.752\n",
            "Stats - Epoch: 15 AUC-val 0.527  AUC-train 0.751\n",
            "Stats - Epoch: 16 AUC-val 0.522  AUC-train 0.752\n",
            "Stats - Epoch: 17 AUC-val 0.521  AUC-train 0.754\n",
            "Stats - Epoch: 18 AUC-val 0.518  AUC-train 0.754\n",
            "Stats - Epoch: 19 AUC-val 0.511  AUC-train 0.754\n",
            "Stats - Epoch: 20 AUC-val 0.514  AUC-train 0.756\n",
            "Stats - Epoch: 21 AUC-val 0.515  AUC-train 0.758\n",
            "Stats - Epoch: 22 AUC-val 0.514  AUC-train 0.759\n",
            "Stats - Epoch: 23 AUC-val 0.514  AUC-train 0.760\n",
            "Stats - Epoch: 24 AUC-val 0.507  AUC-train 0.758\n",
            "Stats - Epoch: 25 AUC-val 0.506  AUC-train 0.760\n",
            "Stats - Epoch: 26 AUC-val 0.506  AUC-train 0.761\n",
            "Stats - Epoch: 27 AUC-val 0.510  AUC-train 0.762\n",
            "Stats - Epoch: 28 AUC-val 0.506  AUC-train 0.764\n",
            "Stats - Epoch: 29 AUC-val 0.507  AUC-train 0.764\n",
            "Stats - Epoch: 30 AUC-val 0.499  AUC-train 0.764\n",
            "Stats - Epoch: 31 AUC-val 0.505  AUC-train 0.766\n",
            "Stats - Epoch: 32 AUC-val 0.509  AUC-train 0.767\n",
            "Stats - Epoch: 33 AUC-val 0.506  AUC-train 0.768\n",
            "Stats - Epoch: 34 AUC-val 0.510  AUC-train 0.767\n",
            "Stats - Epoch: 35 AUC-val 0.508  AUC-train 0.768\n",
            "Stats - Epoch: 36 AUC-val 0.498  AUC-train 0.770\n",
            "Stats - Epoch: 37 AUC-val 0.498  AUC-train 0.770\n",
            "Stats - Epoch: 38 AUC-val 0.511  AUC-train 0.775\n",
            "Stats - Epoch: 39 AUC-val 0.500  AUC-train 0.774\n",
            "Stats - Epoch: 40 AUC-val 0.505  AUC-train 0.776\n",
            "Stats - Epoch: 41 AUC-val 0.492  AUC-train 0.774\n",
            "Stats - Epoch: 42 AUC-val 0.509  AUC-train 0.777\n",
            "Stats - Epoch: 43 AUC-val 0.502  AUC-train 0.777\n",
            "Stats - Epoch: 44 AUC-val 0.509  AUC-train 0.780\n",
            "Stats - Epoch: 45 AUC-val 0.506  AUC-train 0.780\n",
            "Stats - Epoch: 46 AUC-val 0.507  AUC-train 0.783\n",
            "Stats - Epoch: 47 AUC-val 0.510  AUC-train 0.782\n",
            "Stats - Epoch: 48 AUC-val 0.510  AUC-train 0.785\n",
            "Stats - Epoch: 49 AUC-val 0.513  AUC-train 0.784\n",
            "Stats - Epoch: 50 AUC-val 0.514  AUC-train 0.787\n",
            "Stats - Epoch: 51 AUC-val 0.518  AUC-train 0.791\n",
            "Stats - Epoch: 52 AUC-val 0.517  AUC-train 0.791\n",
            "Stats - Epoch: 53 AUC-val 0.521  AUC-train 0.790\n",
            "Stats - Epoch: 54 AUC-val 0.516  AUC-train 0.791\n",
            "Stats - Epoch: 55 AUC-val 0.524  AUC-train 0.794\n",
            "Stats - Epoch: 56 AUC-val 0.516  AUC-train 0.793\n",
            "Stats - Epoch: 57 AUC-val 0.534  AUC-train 0.796\n",
            "Stats - Epoch: 58 AUC-val 0.515  AUC-train 0.799\n",
            "Stats - Epoch: 59 AUC-val 0.519  AUC-train 0.797\n",
            "Stats - Epoch: 60 AUC-val 0.536  AUC-train 0.799\n",
            "Stats - Epoch: 61 AUC-val 0.532  AUC-train 0.802\n",
            "Stats - Epoch: 62 AUC-val 0.524  AUC-train 0.800\n",
            "Stats - Epoch: 63 AUC-val 0.531  AUC-train 0.802\n",
            "Stats - Epoch: 64 AUC-val 0.534  AUC-train 0.803\n",
            "Stats - Epoch: 65 AUC-val 0.529  AUC-train 0.806\n",
            "Stats - Epoch: 66 AUC-val 0.521  AUC-train 0.805\n",
            "Stats - Epoch: 67 AUC-val 0.543  AUC-train 0.807\n",
            "Stats - Epoch: 68 AUC-val 0.516  AUC-train 0.807\n",
            "Stats - Epoch: 69 AUC-val 0.529  AUC-train 0.809\n",
            "Stats - Epoch: 70 AUC-val 0.534  AUC-train 0.810\n",
            "Stats - Epoch: 71 AUC-val 0.534  AUC-train 0.811\n",
            "Stats - Epoch: 72 AUC-val 0.497  AUC-train 0.810\n",
            "Stats - Epoch: 73 AUC-val 0.528  AUC-train 0.808\n",
            "Stats - Epoch: 74 AUC-val 0.536  AUC-train 0.808\n",
            "Stats - Epoch: 75 AUC-val 0.537  AUC-train 0.811\n",
            "Stats - Epoch: 76 AUC-val 0.535  AUC-train 0.811\n",
            "Stats - Epoch: 77 AUC-val 0.534  AUC-train 0.813\n",
            "Stats - Epoch: 78 AUC-val 0.541  AUC-train 0.814\n",
            "Stats - Epoch: 79 AUC-val 0.534  AUC-train 0.816\n",
            "Stats - Epoch: 80 AUC-val 0.550  AUC-train 0.817\n",
            "Stats - Epoch: 81 AUC-val 0.532  AUC-train 0.815\n",
            "Stats - Epoch: 82 AUC-val 0.534  AUC-train 0.815\n",
            "Stats - Epoch: 83 AUC-val 0.551  AUC-train 0.819\n",
            "Stats - Epoch: 84 AUC-val 0.545  AUC-train 0.820\n",
            "Stats - Epoch: 85 AUC-val 0.533  AUC-train 0.820\n",
            "Stats - Epoch: 86 AUC-val 0.538  AUC-train 0.818\n",
            "Stats - Epoch: 87 AUC-val 0.549  AUC-train 0.822\n",
            "Stats - Epoch: 88 AUC-val 0.550  AUC-train 0.821\n",
            "Stats - Epoch: 89 AUC-val 0.548  AUC-train 0.824\n",
            "Stats - Epoch: 90 AUC-val 0.542  AUC-train 0.824\n",
            "Stats - Epoch: 91 AUC-val 0.538  AUC-train 0.827\n",
            "Stats - Epoch: 92 AUC-val 0.537  AUC-train 0.826\n",
            "Stats - Epoch: 93 AUC-val 0.548  AUC-train 0.824\n",
            "Stats - Epoch: 94 AUC-val 0.538  AUC-train 0.828\n",
            "Stats - Epoch: 95 AUC-val 0.550  AUC-train 0.825\n",
            "Stats - Epoch: 96 AUC-val 0.548  AUC-train 0.830\n",
            "Stats - Epoch: 97 AUC-val 0.536  AUC-train 0.833\n",
            "Stats - Epoch: 98 AUC-val 0.556  AUC-train 0.832\n",
            "Stats - Epoch: 99 AUC-val 0.527  AUC-train 0.832\n",
            "Stats - Epoch: 100 AUC-val 0.549  AUC-train 0.833\n",
            "Results 100 AUC-val 0.655 0.599 0.576 0.473 0.483 AUC-train 0.716\n",
            "Shapley [0.01316054] [0.0192102]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.221498\n",
            "         Iterations 7\n",
            "['rsp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.452  AUC-train 0.513\n",
            "Stats - Epoch: 2 AUC-val 0.615  AUC-train 0.609\n",
            "Stats - Epoch: 3 AUC-val 0.695  AUC-train 0.667\n",
            "Stats - Epoch: 4 AUC-val 0.722  AUC-train 0.704\n",
            "Stats - Epoch: 5 AUC-val 0.733  AUC-train 0.731\n",
            "Stats - Epoch: 6 AUC-val 0.766  AUC-train 0.748\n",
            "Stats - Epoch: 7 AUC-val 0.750  AUC-train 0.764\n",
            "Stats - Epoch: 8 AUC-val 0.761  AUC-train 0.776\n",
            "Stats - Epoch: 9 AUC-val 0.777  AUC-train 0.790\n",
            "Stats - Epoch: 10 AUC-val 0.792  AUC-train 0.797\n",
            "Stats - Epoch: 11 AUC-val 0.799  AUC-train 0.806\n",
            "Stats - Epoch: 12 AUC-val 0.798  AUC-train 0.817\n",
            "Stats - Epoch: 13 AUC-val 0.810  AUC-train 0.821\n",
            "Stats - Epoch: 14 AUC-val 0.794  AUC-train 0.831\n",
            "Stats - Epoch: 15 AUC-val 0.791  AUC-train 0.834\n",
            "Stats - Epoch: 16 AUC-val 0.818  AUC-train 0.842\n",
            "Stats - Epoch: 17 AUC-val 0.821  AUC-train 0.847\n",
            "Stats - Epoch: 18 AUC-val 0.814  AUC-train 0.849\n",
            "Stats - Epoch: 19 AUC-val 0.819  AUC-train 0.854\n",
            "Stats - Epoch: 20 AUC-val 0.817  AUC-train 0.859\n",
            "Stats - Epoch: 21 AUC-val 0.809  AUC-train 0.862\n",
            "Stats - Epoch: 22 AUC-val 0.815  AUC-train 0.867\n",
            "Stats - Epoch: 23 AUC-val 0.813  AUC-train 0.877\n",
            "Stats - Epoch: 24 AUC-val 0.829  AUC-train 0.879\n",
            "Stats - Epoch: 25 AUC-val 0.821  AUC-train 0.885\n",
            "Stats - Epoch: 26 AUC-val 0.823  AUC-train 0.886\n",
            "Stats - Epoch: 27 AUC-val 0.804  AUC-train 0.888\n",
            "Stats - Epoch: 28 AUC-val 0.824  AUC-train 0.895\n",
            "Stats - Epoch: 29 AUC-val 0.805  AUC-train 0.897\n",
            "Stats - Epoch: 30 AUC-val 0.803  AUC-train 0.901\n",
            "Stats - Epoch: 31 AUC-val 0.786  AUC-train 0.907\n",
            "Stats - Epoch: 32 AUC-val 0.790  AUC-train 0.906\n",
            "Stats - Epoch: 33 AUC-val 0.816  AUC-train 0.911\n",
            "Stats - Epoch: 34 AUC-val 0.780  AUC-train 0.913\n",
            "Stats - Epoch: 35 AUC-val 0.795  AUC-train 0.917\n",
            "Stats - Epoch: 36 AUC-val 0.772  AUC-train 0.917\n",
            "Stats - Epoch: 37 AUC-val 0.788  AUC-train 0.923\n",
            "Stats - Epoch: 38 AUC-val 0.782  AUC-train 0.928\n",
            "Stats - Epoch: 39 AUC-val 0.798  AUC-train 0.929\n",
            "Stats - Epoch: 40 AUC-val 0.774  AUC-train 0.929\n",
            "Stats - Epoch: 41 AUC-val 0.777  AUC-train 0.930\n",
            "Stats - Epoch: 42 AUC-val 0.771  AUC-train 0.932\n",
            "Stats - Epoch: 43 AUC-val 0.773  AUC-train 0.936\n",
            "Stats - Epoch: 44 AUC-val 0.789  AUC-train 0.939\n",
            "Stats - Epoch: 45 AUC-val 0.758  AUC-train 0.942\n",
            "Stats - Epoch: 46 AUC-val 0.768  AUC-train 0.945\n",
            "Stats - Epoch: 47 AUC-val 0.765  AUC-train 0.944\n",
            "Stats - Epoch: 48 AUC-val 0.774  AUC-train 0.947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 49 AUC-val 0.758  AUC-train 0.947\n",
            "Stats - Epoch: 50 AUC-val 0.759  AUC-train 0.948\n",
            "Stats - Epoch: 51 AUC-val 0.738  AUC-train 0.945\n",
            "Stats - Epoch: 52 AUC-val 0.743  AUC-train 0.952\n",
            "Stats - Epoch: 53 AUC-val 0.752  AUC-train 0.952\n",
            "Stats - Epoch: 54 AUC-val 0.757  AUC-train 0.951\n",
            "Stats - Epoch: 55 AUC-val 0.738  AUC-train 0.954\n",
            "Stats - Epoch: 56 AUC-val 0.768  AUC-train 0.954\n",
            "Stats - Epoch: 57 AUC-val 0.720  AUC-train 0.957\n",
            "Stats - Epoch: 58 AUC-val 0.742  AUC-train 0.955\n",
            "Stats - Epoch: 59 AUC-val 0.755  AUC-train 0.958\n",
            "Stats - Epoch: 60 AUC-val 0.731  AUC-train 0.960\n",
            "Stats - Epoch: 61 AUC-val 0.737  AUC-train 0.964\n",
            "Stats - Epoch: 62 AUC-val 0.734  AUC-train 0.966\n",
            "Stats - Epoch: 63 AUC-val 0.757  AUC-train 0.963\n",
            "Stats - Epoch: 64 AUC-val 0.753  AUC-train 0.966\n",
            "Stats - Epoch: 65 AUC-val 0.748  AUC-train 0.965\n",
            "Stats - Epoch: 66 AUC-val 0.757  AUC-train 0.966\n",
            "Stats - Epoch: 67 AUC-val 0.740  AUC-train 0.969\n",
            "Stats - Epoch: 68 AUC-val 0.729  AUC-train 0.968\n",
            "Stats - Epoch: 69 AUC-val 0.732  AUC-train 0.971\n",
            "Stats - Epoch: 70 AUC-val 0.718  AUC-train 0.973\n",
            "Stats - Epoch: 71 AUC-val 0.722  AUC-train 0.970\n",
            "Stats - Epoch: 72 AUC-val 0.711  AUC-train 0.973\n",
            "Stats - Epoch: 73 AUC-val 0.750  AUC-train 0.972\n",
            "Stats - Epoch: 74 AUC-val 0.708  AUC-train 0.973\n",
            "Stats - Epoch: 75 AUC-val 0.748  AUC-train 0.973\n",
            "Stats - Epoch: 76 AUC-val 0.751  AUC-train 0.972\n",
            "Stats - Epoch: 77 AUC-val 0.742  AUC-train 0.975\n",
            "Stats - Epoch: 78 AUC-val 0.754  AUC-train 0.976\n",
            "Stats - Epoch: 79 AUC-val 0.712  AUC-train 0.978\n",
            "Stats - Epoch: 80 AUC-val 0.708  AUC-train 0.978\n",
            "Stats - Epoch: 81 AUC-val 0.726  AUC-train 0.978\n",
            "Stats - Epoch: 82 AUC-val 0.722  AUC-train 0.979\n",
            "Stats - Epoch: 83 AUC-val 0.733  AUC-train 0.978\n",
            "Stats - Epoch: 84 AUC-val 0.702  AUC-train 0.977\n",
            "Stats - Epoch: 85 AUC-val 0.722  AUC-train 0.980\n",
            "Stats - Epoch: 86 AUC-val 0.727  AUC-train 0.981\n",
            "Stats - Epoch: 87 AUC-val 0.719  AUC-train 0.980\n",
            "Stats - Epoch: 88 AUC-val 0.706  AUC-train 0.978\n",
            "Stats - Epoch: 89 AUC-val 0.712  AUC-train 0.979\n",
            "Stats - Epoch: 90 AUC-val 0.701  AUC-train 0.980\n",
            "Stats - Epoch: 91 AUC-val 0.700  AUC-train 0.982\n",
            "Stats - Epoch: 92 AUC-val 0.732  AUC-train 0.979\n",
            "Stats - Epoch: 93 AUC-val 0.723  AUC-train 0.981\n",
            "Stats - Epoch: 94 AUC-val 0.710  AUC-train 0.983\n",
            "Stats - Epoch: 95 AUC-val 0.702  AUC-train 0.984\n",
            "Stats - Epoch: 96 AUC-val 0.724  AUC-train 0.982\n",
            "Stats - Epoch: 97 AUC-val 0.725  AUC-train 0.984\n",
            "Stats - Epoch: 98 AUC-val 0.669  AUC-train 0.981\n",
            "Stats - Epoch: 99 AUC-val 0.709  AUC-train 0.984\n",
            "Stats - Epoch: 100 AUC-val 0.694  AUC-train 0.983\n",
            "Results 100 AUC-val 0.657 0.720 0.829 0.693 0.277 AUC-train 0.879\n",
            "Shapley [0.04119146] [0.06802555]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.211686\n",
            "         Iterations 7\n",
            "['rhp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.692  AUC-train 0.487\n",
            "Stats - Epoch: 2 AUC-val 0.692  AUC-train 0.558\n",
            "Stats - Epoch: 3 AUC-val 0.678  AUC-train 0.590\n",
            "Stats - Epoch: 4 AUC-val 0.669  AUC-train 0.608\n",
            "Stats - Epoch: 5 AUC-val 0.657  AUC-train 0.622\n",
            "Stats - Epoch: 6 AUC-val 0.652  AUC-train 0.633\n",
            "Stats - Epoch: 7 AUC-val 0.645  AUC-train 0.644\n",
            "Stats - Epoch: 8 AUC-val 0.639  AUC-train 0.656\n",
            "Stats - Epoch: 9 AUC-val 0.634  AUC-train 0.666\n",
            "Stats - Epoch: 10 AUC-val 0.640  AUC-train 0.669\n",
            "Stats - Epoch: 11 AUC-val 0.629  AUC-train 0.673\n",
            "Stats - Epoch: 12 AUC-val 0.637  AUC-train 0.681\n",
            "Stats - Epoch: 13 AUC-val 0.637  AUC-train 0.684\n",
            "Stats - Epoch: 14 AUC-val 0.643  AUC-train 0.695\n",
            "Stats - Epoch: 15 AUC-val 0.644  AUC-train 0.695\n",
            "Stats - Epoch: 16 AUC-val 0.650  AUC-train 0.702\n",
            "Stats - Epoch: 17 AUC-val 0.649  AUC-train 0.704\n",
            "Stats - Epoch: 18 AUC-val 0.647  AUC-train 0.708\n",
            "Stats - Epoch: 19 AUC-val 0.656  AUC-train 0.713\n",
            "Stats - Epoch: 20 AUC-val 0.657  AUC-train 0.714\n",
            "Stats - Epoch: 21 AUC-val 0.666  AUC-train 0.718\n",
            "Stats - Epoch: 22 AUC-val 0.663  AUC-train 0.719\n",
            "Stats - Epoch: 23 AUC-val 0.667  AUC-train 0.727\n",
            "Stats - Epoch: 24 AUC-val 0.665  AUC-train 0.728\n",
            "Stats - Epoch: 25 AUC-val 0.669  AUC-train 0.730\n",
            "Stats - Epoch: 26 AUC-val 0.671  AUC-train 0.736\n",
            "Stats - Epoch: 27 AUC-val 0.678  AUC-train 0.737\n",
            "Stats - Epoch: 28 AUC-val 0.684  AUC-train 0.741\n",
            "Stats - Epoch: 29 AUC-val 0.685  AUC-train 0.743\n",
            "Stats - Epoch: 30 AUC-val 0.684  AUC-train 0.742\n",
            "Stats - Epoch: 31 AUC-val 0.684  AUC-train 0.745\n",
            "Stats - Epoch: 32 AUC-val 0.687  AUC-train 0.748\n",
            "Stats - Epoch: 33 AUC-val 0.689  AUC-train 0.752\n",
            "Stats - Epoch: 34 AUC-val 0.687  AUC-train 0.753\n",
            "Stats - Epoch: 35 AUC-val 0.693  AUC-train 0.758\n",
            "Stats - Epoch: 36 AUC-val 0.689  AUC-train 0.757\n",
            "Stats - Epoch: 37 AUC-val 0.700  AUC-train 0.762\n",
            "Stats - Epoch: 38 AUC-val 0.696  AUC-train 0.763\n",
            "Stats - Epoch: 39 AUC-val 0.695  AUC-train 0.766\n",
            "Stats - Epoch: 40 AUC-val 0.696  AUC-train 0.766\n",
            "Stats - Epoch: 41 AUC-val 0.695  AUC-train 0.767\n",
            "Stats - Epoch: 42 AUC-val 0.700  AUC-train 0.771\n",
            "Stats - Epoch: 43 AUC-val 0.699  AUC-train 0.771\n",
            "Stats - Epoch: 44 AUC-val 0.700  AUC-train 0.775\n",
            "Stats - Epoch: 45 AUC-val 0.696  AUC-train 0.776\n",
            "Stats - Epoch: 46 AUC-val 0.701  AUC-train 0.778\n",
            "Stats - Epoch: 47 AUC-val 0.703  AUC-train 0.780\n",
            "Stats - Epoch: 48 AUC-val 0.702  AUC-train 0.778\n",
            "Stats - Epoch: 49 AUC-val 0.700  AUC-train 0.782\n",
            "Stats - Epoch: 50 AUC-val 0.702  AUC-train 0.784\n",
            "Stats - Epoch: 51 AUC-val 0.705  AUC-train 0.788\n",
            "Stats - Epoch: 52 AUC-val 0.705  AUC-train 0.787\n",
            "Stats - Epoch: 53 AUC-val 0.706  AUC-train 0.793\n",
            "Stats - Epoch: 54 AUC-val 0.709  AUC-train 0.788\n",
            "Stats - Epoch: 55 AUC-val 0.708  AUC-train 0.790\n",
            "Stats - Epoch: 56 AUC-val 0.709  AUC-train 0.794\n",
            "Stats - Epoch: 57 AUC-val 0.704  AUC-train 0.794\n",
            "Stats - Epoch: 58 AUC-val 0.705  AUC-train 0.796\n",
            "Stats - Epoch: 59 AUC-val 0.702  AUC-train 0.796\n",
            "Stats - Epoch: 60 AUC-val 0.704  AUC-train 0.797\n",
            "Stats - Epoch: 61 AUC-val 0.709  AUC-train 0.802\n",
            "Stats - Epoch: 62 AUC-val 0.703  AUC-train 0.799\n",
            "Stats - Epoch: 63 AUC-val 0.709  AUC-train 0.801\n",
            "Stats - Epoch: 64 AUC-val 0.703  AUC-train 0.804\n",
            "Stats - Epoch: 65 AUC-val 0.711  AUC-train 0.804\n",
            "Stats - Epoch: 66 AUC-val 0.705  AUC-train 0.804\n",
            "Stats - Epoch: 67 AUC-val 0.706  AUC-train 0.809\n",
            "Stats - Epoch: 68 AUC-val 0.707  AUC-train 0.806\n",
            "Stats - Epoch: 69 AUC-val 0.709  AUC-train 0.809\n",
            "Stats - Epoch: 70 AUC-val 0.710  AUC-train 0.812\n",
            "Stats - Epoch: 71 AUC-val 0.709  AUC-train 0.812\n",
            "Stats - Epoch: 72 AUC-val 0.707  AUC-train 0.811\n",
            "Stats - Epoch: 73 AUC-val 0.706  AUC-train 0.813\n",
            "Stats - Epoch: 74 AUC-val 0.707  AUC-train 0.815\n",
            "Stats - Epoch: 75 AUC-val 0.707  AUC-train 0.815\n",
            "Stats - Epoch: 76 AUC-val 0.712  AUC-train 0.820\n",
            "Stats - Epoch: 77 AUC-val 0.708  AUC-train 0.818\n",
            "Stats - Epoch: 78 AUC-val 0.704  AUC-train 0.819\n",
            "Stats - Epoch: 79 AUC-val 0.705  AUC-train 0.820\n",
            "Stats - Epoch: 80 AUC-val 0.705  AUC-train 0.821\n",
            "Stats - Epoch: 81 AUC-val 0.708  AUC-train 0.821\n",
            "Stats - Epoch: 82 AUC-val 0.702  AUC-train 0.822\n",
            "Stats - Epoch: 83 AUC-val 0.706  AUC-train 0.825\n",
            "Stats - Epoch: 84 AUC-val 0.708  AUC-train 0.826\n",
            "Stats - Epoch: 85 AUC-val 0.707  AUC-train 0.825\n",
            "Stats - Epoch: 86 AUC-val 0.709  AUC-train 0.828\n",
            "Stats - Epoch: 87 AUC-val 0.711  AUC-train 0.832\n",
            "Stats - Epoch: 88 AUC-val 0.706  AUC-train 0.828\n",
            "Stats - Epoch: 89 AUC-val 0.707  AUC-train 0.828\n",
            "Stats - Epoch: 90 AUC-val 0.705  AUC-train 0.830\n",
            "Stats - Epoch: 91 AUC-val 0.710  AUC-train 0.832\n",
            "Stats - Epoch: 92 AUC-val 0.702  AUC-train 0.831\n",
            "Stats - Epoch: 93 AUC-val 0.704  AUC-train 0.829\n",
            "Stats - Epoch: 94 AUC-val 0.707  AUC-train 0.836\n",
            "Stats - Epoch: 95 AUC-val 0.706  AUC-train 0.832\n",
            "Stats - Epoch: 96 AUC-val 0.710  AUC-train 0.835\n",
            "Stats - Epoch: 97 AUC-val 0.706  AUC-train 0.836\n",
            "Stats - Epoch: 98 AUC-val 0.708  AUC-train 0.842\n",
            "Stats - Epoch: 99 AUC-val 0.710  AUC-train 0.838\n",
            "Stats - Epoch: 100 AUC-val 0.704  AUC-train 0.840\n",
            "Results 100 AUC-val 0.493 0.635 0.712 0.683 0.744 AUC-train 0.820\n",
            "Shapley [0.01272439] [0.01319484]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.221499\n",
            "         Iterations 7\n",
            "['ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.571  AUC-train 0.520\n",
            "Stats - Epoch: 2 AUC-val 0.562  AUC-train 0.535\n",
            "Stats - Epoch: 3 AUC-val 0.559  AUC-train 0.541\n",
            "Stats - Epoch: 4 AUC-val 0.563  AUC-train 0.545\n",
            "Stats - Epoch: 5 AUC-val 0.561  AUC-train 0.549\n",
            "Stats - Epoch: 6 AUC-val 0.564  AUC-train 0.550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 7 AUC-val 0.565  AUC-train 0.549\n",
            "Stats - Epoch: 8 AUC-val 0.564  AUC-train 0.550\n",
            "Stats - Epoch: 9 AUC-val 0.561  AUC-train 0.551\n",
            "Stats - Epoch: 10 AUC-val 0.559  AUC-train 0.554\n",
            "Stats - Epoch: 11 AUC-val 0.558  AUC-train 0.552\n",
            "Stats - Epoch: 12 AUC-val 0.560  AUC-train 0.553\n",
            "Stats - Epoch: 13 AUC-val 0.557  AUC-train 0.552\n",
            "Stats - Epoch: 14 AUC-val 0.552  AUC-train 0.556\n",
            "Stats - Epoch: 15 AUC-val 0.554  AUC-train 0.554\n",
            "Stats - Epoch: 16 AUC-val 0.542  AUC-train 0.550\n",
            "Stats - Epoch: 17 AUC-val 0.534  AUC-train 0.549\n",
            "Stats - Epoch: 18 AUC-val 0.535  AUC-train 0.546\n",
            "Stats - Epoch: 19 AUC-val 0.529  AUC-train 0.544\n",
            "Stats - Epoch: 20 AUC-val 0.516  AUC-train 0.541\n",
            "Stats - Epoch: 21 AUC-val 0.512  AUC-train 0.536\n",
            "Stats - Epoch: 22 AUC-val 0.498  AUC-train 0.532\n",
            "Stats - Epoch: 23 AUC-val 0.495  AUC-train 0.534\n",
            "Stats - Epoch: 24 AUC-val 0.486  AUC-train 0.528\n",
            "Stats - Epoch: 25 AUC-val 0.483  AUC-train 0.529\n",
            "Stats - Epoch: 26 AUC-val 0.467  AUC-train 0.527\n",
            "Stats - Epoch: 27 AUC-val 0.460  AUC-train 0.526\n",
            "Stats - Epoch: 28 AUC-val 0.458  AUC-train 0.525\n",
            "Stats - Epoch: 29 AUC-val 0.455  AUC-train 0.521\n",
            "Stats - Epoch: 30 AUC-val 0.452  AUC-train 0.526\n",
            "Stats - Epoch: 31 AUC-val 0.452  AUC-train 0.524\n",
            "Stats - Epoch: 32 AUC-val 0.450  AUC-train 0.523\n",
            "Stats - Epoch: 33 AUC-val 0.464  AUC-train 0.524\n",
            "Stats - Epoch: 34 AUC-val 0.457  AUC-train 0.522\n",
            "Stats - Epoch: 35 AUC-val 0.459  AUC-train 0.523\n",
            "Stats - Epoch: 36 AUC-val 0.460  AUC-train 0.523\n",
            "Stats - Epoch: 37 AUC-val 0.440  AUC-train 0.522\n",
            "Stats - Epoch: 38 AUC-val 0.438  AUC-train 0.522\n",
            "Stats - Epoch: 39 AUC-val 0.433  AUC-train 0.520\n",
            "Stats - Epoch: 40 AUC-val 0.435  AUC-train 0.520\n",
            "Stats - Epoch: 41 AUC-val 0.436  AUC-train 0.520\n",
            "Stats - Epoch: 42 AUC-val 0.434  AUC-train 0.521\n",
            "Stats - Epoch: 43 AUC-val 0.438  AUC-train 0.520\n",
            "Stats - Epoch: 44 AUC-val 0.446  AUC-train 0.522\n",
            "Stats - Epoch: 45 AUC-val 0.440  AUC-train 0.521\n",
            "Stats - Epoch: 46 AUC-val 0.441  AUC-train 0.521\n",
            "Stats - Epoch: 47 AUC-val 0.472  AUC-train 0.521\n",
            "Stats - Epoch: 48 AUC-val 0.458  AUC-train 0.520\n",
            "Stats - Epoch: 49 AUC-val 0.460  AUC-train 0.521\n",
            "Stats - Epoch: 50 AUC-val 0.463  AUC-train 0.521\n",
            "Stats - Epoch: 51 AUC-val 0.466  AUC-train 0.519\n",
            "Stats - Epoch: 52 AUC-val 0.474  AUC-train 0.520\n",
            "Stats - Epoch: 53 AUC-val 0.486  AUC-train 0.519\n",
            "Stats - Epoch: 54 AUC-val 0.490  AUC-train 0.519\n",
            "Stats - Epoch: 55 AUC-val 0.491  AUC-train 0.520\n",
            "Stats - Epoch: 56 AUC-val 0.495  AUC-train 0.521\n",
            "Stats - Epoch: 57 AUC-val 0.497  AUC-train 0.521\n",
            "Stats - Epoch: 58 AUC-val 0.507  AUC-train 0.520\n",
            "Stats - Epoch: 59 AUC-val 0.515  AUC-train 0.519\n",
            "Stats - Epoch: 60 AUC-val 0.519  AUC-train 0.519\n",
            "Stats - Epoch: 61 AUC-val 0.521  AUC-train 0.520\n",
            "Stats - Epoch: 62 AUC-val 0.523  AUC-train 0.520\n",
            "Stats - Epoch: 63 AUC-val 0.524  AUC-train 0.521\n",
            "Stats - Epoch: 64 AUC-val 0.527  AUC-train 0.520\n",
            "Stats - Epoch: 65 AUC-val 0.528  AUC-train 0.520\n",
            "Stats - Epoch: 66 AUC-val 0.529  AUC-train 0.519\n",
            "Stats - Epoch: 67 AUC-val 0.528  AUC-train 0.520\n",
            "Stats - Epoch: 68 AUC-val 0.529  AUC-train 0.520\n",
            "Stats - Epoch: 69 AUC-val 0.528  AUC-train 0.522\n",
            "Stats - Epoch: 70 AUC-val 0.530  AUC-train 0.520\n",
            "Stats - Epoch: 71 AUC-val 0.531  AUC-train 0.519\n",
            "Stats - Epoch: 72 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 73 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 74 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 75 AUC-val 0.530  AUC-train 0.521\n",
            "Stats - Epoch: 76 AUC-val 0.531  AUC-train 0.519\n",
            "Stats - Epoch: 77 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 78 AUC-val 0.531  AUC-train 0.521\n",
            "Stats - Epoch: 79 AUC-val 0.531  AUC-train 0.521\n",
            "Stats - Epoch: 80 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 81 AUC-val 0.531  AUC-train 0.522\n",
            "Stats - Epoch: 82 AUC-val 0.531  AUC-train 0.525\n",
            "Stats - Epoch: 83 AUC-val 0.531  AUC-train 0.521\n",
            "Stats - Epoch: 84 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 85 AUC-val 0.530  AUC-train 0.522\n",
            "Stats - Epoch: 86 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 87 AUC-val 0.531  AUC-train 0.523\n",
            "Stats - Epoch: 88 AUC-val 0.530  AUC-train 0.524\n",
            "Stats - Epoch: 89 AUC-val 0.531  AUC-train 0.523\n",
            "Stats - Epoch: 90 AUC-val 0.531  AUC-train 0.522\n",
            "Stats - Epoch: 91 AUC-val 0.531  AUC-train 0.522\n",
            "Stats - Epoch: 92 AUC-val 0.531  AUC-train 0.524\n",
            "Stats - Epoch: 93 AUC-val 0.531  AUC-train 0.522\n",
            "Stats - Epoch: 94 AUC-val 0.531  AUC-train 0.522\n",
            "Stats - Epoch: 95 AUC-val 0.531  AUC-train 0.520\n",
            "Stats - Epoch: 96 AUC-val 0.531  AUC-train 0.525\n",
            "Stats - Epoch: 97 AUC-val 0.531  AUC-train 0.523\n",
            "Stats - Epoch: 98 AUC-val 0.531  AUC-train 0.523\n",
            "Stats - Epoch: 99 AUC-val 0.532  AUC-train 0.525\n",
            "Stats - Epoch: 100 AUC-val 0.532  AUC-train 0.522\n",
            "Results 100 AUC-val 0.569 0.582 0.571 0.537 0.483 AUC-train 0.520\n",
            "Shapley [0.02932582] [0.03288148]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.223729\n",
            "         Iterations 7\n",
            "['rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.433  AUC-train 0.470\n",
            "Stats - Epoch: 2 AUC-val 0.373  AUC-train 0.504\n",
            "Stats - Epoch: 3 AUC-val 0.399  AUC-train 0.546\n",
            "Stats - Epoch: 4 AUC-val 0.432  AUC-train 0.576\n",
            "Stats - Epoch: 5 AUC-val 0.450  AUC-train 0.592\n",
            "Stats - Epoch: 6 AUC-val 0.469  AUC-train 0.603\n",
            "Stats - Epoch: 7 AUC-val 0.488  AUC-train 0.608\n",
            "Stats - Epoch: 8 AUC-val 0.500  AUC-train 0.609\n",
            "Stats - Epoch: 9 AUC-val 0.507  AUC-train 0.611\n",
            "Stats - Epoch: 10 AUC-val 0.516  AUC-train 0.610\n",
            "Stats - Epoch: 11 AUC-val 0.521  AUC-train 0.610\n",
            "Stats - Epoch: 12 AUC-val 0.528  AUC-train 0.610\n",
            "Stats - Epoch: 13 AUC-val 0.534  AUC-train 0.609\n",
            "Stats - Epoch: 14 AUC-val 0.536  AUC-train 0.609\n",
            "Stats - Epoch: 15 AUC-val 0.538  AUC-train 0.608\n",
            "Stats - Epoch: 16 AUC-val 0.544  AUC-train 0.607\n",
            "Stats - Epoch: 17 AUC-val 0.555  AUC-train 0.606\n",
            "Stats - Epoch: 18 AUC-val 0.556  AUC-train 0.606\n",
            "Stats - Epoch: 19 AUC-val 0.560  AUC-train 0.606\n",
            "Stats - Epoch: 20 AUC-val 0.562  AUC-train 0.606\n",
            "Stats - Epoch: 21 AUC-val 0.563  AUC-train 0.605\n",
            "Stats - Epoch: 22 AUC-val 0.565  AUC-train 0.605\n",
            "Stats - Epoch: 23 AUC-val 0.566  AUC-train 0.605\n",
            "Stats - Epoch: 24 AUC-val 0.569  AUC-train 0.604\n",
            "Stats - Epoch: 25 AUC-val 0.568  AUC-train 0.604\n",
            "Stats - Epoch: 26 AUC-val 0.570  AUC-train 0.604\n",
            "Stats - Epoch: 27 AUC-val 0.571  AUC-train 0.604\n",
            "Stats - Epoch: 28 AUC-val 0.573  AUC-train 0.603\n",
            "Stats - Epoch: 29 AUC-val 0.574  AUC-train 0.604\n",
            "Stats - Epoch: 30 AUC-val 0.575  AUC-train 0.603\n",
            "Stats - Epoch: 31 AUC-val 0.573  AUC-train 0.603\n",
            "Stats - Epoch: 32 AUC-val 0.576  AUC-train 0.603\n",
            "Stats - Epoch: 33 AUC-val 0.577  AUC-train 0.603\n",
            "Stats - Epoch: 34 AUC-val 0.582  AUC-train 0.602\n",
            "Stats - Epoch: 35 AUC-val 0.578  AUC-train 0.603\n",
            "Stats - Epoch: 36 AUC-val 0.577  AUC-train 0.603\n",
            "Stats - Epoch: 37 AUC-val 0.578  AUC-train 0.603\n",
            "Stats - Epoch: 38 AUC-val 0.581  AUC-train 0.603\n",
            "Stats - Epoch: 39 AUC-val 0.576  AUC-train 0.603\n",
            "Stats - Epoch: 40 AUC-val 0.579  AUC-train 0.603\n",
            "Stats - Epoch: 41 AUC-val 0.582  AUC-train 0.604\n",
            "Stats - Epoch: 42 AUC-val 0.583  AUC-train 0.603\n",
            "Stats - Epoch: 43 AUC-val 0.582  AUC-train 0.604\n",
            "Stats - Epoch: 44 AUC-val 0.583  AUC-train 0.604\n",
            "Stats - Epoch: 45 AUC-val 0.580  AUC-train 0.604\n",
            "Stats - Epoch: 46 AUC-val 0.584  AUC-train 0.603\n",
            "Stats - Epoch: 47 AUC-val 0.587  AUC-train 0.605\n",
            "Stats - Epoch: 48 AUC-val 0.585  AUC-train 0.604\n",
            "Stats - Epoch: 49 AUC-val 0.589  AUC-train 0.605\n",
            "Stats - Epoch: 50 AUC-val 0.589  AUC-train 0.604\n",
            "Stats - Epoch: 51 AUC-val 0.586  AUC-train 0.604\n",
            "Stats - Epoch: 52 AUC-val 0.586  AUC-train 0.605\n",
            "Stats - Epoch: 53 AUC-val 0.590  AUC-train 0.605\n",
            "Stats - Epoch: 54 AUC-val 0.583  AUC-train 0.605\n",
            "Stats - Epoch: 55 AUC-val 0.595  AUC-train 0.605\n",
            "Stats - Epoch: 56 AUC-val 0.589  AUC-train 0.605\n",
            "Stats - Epoch: 57 AUC-val 0.599  AUC-train 0.605\n",
            "Stats - Epoch: 58 AUC-val 0.590  AUC-train 0.605\n",
            "Stats - Epoch: 59 AUC-val 0.587  AUC-train 0.605\n",
            "Stats - Epoch: 60 AUC-val 0.592  AUC-train 0.606\n",
            "Stats - Epoch: 61 AUC-val 0.601  AUC-train 0.606\n",
            "Stats - Epoch: 62 AUC-val 0.588  AUC-train 0.606\n",
            "Stats - Epoch: 63 AUC-val 0.587  AUC-train 0.606\n",
            "Stats - Epoch: 64 AUC-val 0.593  AUC-train 0.606\n",
            "Stats - Epoch: 65 AUC-val 0.594  AUC-train 0.607\n",
            "Stats - Epoch: 66 AUC-val 0.591  AUC-train 0.606\n",
            "Stats - Epoch: 67 AUC-val 0.602  AUC-train 0.607\n",
            "Stats - Epoch: 68 AUC-val 0.603  AUC-train 0.607\n",
            "Stats - Epoch: 69 AUC-val 0.604  AUC-train 0.604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 70 AUC-val 0.600  AUC-train 0.605\n",
            "Stats - Epoch: 71 AUC-val 0.596  AUC-train 0.606\n",
            "Stats - Epoch: 72 AUC-val 0.608  AUC-train 0.606\n",
            "Stats - Epoch: 73 AUC-val 0.592  AUC-train 0.606\n",
            "Stats - Epoch: 74 AUC-val 0.599  AUC-train 0.606\n",
            "Stats - Epoch: 75 AUC-val 0.594  AUC-train 0.606\n",
            "Stats - Epoch: 76 AUC-val 0.598  AUC-train 0.607\n",
            "Stats - Epoch: 77 AUC-val 0.600  AUC-train 0.606\n",
            "Stats - Epoch: 78 AUC-val 0.597  AUC-train 0.607\n",
            "Stats - Epoch: 79 AUC-val 0.596  AUC-train 0.608\n",
            "Stats - Epoch: 80 AUC-val 0.612  AUC-train 0.609\n",
            "Stats - Epoch: 81 AUC-val 0.592  AUC-train 0.607\n",
            "Stats - Epoch: 82 AUC-val 0.607  AUC-train 0.609\n",
            "Stats - Epoch: 83 AUC-val 0.593  AUC-train 0.609\n",
            "Stats - Epoch: 84 AUC-val 0.602  AUC-train 0.608\n",
            "Stats - Epoch: 85 AUC-val 0.600  AUC-train 0.609\n",
            "Stats - Epoch: 86 AUC-val 0.592  AUC-train 0.609\n",
            "Stats - Epoch: 87 AUC-val 0.600  AUC-train 0.610\n",
            "Stats - Epoch: 88 AUC-val 0.597  AUC-train 0.610\n",
            "Stats - Epoch: 89 AUC-val 0.592  AUC-train 0.609\n",
            "Stats - Epoch: 90 AUC-val 0.609  AUC-train 0.611\n",
            "Stats - Epoch: 91 AUC-val 0.591  AUC-train 0.612\n",
            "Stats - Epoch: 92 AUC-val 0.614  AUC-train 0.612\n",
            "Stats - Epoch: 93 AUC-val 0.594  AUC-train 0.612\n",
            "Stats - Epoch: 94 AUC-val 0.597  AUC-train 0.611\n",
            "Stats - Epoch: 95 AUC-val 0.594  AUC-train 0.612\n",
            "Stats - Epoch: 96 AUC-val 0.596  AUC-train 0.614\n",
            "Stats - Epoch: 97 AUC-val 0.607  AUC-train 0.614\n",
            "Stats - Epoch: 98 AUC-val 0.601  AUC-train 0.614\n",
            "Stats - Epoch: 99 AUC-val 0.610  AUC-train 0.615\n",
            "Stats - Epoch: 100 AUC-val 0.617  AUC-train 0.616\n",
            "Results 100 AUC-val 0.701 0.742 0.617 0.612 0.288 AUC-train 0.616\n",
            "Shapley [0.00318649] [0.02788197]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.222737\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'rsp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.267  AUC-train 0.506\n",
            "Stats - Epoch: 2 AUC-val 0.483  AUC-train 0.652\n",
            "Stats - Epoch: 3 AUC-val 0.699  AUC-train 0.755\n",
            "Stats - Epoch: 4 AUC-val 0.773  AUC-train 0.797\n",
            "Stats - Epoch: 5 AUC-val 0.750  AUC-train 0.823\n",
            "Stats - Epoch: 6 AUC-val 0.757  AUC-train 0.841\n",
            "Stats - Epoch: 7 AUC-val 0.750  AUC-train 0.855\n",
            "Stats - Epoch: 8 AUC-val 0.781  AUC-train 0.868\n",
            "Stats - Epoch: 9 AUC-val 0.757  AUC-train 0.884\n",
            "Stats - Epoch: 10 AUC-val 0.750  AUC-train 0.890\n",
            "Stats - Epoch: 11 AUC-val 0.785  AUC-train 0.896\n",
            "Stats - Epoch: 12 AUC-val 0.754  AUC-train 0.902\n",
            "Stats - Epoch: 13 AUC-val 0.757  AUC-train 0.912\n",
            "Stats - Epoch: 14 AUC-val 0.775  AUC-train 0.919\n",
            "Stats - Epoch: 15 AUC-val 0.757  AUC-train 0.922\n",
            "Stats - Epoch: 16 AUC-val 0.752  AUC-train 0.927\n",
            "Stats - Epoch: 17 AUC-val 0.720  AUC-train 0.932\n",
            "Stats - Epoch: 18 AUC-val 0.765  AUC-train 0.938\n",
            "Stats - Epoch: 19 AUC-val 0.717  AUC-train 0.942\n",
            "Stats - Epoch: 20 AUC-val 0.740  AUC-train 0.946\n",
            "Stats - Epoch: 21 AUC-val 0.683  AUC-train 0.945\n",
            "Stats - Epoch: 22 AUC-val 0.710  AUC-train 0.950\n",
            "Stats - Epoch: 23 AUC-val 0.688  AUC-train 0.954\n",
            "Stats - Epoch: 24 AUC-val 0.728  AUC-train 0.954\n",
            "Stats - Epoch: 25 AUC-val 0.720  AUC-train 0.957\n",
            "Stats - Epoch: 26 AUC-val 0.726  AUC-train 0.960\n",
            "Stats - Epoch: 27 AUC-val 0.670  AUC-train 0.962\n",
            "Stats - Epoch: 28 AUC-val 0.681  AUC-train 0.962\n",
            "Stats - Epoch: 29 AUC-val 0.697  AUC-train 0.964\n",
            "Stats - Epoch: 30 AUC-val 0.719  AUC-train 0.966\n",
            "Stats - Epoch: 31 AUC-val 0.671  AUC-train 0.967\n",
            "Stats - Epoch: 32 AUC-val 0.676  AUC-train 0.968\n",
            "Stats - Epoch: 33 AUC-val 0.711  AUC-train 0.968\n",
            "Stats - Epoch: 34 AUC-val 0.688  AUC-train 0.971\n",
            "Stats - Epoch: 35 AUC-val 0.666  AUC-train 0.972\n",
            "Stats - Epoch: 36 AUC-val 0.685  AUC-train 0.972\n",
            "Stats - Epoch: 37 AUC-val 0.689  AUC-train 0.974\n",
            "Stats - Epoch: 38 AUC-val 0.679  AUC-train 0.977\n",
            "Stats - Epoch: 39 AUC-val 0.646  AUC-train 0.978\n",
            "Stats - Epoch: 40 AUC-val 0.685  AUC-train 0.980\n",
            "Stats - Epoch: 41 AUC-val 0.695  AUC-train 0.978\n",
            "Stats - Epoch: 42 AUC-val 0.693  AUC-train 0.979\n",
            "Stats - Epoch: 43 AUC-val 0.665  AUC-train 0.975\n",
            "Stats - Epoch: 44 AUC-val 0.670  AUC-train 0.980\n",
            "Stats - Epoch: 45 AUC-val 0.667  AUC-train 0.980\n",
            "Stats - Epoch: 46 AUC-val 0.646  AUC-train 0.981\n",
            "Stats - Epoch: 47 AUC-val 0.616  AUC-train 0.978\n",
            "Stats - Epoch: 48 AUC-val 0.643  AUC-train 0.982\n",
            "Stats - Epoch: 49 AUC-val 0.647  AUC-train 0.985\n",
            "Stats - Epoch: 50 AUC-val 0.613  AUC-train 0.986\n",
            "Stats - Epoch: 51 AUC-val 0.630  AUC-train 0.987\n",
            "Stats - Epoch: 52 AUC-val 0.612  AUC-train 0.987\n",
            "Stats - Epoch: 53 AUC-val 0.630  AUC-train 0.984\n",
            "Stats - Epoch: 54 AUC-val 0.593  AUC-train 0.985\n",
            "Stats - Epoch: 55 AUC-val 0.598  AUC-train 0.987\n",
            "Stats - Epoch: 56 AUC-val 0.652  AUC-train 0.987\n",
            "Stats - Epoch: 57 AUC-val 0.630  AUC-train 0.989\n",
            "Stats - Epoch: 58 AUC-val 0.633  AUC-train 0.989\n",
            "Stats - Epoch: 59 AUC-val 0.627  AUC-train 0.990\n",
            "Stats - Epoch: 60 AUC-val 0.575  AUC-train 0.990\n",
            "Stats - Epoch: 61 AUC-val 0.625  AUC-train 0.991\n",
            "Stats - Epoch: 62 AUC-val 0.611  AUC-train 0.991\n",
            "Stats - Epoch: 63 AUC-val 0.615  AUC-train 0.992\n",
            "Stats - Epoch: 64 AUC-val 0.607  AUC-train 0.991\n",
            "Stats - Epoch: 65 AUC-val 0.658  AUC-train 0.991\n",
            "Stats - Epoch: 66 AUC-val 0.613  AUC-train 0.991\n",
            "Stats - Epoch: 67 AUC-val 0.594  AUC-train 0.992\n",
            "Stats - Epoch: 68 AUC-val 0.710  AUC-train 0.992\n",
            "Stats - Epoch: 69 AUC-val 0.614  AUC-train 0.992\n",
            "Stats - Epoch: 70 AUC-val 0.705  AUC-train 0.991\n",
            "Stats - Epoch: 71 AUC-val 0.615  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.587  AUC-train 0.993\n",
            "Stats - Epoch: 73 AUC-val 0.602  AUC-train 0.994\n",
            "Stats - Epoch: 74 AUC-val 0.609  AUC-train 0.994\n",
            "Stats - Epoch: 75 AUC-val 0.719  AUC-train 0.992\n",
            "Stats - Epoch: 76 AUC-val 0.617  AUC-train 0.995\n",
            "Stats - Epoch: 77 AUC-val 0.615  AUC-train 0.994\n",
            "Stats - Epoch: 78 AUC-val 0.573  AUC-train 0.993\n",
            "Stats - Epoch: 79 AUC-val 0.651  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.550  AUC-train 0.995\n",
            "Stats - Epoch: 81 AUC-val 0.548  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.663  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.560  AUC-train 0.994\n",
            "Stats - Epoch: 84 AUC-val 0.672  AUC-train 0.992\n",
            "Stats - Epoch: 85 AUC-val 0.603  AUC-train 0.995\n",
            "Stats - Epoch: 86 AUC-val 0.545  AUC-train 0.994\n",
            "Stats - Epoch: 87 AUC-val 0.562  AUC-train 0.995\n",
            "Stats - Epoch: 88 AUC-val 0.630  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.600  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.634  AUC-train 0.994\n",
            "Stats - Epoch: 91 AUC-val 0.578  AUC-train 0.994\n",
            "Stats - Epoch: 92 AUC-val 0.593  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.562  AUC-train 0.994\n",
            "Stats - Epoch: 94 AUC-val 0.672  AUC-train 0.994\n",
            "Stats - Epoch: 95 AUC-val 0.629  AUC-train 0.994\n",
            "Stats - Epoch: 96 AUC-val 0.661  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.639  AUC-train 0.995\n",
            "Stats - Epoch: 98 AUC-val 0.568  AUC-train 0.992\n",
            "Stats - Epoch: 99 AUC-val 0.614  AUC-train 0.995\n",
            "Stats - Epoch: 100 AUC-val 0.595  AUC-train 0.995\n",
            "Results 100 AUC-val 0.764 0.803 0.785 0.712 0.477 AUC-train 0.896\n",
            "Shapley [0.02347118 0.01806205] [0.01892639]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.212259\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'rhp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.529  AUC-train 0.477\n",
            "Stats - Epoch: 2 AUC-val 0.661  AUC-train 0.629\n",
            "Stats - Epoch: 3 AUC-val 0.667  AUC-train 0.705\n",
            "Stats - Epoch: 4 AUC-val 0.658  AUC-train 0.740\n",
            "Stats - Epoch: 5 AUC-val 0.649  AUC-train 0.765\n",
            "Stats - Epoch: 6 AUC-val 0.640  AUC-train 0.782\n",
            "Stats - Epoch: 7 AUC-val 0.626  AUC-train 0.801\n",
            "Stats - Epoch: 8 AUC-val 0.618  AUC-train 0.813\n",
            "Stats - Epoch: 9 AUC-val 0.608  AUC-train 0.823\n",
            "Stats - Epoch: 10 AUC-val 0.601  AUC-train 0.833\n",
            "Stats - Epoch: 11 AUC-val 0.594  AUC-train 0.835\n",
            "Stats - Epoch: 12 AUC-val 0.596  AUC-train 0.847\n",
            "Stats - Epoch: 13 AUC-val 0.590  AUC-train 0.850\n",
            "Stats - Epoch: 14 AUC-val 0.595  AUC-train 0.861\n",
            "Stats - Epoch: 15 AUC-val 0.591  AUC-train 0.866\n",
            "Stats - Epoch: 16 AUC-val 0.582  AUC-train 0.870\n",
            "Stats - Epoch: 17 AUC-val 0.590  AUC-train 0.877\n",
            "Stats - Epoch: 18 AUC-val 0.582  AUC-train 0.880\n",
            "Stats - Epoch: 19 AUC-val 0.574  AUC-train 0.887\n",
            "Stats - Epoch: 20 AUC-val 0.582  AUC-train 0.888\n",
            "Stats - Epoch: 21 AUC-val 0.590  AUC-train 0.896\n",
            "Stats - Epoch: 22 AUC-val 0.591  AUC-train 0.902\n",
            "Stats - Epoch: 23 AUC-val 0.595  AUC-train 0.909\n",
            "Stats - Epoch: 24 AUC-val 0.581  AUC-train 0.910\n",
            "Stats - Epoch: 25 AUC-val 0.582  AUC-train 0.915\n",
            "Stats - Epoch: 26 AUC-val 0.595  AUC-train 0.915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 27 AUC-val 0.597  AUC-train 0.924\n",
            "Stats - Epoch: 28 AUC-val 0.582  AUC-train 0.925\n",
            "Stats - Epoch: 29 AUC-val 0.589  AUC-train 0.927\n",
            "Stats - Epoch: 30 AUC-val 0.613  AUC-train 0.929\n",
            "Stats - Epoch: 31 AUC-val 0.604  AUC-train 0.935\n",
            "Stats - Epoch: 32 AUC-val 0.607  AUC-train 0.937\n",
            "Stats - Epoch: 33 AUC-val 0.601  AUC-train 0.939\n",
            "Stats - Epoch: 34 AUC-val 0.620  AUC-train 0.944\n",
            "Stats - Epoch: 35 AUC-val 0.612  AUC-train 0.946\n",
            "Stats - Epoch: 36 AUC-val 0.610  AUC-train 0.948\n",
            "Stats - Epoch: 37 AUC-val 0.614  AUC-train 0.951\n",
            "Stats - Epoch: 38 AUC-val 0.623  AUC-train 0.951\n",
            "Stats - Epoch: 39 AUC-val 0.621  AUC-train 0.955\n",
            "Stats - Epoch: 40 AUC-val 0.615  AUC-train 0.957\n",
            "Stats - Epoch: 41 AUC-val 0.625  AUC-train 0.959\n",
            "Stats - Epoch: 42 AUC-val 0.616  AUC-train 0.959\n",
            "Stats - Epoch: 43 AUC-val 0.635  AUC-train 0.962\n",
            "Stats - Epoch: 44 AUC-val 0.627  AUC-train 0.963\n",
            "Stats - Epoch: 45 AUC-val 0.627  AUC-train 0.964\n",
            "Stats - Epoch: 46 AUC-val 0.634  AUC-train 0.964\n",
            "Stats - Epoch: 47 AUC-val 0.641  AUC-train 0.966\n",
            "Stats - Epoch: 48 AUC-val 0.630  AUC-train 0.965\n",
            "Stats - Epoch: 49 AUC-val 0.617  AUC-train 0.966\n",
            "Stats - Epoch: 50 AUC-val 0.634  AUC-train 0.967\n",
            "Stats - Epoch: 51 AUC-val 0.656  AUC-train 0.968\n",
            "Stats - Epoch: 52 AUC-val 0.636  AUC-train 0.970\n",
            "Stats - Epoch: 53 AUC-val 0.639  AUC-train 0.970\n",
            "Stats - Epoch: 54 AUC-val 0.625  AUC-train 0.970\n",
            "Stats - Epoch: 55 AUC-val 0.637  AUC-train 0.972\n",
            "Stats - Epoch: 56 AUC-val 0.649  AUC-train 0.970\n",
            "Stats - Epoch: 57 AUC-val 0.647  AUC-train 0.972\n",
            "Stats - Epoch: 58 AUC-val 0.636  AUC-train 0.973\n",
            "Stats - Epoch: 59 AUC-val 0.653  AUC-train 0.971\n",
            "Stats - Epoch: 60 AUC-val 0.652  AUC-train 0.969\n",
            "Stats - Epoch: 61 AUC-val 0.631  AUC-train 0.973\n",
            "Stats - Epoch: 62 AUC-val 0.663  AUC-train 0.976\n",
            "Stats - Epoch: 63 AUC-val 0.636  AUC-train 0.975\n",
            "Stats - Epoch: 64 AUC-val 0.678  AUC-train 0.973\n",
            "Stats - Epoch: 65 AUC-val 0.642  AUC-train 0.974\n",
            "Stats - Epoch: 66 AUC-val 0.655  AUC-train 0.976\n",
            "Stats - Epoch: 67 AUC-val 0.664  AUC-train 0.977\n",
            "Stats - Epoch: 68 AUC-val 0.671  AUC-train 0.978\n",
            "Stats - Epoch: 69 AUC-val 0.661  AUC-train 0.979\n",
            "Stats - Epoch: 70 AUC-val 0.661  AUC-train 0.978\n",
            "Stats - Epoch: 71 AUC-val 0.656  AUC-train 0.979\n",
            "Stats - Epoch: 72 AUC-val 0.648  AUC-train 0.978\n",
            "Stats - Epoch: 73 AUC-val 0.668  AUC-train 0.975\n",
            "Stats - Epoch: 74 AUC-val 0.654  AUC-train 0.977\n",
            "Stats - Epoch: 75 AUC-val 0.663  AUC-train 0.980\n",
            "Stats - Epoch: 76 AUC-val 0.653  AUC-train 0.981\n",
            "Stats - Epoch: 77 AUC-val 0.678  AUC-train 0.982\n",
            "Stats - Epoch: 78 AUC-val 0.653  AUC-train 0.980\n",
            "Stats - Epoch: 79 AUC-val 0.659  AUC-train 0.978\n",
            "Stats - Epoch: 80 AUC-val 0.655  AUC-train 0.981\n",
            "Stats - Epoch: 81 AUC-val 0.664  AUC-train 0.981\n",
            "Stats - Epoch: 82 AUC-val 0.654  AUC-train 0.982\n",
            "Stats - Epoch: 83 AUC-val 0.654  AUC-train 0.980\n",
            "Stats - Epoch: 84 AUC-val 0.644  AUC-train 0.983\n",
            "Stats - Epoch: 85 AUC-val 0.657  AUC-train 0.982\n",
            "Stats - Epoch: 86 AUC-val 0.675  AUC-train 0.983\n",
            "Stats - Epoch: 87 AUC-val 0.642  AUC-train 0.981\n",
            "Stats - Epoch: 88 AUC-val 0.653  AUC-train 0.982\n",
            "Stats - Epoch: 89 AUC-val 0.649  AUC-train 0.983\n",
            "Stats - Epoch: 90 AUC-val 0.654  AUC-train 0.985\n",
            "Stats - Epoch: 91 AUC-val 0.661  AUC-train 0.981\n",
            "Stats - Epoch: 92 AUC-val 0.642  AUC-train 0.982\n",
            "Stats - Epoch: 93 AUC-val 0.680  AUC-train 0.984\n",
            "Stats - Epoch: 94 AUC-val 0.662  AUC-train 0.985\n",
            "Stats - Epoch: 95 AUC-val 0.671  AUC-train 0.984\n",
            "Stats - Epoch: 96 AUC-val 0.661  AUC-train 0.986\n",
            "Stats - Epoch: 97 AUC-val 0.650  AUC-train 0.985\n",
            "Stats - Epoch: 98 AUC-val 0.654  AUC-train 0.984\n",
            "Stats - Epoch: 99 AUC-val 0.671  AUC-train 0.985\n",
            "Stats - Epoch: 100 AUC-val 0.672  AUC-train 0.987\n",
            "Results 100 AUC-val 0.574 0.654 0.680 0.617 0.665 AUC-train 0.984\n",
            "Shapley [0.01585163 0.01080824] [0.01721997]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.215688\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.481  AUC-train 0.522\n",
            "Stats - Epoch: 2 AUC-val 0.543  AUC-train 0.654\n",
            "Stats - Epoch: 3 AUC-val 0.587  AUC-train 0.695\n",
            "Stats - Epoch: 4 AUC-val 0.592  AUC-train 0.715\n",
            "Stats - Epoch: 5 AUC-val 0.589  AUC-train 0.727\n",
            "Stats - Epoch: 6 AUC-val 0.582  AUC-train 0.734\n",
            "Stats - Epoch: 7 AUC-val 0.581  AUC-train 0.739\n",
            "Stats - Epoch: 8 AUC-val 0.577  AUC-train 0.744\n",
            "Stats - Epoch: 9 AUC-val 0.568  AUC-train 0.748\n",
            "Stats - Epoch: 10 AUC-val 0.570  AUC-train 0.753\n",
            "Stats - Epoch: 11 AUC-val 0.566  AUC-train 0.755\n",
            "Stats - Epoch: 12 AUC-val 0.567  AUC-train 0.760\n",
            "Stats - Epoch: 13 AUC-val 0.561  AUC-train 0.760\n",
            "Stats - Epoch: 14 AUC-val 0.563  AUC-train 0.767\n",
            "Stats - Epoch: 15 AUC-val 0.561  AUC-train 0.768\n",
            "Stats - Epoch: 16 AUC-val 0.558  AUC-train 0.771\n",
            "Stats - Epoch: 17 AUC-val 0.550  AUC-train 0.774\n",
            "Stats - Epoch: 18 AUC-val 0.546  AUC-train 0.778\n",
            "Stats - Epoch: 19 AUC-val 0.548  AUC-train 0.778\n",
            "Stats - Epoch: 20 AUC-val 0.551  AUC-train 0.782\n",
            "Stats - Epoch: 21 AUC-val 0.547  AUC-train 0.782\n",
            "Stats - Epoch: 22 AUC-val 0.549  AUC-train 0.786\n",
            "Stats - Epoch: 23 AUC-val 0.546  AUC-train 0.790\n",
            "Stats - Epoch: 24 AUC-val 0.541  AUC-train 0.788\n",
            "Stats - Epoch: 25 AUC-val 0.538  AUC-train 0.791\n",
            "Stats - Epoch: 26 AUC-val 0.538  AUC-train 0.795\n",
            "Stats - Epoch: 27 AUC-val 0.543  AUC-train 0.798\n",
            "Stats - Epoch: 28 AUC-val 0.549  AUC-train 0.801\n",
            "Stats - Epoch: 29 AUC-val 0.541  AUC-train 0.802\n",
            "Stats - Epoch: 30 AUC-val 0.537  AUC-train 0.804\n",
            "Stats - Epoch: 31 AUC-val 0.537  AUC-train 0.806\n",
            "Stats - Epoch: 32 AUC-val 0.541  AUC-train 0.807\n",
            "Stats - Epoch: 33 AUC-val 0.529  AUC-train 0.808\n",
            "Stats - Epoch: 34 AUC-val 0.529  AUC-train 0.809\n",
            "Stats - Epoch: 35 AUC-val 0.537  AUC-train 0.810\n",
            "Stats - Epoch: 36 AUC-val 0.537  AUC-train 0.813\n",
            "Stats - Epoch: 37 AUC-val 0.523  AUC-train 0.815\n",
            "Stats - Epoch: 38 AUC-val 0.525  AUC-train 0.813\n",
            "Stats - Epoch: 39 AUC-val 0.544  AUC-train 0.816\n",
            "Stats - Epoch: 40 AUC-val 0.530  AUC-train 0.819\n",
            "Stats - Epoch: 41 AUC-val 0.533  AUC-train 0.818\n",
            "Stats - Epoch: 42 AUC-val 0.527  AUC-train 0.822\n",
            "Stats - Epoch: 43 AUC-val 0.523  AUC-train 0.825\n",
            "Stats - Epoch: 44 AUC-val 0.530  AUC-train 0.827\n",
            "Stats - Epoch: 45 AUC-val 0.530  AUC-train 0.825\n",
            "Stats - Epoch: 46 AUC-val 0.511  AUC-train 0.825\n",
            "Stats - Epoch: 47 AUC-val 0.523  AUC-train 0.828\n",
            "Stats - Epoch: 48 AUC-val 0.518  AUC-train 0.829\n",
            "Stats - Epoch: 49 AUC-val 0.515  AUC-train 0.833\n",
            "Stats - Epoch: 50 AUC-val 0.520  AUC-train 0.830\n",
            "Stats - Epoch: 51 AUC-val 0.514  AUC-train 0.832\n",
            "Stats - Epoch: 52 AUC-val 0.530  AUC-train 0.835\n",
            "Stats - Epoch: 53 AUC-val 0.525  AUC-train 0.836\n",
            "Stats - Epoch: 54 AUC-val 0.508  AUC-train 0.834\n",
            "Stats - Epoch: 55 AUC-val 0.552  AUC-train 0.831\n",
            "Stats - Epoch: 56 AUC-val 0.522  AUC-train 0.835\n",
            "Stats - Epoch: 57 AUC-val 0.527  AUC-train 0.836\n",
            "Stats - Epoch: 58 AUC-val 0.515  AUC-train 0.838\n",
            "Stats - Epoch: 59 AUC-val 0.530  AUC-train 0.838\n",
            "Stats - Epoch: 60 AUC-val 0.531  AUC-train 0.839\n",
            "Stats - Epoch: 61 AUC-val 0.510  AUC-train 0.840\n",
            "Stats - Epoch: 62 AUC-val 0.524  AUC-train 0.841\n",
            "Stats - Epoch: 63 AUC-val 0.513  AUC-train 0.842\n",
            "Stats - Epoch: 64 AUC-val 0.510  AUC-train 0.839\n",
            "Stats - Epoch: 65 AUC-val 0.504  AUC-train 0.840\n",
            "Stats - Epoch: 66 AUC-val 0.508  AUC-train 0.838\n",
            "Stats - Epoch: 67 AUC-val 0.505  AUC-train 0.841\n",
            "Stats - Epoch: 68 AUC-val 0.515  AUC-train 0.844\n",
            "Stats - Epoch: 69 AUC-val 0.506  AUC-train 0.844\n",
            "Stats - Epoch: 70 AUC-val 0.511  AUC-train 0.843\n",
            "Stats - Epoch: 71 AUC-val 0.507  AUC-train 0.844\n",
            "Stats - Epoch: 72 AUC-val 0.498  AUC-train 0.845\n",
            "Stats - Epoch: 73 AUC-val 0.492  AUC-train 0.849\n",
            "Stats - Epoch: 74 AUC-val 0.493  AUC-train 0.848\n",
            "Stats - Epoch: 75 AUC-val 0.498  AUC-train 0.850\n",
            "Stats - Epoch: 76 AUC-val 0.510  AUC-train 0.850\n",
            "Stats - Epoch: 77 AUC-val 0.508  AUC-train 0.852\n",
            "Stats - Epoch: 78 AUC-val 0.504  AUC-train 0.855\n",
            "Stats - Epoch: 79 AUC-val 0.489  AUC-train 0.857\n",
            "Stats - Epoch: 80 AUC-val 0.493  AUC-train 0.856\n",
            "Stats - Epoch: 81 AUC-val 0.498  AUC-train 0.855\n",
            "Stats - Epoch: 82 AUC-val 0.498  AUC-train 0.857\n",
            "Stats - Epoch: 83 AUC-val 0.492  AUC-train 0.858\n",
            "Stats - Epoch: 84 AUC-val 0.497  AUC-train 0.860\n",
            "Stats - Epoch: 85 AUC-val 0.498  AUC-train 0.859\n",
            "Stats - Epoch: 86 AUC-val 0.488  AUC-train 0.860\n",
            "Stats - Epoch: 87 AUC-val 0.497  AUC-train 0.859\n",
            "Stats - Epoch: 88 AUC-val 0.497  AUC-train 0.860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 89 AUC-val 0.509  AUC-train 0.863\n",
            "Stats - Epoch: 90 AUC-val 0.479  AUC-train 0.861\n",
            "Stats - Epoch: 91 AUC-val 0.490  AUC-train 0.864\n",
            "Stats - Epoch: 92 AUC-val 0.490  AUC-train 0.867\n",
            "Stats - Epoch: 93 AUC-val 0.507  AUC-train 0.869\n",
            "Stats - Epoch: 94 AUC-val 0.489  AUC-train 0.867\n",
            "Stats - Epoch: 95 AUC-val 0.498  AUC-train 0.865\n",
            "Stats - Epoch: 96 AUC-val 0.473  AUC-train 0.867\n",
            "Stats - Epoch: 97 AUC-val 0.504  AUC-train 0.869\n",
            "Stats - Epoch: 98 AUC-val 0.489  AUC-train 0.870\n",
            "Stats - Epoch: 99 AUC-val 0.495  AUC-train 0.871\n",
            "Stats - Epoch: 100 AUC-val 0.487  AUC-train 0.872\n",
            "Results 100 AUC-val 0.700 0.642 0.592 0.498 0.482 AUC-train 0.715\n",
            "Shapley [0.01207929 0.00877604] [0.01842409]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.219967\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.401  AUC-train 0.546\n",
            "Stats - Epoch: 2 AUC-val 0.471  AUC-train 0.677\n",
            "Stats - Epoch: 3 AUC-val 0.514  AUC-train 0.714\n",
            "Stats - Epoch: 4 AUC-val 0.517  AUC-train 0.733\n",
            "Stats - Epoch: 5 AUC-val 0.508  AUC-train 0.746\n",
            "Stats - Epoch: 6 AUC-val 0.500  AUC-train 0.753\n",
            "Stats - Epoch: 7 AUC-val 0.486  AUC-train 0.760\n",
            "Stats - Epoch: 8 AUC-val 0.471  AUC-train 0.768\n",
            "Stats - Epoch: 9 AUC-val 0.464  AUC-train 0.776\n",
            "Stats - Epoch: 10 AUC-val 0.464  AUC-train 0.782\n",
            "Stats - Epoch: 11 AUC-val 0.459  AUC-train 0.787\n",
            "Stats - Epoch: 12 AUC-val 0.452  AUC-train 0.793\n",
            "Stats - Epoch: 13 AUC-val 0.452  AUC-train 0.795\n",
            "Stats - Epoch: 14 AUC-val 0.451  AUC-train 0.801\n",
            "Stats - Epoch: 15 AUC-val 0.455  AUC-train 0.806\n",
            "Stats - Epoch: 16 AUC-val 0.446  AUC-train 0.807\n",
            "Stats - Epoch: 17 AUC-val 0.438  AUC-train 0.810\n",
            "Stats - Epoch: 18 AUC-val 0.444  AUC-train 0.812\n",
            "Stats - Epoch: 19 AUC-val 0.440  AUC-train 0.814\n",
            "Stats - Epoch: 20 AUC-val 0.447  AUC-train 0.818\n",
            "Stats - Epoch: 21 AUC-val 0.456  AUC-train 0.822\n",
            "Stats - Epoch: 22 AUC-val 0.446  AUC-train 0.826\n",
            "Stats - Epoch: 23 AUC-val 0.447  AUC-train 0.826\n",
            "Stats - Epoch: 24 AUC-val 0.467  AUC-train 0.830\n",
            "Stats - Epoch: 25 AUC-val 0.468  AUC-train 0.832\n",
            "Stats - Epoch: 26 AUC-val 0.459  AUC-train 0.833\n",
            "Stats - Epoch: 27 AUC-val 0.465  AUC-train 0.833\n",
            "Stats - Epoch: 28 AUC-val 0.457  AUC-train 0.837\n",
            "Stats - Epoch: 29 AUC-val 0.462  AUC-train 0.839\n",
            "Stats - Epoch: 30 AUC-val 0.468  AUC-train 0.841\n",
            "Stats - Epoch: 31 AUC-val 0.472  AUC-train 0.843\n",
            "Stats - Epoch: 32 AUC-val 0.474  AUC-train 0.846\n",
            "Stats - Epoch: 33 AUC-val 0.476  AUC-train 0.848\n",
            "Stats - Epoch: 34 AUC-val 0.477  AUC-train 0.852\n",
            "Stats - Epoch: 35 AUC-val 0.479  AUC-train 0.858\n",
            "Stats - Epoch: 36 AUC-val 0.479  AUC-train 0.857\n",
            "Stats - Epoch: 37 AUC-val 0.471  AUC-train 0.853\n",
            "Stats - Epoch: 38 AUC-val 0.493  AUC-train 0.860\n",
            "Stats - Epoch: 39 AUC-val 0.503  AUC-train 0.866\n",
            "Stats - Epoch: 40 AUC-val 0.500  AUC-train 0.868\n",
            "Stats - Epoch: 41 AUC-val 0.498  AUC-train 0.870\n",
            "Stats - Epoch: 42 AUC-val 0.511  AUC-train 0.874\n",
            "Stats - Epoch: 43 AUC-val 0.506  AUC-train 0.871\n",
            "Stats - Epoch: 44 AUC-val 0.506  AUC-train 0.874\n",
            "Stats - Epoch: 45 AUC-val 0.489  AUC-train 0.872\n",
            "Stats - Epoch: 46 AUC-val 0.506  AUC-train 0.876\n",
            "Stats - Epoch: 47 AUC-val 0.522  AUC-train 0.880\n",
            "Stats - Epoch: 48 AUC-val 0.510  AUC-train 0.878\n",
            "Stats - Epoch: 49 AUC-val 0.521  AUC-train 0.881\n",
            "Stats - Epoch: 50 AUC-val 0.532  AUC-train 0.882\n",
            "Stats - Epoch: 51 AUC-val 0.521  AUC-train 0.878\n",
            "Stats - Epoch: 52 AUC-val 0.528  AUC-train 0.885\n",
            "Stats - Epoch: 53 AUC-val 0.523  AUC-train 0.887\n",
            "Stats - Epoch: 54 AUC-val 0.542  AUC-train 0.888\n",
            "Stats - Epoch: 55 AUC-val 0.535  AUC-train 0.892\n",
            "Stats - Epoch: 56 AUC-val 0.535  AUC-train 0.890\n",
            "Stats - Epoch: 57 AUC-val 0.537  AUC-train 0.895\n",
            "Stats - Epoch: 58 AUC-val 0.542  AUC-train 0.898\n",
            "Stats - Epoch: 59 AUC-val 0.537  AUC-train 0.899\n",
            "Stats - Epoch: 60 AUC-val 0.541  AUC-train 0.900\n",
            "Stats - Epoch: 61 AUC-val 0.524  AUC-train 0.900\n",
            "Stats - Epoch: 62 AUC-val 0.527  AUC-train 0.902\n",
            "Stats - Epoch: 63 AUC-val 0.533  AUC-train 0.905\n",
            "Stats - Epoch: 64 AUC-val 0.521  AUC-train 0.907\n",
            "Stats - Epoch: 65 AUC-val 0.535  AUC-train 0.910\n",
            "Stats - Epoch: 66 AUC-val 0.524  AUC-train 0.910\n",
            "Stats - Epoch: 67 AUC-val 0.538  AUC-train 0.907\n",
            "Stats - Epoch: 68 AUC-val 0.534  AUC-train 0.910\n",
            "Stats - Epoch: 69 AUC-val 0.544  AUC-train 0.913\n",
            "Stats - Epoch: 70 AUC-val 0.539  AUC-train 0.914\n",
            "Stats - Epoch: 71 AUC-val 0.541  AUC-train 0.917\n",
            "Stats - Epoch: 72 AUC-val 0.514  AUC-train 0.918\n",
            "Stats - Epoch: 73 AUC-val 0.532  AUC-train 0.919\n",
            "Stats - Epoch: 74 AUC-val 0.541  AUC-train 0.921\n",
            "Stats - Epoch: 75 AUC-val 0.521  AUC-train 0.921\n",
            "Stats - Epoch: 76 AUC-val 0.540  AUC-train 0.921\n",
            "Stats - Epoch: 77 AUC-val 0.541  AUC-train 0.924\n",
            "Stats - Epoch: 78 AUC-val 0.540  AUC-train 0.924\n",
            "Stats - Epoch: 79 AUC-val 0.540  AUC-train 0.927\n",
            "Stats - Epoch: 80 AUC-val 0.552  AUC-train 0.925\n",
            "Stats - Epoch: 81 AUC-val 0.540  AUC-train 0.925\n",
            "Stats - Epoch: 82 AUC-val 0.535  AUC-train 0.923\n",
            "Stats - Epoch: 83 AUC-val 0.520  AUC-train 0.927\n",
            "Stats - Epoch: 84 AUC-val 0.540  AUC-train 0.928\n",
            "Stats - Epoch: 85 AUC-val 0.537  AUC-train 0.931\n",
            "Stats - Epoch: 86 AUC-val 0.516  AUC-train 0.928\n",
            "Stats - Epoch: 87 AUC-val 0.547  AUC-train 0.932\n",
            "Stats - Epoch: 88 AUC-val 0.545  AUC-train 0.932\n",
            "Stats - Epoch: 89 AUC-val 0.538  AUC-train 0.934\n",
            "Stats - Epoch: 90 AUC-val 0.538  AUC-train 0.934\n",
            "Stats - Epoch: 91 AUC-val 0.549  AUC-train 0.937\n",
            "Stats - Epoch: 92 AUC-val 0.553  AUC-train 0.938\n",
            "Stats - Epoch: 93 AUC-val 0.543  AUC-train 0.938\n",
            "Stats - Epoch: 94 AUC-val 0.558  AUC-train 0.939\n",
            "Stats - Epoch: 95 AUC-val 0.545  AUC-train 0.941\n",
            "Stats - Epoch: 96 AUC-val 0.549  AUC-train 0.941\n",
            "Stats - Epoch: 97 AUC-val 0.562  AUC-train 0.943\n",
            "Stats - Epoch: 98 AUC-val 0.555  AUC-train 0.943\n",
            "Stats - Epoch: 99 AUC-val 0.547  AUC-train 0.941\n",
            "Stats - Epoch: 100 AUC-val 0.555  AUC-train 0.942\n",
            "Results 100 AUC-val 0.605 0.538 0.562 0.553 0.534 AUC-train 0.943\n",
            "Shapley [0.02341761 0.01388282] [0.00942033]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.222843\n",
            "         Iterations 7\n",
            "['rsp_g', 'rhp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.387  AUC-train 0.561\n",
            "Stats - Epoch: 2 AUC-val 0.605  AUC-train 0.658\n",
            "Stats - Epoch: 3 AUC-val 0.739  AUC-train 0.735\n",
            "Stats - Epoch: 4 AUC-val 0.772  AUC-train 0.771\n",
            "Stats - Epoch: 5 AUC-val 0.791  AUC-train 0.797\n",
            "Stats - Epoch: 6 AUC-val 0.808  AUC-train 0.817\n",
            "Stats - Epoch: 7 AUC-val 0.822  AUC-train 0.831\n",
            "Stats - Epoch: 8 AUC-val 0.835  AUC-train 0.847\n",
            "Stats - Epoch: 9 AUC-val 0.842  AUC-train 0.860\n",
            "Stats - Epoch: 10 AUC-val 0.840  AUC-train 0.866\n",
            "Stats - Epoch: 11 AUC-val 0.842  AUC-train 0.876\n",
            "Stats - Epoch: 12 AUC-val 0.844  AUC-train 0.884\n",
            "Stats - Epoch: 13 AUC-val 0.847  AUC-train 0.893\n",
            "Stats - Epoch: 14 AUC-val 0.866  AUC-train 0.905\n",
            "Stats - Epoch: 15 AUC-val 0.876  AUC-train 0.911\n",
            "Stats - Epoch: 16 AUC-val 0.868  AUC-train 0.920\n",
            "Stats - Epoch: 17 AUC-val 0.864  AUC-train 0.925\n",
            "Stats - Epoch: 18 AUC-val 0.867  AUC-train 0.932\n",
            "Stats - Epoch: 19 AUC-val 0.880  AUC-train 0.939\n",
            "Stats - Epoch: 20 AUC-val 0.870  AUC-train 0.942\n",
            "Stats - Epoch: 21 AUC-val 0.887  AUC-train 0.949\n",
            "Stats - Epoch: 22 AUC-val 0.878  AUC-train 0.951\n",
            "Stats - Epoch: 23 AUC-val 0.879  AUC-train 0.954\n",
            "Stats - Epoch: 24 AUC-val 0.886  AUC-train 0.957\n",
            "Stats - Epoch: 25 AUC-val 0.874  AUC-train 0.959\n",
            "Stats - Epoch: 26 AUC-val 0.881  AUC-train 0.961\n",
            "Stats - Epoch: 27 AUC-val 0.866  AUC-train 0.963\n",
            "Stats - Epoch: 28 AUC-val 0.878  AUC-train 0.966\n",
            "Stats - Epoch: 29 AUC-val 0.870  AUC-train 0.966\n",
            "Stats - Epoch: 30 AUC-val 0.881  AUC-train 0.966\n",
            "Stats - Epoch: 31 AUC-val 0.873  AUC-train 0.969\n",
            "Stats - Epoch: 32 AUC-val 0.875  AUC-train 0.970\n",
            "Stats - Epoch: 33 AUC-val 0.874  AUC-train 0.973\n",
            "Stats - Epoch: 34 AUC-val 0.870  AUC-train 0.974\n",
            "Stats - Epoch: 35 AUC-val 0.860  AUC-train 0.978\n",
            "Stats - Epoch: 36 AUC-val 0.862  AUC-train 0.976\n",
            "Stats - Epoch: 37 AUC-val 0.851  AUC-train 0.980\n",
            "Stats - Epoch: 38 AUC-val 0.874  AUC-train 0.979\n",
            "Stats - Epoch: 39 AUC-val 0.871  AUC-train 0.978\n",
            "Stats - Epoch: 40 AUC-val 0.874  AUC-train 0.982\n",
            "Stats - Epoch: 41 AUC-val 0.868  AUC-train 0.982\n",
            "Stats - Epoch: 42 AUC-val 0.852  AUC-train 0.982\n",
            "Stats - Epoch: 43 AUC-val 0.860  AUC-train 0.981\n",
            "Stats - Epoch: 44 AUC-val 0.852  AUC-train 0.982\n",
            "Stats - Epoch: 45 AUC-val 0.853  AUC-train 0.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 46 AUC-val 0.853  AUC-train 0.985\n",
            "Stats - Epoch: 47 AUC-val 0.863  AUC-train 0.987\n",
            "Stats - Epoch: 48 AUC-val 0.855  AUC-train 0.986\n",
            "Stats - Epoch: 49 AUC-val 0.855  AUC-train 0.985\n",
            "Stats - Epoch: 50 AUC-val 0.867  AUC-train 0.985\n",
            "Stats - Epoch: 51 AUC-val 0.871  AUC-train 0.985\n",
            "Stats - Epoch: 52 AUC-val 0.851  AUC-train 0.988\n",
            "Stats - Epoch: 53 AUC-val 0.855  AUC-train 0.987\n",
            "Stats - Epoch: 54 AUC-val 0.850  AUC-train 0.988\n",
            "Stats - Epoch: 55 AUC-val 0.855  AUC-train 0.990\n",
            "Stats - Epoch: 56 AUC-val 0.857  AUC-train 0.989\n",
            "Stats - Epoch: 57 AUC-val 0.853  AUC-train 0.990\n",
            "Stats - Epoch: 58 AUC-val 0.854  AUC-train 0.991\n",
            "Stats - Epoch: 59 AUC-val 0.853  AUC-train 0.990\n",
            "Stats - Epoch: 60 AUC-val 0.837  AUC-train 0.990\n",
            "Stats - Epoch: 61 AUC-val 0.848  AUC-train 0.989\n",
            "Stats - Epoch: 62 AUC-val 0.827  AUC-train 0.990\n",
            "Stats - Epoch: 63 AUC-val 0.843  AUC-train 0.992\n",
            "Stats - Epoch: 64 AUC-val 0.836  AUC-train 0.992\n",
            "Stats - Epoch: 65 AUC-val 0.826  AUC-train 0.993\n",
            "Stats - Epoch: 66 AUC-val 0.847  AUC-train 0.993\n",
            "Stats - Epoch: 67 AUC-val 0.836  AUC-train 0.993\n",
            "Stats - Epoch: 68 AUC-val 0.805  AUC-train 0.993\n",
            "Stats - Epoch: 69 AUC-val 0.815  AUC-train 0.995\n",
            "Stats - Epoch: 70 AUC-val 0.833  AUC-train 0.993\n",
            "Stats - Epoch: 71 AUC-val 0.819  AUC-train 0.994\n",
            "Stats - Epoch: 72 AUC-val 0.845  AUC-train 0.994\n",
            "Stats - Epoch: 73 AUC-val 0.828  AUC-train 0.994\n",
            "Stats - Epoch: 74 AUC-val 0.840  AUC-train 0.991\n",
            "Stats - Epoch: 75 AUC-val 0.827  AUC-train 0.992\n",
            "Stats - Epoch: 76 AUC-val 0.826  AUC-train 0.994\n",
            "Stats - Epoch: 77 AUC-val 0.834  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.818  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.819  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.825  AUC-train 0.994\n",
            "Stats - Epoch: 81 AUC-val 0.816  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.836  AUC-train 0.992\n",
            "Stats - Epoch: 83 AUC-val 0.825  AUC-train 0.992\n",
            "Stats - Epoch: 84 AUC-val 0.821  AUC-train 0.991\n",
            "Stats - Epoch: 85 AUC-val 0.802  AUC-train 0.992\n",
            "Stats - Epoch: 86 AUC-val 0.837  AUC-train 0.993\n",
            "Stats - Epoch: 87 AUC-val 0.811  AUC-train 0.993\n",
            "Stats - Epoch: 88 AUC-val 0.812  AUC-train 0.994\n",
            "Stats - Epoch: 89 AUC-val 0.789  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.833  AUC-train 0.992\n",
            "Stats - Epoch: 91 AUC-val 0.795  AUC-train 0.995\n",
            "Stats - Epoch: 92 AUC-val 0.803  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.787  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.834  AUC-train 0.997\n",
            "Stats - Epoch: 95 AUC-val 0.796  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.802  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.812  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.800  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.794  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.834  AUC-train 0.997\n",
            "Results 100 AUC-val 0.626 0.813 0.887 0.797 0.554 AUC-train 0.949\n",
            "Shapley [0.01451898 0.01439553] [0.00699934]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.173532\n",
            "         Iterations 8\n",
            "['rsp_g', 'ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.425  AUC-train 0.523\n",
            "Stats - Epoch: 2 AUC-val 0.578  AUC-train 0.616\n",
            "Stats - Epoch: 3 AUC-val 0.679  AUC-train 0.688\n",
            "Stats - Epoch: 4 AUC-val 0.699  AUC-train 0.727\n",
            "Stats - Epoch: 5 AUC-val 0.706  AUC-train 0.753\n",
            "Stats - Epoch: 6 AUC-val 0.702  AUC-train 0.771\n",
            "Stats - Epoch: 7 AUC-val 0.662  AUC-train 0.786\n",
            "Stats - Epoch: 8 AUC-val 0.705  AUC-train 0.800\n",
            "Stats - Epoch: 9 AUC-val 0.683  AUC-train 0.818\n",
            "Stats - Epoch: 10 AUC-val 0.681  AUC-train 0.823\n",
            "Stats - Epoch: 11 AUC-val 0.688  AUC-train 0.834\n",
            "Stats - Epoch: 12 AUC-val 0.700  AUC-train 0.848\n",
            "Stats - Epoch: 13 AUC-val 0.692  AUC-train 0.851\n",
            "Stats - Epoch: 14 AUC-val 0.673  AUC-train 0.861\n",
            "Stats - Epoch: 15 AUC-val 0.703  AUC-train 0.868\n",
            "Stats - Epoch: 16 AUC-val 0.710  AUC-train 0.877\n",
            "Stats - Epoch: 17 AUC-val 0.699  AUC-train 0.882\n",
            "Stats - Epoch: 18 AUC-val 0.699  AUC-train 0.885\n",
            "Stats - Epoch: 19 AUC-val 0.693  AUC-train 0.889\n",
            "Stats - Epoch: 20 AUC-val 0.702  AUC-train 0.894\n",
            "Stats - Epoch: 21 AUC-val 0.684  AUC-train 0.899\n",
            "Stats - Epoch: 22 AUC-val 0.692  AUC-train 0.902\n",
            "Stats - Epoch: 23 AUC-val 0.688  AUC-train 0.909\n",
            "Stats - Epoch: 24 AUC-val 0.690  AUC-train 0.909\n",
            "Stats - Epoch: 25 AUC-val 0.685  AUC-train 0.915\n",
            "Stats - Epoch: 26 AUC-val 0.690  AUC-train 0.917\n",
            "Stats - Epoch: 27 AUC-val 0.673  AUC-train 0.925\n",
            "Stats - Epoch: 28 AUC-val 0.692  AUC-train 0.926\n",
            "Stats - Epoch: 29 AUC-val 0.682  AUC-train 0.929\n",
            "Stats - Epoch: 30 AUC-val 0.689  AUC-train 0.932\n",
            "Stats - Epoch: 31 AUC-val 0.691  AUC-train 0.935\n",
            "Stats - Epoch: 32 AUC-val 0.691  AUC-train 0.933\n",
            "Stats - Epoch: 33 AUC-val 0.665  AUC-train 0.940\n",
            "Stats - Epoch: 34 AUC-val 0.670  AUC-train 0.943\n",
            "Stats - Epoch: 35 AUC-val 0.670  AUC-train 0.945\n",
            "Stats - Epoch: 36 AUC-val 0.655  AUC-train 0.944\n",
            "Stats - Epoch: 37 AUC-val 0.658  AUC-train 0.949\n",
            "Stats - Epoch: 38 AUC-val 0.655  AUC-train 0.952\n",
            "Stats - Epoch: 39 AUC-val 0.646  AUC-train 0.954\n",
            "Stats - Epoch: 40 AUC-val 0.649  AUC-train 0.955\n",
            "Stats - Epoch: 41 AUC-val 0.662  AUC-train 0.949\n",
            "Stats - Epoch: 42 AUC-val 0.654  AUC-train 0.957\n",
            "Stats - Epoch: 43 AUC-val 0.632  AUC-train 0.959\n",
            "Stats - Epoch: 44 AUC-val 0.646  AUC-train 0.961\n",
            "Stats - Epoch: 45 AUC-val 0.627  AUC-train 0.962\n",
            "Stats - Epoch: 46 AUC-val 0.640  AUC-train 0.964\n",
            "Stats - Epoch: 47 AUC-val 0.621  AUC-train 0.967\n",
            "Stats - Epoch: 48 AUC-val 0.617  AUC-train 0.967\n",
            "Stats - Epoch: 49 AUC-val 0.627  AUC-train 0.967\n",
            "Stats - Epoch: 50 AUC-val 0.624  AUC-train 0.963\n",
            "Stats - Epoch: 51 AUC-val 0.628  AUC-train 0.969\n",
            "Stats - Epoch: 52 AUC-val 0.611  AUC-train 0.968\n",
            "Stats - Epoch: 53 AUC-val 0.629  AUC-train 0.965\n",
            "Stats - Epoch: 54 AUC-val 0.632  AUC-train 0.969\n",
            "Stats - Epoch: 55 AUC-val 0.623  AUC-train 0.971\n",
            "Stats - Epoch: 56 AUC-val 0.630  AUC-train 0.970\n",
            "Stats - Epoch: 57 AUC-val 0.643  AUC-train 0.973\n",
            "Stats - Epoch: 58 AUC-val 0.638  AUC-train 0.973\n",
            "Stats - Epoch: 59 AUC-val 0.623  AUC-train 0.974\n",
            "Stats - Epoch: 60 AUC-val 0.655  AUC-train 0.975\n",
            "Stats - Epoch: 61 AUC-val 0.632  AUC-train 0.974\n",
            "Stats - Epoch: 62 AUC-val 0.637  AUC-train 0.976\n",
            "Stats - Epoch: 63 AUC-val 0.618  AUC-train 0.978\n",
            "Stats - Epoch: 64 AUC-val 0.616  AUC-train 0.978\n",
            "Stats - Epoch: 65 AUC-val 0.611  AUC-train 0.979\n",
            "Stats - Epoch: 66 AUC-val 0.629  AUC-train 0.979\n",
            "Stats - Epoch: 67 AUC-val 0.625  AUC-train 0.980\n",
            "Stats - Epoch: 68 AUC-val 0.633  AUC-train 0.980\n",
            "Stats - Epoch: 69 AUC-val 0.618  AUC-train 0.980\n",
            "Stats - Epoch: 70 AUC-val 0.648  AUC-train 0.979\n",
            "Stats - Epoch: 71 AUC-val 0.625  AUC-train 0.980\n",
            "Stats - Epoch: 72 AUC-val 0.611  AUC-train 0.980\n",
            "Stats - Epoch: 73 AUC-val 0.663  AUC-train 0.978\n",
            "Stats - Epoch: 74 AUC-val 0.651  AUC-train 0.981\n",
            "Stats - Epoch: 75 AUC-val 0.634  AUC-train 0.980\n",
            "Stats - Epoch: 76 AUC-val 0.620  AUC-train 0.982\n",
            "Stats - Epoch: 77 AUC-val 0.627  AUC-train 0.983\n",
            "Stats - Epoch: 78 AUC-val 0.626  AUC-train 0.982\n",
            "Stats - Epoch: 79 AUC-val 0.614  AUC-train 0.980\n",
            "Stats - Epoch: 80 AUC-val 0.630  AUC-train 0.981\n",
            "Stats - Epoch: 81 AUC-val 0.620  AUC-train 0.983\n",
            "Stats - Epoch: 82 AUC-val 0.623  AUC-train 0.983\n",
            "Stats - Epoch: 83 AUC-val 0.602  AUC-train 0.984\n",
            "Stats - Epoch: 84 AUC-val 0.599  AUC-train 0.978\n",
            "Stats - Epoch: 85 AUC-val 0.613  AUC-train 0.981\n",
            "Stats - Epoch: 86 AUC-val 0.610  AUC-train 0.983\n",
            "Stats - Epoch: 87 AUC-val 0.633  AUC-train 0.981\n",
            "Stats - Epoch: 88 AUC-val 0.604  AUC-train 0.981\n",
            "Stats - Epoch: 89 AUC-val 0.588  AUC-train 0.981\n",
            "Stats - Epoch: 90 AUC-val 0.591  AUC-train 0.983\n",
            "Stats - Epoch: 91 AUC-val 0.616  AUC-train 0.983\n",
            "Stats - Epoch: 92 AUC-val 0.604  AUC-train 0.983\n",
            "Stats - Epoch: 93 AUC-val 0.601  AUC-train 0.983\n",
            "Stats - Epoch: 94 AUC-val 0.598  AUC-train 0.983\n",
            "Stats - Epoch: 95 AUC-val 0.612  AUC-train 0.986\n",
            "Stats - Epoch: 96 AUC-val 0.600  AUC-train 0.986\n",
            "Stats - Epoch: 97 AUC-val 0.616  AUC-train 0.987\n",
            "Stats - Epoch: 98 AUC-val 0.609  AUC-train 0.986\n",
            "Stats - Epoch: 99 AUC-val 0.595  AUC-train 0.986\n",
            "Stats - Epoch: 100 AUC-val 0.589  AUC-train 0.988\n",
            "Results 100 AUC-val 0.631 0.672 0.710 0.606 0.370 AUC-train 0.877\n",
            "Shapley [0.06511972 0.04761127] [0.07181467]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.196638\n",
            "         Iterations 8\n",
            "['rsp_g', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.351  AUC-train 0.493\n",
            "Stats - Epoch: 2 AUC-val 0.531  AUC-train 0.592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 3 AUC-val 0.616  AUC-train 0.667\n",
            "Stats - Epoch: 4 AUC-val 0.653  AUC-train 0.706\n",
            "Stats - Epoch: 5 AUC-val 0.658  AUC-train 0.733\n",
            "Stats - Epoch: 6 AUC-val 0.717  AUC-train 0.749\n",
            "Stats - Epoch: 7 AUC-val 0.742  AUC-train 0.774\n",
            "Stats - Epoch: 8 AUC-val 0.770  AUC-train 0.789\n",
            "Stats - Epoch: 9 AUC-val 0.783  AUC-train 0.807\n",
            "Stats - Epoch: 10 AUC-val 0.797  AUC-train 0.816\n",
            "Stats - Epoch: 11 AUC-val 0.819  AUC-train 0.825\n",
            "Stats - Epoch: 12 AUC-val 0.825  AUC-train 0.835\n",
            "Stats - Epoch: 13 AUC-val 0.825  AUC-train 0.844\n",
            "Stats - Epoch: 14 AUC-val 0.839  AUC-train 0.854\n",
            "Stats - Epoch: 15 AUC-val 0.846  AUC-train 0.866\n",
            "Stats - Epoch: 16 AUC-val 0.840  AUC-train 0.876\n",
            "Stats - Epoch: 17 AUC-val 0.833  AUC-train 0.883\n",
            "Stats - Epoch: 18 AUC-val 0.864  AUC-train 0.889\n",
            "Stats - Epoch: 19 AUC-val 0.839  AUC-train 0.894\n",
            "Stats - Epoch: 20 AUC-val 0.845  AUC-train 0.900\n",
            "Stats - Epoch: 21 AUC-val 0.833  AUC-train 0.910\n",
            "Stats - Epoch: 22 AUC-val 0.865  AUC-train 0.915\n",
            "Stats - Epoch: 23 AUC-val 0.846  AUC-train 0.920\n",
            "Stats - Epoch: 24 AUC-val 0.861  AUC-train 0.924\n",
            "Stats - Epoch: 25 AUC-val 0.850  AUC-train 0.929\n",
            "Stats - Epoch: 26 AUC-val 0.851  AUC-train 0.933\n",
            "Stats - Epoch: 27 AUC-val 0.859  AUC-train 0.936\n",
            "Stats - Epoch: 28 AUC-val 0.837  AUC-train 0.944\n",
            "Stats - Epoch: 29 AUC-val 0.847  AUC-train 0.947\n",
            "Stats - Epoch: 30 AUC-val 0.869  AUC-train 0.949\n",
            "Stats - Epoch: 31 AUC-val 0.837  AUC-train 0.954\n",
            "Stats - Epoch: 32 AUC-val 0.847  AUC-train 0.955\n",
            "Stats - Epoch: 33 AUC-val 0.832  AUC-train 0.957\n",
            "Stats - Epoch: 34 AUC-val 0.849  AUC-train 0.959\n",
            "Stats - Epoch: 35 AUC-val 0.831  AUC-train 0.965\n",
            "Stats - Epoch: 36 AUC-val 0.826  AUC-train 0.966\n",
            "Stats - Epoch: 37 AUC-val 0.808  AUC-train 0.968\n",
            "Stats - Epoch: 38 AUC-val 0.808  AUC-train 0.969\n",
            "Stats - Epoch: 39 AUC-val 0.806  AUC-train 0.973\n",
            "Stats - Epoch: 40 AUC-val 0.819  AUC-train 0.973\n",
            "Stats - Epoch: 41 AUC-val 0.839  AUC-train 0.975\n",
            "Stats - Epoch: 42 AUC-val 0.790  AUC-train 0.973\n",
            "Stats - Epoch: 43 AUC-val 0.802  AUC-train 0.975\n",
            "Stats - Epoch: 44 AUC-val 0.791  AUC-train 0.978\n",
            "Stats - Epoch: 45 AUC-val 0.799  AUC-train 0.977\n",
            "Stats - Epoch: 46 AUC-val 0.788  AUC-train 0.979\n",
            "Stats - Epoch: 47 AUC-val 0.757  AUC-train 0.982\n",
            "Stats - Epoch: 48 AUC-val 0.757  AUC-train 0.982\n",
            "Stats - Epoch: 49 AUC-val 0.780  AUC-train 0.982\n",
            "Stats - Epoch: 50 AUC-val 0.784  AUC-train 0.983\n",
            "Stats - Epoch: 51 AUC-val 0.784  AUC-train 0.981\n",
            "Stats - Epoch: 52 AUC-val 0.764  AUC-train 0.983\n",
            "Stats - Epoch: 53 AUC-val 0.753  AUC-train 0.982\n",
            "Stats - Epoch: 54 AUC-val 0.760  AUC-train 0.984\n",
            "Stats - Epoch: 55 AUC-val 0.754  AUC-train 0.986\n",
            "Stats - Epoch: 56 AUC-val 0.773  AUC-train 0.987\n",
            "Stats - Epoch: 57 AUC-val 0.766  AUC-train 0.986\n",
            "Stats - Epoch: 58 AUC-val 0.776  AUC-train 0.986\n",
            "Stats - Epoch: 59 AUC-val 0.787  AUC-train 0.986\n",
            "Stats - Epoch: 60 AUC-val 0.752  AUC-train 0.987\n",
            "Stats - Epoch: 61 AUC-val 0.745  AUC-train 0.988\n",
            "Stats - Epoch: 62 AUC-val 0.765  AUC-train 0.989\n",
            "Stats - Epoch: 63 AUC-val 0.759  AUC-train 0.988\n",
            "Stats - Epoch: 64 AUC-val 0.771  AUC-train 0.987\n",
            "Stats - Epoch: 65 AUC-val 0.805  AUC-train 0.988\n",
            "Stats - Epoch: 66 AUC-val 0.769  AUC-train 0.989\n",
            "Stats - Epoch: 67 AUC-val 0.765  AUC-train 0.990\n",
            "Stats - Epoch: 68 AUC-val 0.753  AUC-train 0.990\n",
            "Stats - Epoch: 69 AUC-val 0.736  AUC-train 0.991\n",
            "Stats - Epoch: 70 AUC-val 0.751  AUC-train 0.992\n",
            "Stats - Epoch: 71 AUC-val 0.713  AUC-train 0.992\n",
            "Stats - Epoch: 72 AUC-val 0.726  AUC-train 0.993\n",
            "Stats - Epoch: 73 AUC-val 0.716  AUC-train 0.992\n",
            "Stats - Epoch: 74 AUC-val 0.713  AUC-train 0.991\n",
            "Stats - Epoch: 75 AUC-val 0.702  AUC-train 0.992\n",
            "Stats - Epoch: 76 AUC-val 0.724  AUC-train 0.993\n",
            "Stats - Epoch: 77 AUC-val 0.741  AUC-train 0.994\n",
            "Stats - Epoch: 78 AUC-val 0.771  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.777  AUC-train 0.994\n",
            "Stats - Epoch: 80 AUC-val 0.742  AUC-train 0.994\n",
            "Stats - Epoch: 81 AUC-val 0.685  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.699  AUC-train 0.994\n",
            "Stats - Epoch: 83 AUC-val 0.746  AUC-train 0.993\n",
            "Stats - Epoch: 84 AUC-val 0.737  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.734  AUC-train 0.993\n",
            "Stats - Epoch: 86 AUC-val 0.748  AUC-train 0.993\n",
            "Stats - Epoch: 87 AUC-val 0.734  AUC-train 0.994\n",
            "Stats - Epoch: 88 AUC-val 0.750  AUC-train 0.994\n",
            "Stats - Epoch: 89 AUC-val 0.748  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.744  AUC-train 0.994\n",
            "Stats - Epoch: 91 AUC-val 0.732  AUC-train 0.995\n",
            "Stats - Epoch: 92 AUC-val 0.702  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.721  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.722  AUC-train 0.996\n",
            "Stats - Epoch: 95 AUC-val 0.699  AUC-train 0.996\n",
            "Stats - Epoch: 96 AUC-val 0.691  AUC-train 0.994\n",
            "Stats - Epoch: 97 AUC-val 0.708  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.707  AUC-train 0.993\n",
            "Stats - Epoch: 99 AUC-val 0.720  AUC-train 0.993\n",
            "Stats - Epoch: 100 AUC-val 0.716  AUC-train 0.994\n",
            "Results 100 AUC-val 0.652 0.728 0.869 0.657 0.325 AUC-train 0.949\n",
            "Shapley [0.03047714 0.00739893] [0.05166442]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.200997\n",
            "         Iterations 8\n",
            "['rhp_g', 'ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.618  AUC-train 0.520\n",
            "Stats - Epoch: 2 AUC-val 0.696  AUC-train 0.609\n",
            "Stats - Epoch: 3 AUC-val 0.738  AUC-train 0.657\n",
            "Stats - Epoch: 4 AUC-val 0.741  AUC-train 0.691\n",
            "Stats - Epoch: 5 AUC-val 0.733  AUC-train 0.720\n",
            "Stats - Epoch: 6 AUC-val 0.734  AUC-train 0.745\n",
            "Stats - Epoch: 7 AUC-val 0.733  AUC-train 0.769\n",
            "Stats - Epoch: 8 AUC-val 0.730  AUC-train 0.785\n",
            "Stats - Epoch: 9 AUC-val 0.727  AUC-train 0.802\n",
            "Stats - Epoch: 10 AUC-val 0.723  AUC-train 0.808\n",
            "Stats - Epoch: 11 AUC-val 0.721  AUC-train 0.815\n",
            "Stats - Epoch: 12 AUC-val 0.723  AUC-train 0.829\n",
            "Stats - Epoch: 13 AUC-val 0.710  AUC-train 0.828\n",
            "Stats - Epoch: 14 AUC-val 0.719  AUC-train 0.843\n",
            "Stats - Epoch: 15 AUC-val 0.712  AUC-train 0.846\n",
            "Stats - Epoch: 16 AUC-val 0.706  AUC-train 0.851\n",
            "Stats - Epoch: 17 AUC-val 0.712  AUC-train 0.856\n",
            "Stats - Epoch: 18 AUC-val 0.710  AUC-train 0.858\n",
            "Stats - Epoch: 19 AUC-val 0.709  AUC-train 0.866\n",
            "Stats - Epoch: 20 AUC-val 0.706  AUC-train 0.870\n",
            "Stats - Epoch: 21 AUC-val 0.710  AUC-train 0.872\n",
            "Stats - Epoch: 22 AUC-val 0.710  AUC-train 0.875\n",
            "Stats - Epoch: 23 AUC-val 0.706  AUC-train 0.880\n",
            "Stats - Epoch: 24 AUC-val 0.694  AUC-train 0.881\n",
            "Stats - Epoch: 25 AUC-val 0.701  AUC-train 0.884\n",
            "Stats - Epoch: 26 AUC-val 0.703  AUC-train 0.887\n",
            "Stats - Epoch: 27 AUC-val 0.701  AUC-train 0.893\n",
            "Stats - Epoch: 28 AUC-val 0.701  AUC-train 0.893\n",
            "Stats - Epoch: 29 AUC-val 0.706  AUC-train 0.900\n",
            "Stats - Epoch: 30 AUC-val 0.695  AUC-train 0.902\n",
            "Stats - Epoch: 31 AUC-val 0.697  AUC-train 0.903\n",
            "Stats - Epoch: 32 AUC-val 0.696  AUC-train 0.905\n",
            "Stats - Epoch: 33 AUC-val 0.696  AUC-train 0.909\n",
            "Stats - Epoch: 34 AUC-val 0.697  AUC-train 0.912\n",
            "Stats - Epoch: 35 AUC-val 0.694  AUC-train 0.912\n",
            "Stats - Epoch: 36 AUC-val 0.697  AUC-train 0.915\n",
            "Stats - Epoch: 37 AUC-val 0.690  AUC-train 0.920\n",
            "Stats - Epoch: 38 AUC-val 0.686  AUC-train 0.919\n",
            "Stats - Epoch: 39 AUC-val 0.694  AUC-train 0.920\n",
            "Stats - Epoch: 40 AUC-val 0.686  AUC-train 0.920\n",
            "Stats - Epoch: 41 AUC-val 0.686  AUC-train 0.923\n",
            "Stats - Epoch: 42 AUC-val 0.693  AUC-train 0.924\n",
            "Stats - Epoch: 43 AUC-val 0.692  AUC-train 0.927\n",
            "Stats - Epoch: 44 AUC-val 0.688  AUC-train 0.931\n",
            "Stats - Epoch: 45 AUC-val 0.687  AUC-train 0.928\n",
            "Stats - Epoch: 46 AUC-val 0.685  AUC-train 0.929\n",
            "Stats - Epoch: 47 AUC-val 0.694  AUC-train 0.931\n",
            "Stats - Epoch: 48 AUC-val 0.687  AUC-train 0.932\n",
            "Stats - Epoch: 49 AUC-val 0.682  AUC-train 0.934\n",
            "Stats - Epoch: 50 AUC-val 0.682  AUC-train 0.934\n",
            "Stats - Epoch: 51 AUC-val 0.683  AUC-train 0.937\n",
            "Stats - Epoch: 52 AUC-val 0.678  AUC-train 0.938\n",
            "Stats - Epoch: 53 AUC-val 0.673  AUC-train 0.939\n",
            "Stats - Epoch: 54 AUC-val 0.685  AUC-train 0.940\n",
            "Stats - Epoch: 55 AUC-val 0.684  AUC-train 0.942\n",
            "Stats - Epoch: 56 AUC-val 0.671  AUC-train 0.940\n",
            "Stats - Epoch: 57 AUC-val 0.682  AUC-train 0.945\n",
            "Stats - Epoch: 58 AUC-val 0.678  AUC-train 0.946\n",
            "Stats - Epoch: 59 AUC-val 0.678  AUC-train 0.945\n",
            "Stats - Epoch: 60 AUC-val 0.683  AUC-train 0.947\n",
            "Stats - Epoch: 61 AUC-val 0.675  AUC-train 0.946\n",
            "Stats - Epoch: 62 AUC-val 0.677  AUC-train 0.946\n",
            "Stats - Epoch: 63 AUC-val 0.677  AUC-train 0.950\n",
            "Stats - Epoch: 64 AUC-val 0.675  AUC-train 0.950\n",
            "Stats - Epoch: 65 AUC-val 0.674  AUC-train 0.950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 66 AUC-val 0.677  AUC-train 0.952\n",
            "Stats - Epoch: 67 AUC-val 0.679  AUC-train 0.953\n",
            "Stats - Epoch: 68 AUC-val 0.679  AUC-train 0.952\n",
            "Stats - Epoch: 69 AUC-val 0.667  AUC-train 0.953\n",
            "Stats - Epoch: 70 AUC-val 0.664  AUC-train 0.951\n",
            "Stats - Epoch: 71 AUC-val 0.676  AUC-train 0.955\n",
            "Stats - Epoch: 72 AUC-val 0.675  AUC-train 0.954\n",
            "Stats - Epoch: 73 AUC-val 0.661  AUC-train 0.953\n",
            "Stats - Epoch: 74 AUC-val 0.656  AUC-train 0.956\n",
            "Stats - Epoch: 75 AUC-val 0.656  AUC-train 0.954\n",
            "Stats - Epoch: 76 AUC-val 0.661  AUC-train 0.958\n",
            "Stats - Epoch: 77 AUC-val 0.668  AUC-train 0.958\n",
            "Stats - Epoch: 78 AUC-val 0.671  AUC-train 0.960\n",
            "Stats - Epoch: 79 AUC-val 0.667  AUC-train 0.958\n",
            "Stats - Epoch: 80 AUC-val 0.664  AUC-train 0.956\n",
            "Stats - Epoch: 81 AUC-val 0.666  AUC-train 0.959\n",
            "Stats - Epoch: 82 AUC-val 0.663  AUC-train 0.961\n",
            "Stats - Epoch: 83 AUC-val 0.671  AUC-train 0.962\n",
            "Stats - Epoch: 84 AUC-val 0.668  AUC-train 0.961\n",
            "Stats - Epoch: 85 AUC-val 0.665  AUC-train 0.961\n",
            "Stats - Epoch: 86 AUC-val 0.666  AUC-train 0.963\n",
            "Stats - Epoch: 87 AUC-val 0.665  AUC-train 0.962\n",
            "Stats - Epoch: 88 AUC-val 0.672  AUC-train 0.960\n",
            "Stats - Epoch: 89 AUC-val 0.673  AUC-train 0.964\n",
            "Stats - Epoch: 90 AUC-val 0.676  AUC-train 0.965\n",
            "Stats - Epoch: 91 AUC-val 0.672  AUC-train 0.966\n",
            "Stats - Epoch: 92 AUC-val 0.669  AUC-train 0.964\n",
            "Stats - Epoch: 93 AUC-val 0.669  AUC-train 0.962\n",
            "Stats - Epoch: 94 AUC-val 0.664  AUC-train 0.962\n",
            "Stats - Epoch: 95 AUC-val 0.666  AUC-train 0.964\n",
            "Stats - Epoch: 96 AUC-val 0.665  AUC-train 0.965\n",
            "Stats - Epoch: 97 AUC-val 0.663  AUC-train 0.967\n",
            "Stats - Epoch: 98 AUC-val 0.668  AUC-train 0.968\n",
            "Stats - Epoch: 99 AUC-val 0.662  AUC-train 0.967\n",
            "Stats - Epoch: 100 AUC-val 0.660  AUC-train 0.966\n",
            "Results 100 AUC-val 0.607 0.737 0.741 0.665 0.602 AUC-train 0.691\n",
            "Shapley [0.00928997 0.00974362] [0.02037365]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.204616\n",
            "         Iterations 7\n",
            "['rhp_g', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.637  AUC-train 0.503\n",
            "Stats - Epoch: 2 AUC-val 0.653  AUC-train 0.551\n",
            "Stats - Epoch: 3 AUC-val 0.645  AUC-train 0.585\n",
            "Stats - Epoch: 4 AUC-val 0.651  AUC-train 0.604\n",
            "Stats - Epoch: 5 AUC-val 0.648  AUC-train 0.617\n",
            "Stats - Epoch: 6 AUC-val 0.644  AUC-train 0.627\n",
            "Stats - Epoch: 7 AUC-val 0.639  AUC-train 0.636\n",
            "Stats - Epoch: 8 AUC-val 0.630  AUC-train 0.645\n",
            "Stats - Epoch: 9 AUC-val 0.626  AUC-train 0.652\n",
            "Stats - Epoch: 10 AUC-val 0.628  AUC-train 0.657\n",
            "Stats - Epoch: 11 AUC-val 0.616  AUC-train 0.664\n",
            "Stats - Epoch: 12 AUC-val 0.622  AUC-train 0.672\n",
            "Stats - Epoch: 13 AUC-val 0.616  AUC-train 0.673\n",
            "Stats - Epoch: 14 AUC-val 0.616  AUC-train 0.681\n",
            "Stats - Epoch: 15 AUC-val 0.616  AUC-train 0.686\n",
            "Stats - Epoch: 16 AUC-val 0.617  AUC-train 0.689\n",
            "Stats - Epoch: 17 AUC-val 0.617  AUC-train 0.690\n",
            "Stats - Epoch: 18 AUC-val 0.617  AUC-train 0.695\n",
            "Stats - Epoch: 19 AUC-val 0.614  AUC-train 0.701\n",
            "Stats - Epoch: 20 AUC-val 0.613  AUC-train 0.700\n",
            "Stats - Epoch: 21 AUC-val 0.620  AUC-train 0.706\n",
            "Stats - Epoch: 22 AUC-val 0.667  AUC-train 0.705\n",
            "Stats - Epoch: 23 AUC-val 0.635  AUC-train 0.711\n",
            "Stats - Epoch: 24 AUC-val 0.625  AUC-train 0.714\n",
            "Stats - Epoch: 25 AUC-val 0.634  AUC-train 0.717\n",
            "Stats - Epoch: 26 AUC-val 0.627  AUC-train 0.719\n",
            "Stats - Epoch: 27 AUC-val 0.645  AUC-train 0.722\n",
            "Stats - Epoch: 28 AUC-val 0.642  AUC-train 0.724\n",
            "Stats - Epoch: 29 AUC-val 0.650  AUC-train 0.730\n",
            "Stats - Epoch: 30 AUC-val 0.655  AUC-train 0.734\n",
            "Stats - Epoch: 31 AUC-val 0.661  AUC-train 0.738\n",
            "Stats - Epoch: 32 AUC-val 0.663  AUC-train 0.741\n",
            "Stats - Epoch: 33 AUC-val 0.653  AUC-train 0.746\n",
            "Stats - Epoch: 34 AUC-val 0.666  AUC-train 0.749\n",
            "Stats - Epoch: 35 AUC-val 0.675  AUC-train 0.756\n",
            "Stats - Epoch: 36 AUC-val 0.663  AUC-train 0.755\n",
            "Stats - Epoch: 37 AUC-val 0.675  AUC-train 0.763\n",
            "Stats - Epoch: 38 AUC-val 0.671  AUC-train 0.764\n",
            "Stats - Epoch: 39 AUC-val 0.673  AUC-train 0.768\n",
            "Stats - Epoch: 40 AUC-val 0.678  AUC-train 0.774\n",
            "Stats - Epoch: 41 AUC-val 0.673  AUC-train 0.775\n",
            "Stats - Epoch: 42 AUC-val 0.675  AUC-train 0.779\n",
            "Stats - Epoch: 43 AUC-val 0.672  AUC-train 0.779\n",
            "Stats - Epoch: 44 AUC-val 0.684  AUC-train 0.786\n",
            "Stats - Epoch: 45 AUC-val 0.673  AUC-train 0.787\n",
            "Stats - Epoch: 46 AUC-val 0.677  AUC-train 0.793\n",
            "Stats - Epoch: 47 AUC-val 0.687  AUC-train 0.793\n",
            "Stats - Epoch: 48 AUC-val 0.680  AUC-train 0.793\n",
            "Stats - Epoch: 49 AUC-val 0.682  AUC-train 0.799\n",
            "Stats - Epoch: 50 AUC-val 0.674  AUC-train 0.801\n",
            "Stats - Epoch: 51 AUC-val 0.679  AUC-train 0.805\n",
            "Stats - Epoch: 52 AUC-val 0.691  AUC-train 0.808\n",
            "Stats - Epoch: 53 AUC-val 0.685  AUC-train 0.815\n",
            "Stats - Epoch: 54 AUC-val 0.681  AUC-train 0.813\n",
            "Stats - Epoch: 55 AUC-val 0.691  AUC-train 0.811\n",
            "Stats - Epoch: 56 AUC-val 0.668  AUC-train 0.813\n",
            "Stats - Epoch: 57 AUC-val 0.686  AUC-train 0.819\n",
            "Stats - Epoch: 58 AUC-val 0.685  AUC-train 0.820\n",
            "Stats - Epoch: 59 AUC-val 0.682  AUC-train 0.825\n",
            "Stats - Epoch: 60 AUC-val 0.721  AUC-train 0.826\n",
            "Stats - Epoch: 61 AUC-val 0.686  AUC-train 0.832\n",
            "Stats - Epoch: 62 AUC-val 0.689  AUC-train 0.831\n",
            "Stats - Epoch: 63 AUC-val 0.692  AUC-train 0.835\n",
            "Stats - Epoch: 64 AUC-val 0.682  AUC-train 0.837\n",
            "Stats - Epoch: 65 AUC-val 0.692  AUC-train 0.835\n",
            "Stats - Epoch: 66 AUC-val 0.689  AUC-train 0.837\n",
            "Stats - Epoch: 67 AUC-val 0.693  AUC-train 0.839\n",
            "Stats - Epoch: 68 AUC-val 0.688  AUC-train 0.842\n",
            "Stats - Epoch: 69 AUC-val 0.693  AUC-train 0.842\n",
            "Stats - Epoch: 70 AUC-val 0.682  AUC-train 0.840\n",
            "Stats - Epoch: 71 AUC-val 0.693  AUC-train 0.842\n",
            "Stats - Epoch: 72 AUC-val 0.692  AUC-train 0.847\n",
            "Stats - Epoch: 73 AUC-val 0.687  AUC-train 0.847\n",
            "Stats - Epoch: 74 AUC-val 0.693  AUC-train 0.848\n",
            "Stats - Epoch: 75 AUC-val 0.697  AUC-train 0.847\n",
            "Stats - Epoch: 76 AUC-val 0.688  AUC-train 0.850\n",
            "Stats - Epoch: 77 AUC-val 0.700  AUC-train 0.853\n",
            "Stats - Epoch: 78 AUC-val 0.668  AUC-train 0.851\n",
            "Stats - Epoch: 79 AUC-val 0.689  AUC-train 0.858\n",
            "Stats - Epoch: 80 AUC-val 0.689  AUC-train 0.857\n",
            "Stats - Epoch: 81 AUC-val 0.690  AUC-train 0.860\n",
            "Stats - Epoch: 82 AUC-val 0.698  AUC-train 0.858\n",
            "Stats - Epoch: 83 AUC-val 0.688  AUC-train 0.861\n",
            "Stats - Epoch: 84 AUC-val 0.690  AUC-train 0.860\n",
            "Stats - Epoch: 85 AUC-val 0.685  AUC-train 0.861\n",
            "Stats - Epoch: 86 AUC-val 0.697  AUC-train 0.861\n",
            "Stats - Epoch: 87 AUC-val 0.687  AUC-train 0.866\n",
            "Stats - Epoch: 88 AUC-val 0.671  AUC-train 0.861\n",
            "Stats - Epoch: 89 AUC-val 0.695  AUC-train 0.868\n",
            "Stats - Epoch: 90 AUC-val 0.695  AUC-train 0.867\n",
            "Stats - Epoch: 91 AUC-val 0.688  AUC-train 0.869\n",
            "Stats - Epoch: 92 AUC-val 0.691  AUC-train 0.874\n",
            "Stats - Epoch: 93 AUC-val 0.688  AUC-train 0.869\n",
            "Stats - Epoch: 94 AUC-val 0.692  AUC-train 0.870\n",
            "Stats - Epoch: 95 AUC-val 0.687  AUC-train 0.871\n",
            "Stats - Epoch: 96 AUC-val 0.687  AUC-train 0.876\n",
            "Stats - Epoch: 97 AUC-val 0.696  AUC-train 0.879\n",
            "Stats - Epoch: 98 AUC-val 0.668  AUC-train 0.878\n",
            "Stats - Epoch: 99 AUC-val 0.692  AUC-train 0.882\n",
            "Stats - Epoch: 100 AUC-val 0.689  AUC-train 0.880\n",
            "Results 100 AUC-val 0.554 0.660 0.721 0.679 0.694 AUC-train 0.826\n",
            "Shapley [0.01357219 0.00249084] [0.01390744]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.206760\n",
            "         Iterations 8\n",
            "['ca/gdp', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.452  AUC-train 0.486\n",
            "Stats - Epoch: 2 AUC-val 0.475  AUC-train 0.526\n",
            "Stats - Epoch: 3 AUC-val 0.494  AUC-train 0.554\n",
            "Stats - Epoch: 4 AUC-val 0.500  AUC-train 0.582\n",
            "Stats - Epoch: 5 AUC-val 0.509  AUC-train 0.604\n",
            "Stats - Epoch: 6 AUC-val 0.521  AUC-train 0.614\n",
            "Stats - Epoch: 7 AUC-val 0.522  AUC-train 0.621\n",
            "Stats - Epoch: 8 AUC-val 0.521  AUC-train 0.623\n",
            "Stats - Epoch: 9 AUC-val 0.531  AUC-train 0.630\n",
            "Stats - Epoch: 10 AUC-val 0.538  AUC-train 0.635\n",
            "Stats - Epoch: 11 AUC-val 0.541  AUC-train 0.638\n",
            "Stats - Epoch: 12 AUC-val 0.549  AUC-train 0.641\n",
            "Stats - Epoch: 13 AUC-val 0.556  AUC-train 0.641\n",
            "Stats - Epoch: 14 AUC-val 0.557  AUC-train 0.646\n",
            "Stats - Epoch: 15 AUC-val 0.556  AUC-train 0.651\n",
            "Stats - Epoch: 16 AUC-val 0.566  AUC-train 0.652\n",
            "Stats - Epoch: 17 AUC-val 0.575  AUC-train 0.659\n",
            "Stats - Epoch: 18 AUC-val 0.582  AUC-train 0.656\n",
            "Stats - Epoch: 19 AUC-val 0.572  AUC-train 0.664\n",
            "Stats - Epoch: 20 AUC-val 0.580  AUC-train 0.665\n",
            "Stats - Epoch: 21 AUC-val 0.572  AUC-train 0.670\n",
            "Stats - Epoch: 22 AUC-val 0.584  AUC-train 0.668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 23 AUC-val 0.586  AUC-train 0.676\n",
            "Stats - Epoch: 24 AUC-val 0.598  AUC-train 0.674\n",
            "Stats - Epoch: 25 AUC-val 0.600  AUC-train 0.682\n",
            "Stats - Epoch: 26 AUC-val 0.588  AUC-train 0.681\n",
            "Stats - Epoch: 27 AUC-val 0.588  AUC-train 0.689\n",
            "Stats - Epoch: 28 AUC-val 0.599  AUC-train 0.694\n",
            "Stats - Epoch: 29 AUC-val 0.600  AUC-train 0.693\n",
            "Stats - Epoch: 30 AUC-val 0.599  AUC-train 0.700\n",
            "Stats - Epoch: 31 AUC-val 0.597  AUC-train 0.707\n",
            "Stats - Epoch: 32 AUC-val 0.610  AUC-train 0.702\n",
            "Stats - Epoch: 33 AUC-val 0.606  AUC-train 0.706\n",
            "Stats - Epoch: 34 AUC-val 0.602  AUC-train 0.708\n",
            "Stats - Epoch: 35 AUC-val 0.606  AUC-train 0.709\n",
            "Stats - Epoch: 36 AUC-val 0.612  AUC-train 0.719\n",
            "Stats - Epoch: 37 AUC-val 0.612  AUC-train 0.722\n",
            "Stats - Epoch: 38 AUC-val 0.614  AUC-train 0.711\n",
            "Stats - Epoch: 39 AUC-val 0.610  AUC-train 0.717\n",
            "Stats - Epoch: 40 AUC-val 0.622  AUC-train 0.716\n",
            "Stats - Epoch: 41 AUC-val 0.619  AUC-train 0.725\n",
            "Stats - Epoch: 42 AUC-val 0.630  AUC-train 0.730\n",
            "Stats - Epoch: 43 AUC-val 0.622  AUC-train 0.725\n",
            "Stats - Epoch: 44 AUC-val 0.634  AUC-train 0.735\n",
            "Stats - Epoch: 45 AUC-val 0.625  AUC-train 0.736\n",
            "Stats - Epoch: 46 AUC-val 0.619  AUC-train 0.734\n",
            "Stats - Epoch: 47 AUC-val 0.626  AUC-train 0.736\n",
            "Stats - Epoch: 48 AUC-val 0.625  AUC-train 0.741\n",
            "Stats - Epoch: 49 AUC-val 0.630  AUC-train 0.746\n",
            "Stats - Epoch: 50 AUC-val 0.624  AUC-train 0.747\n",
            "Stats - Epoch: 51 AUC-val 0.623  AUC-train 0.746\n",
            "Stats - Epoch: 52 AUC-val 0.614  AUC-train 0.737\n",
            "Stats - Epoch: 53 AUC-val 0.630  AUC-train 0.746\n",
            "Stats - Epoch: 54 AUC-val 0.636  AUC-train 0.748\n",
            "Stats - Epoch: 55 AUC-val 0.653  AUC-train 0.748\n",
            "Stats - Epoch: 56 AUC-val 0.648  AUC-train 0.751\n",
            "Stats - Epoch: 57 AUC-val 0.634  AUC-train 0.754\n",
            "Stats - Epoch: 58 AUC-val 0.640  AUC-train 0.752\n",
            "Stats - Epoch: 59 AUC-val 0.639  AUC-train 0.757\n",
            "Stats - Epoch: 60 AUC-val 0.631  AUC-train 0.756\n",
            "Stats - Epoch: 61 AUC-val 0.652  AUC-train 0.760\n",
            "Stats - Epoch: 62 AUC-val 0.633  AUC-train 0.767\n",
            "Stats - Epoch: 63 AUC-val 0.643  AUC-train 0.772\n",
            "Stats - Epoch: 64 AUC-val 0.635  AUC-train 0.769\n",
            "Stats - Epoch: 65 AUC-val 0.645  AUC-train 0.769\n",
            "Stats - Epoch: 66 AUC-val 0.634  AUC-train 0.779\n",
            "Stats - Epoch: 67 AUC-val 0.636  AUC-train 0.773\n",
            "Stats - Epoch: 68 AUC-val 0.618  AUC-train 0.778\n",
            "Stats - Epoch: 69 AUC-val 0.656  AUC-train 0.778\n",
            "Stats - Epoch: 70 AUC-val 0.662  AUC-train 0.783\n",
            "Stats - Epoch: 71 AUC-val 0.651  AUC-train 0.780\n",
            "Stats - Epoch: 72 AUC-val 0.641  AUC-train 0.775\n",
            "Stats - Epoch: 73 AUC-val 0.630  AUC-train 0.780\n",
            "Stats - Epoch: 74 AUC-val 0.657  AUC-train 0.774\n",
            "Stats - Epoch: 75 AUC-val 0.654  AUC-train 0.776\n",
            "Stats - Epoch: 76 AUC-val 0.647  AUC-train 0.780\n",
            "Stats - Epoch: 77 AUC-val 0.609  AUC-train 0.778\n",
            "Stats - Epoch: 78 AUC-val 0.632  AUC-train 0.780\n",
            "Stats - Epoch: 79 AUC-val 0.621  AUC-train 0.783\n",
            "Stats - Epoch: 80 AUC-val 0.616  AUC-train 0.782\n",
            "Stats - Epoch: 81 AUC-val 0.643  AUC-train 0.785\n",
            "Stats - Epoch: 82 AUC-val 0.661  AUC-train 0.779\n",
            "Stats - Epoch: 83 AUC-val 0.641  AUC-train 0.780\n",
            "Stats - Epoch: 84 AUC-val 0.633  AUC-train 0.781\n",
            "Stats - Epoch: 85 AUC-val 0.645  AUC-train 0.781\n",
            "Stats - Epoch: 86 AUC-val 0.640  AUC-train 0.786\n",
            "Stats - Epoch: 87 AUC-val 0.641  AUC-train 0.784\n",
            "Stats - Epoch: 88 AUC-val 0.629  AUC-train 0.791\n",
            "Stats - Epoch: 89 AUC-val 0.641  AUC-train 0.787\n",
            "Stats - Epoch: 90 AUC-val 0.663  AUC-train 0.788\n",
            "Stats - Epoch: 91 AUC-val 0.640  AUC-train 0.798\n",
            "Stats - Epoch: 92 AUC-val 0.640  AUC-train 0.791\n",
            "Stats - Epoch: 93 AUC-val 0.633  AUC-train 0.795\n",
            "Stats - Epoch: 94 AUC-val 0.645  AUC-train 0.796\n",
            "Stats - Epoch: 95 AUC-val 0.636  AUC-train 0.800\n",
            "Stats - Epoch: 96 AUC-val 0.614  AUC-train 0.801\n",
            "Stats - Epoch: 97 AUC-val 0.633  AUC-train 0.798\n",
            "Stats - Epoch: 98 AUC-val 0.622  AUC-train 0.805\n",
            "Stats - Epoch: 99 AUC-val 0.623  AUC-train 0.804\n",
            "Stats - Epoch: 100 AUC-val 0.633  AUC-train 0.803\n",
            "Results 100 AUC-val 0.609 0.658 0.663 0.599 0.444 AUC-train 0.788\n",
            "Shapley [0.00978311 0.00957334] [0.03645946]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.220241\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'rsp_g', 'rhp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.268  AUC-train 0.502\n",
            "Stats - Epoch: 2 AUC-val 0.524  AUC-train 0.656\n",
            "Stats - Epoch: 3 AUC-val 0.709  AUC-train 0.766\n",
            "Stats - Epoch: 4 AUC-val 0.747  AUC-train 0.815\n",
            "Stats - Epoch: 5 AUC-val 0.757  AUC-train 0.846\n",
            "Stats - Epoch: 6 AUC-val 0.772  AUC-train 0.865\n",
            "Stats - Epoch: 7 AUC-val 0.781  AUC-train 0.883\n",
            "Stats - Epoch: 8 AUC-val 0.786  AUC-train 0.894\n",
            "Stats - Epoch: 9 AUC-val 0.791  AUC-train 0.908\n",
            "Stats - Epoch: 10 AUC-val 0.795  AUC-train 0.915\n",
            "Stats - Epoch: 11 AUC-val 0.801  AUC-train 0.923\n",
            "Stats - Epoch: 12 AUC-val 0.811  AUC-train 0.934\n",
            "Stats - Epoch: 13 AUC-val 0.834  AUC-train 0.933\n",
            "Stats - Epoch: 14 AUC-val 0.811  AUC-train 0.944\n",
            "Stats - Epoch: 15 AUC-val 0.808  AUC-train 0.948\n",
            "Stats - Epoch: 16 AUC-val 0.804  AUC-train 0.953\n",
            "Stats - Epoch: 17 AUC-val 0.808  AUC-train 0.956\n",
            "Stats - Epoch: 18 AUC-val 0.815  AUC-train 0.958\n",
            "Stats - Epoch: 19 AUC-val 0.787  AUC-train 0.964\n",
            "Stats - Epoch: 20 AUC-val 0.806  AUC-train 0.966\n",
            "Stats - Epoch: 21 AUC-val 0.793  AUC-train 0.968\n",
            "Stats - Epoch: 22 AUC-val 0.784  AUC-train 0.970\n",
            "Stats - Epoch: 23 AUC-val 0.778  AUC-train 0.975\n",
            "Stats - Epoch: 24 AUC-val 0.792  AUC-train 0.974\n",
            "Stats - Epoch: 25 AUC-val 0.801  AUC-train 0.977\n",
            "Stats - Epoch: 26 AUC-val 0.795  AUC-train 0.979\n",
            "Stats - Epoch: 27 AUC-val 0.783  AUC-train 0.980\n",
            "Stats - Epoch: 28 AUC-val 0.788  AUC-train 0.982\n",
            "Stats - Epoch: 29 AUC-val 0.794  AUC-train 0.982\n",
            "Stats - Epoch: 30 AUC-val 0.792  AUC-train 0.983\n",
            "Stats - Epoch: 31 AUC-val 0.783  AUC-train 0.985\n",
            "Stats - Epoch: 32 AUC-val 0.809  AUC-train 0.986\n",
            "Stats - Epoch: 33 AUC-val 0.804  AUC-train 0.985\n",
            "Stats - Epoch: 34 AUC-val 0.776  AUC-train 0.987\n",
            "Stats - Epoch: 35 AUC-val 0.778  AUC-train 0.988\n",
            "Stats - Epoch: 36 AUC-val 0.798  AUC-train 0.989\n",
            "Stats - Epoch: 37 AUC-val 0.772  AUC-train 0.991\n",
            "Stats - Epoch: 38 AUC-val 0.765  AUC-train 0.990\n",
            "Stats - Epoch: 39 AUC-val 0.764  AUC-train 0.990\n",
            "Stats - Epoch: 40 AUC-val 0.774  AUC-train 0.991\n",
            "Stats - Epoch: 41 AUC-val 0.757  AUC-train 0.992\n",
            "Stats - Epoch: 42 AUC-val 0.767  AUC-train 0.993\n",
            "Stats - Epoch: 43 AUC-val 0.753  AUC-train 0.993\n",
            "Stats - Epoch: 44 AUC-val 0.762  AUC-train 0.993\n",
            "Stats - Epoch: 45 AUC-val 0.759  AUC-train 0.993\n",
            "Stats - Epoch: 46 AUC-val 0.756  AUC-train 0.993\n",
            "Stats - Epoch: 47 AUC-val 0.748  AUC-train 0.995\n",
            "Stats - Epoch: 48 AUC-val 0.755  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.748  AUC-train 0.994\n",
            "Stats - Epoch: 50 AUC-val 0.753  AUC-train 0.995\n",
            "Stats - Epoch: 51 AUC-val 0.741  AUC-train 0.994\n",
            "Stats - Epoch: 52 AUC-val 0.723  AUC-train 0.995\n",
            "Stats - Epoch: 53 AUC-val 0.734  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.727  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.737  AUC-train 0.995\n",
            "Stats - Epoch: 56 AUC-val 0.731  AUC-train 0.997\n",
            "Stats - Epoch: 57 AUC-val 0.705  AUC-train 0.996\n",
            "Stats - Epoch: 58 AUC-val 0.752  AUC-train 0.996\n",
            "Stats - Epoch: 59 AUC-val 0.722  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.749  AUC-train 0.993\n",
            "Stats - Epoch: 61 AUC-val 0.763  AUC-train 0.995\n",
            "Stats - Epoch: 62 AUC-val 0.764  AUC-train 0.995\n",
            "Stats - Epoch: 63 AUC-val 0.764  AUC-train 0.995\n",
            "Stats - Epoch: 64 AUC-val 0.729  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.725  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.729  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.745  AUC-train 0.996\n",
            "Stats - Epoch: 68 AUC-val 0.712  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.720  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.717  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.668  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.715  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.741  AUC-train 0.996\n",
            "Stats - Epoch: 74 AUC-val 0.690  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.675  AUC-train 0.994\n",
            "Stats - Epoch: 76 AUC-val 0.738  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.705  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.741  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.713  AUC-train 0.996\n",
            "Stats - Epoch: 80 AUC-val 0.713  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.683  AUC-train 0.998\n",
            "Stats - Epoch: 82 AUC-val 0.723  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.743  AUC-train 0.994\n",
            "Stats - Epoch: 84 AUC-val 0.740  AUC-train 0.996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 85 AUC-val 0.687  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.682  AUC-train 0.997\n",
            "Stats - Epoch: 87 AUC-val 0.682  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.677  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.705  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.731  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.720  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.704  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.657  AUC-train 0.995\n",
            "Stats - Epoch: 94 AUC-val 0.696  AUC-train 0.995\n",
            "Stats - Epoch: 95 AUC-val 0.704  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.702  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.708  AUC-train 0.999\n",
            "Stats - Epoch: 98 AUC-val 0.714  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.678  AUC-train 0.998\n",
            "Stats - Epoch: 100 AUC-val 0.726  AUC-train 0.997\n",
            "Results 100 AUC-val 0.673 0.775 0.834 0.785 0.532 AUC-train 0.933\n",
            "Shapley [0.01432213 0.01564515 0.0109503 ] [0.01212561]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.181611\n",
            "         Iterations 8\n",
            "['tloansgdp_g', 'rsp_g', 'ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.274  AUC-train 0.527\n",
            "Stats - Epoch: 2 AUC-val 0.507  AUC-train 0.672\n",
            "Stats - Epoch: 3 AUC-val 0.716  AUC-train 0.774\n",
            "Stats - Epoch: 4 AUC-val 0.763  AUC-train 0.813\n",
            "Stats - Epoch: 5 AUC-val 0.750  AUC-train 0.837\n",
            "Stats - Epoch: 6 AUC-val 0.748  AUC-train 0.855\n",
            "Stats - Epoch: 7 AUC-val 0.721  AUC-train 0.872\n",
            "Stats - Epoch: 8 AUC-val 0.735  AUC-train 0.885\n",
            "Stats - Epoch: 9 AUC-val 0.712  AUC-train 0.895\n",
            "Stats - Epoch: 10 AUC-val 0.698  AUC-train 0.904\n",
            "Stats - Epoch: 11 AUC-val 0.725  AUC-train 0.911\n",
            "Stats - Epoch: 12 AUC-val 0.698  AUC-train 0.919\n",
            "Stats - Epoch: 13 AUC-val 0.693  AUC-train 0.925\n",
            "Stats - Epoch: 14 AUC-val 0.667  AUC-train 0.935\n",
            "Stats - Epoch: 15 AUC-val 0.691  AUC-train 0.938\n",
            "Stats - Epoch: 16 AUC-val 0.690  AUC-train 0.945\n",
            "Stats - Epoch: 17 AUC-val 0.668  AUC-train 0.948\n",
            "Stats - Epoch: 18 AUC-val 0.697  AUC-train 0.950\n",
            "Stats - Epoch: 19 AUC-val 0.644  AUC-train 0.955\n",
            "Stats - Epoch: 20 AUC-val 0.677  AUC-train 0.956\n",
            "Stats - Epoch: 21 AUC-val 0.647  AUC-train 0.961\n",
            "Stats - Epoch: 22 AUC-val 0.654  AUC-train 0.963\n",
            "Stats - Epoch: 23 AUC-val 0.638  AUC-train 0.967\n",
            "Stats - Epoch: 24 AUC-val 0.661  AUC-train 0.965\n",
            "Stats - Epoch: 25 AUC-val 0.655  AUC-train 0.966\n",
            "Stats - Epoch: 26 AUC-val 0.650  AUC-train 0.970\n",
            "Stats - Epoch: 27 AUC-val 0.631  AUC-train 0.973\n",
            "Stats - Epoch: 28 AUC-val 0.636  AUC-train 0.976\n",
            "Stats - Epoch: 29 AUC-val 0.633  AUC-train 0.974\n",
            "Stats - Epoch: 30 AUC-val 0.626  AUC-train 0.977\n",
            "Stats - Epoch: 31 AUC-val 0.623  AUC-train 0.977\n",
            "Stats - Epoch: 32 AUC-val 0.664  AUC-train 0.978\n",
            "Stats - Epoch: 33 AUC-val 0.627  AUC-train 0.979\n",
            "Stats - Epoch: 34 AUC-val 0.610  AUC-train 0.979\n",
            "Stats - Epoch: 35 AUC-val 0.615  AUC-train 0.981\n",
            "Stats - Epoch: 36 AUC-val 0.616  AUC-train 0.980\n",
            "Stats - Epoch: 37 AUC-val 0.609  AUC-train 0.982\n",
            "Stats - Epoch: 38 AUC-val 0.600  AUC-train 0.984\n",
            "Stats - Epoch: 39 AUC-val 0.596  AUC-train 0.983\n",
            "Stats - Epoch: 40 AUC-val 0.627  AUC-train 0.985\n",
            "Stats - Epoch: 41 AUC-val 0.586  AUC-train 0.985\n",
            "Stats - Epoch: 42 AUC-val 0.633  AUC-train 0.986\n",
            "Stats - Epoch: 43 AUC-val 0.596  AUC-train 0.985\n",
            "Stats - Epoch: 44 AUC-val 0.598  AUC-train 0.986\n",
            "Stats - Epoch: 45 AUC-val 0.575  AUC-train 0.987\n",
            "Stats - Epoch: 46 AUC-val 0.554  AUC-train 0.988\n",
            "Stats - Epoch: 47 AUC-val 0.587  AUC-train 0.988\n",
            "Stats - Epoch: 48 AUC-val 0.557  AUC-train 0.988\n",
            "Stats - Epoch: 49 AUC-val 0.565  AUC-train 0.988\n",
            "Stats - Epoch: 50 AUC-val 0.557  AUC-train 0.989\n",
            "Stats - Epoch: 51 AUC-val 0.556  AUC-train 0.989\n",
            "Stats - Epoch: 52 AUC-val 0.576  AUC-train 0.989\n",
            "Stats - Epoch: 53 AUC-val 0.554  AUC-train 0.991\n",
            "Stats - Epoch: 54 AUC-val 0.585  AUC-train 0.991\n",
            "Stats - Epoch: 55 AUC-val 0.554  AUC-train 0.991\n",
            "Stats - Epoch: 56 AUC-val 0.541  AUC-train 0.990\n",
            "Stats - Epoch: 57 AUC-val 0.555  AUC-train 0.989\n",
            "Stats - Epoch: 58 AUC-val 0.529  AUC-train 0.991\n",
            "Stats - Epoch: 59 AUC-val 0.592  AUC-train 0.991\n",
            "Stats - Epoch: 60 AUC-val 0.578  AUC-train 0.991\n",
            "Stats - Epoch: 61 AUC-val 0.567  AUC-train 0.992\n",
            "Stats - Epoch: 62 AUC-val 0.543  AUC-train 0.992\n",
            "Stats - Epoch: 63 AUC-val 0.580  AUC-train 0.992\n",
            "Stats - Epoch: 64 AUC-val 0.577  AUC-train 0.992\n",
            "Stats - Epoch: 65 AUC-val 0.572  AUC-train 0.990\n",
            "Stats - Epoch: 66 AUC-val 0.582  AUC-train 0.992\n",
            "Stats - Epoch: 67 AUC-val 0.550  AUC-train 0.991\n",
            "Stats - Epoch: 68 AUC-val 0.539  AUC-train 0.991\n",
            "Stats - Epoch: 69 AUC-val 0.536  AUC-train 0.993\n",
            "Stats - Epoch: 70 AUC-val 0.586  AUC-train 0.992\n",
            "Stats - Epoch: 71 AUC-val 0.558  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.528  AUC-train 0.993\n",
            "Stats - Epoch: 73 AUC-val 0.512  AUC-train 0.994\n",
            "Stats - Epoch: 74 AUC-val 0.521  AUC-train 0.994\n",
            "Stats - Epoch: 75 AUC-val 0.508  AUC-train 0.993\n",
            "Stats - Epoch: 76 AUC-val 0.569  AUC-train 0.994\n",
            "Stats - Epoch: 77 AUC-val 0.532  AUC-train 0.994\n",
            "Stats - Epoch: 78 AUC-val 0.579  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.517  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.523  AUC-train 0.995\n",
            "Stats - Epoch: 81 AUC-val 0.527  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.513  AUC-train 0.994\n",
            "Stats - Epoch: 83 AUC-val 0.507  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.515  AUC-train 0.995\n",
            "Stats - Epoch: 85 AUC-val 0.545  AUC-train 0.993\n",
            "Stats - Epoch: 86 AUC-val 0.547  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.578  AUC-train 0.995\n",
            "Stats - Epoch: 88 AUC-val 0.536  AUC-train 0.992\n",
            "Stats - Epoch: 89 AUC-val 0.558  AUC-train 0.994\n",
            "Stats - Epoch: 90 AUC-val 0.548  AUC-train 0.994\n",
            "Stats - Epoch: 91 AUC-val 0.503  AUC-train 0.993\n",
            "Stats - Epoch: 92 AUC-val 0.499  AUC-train 0.993\n",
            "Stats - Epoch: 93 AUC-val 0.528  AUC-train 0.995\n",
            "Stats - Epoch: 94 AUC-val 0.530  AUC-train 0.994\n",
            "Stats - Epoch: 95 AUC-val 0.552  AUC-train 0.995\n",
            "Stats - Epoch: 96 AUC-val 0.547  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.543  AUC-train 0.995\n",
            "Stats - Epoch: 98 AUC-val 0.534  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.518  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.509  AUC-train 0.993\n",
            "Results 100 AUC-val 0.826 0.766 0.763 0.640 0.358 AUC-train 0.813\n",
            "Shapley [0.01318969 0.03200043 0.00810969] [0.04799552]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.218270\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'rsp_g', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.297  AUC-train 0.514\n",
            "Stats - Epoch: 2 AUC-val 0.481  AUC-train 0.643\n",
            "Stats - Epoch: 3 AUC-val 0.645  AUC-train 0.755\n",
            "Stats - Epoch: 4 AUC-val 0.707  AUC-train 0.804\n",
            "Stats - Epoch: 5 AUC-val 0.717  AUC-train 0.834\n",
            "Stats - Epoch: 6 AUC-val 0.717  AUC-train 0.849\n",
            "Stats - Epoch: 7 AUC-val 0.735  AUC-train 0.866\n",
            "Stats - Epoch: 8 AUC-val 0.724  AUC-train 0.875\n",
            "Stats - Epoch: 9 AUC-val 0.719  AUC-train 0.889\n",
            "Stats - Epoch: 10 AUC-val 0.722  AUC-train 0.897\n",
            "Stats - Epoch: 11 AUC-val 0.719  AUC-train 0.904\n",
            "Stats - Epoch: 12 AUC-val 0.742  AUC-train 0.917\n",
            "Stats - Epoch: 13 AUC-val 0.736  AUC-train 0.918\n",
            "Stats - Epoch: 14 AUC-val 0.747  AUC-train 0.928\n",
            "Stats - Epoch: 15 AUC-val 0.738  AUC-train 0.931\n",
            "Stats - Epoch: 16 AUC-val 0.752  AUC-train 0.940\n",
            "Stats - Epoch: 17 AUC-val 0.714  AUC-train 0.945\n",
            "Stats - Epoch: 18 AUC-val 0.735  AUC-train 0.946\n",
            "Stats - Epoch: 19 AUC-val 0.740  AUC-train 0.953\n",
            "Stats - Epoch: 20 AUC-val 0.742  AUC-train 0.955\n",
            "Stats - Epoch: 21 AUC-val 0.702  AUC-train 0.959\n",
            "Stats - Epoch: 22 AUC-val 0.732  AUC-train 0.962\n",
            "Stats - Epoch: 23 AUC-val 0.670  AUC-train 0.967\n",
            "Stats - Epoch: 24 AUC-val 0.704  AUC-train 0.967\n",
            "Stats - Epoch: 25 AUC-val 0.709  AUC-train 0.968\n",
            "Stats - Epoch: 26 AUC-val 0.703  AUC-train 0.971\n",
            "Stats - Epoch: 27 AUC-val 0.702  AUC-train 0.974\n",
            "Stats - Epoch: 28 AUC-val 0.690  AUC-train 0.978\n",
            "Stats - Epoch: 29 AUC-val 0.714  AUC-train 0.977\n",
            "Stats - Epoch: 30 AUC-val 0.695  AUC-train 0.978\n",
            "Stats - Epoch: 31 AUC-val 0.661  AUC-train 0.980\n",
            "Stats - Epoch: 32 AUC-val 0.663  AUC-train 0.976\n",
            "Stats - Epoch: 33 AUC-val 0.678  AUC-train 0.983\n",
            "Stats - Epoch: 34 AUC-val 0.694  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.685  AUC-train 0.985\n",
            "Stats - Epoch: 36 AUC-val 0.668  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.631  AUC-train 0.985\n",
            "Stats - Epoch: 38 AUC-val 0.652  AUC-train 0.986\n",
            "Stats - Epoch: 39 AUC-val 0.659  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.695  AUC-train 0.989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 41 AUC-val 0.676  AUC-train 0.990\n",
            "Stats - Epoch: 42 AUC-val 0.664  AUC-train 0.990\n",
            "Stats - Epoch: 43 AUC-val 0.695  AUC-train 0.990\n",
            "Stats - Epoch: 44 AUC-val 0.631  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.668  AUC-train 0.991\n",
            "Stats - Epoch: 46 AUC-val 0.627  AUC-train 0.990\n",
            "Stats - Epoch: 47 AUC-val 0.616  AUC-train 0.991\n",
            "Stats - Epoch: 48 AUC-val 0.646  AUC-train 0.991\n",
            "Stats - Epoch: 49 AUC-val 0.609  AUC-train 0.991\n",
            "Stats - Epoch: 50 AUC-val 0.648  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.668  AUC-train 0.991\n",
            "Stats - Epoch: 52 AUC-val 0.654  AUC-train 0.992\n",
            "Stats - Epoch: 53 AUC-val 0.675  AUC-train 0.992\n",
            "Stats - Epoch: 54 AUC-val 0.655  AUC-train 0.990\n",
            "Stats - Epoch: 55 AUC-val 0.647  AUC-train 0.994\n",
            "Stats - Epoch: 56 AUC-val 0.645  AUC-train 0.993\n",
            "Stats - Epoch: 57 AUC-val 0.650  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.628  AUC-train 0.995\n",
            "Stats - Epoch: 59 AUC-val 0.620  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.613  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.626  AUC-train 0.993\n",
            "Stats - Epoch: 62 AUC-val 0.639  AUC-train 0.994\n",
            "Stats - Epoch: 63 AUC-val 0.631  AUC-train 0.994\n",
            "Stats - Epoch: 64 AUC-val 0.635  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.651  AUC-train 0.995\n",
            "Stats - Epoch: 66 AUC-val 0.651  AUC-train 0.995\n",
            "Stats - Epoch: 67 AUC-val 0.609  AUC-train 0.996\n",
            "Stats - Epoch: 68 AUC-val 0.631  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.555  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.594  AUC-train 0.994\n",
            "Stats - Epoch: 71 AUC-val 0.626  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.657  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.610  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.663  AUC-train 0.996\n",
            "Stats - Epoch: 75 AUC-val 0.597  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.596  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.617  AUC-train 0.997\n",
            "Stats - Epoch: 78 AUC-val 0.621  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.609  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.614  AUC-train 0.996\n",
            "Stats - Epoch: 81 AUC-val 0.619  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.647  AUC-train 0.994\n",
            "Stats - Epoch: 83 AUC-val 0.577  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.574  AUC-train 0.996\n",
            "Stats - Epoch: 85 AUC-val 0.571  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.640  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.601  AUC-train 0.996\n",
            "Stats - Epoch: 88 AUC-val 0.590  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.609  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.646  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.603  AUC-train 0.997\n",
            "Stats - Epoch: 92 AUC-val 0.613  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.608  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.607  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.652  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.595  AUC-train 0.996\n",
            "Stats - Epoch: 97 AUC-val 0.596  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.587  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.586  AUC-train 0.999\n",
            "Stats - Epoch: 100 AUC-val 0.565  AUC-train 0.998\n",
            "Results 100 AUC-val 0.748 0.771 0.752 0.669 0.464 AUC-train 0.940\n",
            "Shapley [0.02752414 0.01979874 0.00269218] [0.01254189]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.218596\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'rhp_g', 'ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.550  AUC-train 0.472\n",
            "Stats - Epoch: 2 AUC-val 0.666  AUC-train 0.620\n",
            "Stats - Epoch: 3 AUC-val 0.718  AUC-train 0.708\n",
            "Stats - Epoch: 4 AUC-val 0.701  AUC-train 0.752\n",
            "Stats - Epoch: 5 AUC-val 0.687  AUC-train 0.787\n",
            "Stats - Epoch: 6 AUC-val 0.668  AUC-train 0.812\n",
            "Stats - Epoch: 7 AUC-val 0.650  AUC-train 0.833\n",
            "Stats - Epoch: 8 AUC-val 0.628  AUC-train 0.850\n",
            "Stats - Epoch: 9 AUC-val 0.613  AUC-train 0.867\n",
            "Stats - Epoch: 10 AUC-val 0.610  AUC-train 0.874\n",
            "Stats - Epoch: 11 AUC-val 0.610  AUC-train 0.886\n",
            "Stats - Epoch: 12 AUC-val 0.593  AUC-train 0.897\n",
            "Stats - Epoch: 13 AUC-val 0.603  AUC-train 0.898\n",
            "Stats - Epoch: 14 AUC-val 0.586  AUC-train 0.912\n",
            "Stats - Epoch: 15 AUC-val 0.597  AUC-train 0.914\n",
            "Stats - Epoch: 16 AUC-val 0.586  AUC-train 0.919\n",
            "Stats - Epoch: 17 AUC-val 0.586  AUC-train 0.923\n",
            "Stats - Epoch: 18 AUC-val 0.582  AUC-train 0.926\n",
            "Stats - Epoch: 19 AUC-val 0.577  AUC-train 0.933\n",
            "Stats - Epoch: 20 AUC-val 0.589  AUC-train 0.936\n",
            "Stats - Epoch: 21 AUC-val 0.568  AUC-train 0.940\n",
            "Stats - Epoch: 22 AUC-val 0.575  AUC-train 0.943\n",
            "Stats - Epoch: 23 AUC-val 0.565  AUC-train 0.947\n",
            "Stats - Epoch: 24 AUC-val 0.569  AUC-train 0.948\n",
            "Stats - Epoch: 25 AUC-val 0.602  AUC-train 0.951\n",
            "Stats - Epoch: 26 AUC-val 0.565  AUC-train 0.950\n",
            "Stats - Epoch: 27 AUC-val 0.562  AUC-train 0.956\n",
            "Stats - Epoch: 28 AUC-val 0.566  AUC-train 0.959\n",
            "Stats - Epoch: 29 AUC-val 0.584  AUC-train 0.959\n",
            "Stats - Epoch: 30 AUC-val 0.581  AUC-train 0.963\n",
            "Stats - Epoch: 31 AUC-val 0.602  AUC-train 0.966\n",
            "Stats - Epoch: 32 AUC-val 0.570  AUC-train 0.966\n",
            "Stats - Epoch: 33 AUC-val 0.567  AUC-train 0.967\n",
            "Stats - Epoch: 34 AUC-val 0.589  AUC-train 0.970\n",
            "Stats - Epoch: 35 AUC-val 0.572  AUC-train 0.972\n",
            "Stats - Epoch: 36 AUC-val 0.591  AUC-train 0.971\n",
            "Stats - Epoch: 37 AUC-val 0.572  AUC-train 0.972\n",
            "Stats - Epoch: 38 AUC-val 0.567  AUC-train 0.974\n",
            "Stats - Epoch: 39 AUC-val 0.551  AUC-train 0.974\n",
            "Stats - Epoch: 40 AUC-val 0.581  AUC-train 0.976\n",
            "Stats - Epoch: 41 AUC-val 0.561  AUC-train 0.977\n",
            "Stats - Epoch: 42 AUC-val 0.581  AUC-train 0.977\n",
            "Stats - Epoch: 43 AUC-val 0.581  AUC-train 0.979\n",
            "Stats - Epoch: 44 AUC-val 0.574  AUC-train 0.981\n",
            "Stats - Epoch: 45 AUC-val 0.590  AUC-train 0.981\n",
            "Stats - Epoch: 46 AUC-val 0.576  AUC-train 0.980\n",
            "Stats - Epoch: 47 AUC-val 0.569  AUC-train 0.980\n",
            "Stats - Epoch: 48 AUC-val 0.562  AUC-train 0.980\n",
            "Stats - Epoch: 49 AUC-val 0.596  AUC-train 0.981\n",
            "Stats - Epoch: 50 AUC-val 0.572  AUC-train 0.983\n",
            "Stats - Epoch: 51 AUC-val 0.579  AUC-train 0.985\n",
            "Stats - Epoch: 52 AUC-val 0.576  AUC-train 0.984\n",
            "Stats - Epoch: 53 AUC-val 0.575  AUC-train 0.986\n",
            "Stats - Epoch: 54 AUC-val 0.571  AUC-train 0.984\n",
            "Stats - Epoch: 55 AUC-val 0.594  AUC-train 0.984\n",
            "Stats - Epoch: 56 AUC-val 0.610  AUC-train 0.983\n",
            "Stats - Epoch: 57 AUC-val 0.591  AUC-train 0.981\n",
            "Stats - Epoch: 58 AUC-val 0.606  AUC-train 0.985\n",
            "Stats - Epoch: 59 AUC-val 0.588  AUC-train 0.986\n",
            "Stats - Epoch: 60 AUC-val 0.578  AUC-train 0.987\n",
            "Stats - Epoch: 61 AUC-val 0.619  AUC-train 0.988\n",
            "Stats - Epoch: 62 AUC-val 0.587  AUC-train 0.985\n",
            "Stats - Epoch: 63 AUC-val 0.594  AUC-train 0.986\n",
            "Stats - Epoch: 64 AUC-val 0.625  AUC-train 0.986\n",
            "Stats - Epoch: 65 AUC-val 0.599  AUC-train 0.984\n",
            "Stats - Epoch: 66 AUC-val 0.579  AUC-train 0.982\n",
            "Stats - Epoch: 67 AUC-val 0.588  AUC-train 0.986\n",
            "Stats - Epoch: 68 AUC-val 0.608  AUC-train 0.986\n",
            "Stats - Epoch: 69 AUC-val 0.609  AUC-train 0.987\n",
            "Stats - Epoch: 70 AUC-val 0.578  AUC-train 0.987\n",
            "Stats - Epoch: 71 AUC-val 0.603  AUC-train 0.987\n",
            "Stats - Epoch: 72 AUC-val 0.596  AUC-train 0.982\n",
            "Stats - Epoch: 73 AUC-val 0.600  AUC-train 0.986\n",
            "Stats - Epoch: 74 AUC-val 0.603  AUC-train 0.985\n",
            "Stats - Epoch: 75 AUC-val 0.616  AUC-train 0.983\n",
            "Stats - Epoch: 76 AUC-val 0.614  AUC-train 0.984\n",
            "Stats - Epoch: 77 AUC-val 0.602  AUC-train 0.985\n",
            "Stats - Epoch: 78 AUC-val 0.595  AUC-train 0.984\n",
            "Stats - Epoch: 79 AUC-val 0.581  AUC-train 0.984\n",
            "Stats - Epoch: 80 AUC-val 0.631  AUC-train 0.985\n",
            "Stats - Epoch: 81 AUC-val 0.587  AUC-train 0.986\n",
            "Stats - Epoch: 82 AUC-val 0.587  AUC-train 0.986\n",
            "Stats - Epoch: 83 AUC-val 0.592  AUC-train 0.986\n",
            "Stats - Epoch: 84 AUC-val 0.597  AUC-train 0.987\n",
            "Stats - Epoch: 85 AUC-val 0.584  AUC-train 0.985\n",
            "Stats - Epoch: 86 AUC-val 0.589  AUC-train 0.987\n",
            "Stats - Epoch: 87 AUC-val 0.615  AUC-train 0.985\n",
            "Stats - Epoch: 88 AUC-val 0.596  AUC-train 0.988\n",
            "Stats - Epoch: 89 AUC-val 0.620  AUC-train 0.986\n",
            "Stats - Epoch: 90 AUC-val 0.599  AUC-train 0.983\n",
            "Stats - Epoch: 91 AUC-val 0.596  AUC-train 0.986\n",
            "Stats - Epoch: 92 AUC-val 0.596  AUC-train 0.986\n",
            "Stats - Epoch: 93 AUC-val 0.618  AUC-train 0.987\n",
            "Stats - Epoch: 94 AUC-val 0.643  AUC-train 0.987\n",
            "Stats - Epoch: 95 AUC-val 0.588  AUC-train 0.987\n",
            "Stats - Epoch: 96 AUC-val 0.598  AUC-train 0.987\n",
            "Stats - Epoch: 97 AUC-val 0.605  AUC-train 0.986\n",
            "Stats - Epoch: 98 AUC-val 0.615  AUC-train 0.987\n",
            "Stats - Epoch: 99 AUC-val 0.604  AUC-train 0.988\n",
            "Stats - Epoch: 100 AUC-val 0.599  AUC-train 0.987\n",
            "Results 100 AUC-val 0.659 0.730 0.718 0.593 0.525 AUC-train 0.708\n",
            "Shapley [0.00606811 0.00690422 0.00731912] [0.01833438]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.203097\n",
            "         Iterations 8\n",
            "['tloansgdp_g', 'rhp_g', 'rgdp_g']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.575  AUC-train 0.503\n",
            "Stats - Epoch: 2 AUC-val 0.640  AUC-train 0.617\n",
            "Stats - Epoch: 3 AUC-val 0.664  AUC-train 0.684\n",
            "Stats - Epoch: 4 AUC-val 0.666  AUC-train 0.719\n",
            "Stats - Epoch: 5 AUC-val 0.665  AUC-train 0.743\n",
            "Stats - Epoch: 6 AUC-val 0.651  AUC-train 0.764\n",
            "Stats - Epoch: 7 AUC-val 0.637  AUC-train 0.783\n",
            "Stats - Epoch: 8 AUC-val 0.634  AUC-train 0.794\n",
            "Stats - Epoch: 9 AUC-val 0.615  AUC-train 0.809\n",
            "Stats - Epoch: 10 AUC-val 0.610  AUC-train 0.816\n",
            "Stats - Epoch: 11 AUC-val 0.619  AUC-train 0.825\n",
            "Stats - Epoch: 12 AUC-val 0.606  AUC-train 0.840\n",
            "Stats - Epoch: 13 AUC-val 0.629  AUC-train 0.840\n",
            "Stats - Epoch: 14 AUC-val 0.589  AUC-train 0.853\n",
            "Stats - Epoch: 15 AUC-val 0.593  AUC-train 0.855\n",
            "Stats - Epoch: 16 AUC-val 0.581  AUC-train 0.861\n",
            "Stats - Epoch: 17 AUC-val 0.600  AUC-train 0.870\n",
            "Stats - Epoch: 18 AUC-val 0.578  AUC-train 0.873\n",
            "Stats - Epoch: 19 AUC-val 0.578  AUC-train 0.879\n",
            "Stats - Epoch: 20 AUC-val 0.560  AUC-train 0.882\n",
            "Stats - Epoch: 21 AUC-val 0.565  AUC-train 0.890\n",
            "Stats - Epoch: 22 AUC-val 0.583  AUC-train 0.895\n",
            "Stats - Epoch: 23 AUC-val 0.559  AUC-train 0.900\n",
            "Stats - Epoch: 24 AUC-val 0.579  AUC-train 0.906\n",
            "Stats - Epoch: 25 AUC-val 0.579  AUC-train 0.908\n",
            "Stats - Epoch: 26 AUC-val 0.593  AUC-train 0.918\n",
            "Stats - Epoch: 27 AUC-val 0.581  AUC-train 0.921\n",
            "Stats - Epoch: 28 AUC-val 0.585  AUC-train 0.922\n",
            "Stats - Epoch: 29 AUC-val 0.595  AUC-train 0.929\n",
            "Stats - Epoch: 30 AUC-val 0.593  AUC-train 0.933\n",
            "Stats - Epoch: 31 AUC-val 0.592  AUC-train 0.938\n",
            "Stats - Epoch: 32 AUC-val 0.599  AUC-train 0.941\n",
            "Stats - Epoch: 33 AUC-val 0.582  AUC-train 0.944\n",
            "Stats - Epoch: 34 AUC-val 0.603  AUC-train 0.946\n",
            "Stats - Epoch: 35 AUC-val 0.595  AUC-train 0.950\n",
            "Stats - Epoch: 36 AUC-val 0.611  AUC-train 0.953\n",
            "Stats - Epoch: 37 AUC-val 0.603  AUC-train 0.954\n",
            "Stats - Epoch: 38 AUC-val 0.597  AUC-train 0.955\n",
            "Stats - Epoch: 39 AUC-val 0.597  AUC-train 0.958\n",
            "Stats - Epoch: 40 AUC-val 0.614  AUC-train 0.961\n",
            "Stats - Epoch: 41 AUC-val 0.608  AUC-train 0.964\n",
            "Stats - Epoch: 42 AUC-val 0.602  AUC-train 0.964\n",
            "Stats - Epoch: 43 AUC-val 0.620  AUC-train 0.964\n",
            "Stats - Epoch: 44 AUC-val 0.618  AUC-train 0.967\n",
            "Stats - Epoch: 45 AUC-val 0.618  AUC-train 0.970\n",
            "Stats - Epoch: 46 AUC-val 0.610  AUC-train 0.968\n",
            "Stats - Epoch: 47 AUC-val 0.599  AUC-train 0.969\n",
            "Stats - Epoch: 48 AUC-val 0.618  AUC-train 0.969\n",
            "Stats - Epoch: 49 AUC-val 0.619  AUC-train 0.971\n",
            "Stats - Epoch: 50 AUC-val 0.624  AUC-train 0.972\n",
            "Stats - Epoch: 51 AUC-val 0.605  AUC-train 0.974\n",
            "Stats - Epoch: 52 AUC-val 0.621  AUC-train 0.976\n",
            "Stats - Epoch: 53 AUC-val 0.624  AUC-train 0.975\n",
            "Stats - Epoch: 54 AUC-val 0.618  AUC-train 0.978\n",
            "Stats - Epoch: 55 AUC-val 0.627  AUC-train 0.981\n",
            "Stats - Epoch: 56 AUC-val 0.631  AUC-train 0.979\n",
            "Stats - Epoch: 57 AUC-val 0.620  AUC-train 0.979\n",
            "Stats - Epoch: 58 AUC-val 0.637  AUC-train 0.981\n",
            "Stats - Epoch: 59 AUC-val 0.632  AUC-train 0.983\n",
            "Stats - Epoch: 60 AUC-val 0.637  AUC-train 0.983\n",
            "Stats - Epoch: 61 AUC-val 0.633  AUC-train 0.983\n",
            "Stats - Epoch: 62 AUC-val 0.639  AUC-train 0.984\n",
            "Stats - Epoch: 63 AUC-val 0.638  AUC-train 0.985\n",
            "Stats - Epoch: 64 AUC-val 0.637  AUC-train 0.985\n",
            "Stats - Epoch: 65 AUC-val 0.623  AUC-train 0.984\n",
            "Stats - Epoch: 66 AUC-val 0.635  AUC-train 0.985\n",
            "Stats - Epoch: 67 AUC-val 0.638  AUC-train 0.985\n",
            "Stats - Epoch: 68 AUC-val 0.632  AUC-train 0.987\n",
            "Stats - Epoch: 69 AUC-val 0.655  AUC-train 0.987\n",
            "Stats - Epoch: 70 AUC-val 0.629  AUC-train 0.985\n",
            "Stats - Epoch: 71 AUC-val 0.631  AUC-train 0.985\n",
            "Stats - Epoch: 72 AUC-val 0.640  AUC-train 0.987\n",
            "Stats - Epoch: 73 AUC-val 0.637  AUC-train 0.989\n",
            "Stats - Epoch: 74 AUC-val 0.644  AUC-train 0.988\n",
            "Stats - Epoch: 75 AUC-val 0.652  AUC-train 0.987\n",
            "Stats - Epoch: 76 AUC-val 0.634  AUC-train 0.989\n",
            "Stats - Epoch: 77 AUC-val 0.637  AUC-train 0.990\n",
            "Stats - Epoch: 78 AUC-val 0.645  AUC-train 0.990\n",
            "Stats - Epoch: 79 AUC-val 0.639  AUC-train 0.991\n",
            "Stats - Epoch: 80 AUC-val 0.638  AUC-train 0.991\n",
            "Stats - Epoch: 81 AUC-val 0.659  AUC-train 0.991\n",
            "Stats - Epoch: 82 AUC-val 0.644  AUC-train 0.988\n",
            "Stats - Epoch: 83 AUC-val 0.626  AUC-train 0.985\n",
            "Stats - Epoch: 84 AUC-val 0.659  AUC-train 0.990\n",
            "Stats - Epoch: 85 AUC-val 0.650  AUC-train 0.991\n",
            "Stats - Epoch: 86 AUC-val 0.637  AUC-train 0.990\n",
            "Stats - Epoch: 87 AUC-val 0.635  AUC-train 0.987\n",
            "Stats - Epoch: 88 AUC-val 0.640  AUC-train 0.990\n",
            "Stats - Epoch: 89 AUC-val 0.651  AUC-train 0.992\n",
            "Stats - Epoch: 90 AUC-val 0.640  AUC-train 0.991\n",
            "Stats - Epoch: 91 AUC-val 0.635  AUC-train 0.988\n",
            "Stats - Epoch: 92 AUC-val 0.646  AUC-train 0.991\n",
            "Stats - Epoch: 93 AUC-val 0.649  AUC-train 0.991\n",
            "Stats - Epoch: 94 AUC-val 0.655  AUC-train 0.993\n",
            "Stats - Epoch: 95 AUC-val 0.636  AUC-train 0.991\n",
            "Stats - Epoch: 96 AUC-val 0.657  AUC-train 0.993\n",
            "Stats - Epoch: 97 AUC-val 0.675  AUC-train 0.994\n",
            "Stats - Epoch: 98 AUC-val 0.615  AUC-train 0.990\n",
            "Stats - Epoch: 99 AUC-val 0.652  AUC-train 0.992\n",
            "Stats - Epoch: 100 AUC-val 0.650  AUC-train 0.990\n",
            "Results 100 AUC-val 0.593 0.645 0.675 0.604 0.689 AUC-train 0.994\n",
            "Shapley [0.01170362 0.01007082 0.00328105] [0.00596899]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.211921\n",
            "         Iterations 7\n",
            "['tloansgdp_g', 'ca/gdp', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.464  AUC-train 0.512\n",
            "Stats - Epoch: 2 AUC-val 0.484  AUC-train 0.638\n",
            "Stats - Epoch: 3 AUC-val 0.520  AUC-train 0.696\n",
            "Stats - Epoch: 4 AUC-val 0.537  AUC-train 0.727\n",
            "Stats - Epoch: 5 AUC-val 0.531  AUC-train 0.747\n",
            "Stats - Epoch: 6 AUC-val 0.527  AUC-train 0.761\n",
            "Stats - Epoch: 7 AUC-val 0.532  AUC-train 0.769\n",
            "Stats - Epoch: 8 AUC-val 0.527  AUC-train 0.776\n",
            "Stats - Epoch: 9 AUC-val 0.515  AUC-train 0.785\n",
            "Stats - Epoch: 10 AUC-val 0.510  AUC-train 0.792\n",
            "Stats - Epoch: 11 AUC-val 0.508  AUC-train 0.796\n",
            "Stats - Epoch: 12 AUC-val 0.483  AUC-train 0.804\n",
            "Stats - Epoch: 13 AUC-val 0.497  AUC-train 0.803\n",
            "Stats - Epoch: 14 AUC-val 0.486  AUC-train 0.813\n",
            "Stats - Epoch: 15 AUC-val 0.493  AUC-train 0.815\n",
            "Stats - Epoch: 16 AUC-val 0.484  AUC-train 0.818\n",
            "Stats - Epoch: 17 AUC-val 0.486  AUC-train 0.821\n",
            "Stats - Epoch: 18 AUC-val 0.493  AUC-train 0.822\n",
            "Stats - Epoch: 19 AUC-val 0.494  AUC-train 0.824\n",
            "Stats - Epoch: 20 AUC-val 0.483  AUC-train 0.826\n",
            "Stats - Epoch: 21 AUC-val 0.493  AUC-train 0.829\n",
            "Stats - Epoch: 22 AUC-val 0.486  AUC-train 0.829\n",
            "Stats - Epoch: 23 AUC-val 0.478  AUC-train 0.830\n",
            "Stats - Epoch: 24 AUC-val 0.488  AUC-train 0.832\n",
            "Stats - Epoch: 25 AUC-val 0.486  AUC-train 0.832\n",
            "Stats - Epoch: 26 AUC-val 0.485  AUC-train 0.837\n",
            "Stats - Epoch: 27 AUC-val 0.485  AUC-train 0.835\n",
            "Stats - Epoch: 28 AUC-val 0.490  AUC-train 0.843\n",
            "Stats - Epoch: 29 AUC-val 0.478  AUC-train 0.844\n",
            "Stats - Epoch: 30 AUC-val 0.487  AUC-train 0.847\n",
            "Stats - Epoch: 31 AUC-val 0.479  AUC-train 0.848\n",
            "Stats - Epoch: 32 AUC-val 0.485  AUC-train 0.850\n",
            "Stats - Epoch: 33 AUC-val 0.479  AUC-train 0.851\n",
            "Stats - Epoch: 34 AUC-val 0.491  AUC-train 0.853\n",
            "Stats - Epoch: 35 AUC-val 0.496  AUC-train 0.852\n",
            "Stats - Epoch: 36 AUC-val 0.480  AUC-train 0.851\n",
            "Stats - Epoch: 37 AUC-val 0.483  AUC-train 0.855\n",
            "Stats - Epoch: 38 AUC-val 0.486  AUC-train 0.856\n",
            "Stats - Epoch: 39 AUC-val 0.493  AUC-train 0.854\n",
            "Stats - Epoch: 40 AUC-val 0.474  AUC-train 0.856\n",
            "Stats - Epoch: 41 AUC-val 0.496  AUC-train 0.855\n",
            "Stats - Epoch: 42 AUC-val 0.473  AUC-train 0.857\n",
            "Stats - Epoch: 43 AUC-val 0.491  AUC-train 0.860\n",
            "Stats - Epoch: 44 AUC-val 0.472  AUC-train 0.863\n",
            "Stats - Epoch: 45 AUC-val 0.482  AUC-train 0.868\n",
            "Stats - Epoch: 46 AUC-val 0.465  AUC-train 0.868\n",
            "Stats - Epoch: 47 AUC-val 0.466  AUC-train 0.869\n",
            "Stats - Epoch: 48 AUC-val 0.477  AUC-train 0.872\n",
            "Stats - Epoch: 49 AUC-val 0.473  AUC-train 0.873\n",
            "Stats - Epoch: 50 AUC-val 0.479  AUC-train 0.874\n",
            "Stats - Epoch: 51 AUC-val 0.453  AUC-train 0.876\n",
            "Stats - Epoch: 52 AUC-val 0.474  AUC-train 0.875\n",
            "Stats - Epoch: 53 AUC-val 0.460  AUC-train 0.877\n",
            "Stats - Epoch: 54 AUC-val 0.481  AUC-train 0.879\n",
            "Stats - Epoch: 55 AUC-val 0.473  AUC-train 0.880\n",
            "Stats - Epoch: 56 AUC-val 0.474  AUC-train 0.880\n",
            "Stats - Epoch: 57 AUC-val 0.493  AUC-train 0.887\n",
            "Stats - Epoch: 58 AUC-val 0.478  AUC-train 0.888\n",
            "Stats - Epoch: 59 AUC-val 0.490  AUC-train 0.890\n",
            "Stats - Epoch: 60 AUC-val 0.476  AUC-train 0.893\n",
            "Stats - Epoch: 61 AUC-val 0.481  AUC-train 0.892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 62 AUC-val 0.476  AUC-train 0.896\n",
            "Stats - Epoch: 63 AUC-val 0.480  AUC-train 0.901\n",
            "Stats - Epoch: 64 AUC-val 0.505  AUC-train 0.902\n",
            "Stats - Epoch: 65 AUC-val 0.492  AUC-train 0.906\n",
            "Stats - Epoch: 66 AUC-val 0.476  AUC-train 0.906\n",
            "Stats - Epoch: 67 AUC-val 0.475  AUC-train 0.909\n",
            "Stats - Epoch: 68 AUC-val 0.475  AUC-train 0.909\n",
            "Stats - Epoch: 69 AUC-val 0.472  AUC-train 0.910\n",
            "Stats - Epoch: 70 AUC-val 0.496  AUC-train 0.913\n",
            "Stats - Epoch: 71 AUC-val 0.483  AUC-train 0.910\n",
            "Stats - Epoch: 72 AUC-val 0.500  AUC-train 0.912\n",
            "Stats - Epoch: 73 AUC-val 0.514  AUC-train 0.912\n",
            "Stats - Epoch: 74 AUC-val 0.483  AUC-train 0.914\n",
            "Stats - Epoch: 75 AUC-val 0.459  AUC-train 0.907\n",
            "Stats - Epoch: 76 AUC-val 0.469  AUC-train 0.911\n",
            "Stats - Epoch: 77 AUC-val 0.481  AUC-train 0.912\n",
            "Stats - Epoch: 78 AUC-val 0.486  AUC-train 0.917\n",
            "Stats - Epoch: 79 AUC-val 0.466  AUC-train 0.917\n",
            "Stats - Epoch: 80 AUC-val 0.499  AUC-train 0.918\n",
            "Stats - Epoch: 81 AUC-val 0.485  AUC-train 0.918\n",
            "Stats - Epoch: 82 AUC-val 0.482  AUC-train 0.921\n",
            "Stats - Epoch: 83 AUC-val 0.488  AUC-train 0.920\n",
            "Stats - Epoch: 84 AUC-val 0.467  AUC-train 0.920\n",
            "Stats - Epoch: 85 AUC-val 0.459  AUC-train 0.921\n",
            "Stats - Epoch: 86 AUC-val 0.452  AUC-train 0.921\n",
            "Stats - Epoch: 87 AUC-val 0.471  AUC-train 0.922\n",
            "Stats - Epoch: 88 AUC-val 0.475  AUC-train 0.925\n",
            "Stats - Epoch: 89 AUC-val 0.469  AUC-train 0.927\n",
            "Stats - Epoch: 90 AUC-val 0.501  AUC-train 0.930\n",
            "Stats - Epoch: 91 AUC-val 0.469  AUC-train 0.929\n",
            "Stats - Epoch: 92 AUC-val 0.472  AUC-train 0.923\n",
            "Stats - Epoch: 93 AUC-val 0.475  AUC-train 0.925\n",
            "Stats - Epoch: 94 AUC-val 0.482  AUC-train 0.930\n",
            "Stats - Epoch: 95 AUC-val 0.492  AUC-train 0.930\n",
            "Stats - Epoch: 96 AUC-val 0.464  AUC-train 0.931\n",
            "Stats - Epoch: 97 AUC-val 0.466  AUC-train 0.933\n",
            "Stats - Epoch: 98 AUC-val 0.441  AUC-train 0.933\n",
            "Stats - Epoch: 99 AUC-val 0.492  AUC-train 0.932\n",
            "Stats - Epoch: 100 AUC-val 0.464  AUC-train 0.932\n",
            "Results 100 AUC-val 0.622 0.570 0.537 0.392 0.376 AUC-train 0.727\n",
            "Shapley [0.01057767 0.00704775 0.00907091] [0.01989204]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.215367\n",
            "         Iterations 12\n",
            "['rsp_g', 'rhp_g', 'ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.454  AUC-train 0.531\n",
            "Stats - Epoch: 2 AUC-val 0.588  AUC-train 0.669\n",
            "Stats - Epoch: 3 AUC-val 0.727  AUC-train 0.757\n",
            "Stats - Epoch: 4 AUC-val 0.752  AUC-train 0.797\n",
            "Stats - Epoch: 5 AUC-val 0.767  AUC-train 0.824\n",
            "Stats - Epoch: 6 AUC-val 0.774  AUC-train 0.845\n",
            "Stats - Epoch: 7 AUC-val 0.764  AUC-train 0.860\n",
            "Stats - Epoch: 8 AUC-val 0.780  AUC-train 0.873\n",
            "Stats - Epoch: 9 AUC-val 0.779  AUC-train 0.884\n",
            "Stats - Epoch: 10 AUC-val 0.765  AUC-train 0.892\n",
            "Stats - Epoch: 11 AUC-val 0.774  AUC-train 0.903\n",
            "Stats - Epoch: 12 AUC-val 0.769  AUC-train 0.914\n",
            "Stats - Epoch: 13 AUC-val 0.779  AUC-train 0.916\n",
            "Stats - Epoch: 14 AUC-val 0.772  AUC-train 0.927\n",
            "Stats - Epoch: 15 AUC-val 0.777  AUC-train 0.931\n",
            "Stats - Epoch: 16 AUC-val 0.773  AUC-train 0.938\n",
            "Stats - Epoch: 17 AUC-val 0.768  AUC-train 0.941\n",
            "Stats - Epoch: 18 AUC-val 0.785  AUC-train 0.947\n",
            "Stats - Epoch: 19 AUC-val 0.768  AUC-train 0.954\n",
            "Stats - Epoch: 20 AUC-val 0.782  AUC-train 0.955\n",
            "Stats - Epoch: 21 AUC-val 0.770  AUC-train 0.960\n",
            "Stats - Epoch: 22 AUC-val 0.776  AUC-train 0.964\n",
            "Stats - Epoch: 23 AUC-val 0.779  AUC-train 0.967\n",
            "Stats - Epoch: 24 AUC-val 0.773  AUC-train 0.967\n",
            "Stats - Epoch: 25 AUC-val 0.760  AUC-train 0.970\n",
            "Stats - Epoch: 26 AUC-val 0.778  AUC-train 0.971\n",
            "Stats - Epoch: 27 AUC-val 0.756  AUC-train 0.975\n",
            "Stats - Epoch: 28 AUC-val 0.756  AUC-train 0.978\n",
            "Stats - Epoch: 29 AUC-val 0.764  AUC-train 0.979\n",
            "Stats - Epoch: 30 AUC-val 0.763  AUC-train 0.980\n",
            "Stats - Epoch: 31 AUC-val 0.759  AUC-train 0.981\n",
            "Stats - Epoch: 32 AUC-val 0.771  AUC-train 0.982\n",
            "Stats - Epoch: 33 AUC-val 0.751  AUC-train 0.982\n",
            "Stats - Epoch: 34 AUC-val 0.768  AUC-train 0.984\n",
            "Stats - Epoch: 35 AUC-val 0.766  AUC-train 0.983\n",
            "Stats - Epoch: 36 AUC-val 0.752  AUC-train 0.985\n",
            "Stats - Epoch: 37 AUC-val 0.777  AUC-train 0.984\n",
            "Stats - Epoch: 38 AUC-val 0.751  AUC-train 0.987\n",
            "Stats - Epoch: 39 AUC-val 0.759  AUC-train 0.987\n",
            "Stats - Epoch: 40 AUC-val 0.777  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.754  AUC-train 0.989\n",
            "Stats - Epoch: 42 AUC-val 0.757  AUC-train 0.987\n",
            "Stats - Epoch: 43 AUC-val 0.757  AUC-train 0.989\n",
            "Stats - Epoch: 44 AUC-val 0.751  AUC-train 0.990\n",
            "Stats - Epoch: 45 AUC-val 0.752  AUC-train 0.991\n",
            "Stats - Epoch: 46 AUC-val 0.723  AUC-train 0.992\n",
            "Stats - Epoch: 47 AUC-val 0.733  AUC-train 0.989\n",
            "Stats - Epoch: 48 AUC-val 0.757  AUC-train 0.990\n",
            "Stats - Epoch: 49 AUC-val 0.732  AUC-train 0.992\n",
            "Stats - Epoch: 50 AUC-val 0.745  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.747  AUC-train 0.992\n",
            "Stats - Epoch: 52 AUC-val 0.726  AUC-train 0.992\n",
            "Stats - Epoch: 53 AUC-val 0.750  AUC-train 0.989\n",
            "Stats - Epoch: 54 AUC-val 0.749  AUC-train 0.992\n",
            "Stats - Epoch: 55 AUC-val 0.740  AUC-train 0.992\n",
            "Stats - Epoch: 56 AUC-val 0.736  AUC-train 0.993\n",
            "Stats - Epoch: 57 AUC-val 0.729  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.755  AUC-train 0.991\n",
            "Stats - Epoch: 59 AUC-val 0.712  AUC-train 0.991\n",
            "Stats - Epoch: 60 AUC-val 0.737  AUC-train 0.993\n",
            "Stats - Epoch: 61 AUC-val 0.743  AUC-train 0.994\n",
            "Stats - Epoch: 62 AUC-val 0.753  AUC-train 0.993\n",
            "Stats - Epoch: 63 AUC-val 0.742  AUC-train 0.993\n",
            "Stats - Epoch: 64 AUC-val 0.698  AUC-train 0.994\n",
            "Stats - Epoch: 65 AUC-val 0.727  AUC-train 0.994\n",
            "Stats - Epoch: 66 AUC-val 0.734  AUC-train 0.995\n",
            "Stats - Epoch: 67 AUC-val 0.718  AUC-train 0.994\n",
            "Stats - Epoch: 68 AUC-val 0.768  AUC-train 0.993\n",
            "Stats - Epoch: 69 AUC-val 0.715  AUC-train 0.992\n",
            "Stats - Epoch: 70 AUC-val 0.731  AUC-train 0.993\n",
            "Stats - Epoch: 71 AUC-val 0.731  AUC-train 0.995\n",
            "Stats - Epoch: 72 AUC-val 0.745  AUC-train 0.995\n",
            "Stats - Epoch: 73 AUC-val 0.755  AUC-train 0.993\n",
            "Stats - Epoch: 74 AUC-val 0.791  AUC-train 0.993\n",
            "Stats - Epoch: 75 AUC-val 0.745  AUC-train 0.994\n",
            "Stats - Epoch: 76 AUC-val 0.729  AUC-train 0.995\n",
            "Stats - Epoch: 77 AUC-val 0.737  AUC-train 0.995\n",
            "Stats - Epoch: 78 AUC-val 0.719  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.762  AUC-train 0.992\n",
            "Stats - Epoch: 80 AUC-val 0.747  AUC-train 0.992\n",
            "Stats - Epoch: 81 AUC-val 0.712  AUC-train 0.995\n",
            "Stats - Epoch: 82 AUC-val 0.714  AUC-train 0.992\n",
            "Stats - Epoch: 83 AUC-val 0.698  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.702  AUC-train 0.995\n",
            "Stats - Epoch: 85 AUC-val 0.745  AUC-train 0.995\n",
            "Stats - Epoch: 86 AUC-val 0.732  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.757  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.724  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.718  AUC-train 0.997\n",
            "Stats - Epoch: 90 AUC-val 0.696  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.708  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.715  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.718  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.731  AUC-train 0.997\n",
            "Stats - Epoch: 95 AUC-val 0.733  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.712  AUC-train 0.993\n",
            "Stats - Epoch: 97 AUC-val 0.724  AUC-train 0.995\n",
            "Stats - Epoch: 98 AUC-val 0.729  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.716  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.704  AUC-train 0.997\n",
            "Results 100 AUC-val 0.583 0.728 0.791 0.724 0.601 AUC-train 0.993\n",
            "Shapley [0.03591267 0.01263215 0.04848612] [0.00124977]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.187967\n",
            "         Iterations 7\n",
            "['rsp_g', 'rhp_g', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.424  AUC-train 0.530\n",
            "Stats - Epoch: 2 AUC-val 0.583  AUC-train 0.646\n",
            "Stats - Epoch: 3 AUC-val 0.696  AUC-train 0.730\n",
            "Stats - Epoch: 4 AUC-val 0.764  AUC-train 0.772\n",
            "Stats - Epoch: 5 AUC-val 0.781  AUC-train 0.793\n",
            "Stats - Epoch: 6 AUC-val 0.807  AUC-train 0.814\n",
            "Stats - Epoch: 7 AUC-val 0.813  AUC-train 0.832\n",
            "Stats - Epoch: 8 AUC-val 0.836  AUC-train 0.847\n",
            "Stats - Epoch: 9 AUC-val 0.859  AUC-train 0.868\n",
            "Stats - Epoch: 10 AUC-val 0.861  AUC-train 0.874\n",
            "Stats - Epoch: 11 AUC-val 0.865  AUC-train 0.887\n",
            "Stats - Epoch: 12 AUC-val 0.870  AUC-train 0.895\n",
            "Stats - Epoch: 13 AUC-val 0.884  AUC-train 0.900\n",
            "Stats - Epoch: 14 AUC-val 0.884  AUC-train 0.913\n",
            "Stats - Epoch: 15 AUC-val 0.889  AUC-train 0.918\n",
            "Stats - Epoch: 16 AUC-val 0.900  AUC-train 0.925\n",
            "Stats - Epoch: 17 AUC-val 0.901  AUC-train 0.932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 18 AUC-val 0.904  AUC-train 0.937\n",
            "Stats - Epoch: 19 AUC-val 0.902  AUC-train 0.941\n",
            "Stats - Epoch: 20 AUC-val 0.911  AUC-train 0.943\n",
            "Stats - Epoch: 21 AUC-val 0.909  AUC-train 0.946\n",
            "Stats - Epoch: 22 AUC-val 0.920  AUC-train 0.948\n",
            "Stats - Epoch: 23 AUC-val 0.906  AUC-train 0.958\n",
            "Stats - Epoch: 24 AUC-val 0.897  AUC-train 0.958\n",
            "Stats - Epoch: 25 AUC-val 0.909  AUC-train 0.963\n",
            "Stats - Epoch: 26 AUC-val 0.919  AUC-train 0.965\n",
            "Stats - Epoch: 27 AUC-val 0.909  AUC-train 0.965\n",
            "Stats - Epoch: 28 AUC-val 0.902  AUC-train 0.967\n",
            "Stats - Epoch: 29 AUC-val 0.900  AUC-train 0.967\n",
            "Stats - Epoch: 30 AUC-val 0.905  AUC-train 0.970\n",
            "Stats - Epoch: 31 AUC-val 0.909  AUC-train 0.973\n",
            "Stats - Epoch: 32 AUC-val 0.906  AUC-train 0.972\n",
            "Stats - Epoch: 33 AUC-val 0.892  AUC-train 0.977\n",
            "Stats - Epoch: 34 AUC-val 0.897  AUC-train 0.979\n",
            "Stats - Epoch: 35 AUC-val 0.894  AUC-train 0.981\n",
            "Stats - Epoch: 36 AUC-val 0.890  AUC-train 0.980\n",
            "Stats - Epoch: 37 AUC-val 0.884  AUC-train 0.980\n",
            "Stats - Epoch: 38 AUC-val 0.893  AUC-train 0.983\n",
            "Stats - Epoch: 39 AUC-val 0.902  AUC-train 0.984\n",
            "Stats - Epoch: 40 AUC-val 0.897  AUC-train 0.984\n",
            "Stats - Epoch: 41 AUC-val 0.896  AUC-train 0.986\n",
            "Stats - Epoch: 42 AUC-val 0.868  AUC-train 0.986\n",
            "Stats - Epoch: 43 AUC-val 0.879  AUC-train 0.985\n",
            "Stats - Epoch: 44 AUC-val 0.890  AUC-train 0.988\n",
            "Stats - Epoch: 45 AUC-val 0.893  AUC-train 0.987\n",
            "Stats - Epoch: 46 AUC-val 0.894  AUC-train 0.988\n",
            "Stats - Epoch: 47 AUC-val 0.870  AUC-train 0.990\n",
            "Stats - Epoch: 48 AUC-val 0.887  AUC-train 0.989\n",
            "Stats - Epoch: 49 AUC-val 0.891  AUC-train 0.989\n",
            "Stats - Epoch: 50 AUC-val 0.873  AUC-train 0.989\n",
            "Stats - Epoch: 51 AUC-val 0.898  AUC-train 0.988\n",
            "Stats - Epoch: 52 AUC-val 0.898  AUC-train 0.990\n",
            "Stats - Epoch: 53 AUC-val 0.877  AUC-train 0.991\n",
            "Stats - Epoch: 54 AUC-val 0.890  AUC-train 0.992\n",
            "Stats - Epoch: 55 AUC-val 0.889  AUC-train 0.993\n",
            "Stats - Epoch: 56 AUC-val 0.898  AUC-train 0.992\n",
            "Stats - Epoch: 57 AUC-val 0.890  AUC-train 0.993\n",
            "Stats - Epoch: 58 AUC-val 0.889  AUC-train 0.994\n",
            "Stats - Epoch: 59 AUC-val 0.893  AUC-train 0.992\n",
            "Stats - Epoch: 60 AUC-val 0.863  AUC-train 0.992\n",
            "Stats - Epoch: 61 AUC-val 0.880  AUC-train 0.994\n",
            "Stats - Epoch: 62 AUC-val 0.873  AUC-train 0.993\n",
            "Stats - Epoch: 63 AUC-val 0.874  AUC-train 0.992\n",
            "Stats - Epoch: 64 AUC-val 0.888  AUC-train 0.989\n",
            "Stats - Epoch: 65 AUC-val 0.887  AUC-train 0.993\n",
            "Stats - Epoch: 66 AUC-val 0.870  AUC-train 0.994\n",
            "Stats - Epoch: 67 AUC-val 0.871  AUC-train 0.991\n",
            "Stats - Epoch: 68 AUC-val 0.872  AUC-train 0.992\n",
            "Stats - Epoch: 69 AUC-val 0.888  AUC-train 0.994\n",
            "Stats - Epoch: 70 AUC-val 0.899  AUC-train 0.994\n",
            "Stats - Epoch: 71 AUC-val 0.896  AUC-train 0.993\n",
            "Stats - Epoch: 72 AUC-val 0.911  AUC-train 0.994\n",
            "Stats - Epoch: 73 AUC-val 0.879  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.869  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.869  AUC-train 0.995\n",
            "Stats - Epoch: 76 AUC-val 0.864  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.876  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.871  AUC-train 0.996\n",
            "Stats - Epoch: 79 AUC-val 0.852  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.847  AUC-train 0.994\n",
            "Stats - Epoch: 81 AUC-val 0.875  AUC-train 0.993\n",
            "Stats - Epoch: 82 AUC-val 0.869  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.877  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.863  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.886  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.880  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.882  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.870  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.873  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.856  AUC-train 0.996\n",
            "Stats - Epoch: 91 AUC-val 0.877  AUC-train 0.995\n",
            "Stats - Epoch: 92 AUC-val 0.875  AUC-train 0.996\n",
            "Stats - Epoch: 93 AUC-val 0.845  AUC-train 0.997\n",
            "Stats - Epoch: 94 AUC-val 0.870  AUC-train 0.995\n",
            "Stats - Epoch: 95 AUC-val 0.832  AUC-train 0.995\n",
            "Stats - Epoch: 96 AUC-val 0.844  AUC-train 0.996\n",
            "Stats - Epoch: 97 AUC-val 0.850  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.842  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.846  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.849  AUC-train 0.997\n",
            "Results 100 AUC-val 0.620 0.834 0.920 0.812 0.519 AUC-train 0.948\n",
            "Shapley [0.01601582 0.01811644 0.00313813] [0.00609388]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.143926\n",
            "         Iterations 9\n",
            "['rsp_g', 'ca/gdp', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.387  AUC-train 0.498\n",
            "Stats - Epoch: 2 AUC-val 0.483  AUC-train 0.577\n",
            "Stats - Epoch: 3 AUC-val 0.599  AUC-train 0.669\n",
            "Stats - Epoch: 4 AUC-val 0.634  AUC-train 0.718\n",
            "Stats - Epoch: 5 AUC-val 0.639  AUC-train 0.754\n",
            "Stats - Epoch: 6 AUC-val 0.665  AUC-train 0.773\n",
            "Stats - Epoch: 7 AUC-val 0.634  AUC-train 0.790\n",
            "Stats - Epoch: 8 AUC-val 0.674  AUC-train 0.808\n",
            "Stats - Epoch: 9 AUC-val 0.670  AUC-train 0.828\n",
            "Stats - Epoch: 10 AUC-val 0.683  AUC-train 0.839\n",
            "Stats - Epoch: 11 AUC-val 0.669  AUC-train 0.853\n",
            "Stats - Epoch: 12 AUC-val 0.665  AUC-train 0.866\n",
            "Stats - Epoch: 13 AUC-val 0.670  AUC-train 0.873\n",
            "Stats - Epoch: 14 AUC-val 0.675  AUC-train 0.891\n",
            "Stats - Epoch: 15 AUC-val 0.666  AUC-train 0.896\n",
            "Stats - Epoch: 16 AUC-val 0.683  AUC-train 0.900\n",
            "Stats - Epoch: 17 AUC-val 0.668  AUC-train 0.911\n",
            "Stats - Epoch: 18 AUC-val 0.692  AUC-train 0.917\n",
            "Stats - Epoch: 19 AUC-val 0.681  AUC-train 0.919\n",
            "Stats - Epoch: 20 AUC-val 0.689  AUC-train 0.921\n",
            "Stats - Epoch: 21 AUC-val 0.679  AUC-train 0.930\n",
            "Stats - Epoch: 22 AUC-val 0.677  AUC-train 0.935\n",
            "Stats - Epoch: 23 AUC-val 0.677  AUC-train 0.940\n",
            "Stats - Epoch: 24 AUC-val 0.683  AUC-train 0.941\n",
            "Stats - Epoch: 25 AUC-val 0.682  AUC-train 0.946\n",
            "Stats - Epoch: 26 AUC-val 0.685  AUC-train 0.951\n",
            "Stats - Epoch: 27 AUC-val 0.669  AUC-train 0.955\n",
            "Stats - Epoch: 28 AUC-val 0.686  AUC-train 0.956\n",
            "Stats - Epoch: 29 AUC-val 0.680  AUC-train 0.957\n",
            "Stats - Epoch: 30 AUC-val 0.676  AUC-train 0.960\n",
            "Stats - Epoch: 31 AUC-val 0.669  AUC-train 0.962\n",
            "Stats - Epoch: 32 AUC-val 0.658  AUC-train 0.963\n",
            "Stats - Epoch: 33 AUC-val 0.666  AUC-train 0.966\n",
            "Stats - Epoch: 34 AUC-val 0.650  AUC-train 0.968\n",
            "Stats - Epoch: 35 AUC-val 0.648  AUC-train 0.968\n",
            "Stats - Epoch: 36 AUC-val 0.665  AUC-train 0.970\n",
            "Stats - Epoch: 37 AUC-val 0.655  AUC-train 0.973\n",
            "Stats - Epoch: 38 AUC-val 0.656  AUC-train 0.974\n",
            "Stats - Epoch: 39 AUC-val 0.652  AUC-train 0.975\n",
            "Stats - Epoch: 40 AUC-val 0.640  AUC-train 0.978\n",
            "Stats - Epoch: 41 AUC-val 0.643  AUC-train 0.976\n",
            "Stats - Epoch: 42 AUC-val 0.652  AUC-train 0.979\n",
            "Stats - Epoch: 43 AUC-val 0.647  AUC-train 0.977\n",
            "Stats - Epoch: 44 AUC-val 0.644  AUC-train 0.979\n",
            "Stats - Epoch: 45 AUC-val 0.665  AUC-train 0.981\n",
            "Stats - Epoch: 46 AUC-val 0.665  AUC-train 0.981\n",
            "Stats - Epoch: 47 AUC-val 0.650  AUC-train 0.983\n",
            "Stats - Epoch: 48 AUC-val 0.652  AUC-train 0.984\n",
            "Stats - Epoch: 49 AUC-val 0.637  AUC-train 0.984\n",
            "Stats - Epoch: 50 AUC-val 0.630  AUC-train 0.984\n",
            "Stats - Epoch: 51 AUC-val 0.642  AUC-train 0.985\n",
            "Stats - Epoch: 52 AUC-val 0.631  AUC-train 0.986\n",
            "Stats - Epoch: 53 AUC-val 0.644  AUC-train 0.987\n",
            "Stats - Epoch: 54 AUC-val 0.643  AUC-train 0.988\n",
            "Stats - Epoch: 55 AUC-val 0.614  AUC-train 0.987\n",
            "Stats - Epoch: 56 AUC-val 0.627  AUC-train 0.986\n",
            "Stats - Epoch: 57 AUC-val 0.612  AUC-train 0.986\n",
            "Stats - Epoch: 58 AUC-val 0.614  AUC-train 0.984\n",
            "Stats - Epoch: 59 AUC-val 0.618  AUC-train 0.986\n",
            "Stats - Epoch: 60 AUC-val 0.634  AUC-train 0.985\n",
            "Stats - Epoch: 61 AUC-val 0.632  AUC-train 0.987\n",
            "Stats - Epoch: 62 AUC-val 0.606  AUC-train 0.989\n",
            "Stats - Epoch: 63 AUC-val 0.613  AUC-train 0.988\n",
            "Stats - Epoch: 64 AUC-val 0.610  AUC-train 0.989\n",
            "Stats - Epoch: 65 AUC-val 0.603  AUC-train 0.990\n",
            "Stats - Epoch: 66 AUC-val 0.607  AUC-train 0.990\n",
            "Stats - Epoch: 67 AUC-val 0.664  AUC-train 0.989\n",
            "Stats - Epoch: 68 AUC-val 0.618  AUC-train 0.988\n",
            "Stats - Epoch: 69 AUC-val 0.606  AUC-train 0.992\n",
            "Stats - Epoch: 70 AUC-val 0.617  AUC-train 0.991\n",
            "Stats - Epoch: 71 AUC-val 0.594  AUC-train 0.991\n",
            "Stats - Epoch: 72 AUC-val 0.594  AUC-train 0.992\n",
            "Stats - Epoch: 73 AUC-val 0.602  AUC-train 0.990\n",
            "Stats - Epoch: 74 AUC-val 0.576  AUC-train 0.992\n",
            "Stats - Epoch: 75 AUC-val 0.579  AUC-train 0.992\n",
            "Stats - Epoch: 76 AUC-val 0.600  AUC-train 0.993\n",
            "Stats - Epoch: 77 AUC-val 0.576  AUC-train 0.993\n",
            "Stats - Epoch: 78 AUC-val 0.614  AUC-train 0.992\n",
            "Stats - Epoch: 79 AUC-val 0.602  AUC-train 0.994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 80 AUC-val 0.594  AUC-train 0.993\n",
            "Stats - Epoch: 81 AUC-val 0.573  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.577  AUC-train 0.994\n",
            "Stats - Epoch: 83 AUC-val 0.587  AUC-train 0.990\n",
            "Stats - Epoch: 84 AUC-val 0.580  AUC-train 0.993\n",
            "Stats - Epoch: 85 AUC-val 0.584  AUC-train 0.990\n",
            "Stats - Epoch: 86 AUC-val 0.588  AUC-train 0.991\n",
            "Stats - Epoch: 87 AUC-val 0.614  AUC-train 0.988\n",
            "Stats - Epoch: 88 AUC-val 0.589  AUC-train 0.989\n",
            "Stats - Epoch: 89 AUC-val 0.578  AUC-train 0.989\n",
            "Stats - Epoch: 90 AUC-val 0.607  AUC-train 0.993\n",
            "Stats - Epoch: 91 AUC-val 0.613  AUC-train 0.991\n",
            "Stats - Epoch: 92 AUC-val 0.586  AUC-train 0.991\n",
            "Stats - Epoch: 93 AUC-val 0.584  AUC-train 0.991\n",
            "Stats - Epoch: 94 AUC-val 0.593  AUC-train 0.992\n",
            "Stats - Epoch: 95 AUC-val 0.595  AUC-train 0.994\n",
            "Stats - Epoch: 96 AUC-val 0.595  AUC-train 0.992\n",
            "Stats - Epoch: 97 AUC-val 0.596  AUC-train 0.990\n",
            "Stats - Epoch: 98 AUC-val 0.573  AUC-train 0.991\n",
            "Stats - Epoch: 99 AUC-val 0.592  AUC-train 0.992\n",
            "Stats - Epoch: 100 AUC-val 0.580  AUC-train 0.994\n",
            "Results 100 AUC-val 0.621 0.659 0.692 0.577 0.385 AUC-train 0.917\n",
            "Shapley [0.05074261 0.05430772 0.00446881] [0.04962564]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.181092\n",
            "         Iterations 9\n",
            "['rhp_g', 'ca/gdp', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.685  AUC-train 0.520\n",
            "Stats - Epoch: 2 AUC-val 0.704  AUC-train 0.592\n",
            "Stats - Epoch: 3 AUC-val 0.747  AUC-train 0.632\n",
            "Stats - Epoch: 4 AUC-val 0.761  AUC-train 0.657\n",
            "Stats - Epoch: 5 AUC-val 0.756  AUC-train 0.678\n",
            "Stats - Epoch: 6 AUC-val 0.750  AUC-train 0.695\n",
            "Stats - Epoch: 7 AUC-val 0.746  AUC-train 0.708\n",
            "Stats - Epoch: 8 AUC-val 0.747  AUC-train 0.720\n",
            "Stats - Epoch: 9 AUC-val 0.742  AUC-train 0.732\n",
            "Stats - Epoch: 10 AUC-val 0.742  AUC-train 0.743\n",
            "Stats - Epoch: 11 AUC-val 0.729  AUC-train 0.754\n",
            "Stats - Epoch: 12 AUC-val 0.736  AUC-train 0.765\n",
            "Stats - Epoch: 13 AUC-val 0.730  AUC-train 0.769\n",
            "Stats - Epoch: 14 AUC-val 0.739  AUC-train 0.782\n",
            "Stats - Epoch: 15 AUC-val 0.725  AUC-train 0.785\n",
            "Stats - Epoch: 16 AUC-val 0.722  AUC-train 0.800\n",
            "Stats - Epoch: 17 AUC-val 0.726  AUC-train 0.806\n",
            "Stats - Epoch: 18 AUC-val 0.705  AUC-train 0.811\n",
            "Stats - Epoch: 19 AUC-val 0.707  AUC-train 0.820\n",
            "Stats - Epoch: 20 AUC-val 0.708  AUC-train 0.825\n",
            "Stats - Epoch: 21 AUC-val 0.712  AUC-train 0.833\n",
            "Stats - Epoch: 22 AUC-val 0.719  AUC-train 0.839\n",
            "Stats - Epoch: 23 AUC-val 0.710  AUC-train 0.846\n",
            "Stats - Epoch: 24 AUC-val 0.710  AUC-train 0.848\n",
            "Stats - Epoch: 25 AUC-val 0.712  AUC-train 0.852\n",
            "Stats - Epoch: 26 AUC-val 0.712  AUC-train 0.856\n",
            "Stats - Epoch: 27 AUC-val 0.691  AUC-train 0.862\n",
            "Stats - Epoch: 28 AUC-val 0.695  AUC-train 0.866\n",
            "Stats - Epoch: 29 AUC-val 0.697  AUC-train 0.872\n",
            "Stats - Epoch: 30 AUC-val 0.695  AUC-train 0.875\n",
            "Stats - Epoch: 31 AUC-val 0.692  AUC-train 0.879\n",
            "Stats - Epoch: 32 AUC-val 0.693  AUC-train 0.884\n",
            "Stats - Epoch: 33 AUC-val 0.695  AUC-train 0.887\n",
            "Stats - Epoch: 34 AUC-val 0.685  AUC-train 0.890\n",
            "Stats - Epoch: 35 AUC-val 0.685  AUC-train 0.896\n",
            "Stats - Epoch: 36 AUC-val 0.690  AUC-train 0.892\n",
            "Stats - Epoch: 37 AUC-val 0.688  AUC-train 0.900\n",
            "Stats - Epoch: 38 AUC-val 0.683  AUC-train 0.899\n",
            "Stats - Epoch: 39 AUC-val 0.679  AUC-train 0.903\n",
            "Stats - Epoch: 40 AUC-val 0.682  AUC-train 0.908\n",
            "Stats - Epoch: 41 AUC-val 0.676  AUC-train 0.905\n",
            "Stats - Epoch: 42 AUC-val 0.678  AUC-train 0.910\n",
            "Stats - Epoch: 43 AUC-val 0.676  AUC-train 0.914\n",
            "Stats - Epoch: 44 AUC-val 0.679  AUC-train 0.915\n",
            "Stats - Epoch: 45 AUC-val 0.674  AUC-train 0.919\n",
            "Stats - Epoch: 46 AUC-val 0.680  AUC-train 0.917\n",
            "Stats - Epoch: 47 AUC-val 0.683  AUC-train 0.924\n",
            "Stats - Epoch: 48 AUC-val 0.690  AUC-train 0.924\n",
            "Stats - Epoch: 49 AUC-val 0.668  AUC-train 0.925\n",
            "Stats - Epoch: 50 AUC-val 0.685  AUC-train 0.925\n",
            "Stats - Epoch: 51 AUC-val 0.685  AUC-train 0.927\n",
            "Stats - Epoch: 52 AUC-val 0.678  AUC-train 0.930\n",
            "Stats - Epoch: 53 AUC-val 0.678  AUC-train 0.930\n",
            "Stats - Epoch: 54 AUC-val 0.682  AUC-train 0.932\n",
            "Stats - Epoch: 55 AUC-val 0.683  AUC-train 0.934\n",
            "Stats - Epoch: 56 AUC-val 0.668  AUC-train 0.936\n",
            "Stats - Epoch: 57 AUC-val 0.676  AUC-train 0.934\n",
            "Stats - Epoch: 58 AUC-val 0.666  AUC-train 0.938\n",
            "Stats - Epoch: 59 AUC-val 0.672  AUC-train 0.939\n",
            "Stats - Epoch: 60 AUC-val 0.680  AUC-train 0.940\n",
            "Stats - Epoch: 61 AUC-val 0.675  AUC-train 0.941\n",
            "Stats - Epoch: 62 AUC-val 0.676  AUC-train 0.943\n",
            "Stats - Epoch: 63 AUC-val 0.671  AUC-train 0.941\n",
            "Stats - Epoch: 64 AUC-val 0.662  AUC-train 0.941\n",
            "Stats - Epoch: 65 AUC-val 0.681  AUC-train 0.942\n",
            "Stats - Epoch: 66 AUC-val 0.669  AUC-train 0.940\n",
            "Stats - Epoch: 67 AUC-val 0.675  AUC-train 0.946\n",
            "Stats - Epoch: 68 AUC-val 0.678  AUC-train 0.948\n",
            "Stats - Epoch: 69 AUC-val 0.685  AUC-train 0.948\n",
            "Stats - Epoch: 70 AUC-val 0.680  AUC-train 0.947\n",
            "Stats - Epoch: 71 AUC-val 0.682  AUC-train 0.946\n",
            "Stats - Epoch: 72 AUC-val 0.687  AUC-train 0.949\n",
            "Stats - Epoch: 73 AUC-val 0.683  AUC-train 0.952\n",
            "Stats - Epoch: 74 AUC-val 0.679  AUC-train 0.949\n",
            "Stats - Epoch: 75 AUC-val 0.679  AUC-train 0.951\n",
            "Stats - Epoch: 76 AUC-val 0.679  AUC-train 0.953\n",
            "Stats - Epoch: 77 AUC-val 0.673  AUC-train 0.950\n",
            "Stats - Epoch: 78 AUC-val 0.666  AUC-train 0.947\n",
            "Stats - Epoch: 79 AUC-val 0.668  AUC-train 0.947\n",
            "Stats - Epoch: 80 AUC-val 0.665  AUC-train 0.950\n",
            "Stats - Epoch: 81 AUC-val 0.672  AUC-train 0.951\n",
            "Stats - Epoch: 82 AUC-val 0.672  AUC-train 0.950\n",
            "Stats - Epoch: 83 AUC-val 0.655  AUC-train 0.950\n",
            "Stats - Epoch: 84 AUC-val 0.667  AUC-train 0.954\n",
            "Stats - Epoch: 85 AUC-val 0.663  AUC-train 0.954\n",
            "Stats - Epoch: 86 AUC-val 0.681  AUC-train 0.956\n",
            "Stats - Epoch: 87 AUC-val 0.676  AUC-train 0.956\n",
            "Stats - Epoch: 88 AUC-val 0.667  AUC-train 0.953\n",
            "Stats - Epoch: 89 AUC-val 0.676  AUC-train 0.957\n",
            "Stats - Epoch: 90 AUC-val 0.675  AUC-train 0.960\n",
            "Stats - Epoch: 91 AUC-val 0.668  AUC-train 0.958\n",
            "Stats - Epoch: 92 AUC-val 0.664  AUC-train 0.959\n",
            "Stats - Epoch: 93 AUC-val 0.668  AUC-train 0.960\n",
            "Stats - Epoch: 94 AUC-val 0.681  AUC-train 0.960\n",
            "Stats - Epoch: 95 AUC-val 0.680  AUC-train 0.962\n",
            "Stats - Epoch: 96 AUC-val 0.673  AUC-train 0.962\n",
            "Stats - Epoch: 97 AUC-val 0.678  AUC-train 0.963\n",
            "Stats - Epoch: 98 AUC-val 0.674  AUC-train 0.964\n",
            "Stats - Epoch: 99 AUC-val 0.667  AUC-train 0.963\n",
            "Stats - Epoch: 100 AUC-val 0.669  AUC-train 0.962\n",
            "Results 100 AUC-val 0.553 0.724 0.761 0.639 0.579 AUC-train 0.657\n",
            "Shapley [0.01210234 0.00724292 0.00820034] [0.0212115]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.198216\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g', 'rhp_g', 'ca/gdp']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.388  AUC-train 0.515\n",
            "Stats - Epoch: 2 AUC-val 0.595  AUC-train 0.674\n",
            "Stats - Epoch: 3 AUC-val 0.767  AUC-train 0.786\n",
            "Stats - Epoch: 4 AUC-val 0.786  AUC-train 0.834\n",
            "Stats - Epoch: 5 AUC-val 0.778  AUC-train 0.865\n",
            "Stats - Epoch: 6 AUC-val 0.783  AUC-train 0.883\n",
            "Stats - Epoch: 7 AUC-val 0.758  AUC-train 0.898\n",
            "Stats - Epoch: 8 AUC-val 0.774  AUC-train 0.913\n",
            "Stats - Epoch: 9 AUC-val 0.753  AUC-train 0.924\n",
            "Stats - Epoch: 10 AUC-val 0.748  AUC-train 0.930\n",
            "Stats - Epoch: 11 AUC-val 0.773  AUC-train 0.941\n",
            "Stats - Epoch: 12 AUC-val 0.744  AUC-train 0.946\n",
            "Stats - Epoch: 13 AUC-val 0.752  AUC-train 0.949\n",
            "Stats - Epoch: 14 AUC-val 0.737  AUC-train 0.957\n",
            "Stats - Epoch: 15 AUC-val 0.738  AUC-train 0.960\n",
            "Stats - Epoch: 16 AUC-val 0.741  AUC-train 0.964\n",
            "Stats - Epoch: 17 AUC-val 0.739  AUC-train 0.966\n",
            "Stats - Epoch: 18 AUC-val 0.733  AUC-train 0.970\n",
            "Stats - Epoch: 19 AUC-val 0.730  AUC-train 0.973\n",
            "Stats - Epoch: 20 AUC-val 0.748  AUC-train 0.973\n",
            "Stats - Epoch: 21 AUC-val 0.731  AUC-train 0.975\n",
            "Stats - Epoch: 22 AUC-val 0.729  AUC-train 0.978\n",
            "Stats - Epoch: 23 AUC-val 0.725  AUC-train 0.980\n",
            "Stats - Epoch: 24 AUC-val 0.728  AUC-train 0.981\n",
            "Stats - Epoch: 25 AUC-val 0.719  AUC-train 0.982\n",
            "Stats - Epoch: 26 AUC-val 0.726  AUC-train 0.982\n",
            "Stats - Epoch: 27 AUC-val 0.725  AUC-train 0.984\n",
            "Stats - Epoch: 28 AUC-val 0.707  AUC-train 0.986\n",
            "Stats - Epoch: 29 AUC-val 0.712  AUC-train 0.986\n",
            "Stats - Epoch: 30 AUC-val 0.698  AUC-train 0.988\n",
            "Stats - Epoch: 31 AUC-val 0.714  AUC-train 0.989\n",
            "Stats - Epoch: 32 AUC-val 0.688  AUC-train 0.988\n",
            "Stats - Epoch: 33 AUC-val 0.688  AUC-train 0.989\n",
            "Stats - Epoch: 34 AUC-val 0.679  AUC-train 0.989\n",
            "Stats - Epoch: 35 AUC-val 0.712  AUC-train 0.990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 36 AUC-val 0.714  AUC-train 0.989\n",
            "Stats - Epoch: 37 AUC-val 0.710  AUC-train 0.990\n",
            "Stats - Epoch: 38 AUC-val 0.725  AUC-train 0.991\n",
            "Stats - Epoch: 39 AUC-val 0.708  AUC-train 0.991\n",
            "Stats - Epoch: 40 AUC-val 0.703  AUC-train 0.992\n",
            "Stats - Epoch: 41 AUC-val 0.703  AUC-train 0.991\n",
            "Stats - Epoch: 42 AUC-val 0.699  AUC-train 0.993\n",
            "Stats - Epoch: 43 AUC-val 0.690  AUC-train 0.993\n",
            "Stats - Epoch: 44 AUC-val 0.671  AUC-train 0.994\n",
            "Stats - Epoch: 45 AUC-val 0.666  AUC-train 0.995\n",
            "Stats - Epoch: 46 AUC-val 0.682  AUC-train 0.995\n",
            "Stats - Epoch: 47 AUC-val 0.671  AUC-train 0.996\n",
            "Stats - Epoch: 48 AUC-val 0.684  AUC-train 0.996\n",
            "Stats - Epoch: 49 AUC-val 0.678  AUC-train 0.995\n",
            "Stats - Epoch: 50 AUC-val 0.713  AUC-train 0.994\n",
            "Stats - Epoch: 51 AUC-val 0.698  AUC-train 0.995\n",
            "Stats - Epoch: 52 AUC-val 0.702  AUC-train 0.994\n",
            "Stats - Epoch: 53 AUC-val 0.699  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.691  AUC-train 0.995\n",
            "Stats - Epoch: 55 AUC-val 0.680  AUC-train 0.995\n",
            "Stats - Epoch: 56 AUC-val 0.688  AUC-train 0.997\n",
            "Stats - Epoch: 57 AUC-val 0.687  AUC-train 0.996\n",
            "Stats - Epoch: 58 AUC-val 0.675  AUC-train 0.995\n",
            "Stats - Epoch: 59 AUC-val 0.672  AUC-train 0.994\n",
            "Stats - Epoch: 60 AUC-val 0.681  AUC-train 0.996\n",
            "Stats - Epoch: 61 AUC-val 0.677  AUC-train 0.996\n",
            "Stats - Epoch: 62 AUC-val 0.670  AUC-train 0.997\n",
            "Stats - Epoch: 63 AUC-val 0.648  AUC-train 0.995\n",
            "Stats - Epoch: 64 AUC-val 0.711  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.713  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.679  AUC-train 0.996\n",
            "Stats - Epoch: 67 AUC-val 0.662  AUC-train 0.996\n",
            "Stats - Epoch: 68 AUC-val 0.674  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.666  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.694  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.679  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.699  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.681  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.681  AUC-train 0.995\n",
            "Stats - Epoch: 75 AUC-val 0.713  AUC-train 0.997\n",
            "Stats - Epoch: 76 AUC-val 0.755  AUC-train 0.994\n",
            "Stats - Epoch: 77 AUC-val 0.687  AUC-train 0.994\n",
            "Stats - Epoch: 78 AUC-val 0.684  AUC-train 0.995\n",
            "Stats - Epoch: 79 AUC-val 0.668  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.702  AUC-train 0.996\n",
            "Stats - Epoch: 81 AUC-val 0.713  AUC-train 0.997\n",
            "Stats - Epoch: 82 AUC-val 0.723  AUC-train 0.998\n",
            "Stats - Epoch: 83 AUC-val 0.692  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.685  AUC-train 0.996\n",
            "Stats - Epoch: 85 AUC-val 0.701  AUC-train 0.997\n",
            "Stats - Epoch: 86 AUC-val 0.699  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.668  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.690  AUC-train 0.997\n",
            "Stats - Epoch: 89 AUC-val 0.663  AUC-train 0.998\n",
            "Stats - Epoch: 90 AUC-val 0.695  AUC-train 0.995\n",
            "Stats - Epoch: 91 AUC-val 0.697  AUC-train 0.992\n",
            "Stats - Epoch: 92 AUC-val 0.701  AUC-train 0.994\n",
            "Stats - Epoch: 93 AUC-val 0.685  AUC-train 0.993\n",
            "Stats - Epoch: 94 AUC-val 0.663  AUC-train 0.996\n",
            "Stats - Epoch: 95 AUC-val 0.694  AUC-train 0.995\n",
            "Stats - Epoch: 96 AUC-val 0.671  AUC-train 0.998\n",
            "Stats - Epoch: 97 AUC-val 0.695  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.688  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.704  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.676  AUC-train 0.998\n",
            "Results 100 AUC-val 0.731 0.753 0.786 0.717 0.457 AUC-train 0.834\n",
            "Shapley [0.00437287 0.0175935  0.00896266 0.00707018] [0.03106143]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.191180\n",
            "         Iterations 8\n",
            "['tloansgdp_g', 'rsp_g', 'rhp_g', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.355  AUC-train 0.525\n",
            "Stats - Epoch: 2 AUC-val 0.577  AUC-train 0.663\n",
            "Stats - Epoch: 3 AUC-val 0.723  AUC-train 0.765\n",
            "Stats - Epoch: 4 AUC-val 0.750  AUC-train 0.820\n",
            "Stats - Epoch: 5 AUC-val 0.760  AUC-train 0.852\n",
            "Stats - Epoch: 6 AUC-val 0.792  AUC-train 0.874\n",
            "Stats - Epoch: 7 AUC-val 0.795  AUC-train 0.890\n",
            "Stats - Epoch: 8 AUC-val 0.810  AUC-train 0.903\n",
            "Stats - Epoch: 9 AUC-val 0.802  AUC-train 0.918\n",
            "Stats - Epoch: 10 AUC-val 0.832  AUC-train 0.923\n",
            "Stats - Epoch: 11 AUC-val 0.833  AUC-train 0.933\n",
            "Stats - Epoch: 12 AUC-val 0.831  AUC-train 0.938\n",
            "Stats - Epoch: 13 AUC-val 0.834  AUC-train 0.942\n",
            "Stats - Epoch: 14 AUC-val 0.831  AUC-train 0.951\n",
            "Stats - Epoch: 15 AUC-val 0.843  AUC-train 0.955\n",
            "Stats - Epoch: 16 AUC-val 0.818  AUC-train 0.959\n",
            "Stats - Epoch: 17 AUC-val 0.835  AUC-train 0.962\n",
            "Stats - Epoch: 18 AUC-val 0.822  AUC-train 0.966\n",
            "Stats - Epoch: 19 AUC-val 0.820  AUC-train 0.970\n",
            "Stats - Epoch: 20 AUC-val 0.819  AUC-train 0.973\n",
            "Stats - Epoch: 21 AUC-val 0.829  AUC-train 0.974\n",
            "Stats - Epoch: 22 AUC-val 0.815  AUC-train 0.976\n",
            "Stats - Epoch: 23 AUC-val 0.801  AUC-train 0.977\n",
            "Stats - Epoch: 24 AUC-val 0.792  AUC-train 0.978\n",
            "Stats - Epoch: 25 AUC-val 0.804  AUC-train 0.978\n",
            "Stats - Epoch: 26 AUC-val 0.819  AUC-train 0.980\n",
            "Stats - Epoch: 27 AUC-val 0.801  AUC-train 0.981\n",
            "Stats - Epoch: 28 AUC-val 0.800  AUC-train 0.984\n",
            "Stats - Epoch: 29 AUC-val 0.785  AUC-train 0.983\n",
            "Stats - Epoch: 30 AUC-val 0.790  AUC-train 0.986\n",
            "Stats - Epoch: 31 AUC-val 0.797  AUC-train 0.986\n",
            "Stats - Epoch: 32 AUC-val 0.776  AUC-train 0.986\n",
            "Stats - Epoch: 33 AUC-val 0.801  AUC-train 0.986\n",
            "Stats - Epoch: 34 AUC-val 0.764  AUC-train 0.989\n",
            "Stats - Epoch: 35 AUC-val 0.783  AUC-train 0.990\n",
            "Stats - Epoch: 36 AUC-val 0.788  AUC-train 0.991\n",
            "Stats - Epoch: 37 AUC-val 0.772  AUC-train 0.990\n",
            "Stats - Epoch: 38 AUC-val 0.764  AUC-train 0.990\n",
            "Stats - Epoch: 39 AUC-val 0.770  AUC-train 0.991\n",
            "Stats - Epoch: 40 AUC-val 0.780  AUC-train 0.990\n",
            "Stats - Epoch: 41 AUC-val 0.784  AUC-train 0.991\n",
            "Stats - Epoch: 42 AUC-val 0.821  AUC-train 0.991\n",
            "Stats - Epoch: 43 AUC-val 0.783  AUC-train 0.991\n",
            "Stats - Epoch: 44 AUC-val 0.766  AUC-train 0.989\n",
            "Stats - Epoch: 45 AUC-val 0.779  AUC-train 0.991\n",
            "Stats - Epoch: 46 AUC-val 0.766  AUC-train 0.992\n",
            "Stats - Epoch: 47 AUC-val 0.780  AUC-train 0.991\n",
            "Stats - Epoch: 48 AUC-val 0.777  AUC-train 0.992\n",
            "Stats - Epoch: 49 AUC-val 0.777  AUC-train 0.991\n",
            "Stats - Epoch: 50 AUC-val 0.772  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.776  AUC-train 0.994\n",
            "Stats - Epoch: 52 AUC-val 0.768  AUC-train 0.992\n",
            "Stats - Epoch: 53 AUC-val 0.772  AUC-train 0.993\n",
            "Stats - Epoch: 54 AUC-val 0.745  AUC-train 0.993\n",
            "Stats - Epoch: 55 AUC-val 0.773  AUC-train 0.992\n",
            "Stats - Epoch: 56 AUC-val 0.778  AUC-train 0.994\n",
            "Stats - Epoch: 57 AUC-val 0.774  AUC-train 0.994\n",
            "Stats - Epoch: 58 AUC-val 0.775  AUC-train 0.995\n",
            "Stats - Epoch: 59 AUC-val 0.760  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.757  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.771  AUC-train 0.996\n",
            "Stats - Epoch: 62 AUC-val 0.762  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.773  AUC-train 0.996\n",
            "Stats - Epoch: 64 AUC-val 0.763  AUC-train 0.997\n",
            "Stats - Epoch: 65 AUC-val 0.765  AUC-train 0.994\n",
            "Stats - Epoch: 66 AUC-val 0.761  AUC-train 0.991\n",
            "Stats - Epoch: 67 AUC-val 0.742  AUC-train 0.995\n",
            "Stats - Epoch: 68 AUC-val 0.760  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.747  AUC-train 0.996\n",
            "Stats - Epoch: 70 AUC-val 0.735  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.741  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.754  AUC-train 0.995\n",
            "Stats - Epoch: 73 AUC-val 0.774  AUC-train 0.995\n",
            "Stats - Epoch: 74 AUC-val 0.735  AUC-train 0.994\n",
            "Stats - Epoch: 75 AUC-val 0.753  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.757  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.739  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.761  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.745  AUC-train 0.996\n",
            "Stats - Epoch: 80 AUC-val 0.738  AUC-train 0.997\n",
            "Stats - Epoch: 81 AUC-val 0.724  AUC-train 0.996\n",
            "Stats - Epoch: 82 AUC-val 0.739  AUC-train 0.997\n",
            "Stats - Epoch: 83 AUC-val 0.738  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.715  AUC-train 0.997\n",
            "Stats - Epoch: 85 AUC-val 0.783  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.733  AUC-train 0.998\n",
            "Stats - Epoch: 87 AUC-val 0.760  AUC-train 0.998\n",
            "Stats - Epoch: 88 AUC-val 0.716  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.748  AUC-train 0.995\n",
            "Stats - Epoch: 90 AUC-val 0.771  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.732  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.739  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.692  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.712  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.732  AUC-train 0.995\n",
            "Stats - Epoch: 96 AUC-val 0.711  AUC-train 0.994\n",
            "Stats - Epoch: 97 AUC-val 0.732  AUC-train 0.997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 98 AUC-val 0.739  AUC-train 0.997\n",
            "Stats - Epoch: 99 AUC-val 0.787  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.725  AUC-train 0.997\n",
            "Results 100 AUC-val 0.630 0.792 0.843 0.790 0.574 AUC-train 0.955\n",
            "Shapley [0.00967799 0.0154917  0.00997839 0.0026067 ] [0.00438945]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.164741\n",
            "         Iterations 8\n",
            "['tloansgdp_g', 'rsp_g', 'ca/gdp', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.336  AUC-train 0.500\n",
            "Stats - Epoch: 2 AUC-val 0.510  AUC-train 0.648\n",
            "Stats - Epoch: 3 AUC-val 0.680  AUC-train 0.760\n",
            "Stats - Epoch: 4 AUC-val 0.705  AUC-train 0.812\n",
            "Stats - Epoch: 5 AUC-val 0.699  AUC-train 0.844\n",
            "Stats - Epoch: 6 AUC-val 0.699  AUC-train 0.862\n",
            "Stats - Epoch: 7 AUC-val 0.671  AUC-train 0.880\n",
            "Stats - Epoch: 8 AUC-val 0.676  AUC-train 0.891\n",
            "Stats - Epoch: 9 AUC-val 0.654  AUC-train 0.908\n",
            "Stats - Epoch: 10 AUC-val 0.661  AUC-train 0.915\n",
            "Stats - Epoch: 11 AUC-val 0.650  AUC-train 0.922\n",
            "Stats - Epoch: 12 AUC-val 0.645  AUC-train 0.933\n",
            "Stats - Epoch: 13 AUC-val 0.662  AUC-train 0.932\n",
            "Stats - Epoch: 14 AUC-val 0.644  AUC-train 0.943\n",
            "Stats - Epoch: 15 AUC-val 0.654  AUC-train 0.946\n",
            "Stats - Epoch: 16 AUC-val 0.636  AUC-train 0.948\n",
            "Stats - Epoch: 17 AUC-val 0.625  AUC-train 0.954\n",
            "Stats - Epoch: 18 AUC-val 0.637  AUC-train 0.959\n",
            "Stats - Epoch: 19 AUC-val 0.627  AUC-train 0.962\n",
            "Stats - Epoch: 20 AUC-val 0.652  AUC-train 0.963\n",
            "Stats - Epoch: 21 AUC-val 0.638  AUC-train 0.967\n",
            "Stats - Epoch: 22 AUC-val 0.625  AUC-train 0.967\n",
            "Stats - Epoch: 23 AUC-val 0.612  AUC-train 0.973\n",
            "Stats - Epoch: 24 AUC-val 0.632  AUC-train 0.969\n",
            "Stats - Epoch: 25 AUC-val 0.642  AUC-train 0.972\n",
            "Stats - Epoch: 26 AUC-val 0.598  AUC-train 0.975\n",
            "Stats - Epoch: 27 AUC-val 0.610  AUC-train 0.977\n",
            "Stats - Epoch: 28 AUC-val 0.598  AUC-train 0.979\n",
            "Stats - Epoch: 29 AUC-val 0.608  AUC-train 0.979\n",
            "Stats - Epoch: 30 AUC-val 0.618  AUC-train 0.981\n",
            "Stats - Epoch: 31 AUC-val 0.628  AUC-train 0.981\n",
            "Stats - Epoch: 32 AUC-val 0.582  AUC-train 0.983\n",
            "Stats - Epoch: 33 AUC-val 0.607  AUC-train 0.982\n",
            "Stats - Epoch: 34 AUC-val 0.574  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.562  AUC-train 0.987\n",
            "Stats - Epoch: 36 AUC-val 0.582  AUC-train 0.987\n",
            "Stats - Epoch: 37 AUC-val 0.574  AUC-train 0.986\n",
            "Stats - Epoch: 38 AUC-val 0.580  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.580  AUC-train 0.990\n",
            "Stats - Epoch: 40 AUC-val 0.536  AUC-train 0.990\n",
            "Stats - Epoch: 41 AUC-val 0.594  AUC-train 0.989\n",
            "Stats - Epoch: 42 AUC-val 0.586  AUC-train 0.992\n",
            "Stats - Epoch: 43 AUC-val 0.558  AUC-train 0.991\n",
            "Stats - Epoch: 44 AUC-val 0.590  AUC-train 0.991\n",
            "Stats - Epoch: 45 AUC-val 0.579  AUC-train 0.992\n",
            "Stats - Epoch: 46 AUC-val 0.550  AUC-train 0.991\n",
            "Stats - Epoch: 47 AUC-val 0.543  AUC-train 0.991\n",
            "Stats - Epoch: 48 AUC-val 0.542  AUC-train 0.993\n",
            "Stats - Epoch: 49 AUC-val 0.552  AUC-train 0.993\n",
            "Stats - Epoch: 50 AUC-val 0.567  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.552  AUC-train 0.991\n",
            "Stats - Epoch: 52 AUC-val 0.594  AUC-train 0.991\n",
            "Stats - Epoch: 53 AUC-val 0.572  AUC-train 0.994\n",
            "Stats - Epoch: 54 AUC-val 0.560  AUC-train 0.993\n",
            "Stats - Epoch: 55 AUC-val 0.564  AUC-train 0.994\n",
            "Stats - Epoch: 56 AUC-val 0.588  AUC-train 0.994\n",
            "Stats - Epoch: 57 AUC-val 0.565  AUC-train 0.995\n",
            "Stats - Epoch: 58 AUC-val 0.531  AUC-train 0.995\n",
            "Stats - Epoch: 59 AUC-val 0.549  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.510  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.539  AUC-train 0.995\n",
            "Stats - Epoch: 62 AUC-val 0.521  AUC-train 0.996\n",
            "Stats - Epoch: 63 AUC-val 0.519  AUC-train 0.994\n",
            "Stats - Epoch: 64 AUC-val 0.540  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.541  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.566  AUC-train 0.994\n",
            "Stats - Epoch: 67 AUC-val 0.580  AUC-train 0.995\n",
            "Stats - Epoch: 68 AUC-val 0.542  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.572  AUC-train 0.996\n",
            "Stats - Epoch: 70 AUC-val 0.528  AUC-train 0.995\n",
            "Stats - Epoch: 71 AUC-val 0.543  AUC-train 0.995\n",
            "Stats - Epoch: 72 AUC-val 0.578  AUC-train 0.995\n",
            "Stats - Epoch: 73 AUC-val 0.590  AUC-train 0.996\n",
            "Stats - Epoch: 74 AUC-val 0.579  AUC-train 0.993\n",
            "Stats - Epoch: 75 AUC-val 0.519  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.528  AUC-train 0.994\n",
            "Stats - Epoch: 77 AUC-val 0.538  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.599  AUC-train 0.994\n",
            "Stats - Epoch: 79 AUC-val 0.517  AUC-train 0.995\n",
            "Stats - Epoch: 80 AUC-val 0.531  AUC-train 0.996\n",
            "Stats - Epoch: 81 AUC-val 0.562  AUC-train 0.994\n",
            "Stats - Epoch: 82 AUC-val 0.521  AUC-train 0.995\n",
            "Stats - Epoch: 83 AUC-val 0.521  AUC-train 0.995\n",
            "Stats - Epoch: 84 AUC-val 0.518  AUC-train 0.994\n",
            "Stats - Epoch: 85 AUC-val 0.507  AUC-train 0.995\n",
            "Stats - Epoch: 86 AUC-val 0.535  AUC-train 0.995\n",
            "Stats - Epoch: 87 AUC-val 0.561  AUC-train 0.996\n",
            "Stats - Epoch: 88 AUC-val 0.564  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.553  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.501  AUC-train 0.997\n",
            "Stats - Epoch: 91 AUC-val 0.582  AUC-train 0.995\n",
            "Stats - Epoch: 92 AUC-val 0.534  AUC-train 0.995\n",
            "Stats - Epoch: 93 AUC-val 0.542  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.573  AUC-train 0.992\n",
            "Stats - Epoch: 95 AUC-val 0.591  AUC-train 0.993\n",
            "Stats - Epoch: 96 AUC-val 0.603  AUC-train 0.995\n",
            "Stats - Epoch: 97 AUC-val 0.593  AUC-train 0.996\n",
            "Stats - Epoch: 98 AUC-val 0.562  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.547  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.548  AUC-train 0.994\n",
            "Results 100 AUC-val 0.767 0.712 0.705 0.542 0.298 AUC-train 0.812\n",
            "Shapley [0.00909816 0.0191846  0.00503895 0.00677919] [0.0349594]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.215528\n",
            "         Iterations 8\n",
            "['tloansgdp_g', 'rhp_g', 'ca/gdp', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.536  AUC-train 0.472\n",
            "Stats - Epoch: 2 AUC-val 0.656  AUC-train 0.613\n",
            "Stats - Epoch: 3 AUC-val 0.729  AUC-train 0.690\n",
            "Stats - Epoch: 4 AUC-val 0.732  AUC-train 0.732\n",
            "Stats - Epoch: 5 AUC-val 0.716  AUC-train 0.762\n",
            "Stats - Epoch: 6 AUC-val 0.701  AUC-train 0.783\n",
            "Stats - Epoch: 7 AUC-val 0.687  AUC-train 0.805\n",
            "Stats - Epoch: 8 AUC-val 0.678  AUC-train 0.816\n",
            "Stats - Epoch: 9 AUC-val 0.647  AUC-train 0.834\n",
            "Stats - Epoch: 10 AUC-val 0.636  AUC-train 0.843\n",
            "Stats - Epoch: 11 AUC-val 0.630  AUC-train 0.853\n",
            "Stats - Epoch: 12 AUC-val 0.614  AUC-train 0.870\n",
            "Stats - Epoch: 13 AUC-val 0.613  AUC-train 0.867\n",
            "Stats - Epoch: 14 AUC-val 0.606  AUC-train 0.883\n",
            "Stats - Epoch: 15 AUC-val 0.589  AUC-train 0.888\n",
            "Stats - Epoch: 16 AUC-val 0.584  AUC-train 0.895\n",
            "Stats - Epoch: 17 AUC-val 0.589  AUC-train 0.901\n",
            "Stats - Epoch: 18 AUC-val 0.586  AUC-train 0.907\n",
            "Stats - Epoch: 19 AUC-val 0.583  AUC-train 0.914\n",
            "Stats - Epoch: 20 AUC-val 0.576  AUC-train 0.917\n",
            "Stats - Epoch: 21 AUC-val 0.599  AUC-train 0.924\n",
            "Stats - Epoch: 22 AUC-val 0.587  AUC-train 0.924\n",
            "Stats - Epoch: 23 AUC-val 0.587  AUC-train 0.931\n",
            "Stats - Epoch: 24 AUC-val 0.573  AUC-train 0.934\n",
            "Stats - Epoch: 25 AUC-val 0.590  AUC-train 0.937\n",
            "Stats - Epoch: 26 AUC-val 0.578  AUC-train 0.941\n",
            "Stats - Epoch: 27 AUC-val 0.595  AUC-train 0.945\n",
            "Stats - Epoch: 28 AUC-val 0.588  AUC-train 0.944\n",
            "Stats - Epoch: 29 AUC-val 0.568  AUC-train 0.948\n",
            "Stats - Epoch: 30 AUC-val 0.573  AUC-train 0.950\n",
            "Stats - Epoch: 31 AUC-val 0.593  AUC-train 0.954\n",
            "Stats - Epoch: 32 AUC-val 0.586  AUC-train 0.956\n",
            "Stats - Epoch: 33 AUC-val 0.579  AUC-train 0.956\n",
            "Stats - Epoch: 34 AUC-val 0.596  AUC-train 0.959\n",
            "Stats - Epoch: 35 AUC-val 0.584  AUC-train 0.962\n",
            "Stats - Epoch: 36 AUC-val 0.591  AUC-train 0.960\n",
            "Stats - Epoch: 37 AUC-val 0.590  AUC-train 0.961\n",
            "Stats - Epoch: 38 AUC-val 0.572  AUC-train 0.964\n",
            "Stats - Epoch: 39 AUC-val 0.569  AUC-train 0.967\n",
            "Stats - Epoch: 40 AUC-val 0.583  AUC-train 0.966\n",
            "Stats - Epoch: 41 AUC-val 0.556  AUC-train 0.965\n",
            "Stats - Epoch: 42 AUC-val 0.558  AUC-train 0.966\n",
            "Stats - Epoch: 43 AUC-val 0.565  AUC-train 0.969\n",
            "Stats - Epoch: 44 AUC-val 0.578  AUC-train 0.970\n",
            "Stats - Epoch: 45 AUC-val 0.588  AUC-train 0.972\n",
            "Stats - Epoch: 46 AUC-val 0.572  AUC-train 0.974\n",
            "Stats - Epoch: 47 AUC-val 0.573  AUC-train 0.972\n",
            "Stats - Epoch: 48 AUC-val 0.566  AUC-train 0.972\n",
            "Stats - Epoch: 49 AUC-val 0.581  AUC-train 0.975\n",
            "Stats - Epoch: 50 AUC-val 0.577  AUC-train 0.974\n",
            "Stats - Epoch: 51 AUC-val 0.570  AUC-train 0.973\n",
            "Stats - Epoch: 52 AUC-val 0.539  AUC-train 0.974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 53 AUC-val 0.556  AUC-train 0.975\n",
            "Stats - Epoch: 54 AUC-val 0.562  AUC-train 0.979\n",
            "Stats - Epoch: 55 AUC-val 0.568  AUC-train 0.976\n",
            "Stats - Epoch: 56 AUC-val 0.574  AUC-train 0.979\n",
            "Stats - Epoch: 57 AUC-val 0.567  AUC-train 0.977\n",
            "Stats - Epoch: 58 AUC-val 0.585  AUC-train 0.978\n",
            "Stats - Epoch: 59 AUC-val 0.583  AUC-train 0.975\n",
            "Stats - Epoch: 60 AUC-val 0.556  AUC-train 0.976\n",
            "Stats - Epoch: 61 AUC-val 0.570  AUC-train 0.979\n",
            "Stats - Epoch: 62 AUC-val 0.551  AUC-train 0.980\n",
            "Stats - Epoch: 63 AUC-val 0.558  AUC-train 0.979\n",
            "Stats - Epoch: 64 AUC-val 0.562  AUC-train 0.979\n",
            "Stats - Epoch: 65 AUC-val 0.556  AUC-train 0.982\n",
            "Stats - Epoch: 66 AUC-val 0.585  AUC-train 0.980\n",
            "Stats - Epoch: 67 AUC-val 0.579  AUC-train 0.983\n",
            "Stats - Epoch: 68 AUC-val 0.552  AUC-train 0.983\n",
            "Stats - Epoch: 69 AUC-val 0.547  AUC-train 0.984\n",
            "Stats - Epoch: 70 AUC-val 0.579  AUC-train 0.983\n",
            "Stats - Epoch: 71 AUC-val 0.555  AUC-train 0.983\n",
            "Stats - Epoch: 72 AUC-val 0.561  AUC-train 0.984\n",
            "Stats - Epoch: 73 AUC-val 0.565  AUC-train 0.983\n",
            "Stats - Epoch: 74 AUC-val 0.576  AUC-train 0.982\n",
            "Stats - Epoch: 75 AUC-val 0.565  AUC-train 0.979\n",
            "Stats - Epoch: 76 AUC-val 0.583  AUC-train 0.979\n",
            "Stats - Epoch: 77 AUC-val 0.573  AUC-train 0.981\n",
            "Stats - Epoch: 78 AUC-val 0.550  AUC-train 0.983\n",
            "Stats - Epoch: 79 AUC-val 0.563  AUC-train 0.985\n",
            "Stats - Epoch: 80 AUC-val 0.562  AUC-train 0.984\n",
            "Stats - Epoch: 81 AUC-val 0.560  AUC-train 0.986\n",
            "Stats - Epoch: 82 AUC-val 0.563  AUC-train 0.987\n",
            "Stats - Epoch: 83 AUC-val 0.570  AUC-train 0.987\n",
            "Stats - Epoch: 84 AUC-val 0.572  AUC-train 0.985\n",
            "Stats - Epoch: 85 AUC-val 0.573  AUC-train 0.986\n",
            "Stats - Epoch: 86 AUC-val 0.585  AUC-train 0.980\n",
            "Stats - Epoch: 87 AUC-val 0.572  AUC-train 0.982\n",
            "Stats - Epoch: 88 AUC-val 0.575  AUC-train 0.984\n",
            "Stats - Epoch: 89 AUC-val 0.586  AUC-train 0.984\n",
            "Stats - Epoch: 90 AUC-val 0.572  AUC-train 0.986\n",
            "Stats - Epoch: 91 AUC-val 0.573  AUC-train 0.982\n",
            "Stats - Epoch: 92 AUC-val 0.567  AUC-train 0.984\n",
            "Stats - Epoch: 93 AUC-val 0.582  AUC-train 0.986\n",
            "Stats - Epoch: 94 AUC-val 0.579  AUC-train 0.983\n",
            "Stats - Epoch: 95 AUC-val 0.568  AUC-train 0.984\n",
            "Stats - Epoch: 96 AUC-val 0.587  AUC-train 0.984\n",
            "Stats - Epoch: 97 AUC-val 0.573  AUC-train 0.984\n",
            "Stats - Epoch: 98 AUC-val 0.573  AUC-train 0.982\n",
            "Stats - Epoch: 99 AUC-val 0.598  AUC-train 0.982\n",
            "Stats - Epoch: 100 AUC-val 0.581  AUC-train 0.981\n",
            "Results 100 AUC-val 0.580 0.682 0.732 0.568 0.529 AUC-train 0.732\n",
            "Shapley [0.00686539 0.00889717 0.00506102 0.00704042] [0.01930787]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.199046\n",
            "         Iterations 9\n",
            "['rsp_g', 'rhp_g', 'ca/gdp', 'rgdp_g']\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.441  AUC-train 0.533\n",
            "Stats - Epoch: 2 AUC-val 0.627  AUC-train 0.673\n",
            "Stats - Epoch: 3 AUC-val 0.737  AUC-train 0.763\n",
            "Stats - Epoch: 4 AUC-val 0.764  AUC-train 0.808\n",
            "Stats - Epoch: 5 AUC-val 0.765  AUC-train 0.834\n",
            "Stats - Epoch: 6 AUC-val 0.782  AUC-train 0.856\n",
            "Stats - Epoch: 7 AUC-val 0.767  AUC-train 0.869\n",
            "Stats - Epoch: 8 AUC-val 0.790  AUC-train 0.883\n",
            "Stats - Epoch: 9 AUC-val 0.785  AUC-train 0.893\n",
            "Stats - Epoch: 10 AUC-val 0.795  AUC-train 0.902\n",
            "Stats - Epoch: 11 AUC-val 0.788  AUC-train 0.911\n",
            "Stats - Epoch: 12 AUC-val 0.798  AUC-train 0.919\n",
            "Stats - Epoch: 13 AUC-val 0.797  AUC-train 0.925\n",
            "Stats - Epoch: 14 AUC-val 0.790  AUC-train 0.933\n",
            "Stats - Epoch: 15 AUC-val 0.805  AUC-train 0.939\n",
            "Stats - Epoch: 16 AUC-val 0.788  AUC-train 0.947\n",
            "Stats - Epoch: 17 AUC-val 0.795  AUC-train 0.951\n",
            "Stats - Epoch: 18 AUC-val 0.791  AUC-train 0.954\n",
            "Stats - Epoch: 19 AUC-val 0.793  AUC-train 0.959\n",
            "Stats - Epoch: 20 AUC-val 0.781  AUC-train 0.963\n",
            "Stats - Epoch: 21 AUC-val 0.791  AUC-train 0.967\n",
            "Stats - Epoch: 22 AUC-val 0.788  AUC-train 0.968\n",
            "Stats - Epoch: 23 AUC-val 0.782  AUC-train 0.970\n",
            "Stats - Epoch: 24 AUC-val 0.782  AUC-train 0.972\n",
            "Stats - Epoch: 25 AUC-val 0.789  AUC-train 0.974\n",
            "Stats - Epoch: 26 AUC-val 0.795  AUC-train 0.975\n",
            "Stats - Epoch: 27 AUC-val 0.771  AUC-train 0.979\n",
            "Stats - Epoch: 28 AUC-val 0.771  AUC-train 0.981\n",
            "Stats - Epoch: 29 AUC-val 0.790  AUC-train 0.981\n",
            "Stats - Epoch: 30 AUC-val 0.781  AUC-train 0.982\n",
            "Stats - Epoch: 31 AUC-val 0.767  AUC-train 0.984\n",
            "Stats - Epoch: 32 AUC-val 0.772  AUC-train 0.983\n",
            "Stats - Epoch: 33 AUC-val 0.767  AUC-train 0.986\n",
            "Stats - Epoch: 34 AUC-val 0.767  AUC-train 0.985\n",
            "Stats - Epoch: 35 AUC-val 0.785  AUC-train 0.988\n",
            "Stats - Epoch: 36 AUC-val 0.778  AUC-train 0.988\n",
            "Stats - Epoch: 37 AUC-val 0.781  AUC-train 0.991\n",
            "Stats - Epoch: 38 AUC-val 0.810  AUC-train 0.988\n",
            "Stats - Epoch: 39 AUC-val 0.793  AUC-train 0.989\n",
            "Stats - Epoch: 40 AUC-val 0.774  AUC-train 0.989\n",
            "Stats - Epoch: 41 AUC-val 0.784  AUC-train 0.991\n",
            "Stats - Epoch: 42 AUC-val 0.782  AUC-train 0.991\n",
            "Stats - Epoch: 43 AUC-val 0.774  AUC-train 0.991\n",
            "Stats - Epoch: 44 AUC-val 0.764  AUC-train 0.990\n",
            "Stats - Epoch: 45 AUC-val 0.774  AUC-train 0.991\n",
            "Stats - Epoch: 46 AUC-val 0.778  AUC-train 0.993\n",
            "Stats - Epoch: 47 AUC-val 0.765  AUC-train 0.994\n",
            "Stats - Epoch: 48 AUC-val 0.782  AUC-train 0.993\n",
            "Stats - Epoch: 49 AUC-val 0.777  AUC-train 0.993\n",
            "Stats - Epoch: 50 AUC-val 0.785  AUC-train 0.993\n",
            "Stats - Epoch: 51 AUC-val 0.810  AUC-train 0.995\n",
            "Stats - Epoch: 52 AUC-val 0.781  AUC-train 0.994\n",
            "Stats - Epoch: 53 AUC-val 0.767  AUC-train 0.994\n",
            "Stats - Epoch: 54 AUC-val 0.785  AUC-train 0.994\n",
            "Stats - Epoch: 55 AUC-val 0.743  AUC-train 0.994\n",
            "Stats - Epoch: 56 AUC-val 0.764  AUC-train 0.993\n",
            "Stats - Epoch: 57 AUC-val 0.756  AUC-train 0.995\n",
            "Stats - Epoch: 58 AUC-val 0.759  AUC-train 0.995\n",
            "Stats - Epoch: 59 AUC-val 0.771  AUC-train 0.996\n",
            "Stats - Epoch: 60 AUC-val 0.761  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.800  AUC-train 0.991\n",
            "Stats - Epoch: 62 AUC-val 0.801  AUC-train 0.995\n",
            "Stats - Epoch: 63 AUC-val 0.798  AUC-train 0.996\n",
            "Stats - Epoch: 64 AUC-val 0.779  AUC-train 0.996\n",
            "Stats - Epoch: 65 AUC-val 0.772  AUC-train 0.995\n",
            "Stats - Epoch: 66 AUC-val 0.765  AUC-train 0.994\n",
            "Stats - Epoch: 67 AUC-val 0.771  AUC-train 0.997\n",
            "Stats - Epoch: 68 AUC-val 0.774  AUC-train 0.996\n",
            "Stats - Epoch: 69 AUC-val 0.768  AUC-train 0.996\n",
            "Stats - Epoch: 70 AUC-val 0.760  AUC-train 0.997\n",
            "Stats - Epoch: 71 AUC-val 0.756  AUC-train 0.997\n",
            "Stats - Epoch: 72 AUC-val 0.780  AUC-train 0.996\n",
            "Stats - Epoch: 73 AUC-val 0.786  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.759  AUC-train 0.998\n",
            "Stats - Epoch: 75 AUC-val 0.790  AUC-train 0.998\n",
            "Stats - Epoch: 76 AUC-val 0.767  AUC-train 0.996\n",
            "Stats - Epoch: 77 AUC-val 0.767  AUC-train 0.996\n",
            "Stats - Epoch: 78 AUC-val 0.780  AUC-train 0.998\n",
            "Stats - Epoch: 79 AUC-val 0.771  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.775  AUC-train 0.994\n",
            "Stats - Epoch: 81 AUC-val 0.774  AUC-train 0.993\n",
            "Stats - Epoch: 82 AUC-val 0.771  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.783  AUC-train 0.997\n",
            "Stats - Epoch: 84 AUC-val 0.780  AUC-train 0.998\n",
            "Stats - Epoch: 85 AUC-val 0.746  AUC-train 0.998\n",
            "Stats - Epoch: 86 AUC-val 0.775  AUC-train 0.997\n",
            "Stats - Epoch: 87 AUC-val 0.770  AUC-train 0.993\n",
            "Stats - Epoch: 88 AUC-val 0.767  AUC-train 0.991\n",
            "Stats - Epoch: 89 AUC-val 0.770  AUC-train 0.993\n",
            "Stats - Epoch: 90 AUC-val 0.741  AUC-train 0.995\n",
            "Stats - Epoch: 91 AUC-val 0.740  AUC-train 0.996\n",
            "Stats - Epoch: 92 AUC-val 0.738  AUC-train 0.997\n",
            "Stats - Epoch: 93 AUC-val 0.742  AUC-train 0.998\n",
            "Stats - Epoch: 94 AUC-val 0.747  AUC-train 0.998\n",
            "Stats - Epoch: 95 AUC-val 0.737  AUC-train 0.997\n",
            "Stats - Epoch: 96 AUC-val 0.757  AUC-train 0.996\n",
            "Stats - Epoch: 97 AUC-val 0.774  AUC-train 0.998\n",
            "Stats - Epoch: 98 AUC-val 0.741  AUC-train 0.998\n",
            "Stats - Epoch: 99 AUC-val 0.766  AUC-train 0.997\n",
            "Stats - Epoch: 100 AUC-val 0.762  AUC-train 0.999\n",
            "Results 100 AUC-val 0.600 0.760 0.810 0.713 0.547 AUC-train 0.988\n",
            "Shapley [0.04348886 0.02023402 0.06258851 0.00575491] [0.00289222]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.149304\n",
            "         Iterations 9\n",
            "Crises train:11\n",
            "Crises test:12\n",
            "Stats - Epoch: 1 AUC-val 0.348  AUC-train 0.524\n",
            "Stats - Epoch: 2 AUC-val 0.542  AUC-train 0.675\n",
            "Stats - Epoch: 3 AUC-val 0.737  AUC-train 0.789\n",
            "Stats - Epoch: 4 AUC-val 0.778  AUC-train 0.842\n",
            "Stats - Epoch: 5 AUC-val 0.777  AUC-train 0.871\n",
            "Stats - Epoch: 6 AUC-val 0.794  AUC-train 0.887\n",
            "Stats - Epoch: 7 AUC-val 0.780  AUC-train 0.904\n",
            "Stats - Epoch: 8 AUC-val 0.801  AUC-train 0.917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stats - Epoch: 9 AUC-val 0.780  AUC-train 0.929\n",
            "Stats - Epoch: 10 AUC-val 0.766  AUC-train 0.938\n",
            "Stats - Epoch: 11 AUC-val 0.772  AUC-train 0.943\n",
            "Stats - Epoch: 12 AUC-val 0.767  AUC-train 0.951\n",
            "Stats - Epoch: 13 AUC-val 0.775  AUC-train 0.956\n",
            "Stats - Epoch: 14 AUC-val 0.773  AUC-train 0.960\n",
            "Stats - Epoch: 15 AUC-val 0.778  AUC-train 0.965\n",
            "Stats - Epoch: 16 AUC-val 0.775  AUC-train 0.968\n",
            "Stats - Epoch: 17 AUC-val 0.773  AUC-train 0.967\n",
            "Stats - Epoch: 18 AUC-val 0.773  AUC-train 0.971\n",
            "Stats - Epoch: 19 AUC-val 0.769  AUC-train 0.973\n",
            "Stats - Epoch: 20 AUC-val 0.775  AUC-train 0.977\n",
            "Stats - Epoch: 21 AUC-val 0.768  AUC-train 0.978\n",
            "Stats - Epoch: 22 AUC-val 0.775  AUC-train 0.980\n",
            "Stats - Epoch: 23 AUC-val 0.774  AUC-train 0.982\n",
            "Stats - Epoch: 24 AUC-val 0.766  AUC-train 0.982\n",
            "Stats - Epoch: 25 AUC-val 0.772  AUC-train 0.984\n",
            "Stats - Epoch: 26 AUC-val 0.773  AUC-train 0.983\n",
            "Stats - Epoch: 27 AUC-val 0.759  AUC-train 0.986\n",
            "Stats - Epoch: 28 AUC-val 0.759  AUC-train 0.987\n",
            "Stats - Epoch: 29 AUC-val 0.766  AUC-train 0.987\n",
            "Stats - Epoch: 30 AUC-val 0.756  AUC-train 0.988\n",
            "Stats - Epoch: 31 AUC-val 0.755  AUC-train 0.988\n",
            "Stats - Epoch: 32 AUC-val 0.762  AUC-train 0.989\n",
            "Stats - Epoch: 33 AUC-val 0.766  AUC-train 0.990\n",
            "Stats - Epoch: 34 AUC-val 0.751  AUC-train 0.990\n",
            "Stats - Epoch: 35 AUC-val 0.753  AUC-train 0.991\n",
            "Stats - Epoch: 36 AUC-val 0.747  AUC-train 0.990\n",
            "Stats - Epoch: 37 AUC-val 0.769  AUC-train 0.991\n",
            "Stats - Epoch: 38 AUC-val 0.768  AUC-train 0.992\n",
            "Stats - Epoch: 39 AUC-val 0.760  AUC-train 0.991\n",
            "Stats - Epoch: 40 AUC-val 0.750  AUC-train 0.992\n",
            "Stats - Epoch: 41 AUC-val 0.761  AUC-train 0.993\n",
            "Stats - Epoch: 42 AUC-val 0.745  AUC-train 0.993\n",
            "Stats - Epoch: 43 AUC-val 0.759  AUC-train 0.993\n",
            "Stats - Epoch: 44 AUC-val 0.732  AUC-train 0.994\n",
            "Stats - Epoch: 45 AUC-val 0.734  AUC-train 0.995\n",
            "Stats - Epoch: 46 AUC-val 0.719  AUC-train 0.995\n",
            "Stats - Epoch: 47 AUC-val 0.752  AUC-train 0.994\n",
            "Stats - Epoch: 48 AUC-val 0.741  AUC-train 0.995\n",
            "Stats - Epoch: 49 AUC-val 0.723  AUC-train 0.993\n",
            "Stats - Epoch: 50 AUC-val 0.749  AUC-train 0.992\n",
            "Stats - Epoch: 51 AUC-val 0.719  AUC-train 0.992\n",
            "Stats - Epoch: 52 AUC-val 0.723  AUC-train 0.994\n",
            "Stats - Epoch: 53 AUC-val 0.729  AUC-train 0.995\n",
            "Stats - Epoch: 54 AUC-val 0.716  AUC-train 0.996\n",
            "Stats - Epoch: 55 AUC-val 0.734  AUC-train 0.995\n",
            "Stats - Epoch: 56 AUC-val 0.733  AUC-train 0.996\n",
            "Stats - Epoch: 57 AUC-val 0.735  AUC-train 0.996\n",
            "Stats - Epoch: 58 AUC-val 0.735  AUC-train 0.997\n",
            "Stats - Epoch: 59 AUC-val 0.723  AUC-train 0.995\n",
            "Stats - Epoch: 60 AUC-val 0.735  AUC-train 0.995\n",
            "Stats - Epoch: 61 AUC-val 0.765  AUC-train 0.993\n",
            "Stats - Epoch: 62 AUC-val 0.724  AUC-train 0.994\n",
            "Stats - Epoch: 63 AUC-val 0.726  AUC-train 0.996\n",
            "Stats - Epoch: 64 AUC-val 0.729  AUC-train 0.995\n",
            "Stats - Epoch: 65 AUC-val 0.724  AUC-train 0.996\n",
            "Stats - Epoch: 66 AUC-val 0.734  AUC-train 0.994\n",
            "Stats - Epoch: 67 AUC-val 0.729  AUC-train 0.995\n",
            "Stats - Epoch: 68 AUC-val 0.734  AUC-train 0.997\n",
            "Stats - Epoch: 69 AUC-val 0.724  AUC-train 0.997\n",
            "Stats - Epoch: 70 AUC-val 0.734  AUC-train 0.996\n",
            "Stats - Epoch: 71 AUC-val 0.733  AUC-train 0.996\n",
            "Stats - Epoch: 72 AUC-val 0.715  AUC-train 0.997\n",
            "Stats - Epoch: 73 AUC-val 0.698  AUC-train 0.997\n",
            "Stats - Epoch: 74 AUC-val 0.714  AUC-train 0.997\n",
            "Stats - Epoch: 75 AUC-val 0.710  AUC-train 0.996\n",
            "Stats - Epoch: 76 AUC-val 0.726  AUC-train 0.998\n",
            "Stats - Epoch: 77 AUC-val 0.714  AUC-train 0.997\n",
            "Stats - Epoch: 78 AUC-val 0.726  AUC-train 0.997\n",
            "Stats - Epoch: 79 AUC-val 0.703  AUC-train 0.997\n",
            "Stats - Epoch: 80 AUC-val 0.719  AUC-train 0.996\n",
            "Stats - Epoch: 81 AUC-val 0.705  AUC-train 0.996\n",
            "Stats - Epoch: 82 AUC-val 0.711  AUC-train 0.996\n",
            "Stats - Epoch: 83 AUC-val 0.733  AUC-train 0.996\n",
            "Stats - Epoch: 84 AUC-val 0.727  AUC-train 0.996\n",
            "Stats - Epoch: 85 AUC-val 0.735  AUC-train 0.996\n",
            "Stats - Epoch: 86 AUC-val 0.731  AUC-train 0.996\n",
            "Stats - Epoch: 87 AUC-val 0.767  AUC-train 0.997\n",
            "Stats - Epoch: 88 AUC-val 0.736  AUC-train 0.996\n",
            "Stats - Epoch: 89 AUC-val 0.737  AUC-train 0.996\n",
            "Stats - Epoch: 90 AUC-val 0.733  AUC-train 0.998\n",
            "Stats - Epoch: 91 AUC-val 0.762  AUC-train 0.998\n",
            "Stats - Epoch: 92 AUC-val 0.789  AUC-train 0.998\n",
            "Stats - Epoch: 93 AUC-val 0.752  AUC-train 0.996\n",
            "Stats - Epoch: 94 AUC-val 0.754  AUC-train 0.997\n",
            "Stats - Epoch: 95 AUC-val 0.706  AUC-train 0.998\n",
            "Stats - Epoch: 96 AUC-val 0.712  AUC-train 0.997\n",
            "Stats - Epoch: 97 AUC-val 0.747  AUC-train 0.997\n",
            "Stats - Epoch: 98 AUC-val 0.725  AUC-train 0.995\n",
            "Stats - Epoch: 99 AUC-val 0.706  AUC-train 0.996\n",
            "Stats - Epoch: 100 AUC-val 0.688  AUC-train 0.997\n",
            "Results 100 AUC-val 0.640 0.759 0.801 0.728 0.541 AUC-train 0.917\n",
            "Shapley [0.00930272 0.01970556 0.01041594 0.0185527  0.00721243] [0.01425874]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.151972\n",
            "         Iterations 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWufJ2Yotap1"
      },
      "source": [
        "# Few variable LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Ebk_xJtap1",
        "outputId": "72e51012-7e6b-4151-fe7d-e2ffe0b4528e"
      },
      "source": [
        "# LSTM with 1-variable and 2-variable\n",
        "\n",
        "# Cross-validation:\n",
        "filename = 'C:/Users/eerot/Desktop/NNCALC/fewvar_logit5b.csv';    \n",
        "f=open(filename, \"w\")\n",
        "predictors=['tloansgdp_g','rsp_g','rhp_g','ca/gdp','rgdp_g'];\n",
        "for fcast_horizon in [1]:\n",
        "  dates = [1974,2016]  \n",
        "  end_year=dates[1]\n",
        "  start_year=dates[0];\n",
        "  epochs = 1;\n",
        "  df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "  \n",
        "  for pp in range(0,5):\n",
        "    bs=[0,0,0,0,0,0,0,0];\n",
        "    bs[3+pp]=1;\n",
        "    S = np.packbits(bs, axis=0)[0];\n",
        "    all_predictors = [predictors[pp]];\n",
        "    print(all_predictors);\n",
        "    f.write(predictors[pp] + \";\" + cross_validation2(d2cgraph=True,Nf=1,mm=0,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True,code=S));\n",
        "    f.write(\"\\n\");f.flush();\n",
        "  \n",
        "  \n",
        "  for pp in range(0,5):\n",
        "    for pp2 in range(0,5):\n",
        "      if(pp2>pp):\n",
        "        bs=[0,0,0,0,0,0,0,0];\n",
        "        bs[3+pp]=1;\n",
        "        bs[3+pp2]=1;\n",
        "        S = np.packbits(bs, axis=0)[0];\n",
        "        all_predictors = [predictors[pp],predictors[pp2]];\n",
        "        print(all_predictors);\n",
        "        f.write(predictors[pp] + \";\" + predictors[pp2] + \";\" + cross_validation2(d2cgraph=True,Nf=2,mm=0,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True,code=S));\n",
        "        f.write(\"\\n\");f.flush();\n",
        "   \n",
        "  for pp in range(0,5):\n",
        "    for pp2 in range(0,5):\n",
        "        for pp3 in range(0,5):\n",
        "          if(pp2>pp and pp3>pp2):\n",
        "            bs=[0,0,0,0,0,0,0,0];\n",
        "            bs[3+pp]=1;\n",
        "            bs[3+pp2]=1;\n",
        "            bs[3+pp3]=1;\n",
        "            S = np.packbits(bs, axis=0)[0];\n",
        "            all_predictors = [predictors[pp],predictors[pp2],predictors[pp3]];\n",
        "            print(all_predictors);\n",
        "            f.write(predictors[pp] + \";\" + predictors[pp2] + \";\" + predictors[pp3] + \";\" + cross_validation2(d2cgraph=True,Nf=3,mm=0,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True,code=S));\n",
        "            f.write(\"\\n\");f.flush();\n",
        "\n",
        "  for pp in range(0,5):\n",
        "    for pp2 in range(0,5):\n",
        "        for pp3 in range(0,5):\n",
        "            for pp4 in range(0,5):\n",
        "              if(pp2>pp and pp3>pp2 and pp4>pp3):\n",
        "                bs=[0,0,0,0,0,0,0,0];\n",
        "                bs[3+pp]=1;\n",
        "                bs[3+pp2]=1;\n",
        "                bs[3+pp3]=1;\n",
        "                bs[3+pp4]=1;\n",
        "                S = np.packbits(bs, axis=0)[0];\n",
        "                all_predictors = [predictors[pp],predictors[pp2],predictors[pp3],predictors[pp4]];\n",
        "                print(all_predictors);\n",
        "                f.write(predictors[pp] + \";\" + predictors[pp2] + \";\" + predictors[pp3] + \";\" + predictors[pp4] + \";\" + cross_validation2(d2cgraph=True,Nf=4,mm=0,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True,code=S));\n",
        "                f.write(\"\\n\");f.flush();\n",
        "  all_predictors=['tloansgdp_g','rsp_g','rhp_g','ca/gdp','rgdp_g']\n",
        "  f.write(\"all;\" + cross_validation2(d2cgraph=True,Nf=5,mm=0,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=False,epochs=epochs,time_start=start_year,time_end=end_year,do_shapley=True,code=31));\n",
        "  f.write(\"\\n\");f.flush();\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "['tloansgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.652  AUC-train 0.717\n",
            "Results 1 AUC-val 0.652 0.644 0.635 0.610 0.537 AUC-train 0.717\n",
            "Shapley [0.02213177] [0.02974163]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.160293\n",
            "         Iterations 9\n",
            "['rsp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.674  AUC-train 0.735\n",
            "Results 1 AUC-val 0.674 0.505 0.331 0.261 0.521 AUC-train 0.735\n",
            "Shapley [0.01992247] [0.03141855]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159401\n",
            "         Iterations 9\n",
            "['rhp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.656  AUC-train 0.705\n",
            "Results 1 AUC-val 0.656 0.633 0.585 0.580 0.596 AUC-train 0.705\n",
            "Shapley [0.02171946] [0.02951496]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159756\n",
            "         Iterations 9\n",
            "['ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.659  AUC-train 0.713\n",
            "Results 1 AUC-val 0.659 0.557 0.479 0.446 0.368 AUC-train 0.713\n",
            "Shapley [0.01947447] [0.03069205]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159948\n",
            "         Iterations 9\n",
            "['rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.550  AUC-train 0.647\n",
            "Results 1 AUC-val 0.550 0.568 0.385 0.396 0.516 AUC-train 0.647\n",
            "Shapley [0.0133529] [0.03548194]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.160851\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.686  AUC-train 0.779\n",
            "Results 1 AUC-val 0.686 0.611 0.536 0.393 0.587 AUC-train 0.779\n",
            "Shapley [0.01827308 0.01589778] [0.02597994]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.160147\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rhp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.659  AUC-train 0.751\n",
            "Results 1 AUC-val 0.659 0.664 0.622 0.593 0.568 AUC-train 0.751\n",
            "Shapley [0.01556943 0.01544139] [0.0254427]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158823\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.654  AUC-train 0.772\n",
            "Results 1 AUC-val 0.654 0.628 0.568 0.530 0.426 AUC-train 0.772\n",
            "Shapley [0.01684017 0.01368719] [0.02701799]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.161213\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.644  AUC-train 0.755\n",
            "Results 1 AUC-val 0.644 0.661 0.558 0.507 0.548 AUC-train 0.755\n",
            "Shapley [0.02173397 0.01042919] [0.02791916]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159191\n",
            "         Iterations 9\n",
            "['rsp_g', 'rhp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.671  AUC-train 0.768\n",
            "Results 1 AUC-val 0.671 0.643 0.517 0.394 0.588 AUC-train 0.768\n",
            "Shapley [0.01767153 0.01981895] [0.02469864]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159372\n",
            "         Iterations 9\n",
            "['rsp_g', 'ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.698  AUC-train 0.776\n",
            "Results 1 AUC-val 0.698 0.559 0.431 0.333 0.397 AUC-train 0.776\n",
            "Shapley [0.01742813 0.01721436] [0.02547912]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159798\n",
            "         Iterations 9\n",
            "['rsp_g', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.613  AUC-train 0.750\n",
            "Results 1 AUC-val 0.613 0.522 0.341 0.275 0.547 AUC-train 0.750\n",
            "Shapley [0.01842983 0.00795345] [0.02997373]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158512\n",
            "         Iterations 9\n",
            "['rhp_g', 'ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.662  AUC-train 0.761\n",
            "Results 1 AUC-val 0.662 0.641 0.524 0.516 0.467 AUC-train 0.761\n",
            "Shapley [0.01820275 0.01505588] [0.02469347]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.160267\n",
            "         Iterations 9\n",
            "['rhp_g', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.603  AUC-train 0.727\n",
            "Results 1 AUC-val 0.603 0.669 0.586 0.585 0.616 AUC-train 0.727\n",
            "Shapley [0.02430447 0.00862081] [0.02870484]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159363\n",
            "         Iterations 9\n",
            "['ca/gdp', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.634  AUC-train 0.732\n",
            "Results 1 AUC-val 0.634 0.607 0.463 0.433 0.387 AUC-train 0.732\n",
            "Shapley [0.01761137 0.00880373] [0.02926255]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159593\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g', 'rhp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.677  AUC-train 0.802\n",
            "Results 1 AUC-val 0.677 0.651 0.576 0.450 0.592 AUC-train 0.802\n",
            "Shapley [0.01323445 0.01649022 0.01555572] [0.02148879]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158172\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g', 'ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.693  AUC-train 0.816\n",
            "Results 1 AUC-val 0.693 0.585 0.496 0.372 0.473 AUC-train 0.816\n",
            "Shapley [0.01360097 0.01544814 0.01269799] [0.02366666]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.161198\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.649  AUC-train 0.793\n",
            "Results 1 AUC-val 0.649 0.607 0.498 0.363 0.603 AUC-train 0.793\n",
            "Shapley [0.01959827 0.01538011 0.0081439 ] [0.02440594]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.156399\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rhp_g', 'ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.646  AUC-train 0.786\n",
            "Results 1 AUC-val 0.646 0.664 0.561 0.535 0.471 AUC-train 0.786\n",
            "Shapley [0.0116625  0.01512268 0.01202248] [0.02322048]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.160144\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rhp_g', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.633  AUC-train 0.772\n",
            "Results 1 AUC-val 0.633 0.691 0.625 0.581 0.606 AUC-train 0.772\n",
            "Shapley [0.01754364 0.01849854 0.01171809] [0.02373091]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.156630\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'ca/gdp', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.651  AUC-train 0.797\n",
            "Results 1 AUC-val 0.651 0.652 0.532 0.465 0.433 AUC-train 0.797\n",
            "Shapley [0.01787776 0.01339175 0.01004945] [0.02518366]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.160187\n",
            "         Iterations 9\n",
            "['rsp_g', 'rhp_g', 'ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.678  AUC-train 0.802\n",
            "Results 1 AUC-val 0.678 0.627 0.515 0.414 0.482 AUC-train 0.802\n",
            "Shapley [0.01729993 0.0175228  0.0144827 ] [0.0207182]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.159217\n",
            "         Iterations 9\n",
            "['rsp_g', 'rhp_g', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.622  AUC-train 0.774\n",
            "Results 1 AUC-val 0.622 0.676 0.540 0.424 0.602 AUC-train 0.774\n",
            "Shapley [0.02040471 0.02673686 0.01276919] [0.0232157]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158196\n",
            "         Iterations 8\n",
            "['rsp_g', 'ca/gdp', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.645  AUC-train 0.781\n",
            "Results 1 AUC-val 0.645 0.564 0.422 0.334 0.410 AUC-train 0.781\n",
            "Shapley [0.0174224  0.01690304 0.00528697] [0.02469508]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.152891\n",
            "         Iterations 9\n",
            "['rhp_g', 'ca/gdp', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.653  AUC-train 0.787\n",
            "Results 1 AUC-val 0.653 0.691 0.541 0.520 0.453 AUC-train 0.787\n",
            "Shapley [0.02173716 0.01653954 0.01010246] [0.02370933]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158287\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g', 'rhp_g', 'ca/gdp']\n",
            "Stats - Epoch: 1 AUC-val 0.673  AUC-train 0.832\n",
            "Results 1 AUC-val 0.673 0.628 0.550 0.434 0.505 AUC-train 0.832\n",
            "Shapley [0.00948236 0.01753654 0.0164189  0.01287602] [0.01939034]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.160136\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g', 'rhp_g', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.641  AUC-train 0.805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Results 1 AUC-val 0.641 0.679 0.605 0.473 0.627 AUC-train 0.805\n",
            "Shapley [0.01576449 0.01888753 0.02144864 0.01462333] [0.01916221]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.156827\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rsp_g', 'ca/gdp', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.652  AUC-train 0.824\n",
            "Results 1 AUC-val 0.652 0.581 0.476 0.356 0.491 AUC-train 0.824\n",
            "Shapley [0.01564598 0.01520844 0.01314156 0.00817025] [0.02211906]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158417\n",
            "         Iterations 9\n",
            "['tloansgdp_g', 'rhp_g', 'ca/gdp', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.646  AUC-train 0.814\n",
            "Results 1 AUC-val 0.646 0.711 0.576 0.521 0.485 AUC-train 0.814\n",
            "Shapley [0.01396978 0.01903967 0.01370194 0.01297846] [0.02108637]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.158515\n",
            "         Iterations 9\n",
            "['rsp_g', 'rhp_g', 'ca/gdp', 'rgdp_g']\n",
            "Stats - Epoch: 1 AUC-val 0.649  AUC-train 0.810\n",
            "Results 1 AUC-val 0.649 0.655 0.526 0.410 0.477 AUC-train 0.810\n",
            "Shapley [0.02022908 0.02428333 0.01643335 0.01497158] [0.01881022]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.157021\n",
            "         Iterations 9\n",
            "Stats - Epoch: 1 AUC-val 0.645  AUC-train 0.842\n",
            "Results 1 AUC-val 0.645 0.654 0.579 0.435 0.519 AUC-train 0.842\n",
            "Shapley [0.01216097 0.02005307 0.02328923 0.0150315  0.01653861] [0.01691053]\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.157955\n",
            "         Iterations 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LdwlhD5tap1",
        "outputId": "e5c05f5f-d0ac-4544-fe2c-878b0bf9fd04"
      },
      "source": [
        "'''Test module for clustered standard errors'''\n",
        "\n",
        "\n",
        "def test_probit_logit():\n",
        "    '''\n",
        "    SAMPLE PROGRAM COMPARING CLUSTERED AND REGULAR STANDARD ERRORS FOR PROBIT AND LOGIT\n",
        "    '''\n",
        "\n",
        "    import numpy\n",
        "    import pandas\n",
        "    import statsmodels.api as sm\n",
        "    #import clustered_se\n",
        "\n",
        "    print('TEST OF PROBIT/LOGIT CLUSTERED STANDARD ERROR CORRECTION')\n",
        "\n",
        "    #generate probit data with cluster correlated error structure\n",
        "    gps = 30 # number of clusters (groups)\n",
        "    obs = 1000 # number of observations per group\n",
        "\n",
        "    #generate errors\n",
        "    e1 = numpy.random.randn(obs,gps) #iid errors across groups and observations\n",
        "    e2 = numpy.random.randn(gps) #errors correlated across observations within a group\n",
        "    u = 1+2*numpy.random.rand(gps) #scaling of errors with a group (scale heteroskedasticity by group)\n",
        "    e = (e1*u + e2).ravel()\n",
        "    e = e / (e.dot(e)/len(e))**0.5 #normalize to make it easier to interpret parameters\n",
        "\n",
        "    #generate regressor, dependant variable and group variable\n",
        "    x = 5*(numpy.random.randn(obs,gps) + 2.0*numpy.random.randn(gps)).ravel() #regressor (has group correlation)\n",
        "    gp = (numpy.ones((obs,gps))*numpy.arange(1,gps+1)).ravel()\n",
        "    X = pandas.DataFrame([numpy.ones(obs*gps),x]).transpose() #put the regressor and constant into a dataframe\n",
        "    X.columns = ['one','x']\n",
        "    y_lat = 2 * x + e  #latent variable\n",
        "    y = pandas.Series(1*(y_lat>0)) #observed dependent variable\n",
        "#    for i in range(2,gps+1):\n",
        "#        X['G%i'%(i,)]=1*(gp == i)\n",
        "\n",
        "\n",
        "    print('LOGIT')\n",
        "    modl = sm.Logit(y,X)\n",
        "    resl = modl.fit()\n",
        "    print(clustered_output(resl,gp))\n",
        "    \n",
        "\n",
        "    print('PROBIT')\n",
        "    modp = sm.Probit(y,X)\n",
        "    resp = modp.fit()\n",
        "    print(clustered_output(resp,gp))\n",
        "    \n",
        "\n",
        "def test_petersen():\n",
        "    '''\n",
        "    A test of the clustered standard error module using Mitch Petersen's test data\n",
        "    http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm\n",
        "    '''\n",
        "    import statsmodels.api as sm\n",
        "    #import clustered_se\n",
        "    import pandas\n",
        "    import numpy\n",
        "    from scipy.stats import norm\n",
        "\n",
        "    print('TEST OF PETERSEN CLUSTERED STANDARD ERROR CORRECTIONS')\n",
        "    df = pandas.read_csv('petersen-data/test_data.txt')\n",
        "    '''\n",
        "    OLS Coefficients and Standard Errors\n",
        "    Reported at http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.htm\n",
        "    '''\n",
        "    b = numpy.array([0.0297,1.0348])\n",
        "    se = numpy.array([0.028359,0.028583])\n",
        "    se_by_firm= numpy.array([0.067013,0.050596])\n",
        "    se_by_yr = numpy.array([0.0233387,0.033389])\n",
        "    se_by_firm_and_yr = numpy.array([0.065064,0.053558])\n",
        "\n",
        "\n",
        "    #add a constant and run the regression\n",
        "    df['one']=1\n",
        "    mod = sm.OLS(df['y'],df[['one','x']])\n",
        "    res = mod.fit()\n",
        "    print(res.summary())\n",
        "\n",
        "    #now generate the clustered standard errors\n",
        "    #becasue loglikeobs is not implemented in the default OLS implementation, we'll monkey patch it here\n",
        "    def llo(b):\n",
        "        y = numpy.array(df['y'])\n",
        "        X = numpy.array(df[['one','x']])\n",
        "        b=numpy.array(b)\n",
        "        e = y - numpy.inner(X,b)\n",
        "        s = (e.dot(e)/(len(e)))**0.5\n",
        "        return numpy.log(norm.pdf(e/s)/s)\n",
        "    def info(b):\n",
        "        y = numpy.array(df['y'])\n",
        "        X = numpy.array(df[['one','x']])\n",
        "        b=numpy.array(b)\n",
        "        e = y - numpy.inner(X,b)\n",
        "        s2 = (e.dot(e)/(len(e)))\n",
        "        return numpy.dot(X.T,X)/s2\n",
        "\n",
        "    mod.loglikeobs =llo\n",
        "    mod.information =info\n",
        "\n",
        "    \n",
        "    print('CLUSTERED STANDARD ERRORS')\n",
        "\n",
        "    print('BY YR')\n",
        "    my_se_yr = numpy.diag(clustered_cov(res,df['yr']))**0.5\n",
        "    print('Mine',my_se_yr)\n",
        "    print('Petersen',se_by_yr)\n",
        "    \n",
        "\n",
        "    print('BY FIRM')\n",
        "    my_se_firm = numpy.diag(clustered_cov(res,df['firmid']))**0.5\n",
        "    print('Mine',my_se_firm)\n",
        "    print('Petersen',se_by_firm)\n",
        "    \n",
        "\n",
        "    print('BY FIRM AND YEAR')\n",
        "    my_se_firm_and_yr = numpy.diag(multiway_clustered_cov(res,df[['firmid','yr']]))**0.5\n",
        "    print('Mine',my_se_firm_and_yr)\n",
        "    print('Petersen',se_by_firm_and_yr)\n",
        "    \n",
        "\n",
        "    print('Running assertions')\n",
        "    assert(numpy.abs(b-res.params).sum()<1e-4)\n",
        "    assert(numpy.abs(se-res.bse).sum()<1e-4)\n",
        "    assert(numpy.abs(se_by_yr-my_se_yr).sum()<1e-4)\n",
        "    assert(numpy.abs(se_by_firm-my_se_firm).sum()<1e-4)\n",
        "    assert(numpy.abs(se_by_firm_and_yr-my_se_firm_and_yr).sum()<1e-4)\n",
        "    print('Petersen test passed')\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test_probit_logit()\n",
        "    test_petersen()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST OF PROBIT/LOGIT CLUSTERED STANDARD ERROR CORRECTION\n",
            "LOGIT\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.030468\n",
            "         Iterations 13\n",
            "         Coef        SE    Cl. SE\n",
            "one -0.377245  0.061134       NaN\n",
            "x    3.564689  0.118168       NaN\n",
            "0         NaN       NaN  0.229400\n",
            "1         NaN       NaN  0.206049\n",
            "PROBIT\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.030451\n",
            "         Iterations 13\n",
            "         Coef        SE   Cl. SE\n",
            "one -0.202041  0.033471      NaN\n",
            "x    1.950498  0.058028      NaN\n",
            "0         NaN       NaN  0.12257\n",
            "1         NaN       NaN  0.10585\n",
            "TEST OF PETERSEN CLUSTERED STANDARD ERROR CORRECTIONS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] File b'petersen-data/test_data.txt' does not exist: b'petersen-data/test_data.txt'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-34-5077f752b24d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[0mtest_probit_logit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mtest_petersen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-34-5077f752b24d>\u001b[0m in \u001b[0;36mtest_petersen\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TEST OF PETERSEN CLUSTERED STANDARD ERROR CORRECTIONS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'petersen-data/test_data.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     '''\n\u001b[0;32m     64\u001b[0m     \u001b[0mOLS\u001b[0m \u001b[0mCoefficients\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mStandard\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'petersen-data/test_data.txt' does not exist: b'petersen-data/test_data.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7F2Wvv3tap1"
      },
      "source": [
        "# Calculate True Shapley Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdniN9sZtap2"
      },
      "source": [
        "def Shapley_analysis2(Nf):\n",
        "    \n",
        "    for Si in range(1,pow(2,Nf)):\n",
        "        fname = 'C:/Users/eerot/Desktop/NNCALC/Shapley analysis/import/seq/lstm/' + str(Si) + \".csv\";\n",
        "        x = np.loadtxt(fname,delimiter=\";\");\n",
        "        if(Si==1):\n",
        "            n = x.shape[0];\n",
        "            payoff = np.zeros((n,pow(2,Nf)))\n",
        "        payoff[:,Si] = x[:,1];\n",
        "    # Set payoff of empty set to mean prediction\n",
        "    payoff[:,0] = np.mean(payoff[:,1:pow(2,Nf)])\n",
        "    \n",
        "    # The rest should be general\n",
        "    # Calculate Shapley values using the difference formula\n",
        "    phi = np.zeros((n,Nf),dtype=np.double);\n",
        "    for Si in range(0,pow(2,Nf)):\n",
        "        b = np.unpackbits(np.array([[Si]], dtype=np.uint8));\n",
        "        ksi = b[(8-Nf):8].astype(np.double);\n",
        "        for feat in range(0,Nf):\n",
        "            if(b[8-Nf+feat]==1):\n",
        "                # feature is included in set ksi\n",
        "                bs = np.copy(b);\n",
        "                bs[(8-Nf)+feat]=0;\n",
        "                S = np.packbits(bs, axis=0)[0]; # the index of the set S without feat\n",
        "                NS = np.sum(ksi)-1;\n",
        "                fac = np.math.factorial(NS)*np.math.factorial(Nf-NS-1)/np.math.factorial(Nf);\n",
        "                phi[:,feat] = phi[:,feat] + fac*(payoff[:,Si]-payoff[:,S]);\n",
        "\n",
        "    # Calculate the mean Shapley values\n",
        "    #shapley_means = np.mean(phi,axis=0);\n",
        "    return phi,payoff[0,0];\n",
        "\n",
        "phi,phi0 = Shapley_analysis2(5)\n",
        "np.savetxt(fname='C:/Users/eerot/Desktop/NNCALC/Shapley analysis/import/seq/lstm/phiout_fc1.csv',X=phi,delimiter=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3PfO8oetap2"
      },
      "source": [
        "# Calculate distance to crisis Shapley values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ct23rKtap2"
      },
      "source": [
        "def Shapley_analysis3(Nf):\n",
        "    n=21;\n",
        "    payoff = np.zeros((n,pow(2,Nf)))\n",
        "    for Si in range(1,pow(2,Nf)):\n",
        "        fname = 'C:/Users/eerot/Desktop/NNCALC/Shapley analysis/import/seq/lstm/' + str(Si) + \".txt\";\n",
        "        with open(fname) as f:\n",
        "            ii=-1;\n",
        "            for line in f:\n",
        "                ii+=1;\n",
        "                #my_list = line.split(\";\");\n",
        "                my_np = np.fromstring(line, dtype=float, sep=';')\n",
        "                payoff[ii,Si] = np.mean(my_np[1:]);\n",
        "\n",
        "    # Set payoff of empty set to mean prediction\n",
        "    payoff[:,0] = np.mean(payoff[2:,1:pow(2,Nf)])\n",
        "    \n",
        "    # The rest should be general\n",
        "    # Calculate Shapley values using the difference formula\n",
        "    phi = np.zeros((n,Nf),dtype=np.double);\n",
        "    for Si in range(0,pow(2,Nf)):\n",
        "        b = np.unpackbits(np.array([[Si]], dtype=np.uint8));\n",
        "        ksi = b[(8-Nf):8].astype(np.double);\n",
        "        for feat in range(0,Nf):\n",
        "            if(b[8-Nf+feat]==1):\n",
        "                # feature is included in set ksi\n",
        "                bs = np.copy(b);\n",
        "                bs[(8-Nf)+feat]=0;\n",
        "                S = np.packbits(bs, axis=0)[0]; # the index of the set S without feat\n",
        "                NS = np.sum(ksi)-1;\n",
        "                fac = np.math.factorial(NS)*np.math.factorial(Nf-NS-1)/np.math.factorial(Nf);\n",
        "                phi[:,feat] = phi[:,feat] + fac*(payoff[:,Si]-payoff[:,S]);\n",
        "\n",
        "    # Calculate the mean Shapley values\n",
        "    #shapley_means = np.mean(phi,axis=0);\n",
        "    return phi,payoff[0,0];\n",
        "\n",
        "phi,phi0 = Shapley_analysis3(5)\n",
        "np.savetxt(fname='C:/Users/eerot/Desktop/NNCALC/Shapley analysis/import/seq/lstm/phiout21_fc1.csv',X=phi,delimiter=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGNd7lF_tap2"
      },
      "source": [
        "# Calculate performance Shapley values for AUC lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM6S5rLPtap2"
      },
      "source": [
        "\n",
        "#SEQ_LSTM1; 0.5,0.618,0.585,0.635,0.709,0.692,0.748,0.732,0.622,0.629,0.703,0.734,0.701,0.719,0.772,0.767,0.659,0.677,0.688,0.693,0.692,0.69,0.782,0.795,0.731,0.726,0.811,0.793,0.787,0.743,0.798,0.782\n",
        "#SEQ_LOGIT1; 0.5,0.445,0.609,0.515,0.681,0.403,0.655,0.537,0.434,0.324,0.524,0.39,0.461,0.273,0.556,0.379,0.604,0.536,0.595,0.522,0.597,0.399,0.584,0.423,0.49,0.397,0.504,0.383,0.433,0.321,0.459,0.327\n",
        "#SEQ_LSTM3; 0.5,0.646,0.565,0.671,0.771,0.739,0.772,0.783,0.811,0.833,0.736,0.781,0.907,0.906,0.874,0.913,0.595,0.564,0.608,0.565,0.748,0.709,0.776,0.765,0.784,0.825,0.767,0.729,0.863,0.846,0.845,0.878\n",
        "#SEQ_LOGIT3; 0.5,0.571,0.507,0.579,0.68,0.617,0.569,0.557,0.548,0.513,0.513,0.492,0.623,0.506,0.469,0.443,0.58,0.596,0.566,0.59,0.549,0.495,0.509,0.437,0.57,0.493,0.495,0.427,0.423,0.364,0.377,0.298\n",
        "\n",
        "#FC1_Logit5#0.5,0.55,0.659,0.634,0.656,0.603,0.662,0.653,0.674,0.613,0.698,0.645,0.671,0.622,0.678,0.649,0.652,0.644,0.654,0.651,0.659,0.633,0.646,0.646,0.686,0.649,0.693,0.652,0.677,0.641,0.673,0.645\n",
        "#FC3_Logit5#0.5,0.627,0.538,0.612,0.621,0.699,0.612,0.688,0.788,0.748,0.784,0.741,0.787,0.753,0.775,0.747,0.636,0.688,0.604,0.66,0.641,0.697,0.619,0.676,0.798,0.748,0.786,0.738,0.777,0.73,0.763,0.726\n",
        "\n",
        "#import numpy as np\n",
        "Nf = 5;\n",
        "#FC1_LSTM#0.5,0.653,0.694,0.66,0.694,0.736,0.737,0.741,0.744,0.792,0.821,0.804,0.777,0.808,0.813,0.829,0.667,0.684,0.681,0.674,0.671,0.709,0.728,0.68,0.807,0.81,0.835,0.832,0.836,0.831,0.832,0.833\n",
        "#FC3_LSTM#0.5,0.686,0.591,0.569,0.655,0.707,0.68,0.707,0.846,0.871,0.819,0.849,0.896,0.89,0.869,0.895,0.67,0.711,0.628,0.682,0.668,0.745,0.677,0.684,0.891,0.876,0.891,0.897,0.857,0.878,0.861,0.871\n",
        "#payoff=np.array([0.5,0.653,0.694,0.66,0.694,0.736,0.737,0.741,0.744,0.792,0.821,0.804,0.777,0.808,0.813,0.829,0.667,0.684,0.681,0.674,0.671,0.709,0.728,0.68,0.807,0.81,0.835,0.832,0.836,0.831,0.832,0.833]);\n",
        "#payoff=np.array([0.5,0.686,0.591,0.569,0.655,0.707,0.68,0.707,0.846,0.871,0.819,0.849,0.896,0.89,0.869,0.895,0.67,0.711,0.628,0.682,0.668,0.745,0.677,0.684,0.891,0.876,0.891,0.897,0.857,0.878,0.861,0.871]);\n",
        "#payoff=np.array([0.5,0.55,0.659,0.634,0.656,0.603,0.662,0.653,0.674,0.613,0.698,0.645,0.671,0.622,0.678,0.649,0.652,0.644,0.654,0.651,0.659,0.633,0.646,0.646,0.686,0.649,0.693,0.652,0.677,0.641,0.673,0.645]);\n",
        "#payoff=np.array([0.5,0.627,0.538,0.612,0.621,0.699,0.612,0.688,0.788,0.748,0.784,0.741,0.787,0.753,0.775,0.747,0.636,0.688,0.604,0.66,0.641,0.697,0.619,0.676,0.798,0.748,0.786,0.738,0.777,0.73,0.763,0.726]);\n",
        "#payoff=np.array([0.5,0.618,0.585,0.635,0.709,0.692,0.748,0.732,0.622,0.629,0.703,0.734,0.701,0.719,0.772,0.767,0.659,0.677,0.688,0.693,0.692,0.69,0.782,0.795,0.731,0.726,0.811,0.793,0.787,0.743,0.798,0.782])\n",
        "#payoff=np.array([0.5,0.445,0.609,0.515,0.681,0.403,0.655,0.537,0.434,0.324,0.524,0.39,0.461,0.273,0.556,0.379,0.604,0.536,0.595,0.522,0.597,0.399,0.584,0.423,0.49,0.397,0.504,0.383,0.433,0.321,0.459,0.327])\n",
        "#payoff=np.array([0.5,0.646,0.565,0.671,0.771,0.739,0.772,0.783,0.811,0.833,0.736,0.781,0.907,0.906,0.874,0.913,0.595,0.564,0.608,0.565,0.748,0.709,0.776,0.765,0.784,0.825,0.767,0.729,0.863,0.846,0.845,0.878])\n",
        "#payoff=np.array([0.5,0.571,0.507,0.579,0.68,0.617,0.569,0.557,0.548,0.513,0.513,0.492,0.623,0.506,0.469,0.443,0.58,0.596,0.566,0.59,0.549,0.495,0.509,0.437,0.57,0.493,0.495,0.427,0.423,0.364,0.377,0.298])\n",
        "payoff=np.array([0.5,0.61692845,0.57068063,0.66317627,0.71160558,0.72120419,0.7408377,0.7609075,0.82940663,0.86910995,0.70986038,0.69197208,0.88656195,0.91972077,0.79101222,0.81020942,0.57635253,0.56151832,0.59205934,0.53708551,0.67975567,0.67495637,0.71771379,0.73211169,0.78490401,0.7521815,0.76265271,0.70462478,0.83376963,0.84293194,0.78577661,0.80104712])\n",
        "#payoff=np.array([0.5,0.4620155,0.58953488,0.59302326,0.66356589,0.64883721,0.71666667,0.68217054,0.63217054,0.58178295,0.69302326,0.67170543,0.67403101,0.63178295,0.71666667,0.70697674,0.64496124,0.6248062,0.69534884,0.70077519,0.6496124,0.64496124,0.74651163,0.69844961,0.69457364,0.69457364,0.76589147,0.78294574,0.69767442,0.6875969,0.75193798,0.74767442])\n",
        "\n",
        "phi = np.zeros((Nf),dtype=np.double);\n",
        "for Si in range(0,pow(2,Nf)):\n",
        "        b = np.unpackbits(np.array([[Si]], dtype=np.uint8));\n",
        "        ksi = b[(8-Nf):8].astype(np.double);\n",
        "        for feat in range(0,Nf):\n",
        "            if(b[8-Nf+feat]==1):\n",
        "                # feature is included in set ksi\n",
        "                bs = np.copy(b);\n",
        "                bs[(8-Nf)+feat]=0;\n",
        "                S = np.packbits(bs, axis=0)[0]; # the index of the set S without feat\n",
        "                NS = np.sum(ksi)-1;\n",
        "                fac = np.math.factorial(NS)*np.math.factorial(Nf-NS-1)/np.math.factorial(Nf);\n",
        "                phi[feat] = phi[feat] + fac*(payoff[Si]-payoff[S]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq0rEeWwtap2",
        "outputId": "79853413-10c3-40a0-e004-e01d266b0f59"
      },
      "source": [
        "phi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00740256,  0.16748109,  0.12196044, -0.01111111,  0.03011926])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eZ3AEQ9tap3"
      },
      "source": [
        "# Plot variables around crisis dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnsup3w-tap3",
        "outputId": "fc0f8130-2373-4f40-dba2-3dbd23d74ceb"
      },
      "source": [
        "df3=init_data(df,start_year = 1870, end_year=2016, y_shift = 1, normalize = False)\n",
        "df3=add_dist2cris(df3,stfilter=True)\n",
        "varis= ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g'];\n",
        "filename = 'desc_out.tex';    \n",
        "f2=open(filename, \"w\")\n",
        "#a = np.empty((20,))*np.nan;    \n",
        "x = np.zeros((5,));\n",
        "for d in range(-10,1):    \n",
        "    for f in range(0,5):\n",
        "        x[f]=np.median(df3[df3.disttonextcris==-d][varis[f]])        \n",
        "    f2.write(\"%3.0f;\" %(d));\n",
        "    for ix in range(0,x.shape[0]):\n",
        "        f2.write(\"%10.7f;\" %(x[ix]));            \n",
        "    f2.write(\"\\n\");\n",
        "    \n",
        "for d in range(1,11):\n",
        "    for f in range(0,5):\n",
        "        x[f]=np.median(df3[df3.disttoprevcris==d][varis[f]])          \n",
        "    f2.write(\"%3.0f;\" %(d));\n",
        "    for ix in range(0,x.shape[0]):\n",
        "        f2.write(\"%10.7f;\" %(x[ix]));            \n",
        "    f2.write(\"\\n\");\n",
        "f2.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7UJyYTtap3"
      },
      "source": [
        "# Plot descriptive data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trc04f6Jtap3",
        "outputId": "883a5b6a-407f-4325-aa9f-250c0a9527a9"
      },
      "source": [
        "varis= ['tloansgdp_g','rhp_g','ca/gdp','rsp_g','rgdp_g'];\n",
        "df3=init_data(df,start_year = 1870, end_year=2016, y_shift = 1, normalize = False)\n",
        "df3=add_dist2cris(df3,stfilter=True)\n",
        "for f in range(0,5):\n",
        "    print(\"%5.3f;\" %(np.mean(df3[varis[f]])) \\\n",
        "    + \"%5.3f;\" %(np.median(df3[varis[f]])) \\\n",
        "    + \"%5.3f;\" %(np.std(df3[varis[f]])) \\\n",
        "    + \"%5.3f;\" %(np.percentile(df3[varis[f]],10)) \\\n",
        "    + \"%5.3f;\" %(np.percentile(df3[varis[f]],90)) \\\n",
        "    + \"%5.3f;\" %(np.min(df3[varis[f]])) \\\n",
        "    + \"%5.3f;\" %(np.max(df3[varis[f]])) \\\n",
        "    + \"%5.3f;\" %(df3[varis[f]].shape[0]));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "1.836;1.555;7.082;-5.167;8.626;-48.732;84.282;1542.000;\n",
            "2.426;1.858;9.509;-7.264;11.704;-31.873;112.942;1542.000;\n",
            "-0.062;-0.047;4.031;-4.357;4.388;-18.811;16.232;1542.000;\n",
            "3.841;3.411;19.641;-19.814;27.820;-61.103;107.608;1542.000;\n",
            "3.161;3.074;4.477;-1.502;7.625;-21.637;59.279;1542.000;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V94S7wsAtap3"
      },
      "source": [
        "# Plot calibration curves for 1970-2016 subsample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZaLspSftap3",
        "outputId": "524c4ef4-fbbb-4f53-f6fc-2e25b5ac12a8"
      },
      "source": [
        "# Cross-validation:\n",
        "\n",
        "reps=1;\n",
        "predictors=['tloansgdp_g','rsp_g','rhp_g','ca/gdp','rgdp_g'];\n",
        "fcast_horizon=1;\n",
        "time_start=1974;\n",
        "time_end=2016;\n",
        "epochs = 20;\n",
        "df3=init_data(df = df, start_year = 1870, end_year = 2016,y_shift = 1, normalize = False);\n",
        "a=cross_validation2(d2cgraph=True,Nf=5,mm=0,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=True,epochs=epochs,time_start=start_year,time_end=end_year)\n",
        "a=cross_validation2(d2cgraph=True,Nf=5,mm=2,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=True,epochs=epochs,time_start=start_year,time_end=end_year)\n",
        "a=cross_validation2(d2cgraph=True,Nf=5,mm=4,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=True,epochs=epochs,time_start=start_year,time_end=end_year)\n",
        "a=cross_validation2(d2cgraph=True,Nf=5,mm=5,nlags=5,df=df3,fcast_horizon=fcast_horizon,plot_reliability=True,epochs=epochs,time_start=start_year,time_end=end_year)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpi_g mean 3.7957184930220573 std 9.549127570924712\n",
            "rgdp_g mean 3.2186645837041 std 5.545511980110663\n",
            "ca/gdp mean -0.09975467519432686 std 4.273445259216059\n",
            "debtgdp_g mean 1.783568874425672 std 14.680523171411345\n",
            "tloansgdp_g mean 1.5968026221003662 std 7.84838516244777\n",
            "rsp_g mean 3.255455245430876 std 19.907486780223667\n",
            "rhp_g mean 2.210870527472645 std 10.340006522092606\n",
            "rtloans_g mean 4.759274045967108 std 8.710515841020976\n",
            "rtmort_g mean 6.22509578335285 std 10.842771206567095\n",
            "rthh_g mean 6.3382301972338 std 9.020519941303647\n",
            "rtbus_g mean 4.262528084577066 std 9.13685177528974\n",
            "ltrate mean 5.743783944726819 std 3.1710065179149685\n",
            "stir mean 4.9466555079041425 std 3.534947937938998\n",
            "Stats - Epoch: 1 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 2 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 3 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 4 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 5 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 6 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 7 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 8 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 9 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 10 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 11 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 12 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 13 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 14 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 15 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 16 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 17 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 18 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 19 AUC-val 0.645  AUC-train 0.842\n",
            "Stats - Epoch: 20 AUC-val 0.645  AUC-train 0.842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Results 20 AUC-val 0.645 0.654 0.579 0.435 0.519 AUC-train 0.842\n",
            "Stats - Epoch: 1 AUC-val 0.469  AUC-train 0.605\n",
            "Stats - Epoch: 2 AUC-val 0.623  AUC-train 0.773\n",
            "Stats - Epoch: 3 AUC-val 0.682  AUC-train 0.832\n",
            "Stats - Epoch: 4 AUC-val 0.660  AUC-train 0.870\n",
            "Stats - Epoch: 5 AUC-val 0.688  AUC-train 0.900\n",
            "Stats - Epoch: 6 AUC-val 0.672  AUC-train 0.921\n",
            "Stats - Epoch: 7 AUC-val 0.701  AUC-train 0.938\n",
            "Stats - Epoch: 8 AUC-val 0.683  AUC-train 0.949\n",
            "Stats - Epoch: 9 AUC-val 0.684  AUC-train 0.960\n",
            "Stats - Epoch: 10 AUC-val 0.702  AUC-train 0.963\n",
            "Stats - Epoch: 11 AUC-val 0.670  AUC-train 0.971\n",
            "Stats - Epoch: 12 AUC-val 0.688  AUC-train 0.976\n",
            "Stats - Epoch: 13 AUC-val 0.695  AUC-train 0.977\n",
            "Stats - Epoch: 14 AUC-val 0.651  AUC-train 0.972\n",
            "Stats - Epoch: 15 AUC-val 0.676  AUC-train 0.983\n",
            "Stats - Epoch: 16 AUC-val 0.678  AUC-train 0.986\n",
            "Stats - Epoch: 17 AUC-val 0.675  AUC-train 0.988\n",
            "Stats - Epoch: 18 AUC-val 0.694  AUC-train 0.987\n",
            "Stats - Epoch: 19 AUC-val 0.696  AUC-train 0.986\n",
            "Stats - Epoch: 20 AUC-val 0.691  AUC-train 0.989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Results 20 AUC-val 0.702 0.624 0.363 0.297 0.418 AUC-train 0.963\n",
            "Stats - Epoch: 1 AUC-val 0.460  AUC-train 0.569\n",
            "Stats - Epoch: 2 AUC-val 0.641  AUC-train 0.798\n",
            "Stats - Epoch: 3 AUC-val 0.727  AUC-train 0.867\n",
            "Stats - Epoch: 4 AUC-val 0.802  AUC-train 0.891\n",
            "Stats - Epoch: 5 AUC-val 0.749  AUC-train 0.912\n",
            "Stats - Epoch: 6 AUC-val 0.772  AUC-train 0.922\n",
            "Stats - Epoch: 7 AUC-val 0.819  AUC-train 0.931\n",
            "Stats - Epoch: 8 AUC-val 0.821  AUC-train 0.942\n",
            "Stats - Epoch: 9 AUC-val 0.793  AUC-train 0.950\n",
            "Stats - Epoch: 10 AUC-val 0.812  AUC-train 0.957\n",
            "Stats - Epoch: 11 AUC-val 0.809  AUC-train 0.967\n",
            "Stats - Epoch: 12 AUC-val 0.792  AUC-train 0.967\n",
            "Stats - Epoch: 13 AUC-val 0.761  AUC-train 0.975\n",
            "Stats - Epoch: 14 AUC-val 0.808  AUC-train 0.978\n",
            "Stats - Epoch: 15 AUC-val 0.808  AUC-train 0.978\n",
            "Stats - Epoch: 16 AUC-val 0.807  AUC-train 0.980\n",
            "Stats - Epoch: 17 AUC-val 0.812  AUC-train 0.983\n",
            "Stats - Epoch: 18 AUC-val 0.788  AUC-train 0.986\n",
            "Stats - Epoch: 19 AUC-val 0.802  AUC-train 0.986\n",
            "Stats - Epoch: 20 AUC-val 0.803  AUC-train 0.989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Results 20 AUC-val 0.821 0.752 0.593 0.476 0.436 AUC-train 0.942\n",
            "Stats - Epoch: 1 AUC-val 0.493  AUC-train 0.583\n",
            "Stats - Epoch: 2 AUC-val 0.598  AUC-train 0.720\n",
            "Stats - Epoch: 3 AUC-val 0.619  AUC-train 0.782\n",
            "Stats - Epoch: 4 AUC-val 0.673  AUC-train 0.824\n",
            "Stats - Epoch: 5 AUC-val 0.668  AUC-train 0.853\n",
            "Stats - Epoch: 6 AUC-val 0.680  AUC-train 0.870\n",
            "Stats - Epoch: 7 AUC-val 0.664  AUC-train 0.889\n",
            "Stats - Epoch: 8 AUC-val 0.726  AUC-train 0.903\n",
            "Stats - Epoch: 9 AUC-val 0.695  AUC-train 0.917\n",
            "Stats - Epoch: 10 AUC-val 0.690  AUC-train 0.932\n",
            "Stats - Epoch: 11 AUC-val 0.736  AUC-train 0.939\n",
            "Stats - Epoch: 12 AUC-val 0.743  AUC-train 0.950\n",
            "Stats - Epoch: 13 AUC-val 0.740  AUC-train 0.960\n",
            "Stats - Epoch: 14 AUC-val 0.730  AUC-train 0.964\n",
            "Stats - Epoch: 15 AUC-val 0.748  AUC-train 0.971\n",
            "Stats - Epoch: 16 AUC-val 0.710  AUC-train 0.974\n",
            "Stats - Epoch: 17 AUC-val 0.717  AUC-train 0.980\n",
            "Stats - Epoch: 18 AUC-val 0.684  AUC-train 0.979\n",
            "Stats - Epoch: 19 AUC-val 0.719  AUC-train 0.983\n",
            "Stats - Epoch: 20 AUC-val 0.685  AUC-train 0.987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Results 20 AUC-val 0.748 0.687 0.570 0.416 0.380 AUC-train 0.971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgZ_WhqKtap4",
        "outputId": "a88960fc-8962-4b02-ade1-60cbf061ae9e"
      },
      "source": [
        "df3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>iso</th>\n",
              "      <th>cpi_g</th>\n",
              "      <th>rgdp_g</th>\n",
              "      <th>ca/gdp</th>\n",
              "      <th>debtgdp_g</th>\n",
              "      <th>tloansgdp_g</th>\n",
              "      <th>rsp_g</th>\n",
              "      <th>rhp_g</th>\n",
              "      <th>rtloans_g</th>\n",
              "      <th>rtmort_g</th>\n",
              "      <th>rthh_g</th>\n",
              "      <th>rtbus_g</th>\n",
              "      <th>ltrate</th>\n",
              "      <th>stir</th>\n",
              "      <th>crisisJST</th>\n",
              "      <th>cid</th>\n",
              "      <th>precrisis</th>\n",
              "      <th>stfilt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1871</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-1.538437</td>\n",
              "      <td>2.914825</td>\n",
              "      <td>2.486658</td>\n",
              "      <td>11.144013</td>\n",
              "      <td>-3.194398</td>\n",
              "      <td>-6.603148</td>\n",
              "      <td>-3.054001</td>\n",
              "      <td>-0.372684</td>\n",
              "      <td>6.761506</td>\n",
              "      <td>6.761506</td>\n",
              "      <td>-0.598348</td>\n",
              "      <td>4.844633</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1872</td>\n",
              "      <td>AUS</td>\n",
              "      <td>-4.687499</td>\n",
              "      <td>12.773495</td>\n",
              "      <td>3.459822</td>\n",
              "      <td>-19.227942</td>\n",
              "      <td>-3.375740</td>\n",
              "      <td>21.243278</td>\n",
              "      <td>8.248763</td>\n",
              "      <td>8.966555</td>\n",
              "      <td>-12.667323</td>\n",
              "      <td>-12.667323</td>\n",
              "      <td>9.701529</td>\n",
              "      <td>4.737350</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1873</td>\n",
              "      <td>AUS</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.211961</td>\n",
              "      <td>-4.144906</td>\n",
              "      <td>-7.893106</td>\n",
              "      <td>-0.076511</td>\n",
              "      <td>15.630000</td>\n",
              "      <td>-3.076923</td>\n",
              "      <td>17.122282</td>\n",
              "      <td>-7.210884</td>\n",
              "      <td>-7.210884</td>\n",
              "      <td>17.780394</td>\n",
              "      <td>4.671958</td>\n",
              "      <td>4.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1874</td>\n",
              "      <td>AUS</td>\n",
              "      <td>4.918032</td>\n",
              "      <td>2.836231</td>\n",
              "      <td>-1.934752</td>\n",
              "      <td>36.182827</td>\n",
              "      <td>1.328401</td>\n",
              "      <td>0.564219</td>\n",
              "      <td>14.980159</td>\n",
              "      <td>4.202308</td>\n",
              "      <td>0.203905</td>\n",
              "      <td>0.203905</td>\n",
              "      <td>4.287503</td>\n",
              "      <td>4.653317</td>\n",
              "      <td>4.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1875</td>\n",
              "      <td>AUS</td>\n",
              "      <td>3.124987</td>\n",
              "      <td>1.407157</td>\n",
              "      <td>-2.629759</td>\n",
              "      <td>20.257614</td>\n",
              "      <td>6.963422</td>\n",
              "      <td>1.566073</td>\n",
              "      <td>-3.030291</td>\n",
              "      <td>8.468565</td>\n",
              "      <td>5.760547</td>\n",
              "      <td>5.760547</td>\n",
              "      <td>8.524006</td>\n",
              "      <td>4.507325</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1645</td>\n",
              "      <td>2012</td>\n",
              "      <td>USA</td>\n",
              "      <td>2.088378</td>\n",
              "      <td>1.977832</td>\n",
              "      <td>-2.751995</td>\n",
              "      <td>4.270833</td>\n",
              "      <td>-0.870406</td>\n",
              "      <td>12.054405</td>\n",
              "      <td>-2.106521</td>\n",
              "      <td>1.090211</td>\n",
              "      <td>-1.425487</td>\n",
              "      <td>-1.229252</td>\n",
              "      <td>5.772191</td>\n",
              "      <td>1.802500</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1646</td>\n",
              "      <td>2013</td>\n",
              "      <td>USA</td>\n",
              "      <td>1.452713</td>\n",
              "      <td>1.839598</td>\n",
              "      <td>-2.553377</td>\n",
              "      <td>1.098901</td>\n",
              "      <td>-0.281498</td>\n",
              "      <td>25.283465</td>\n",
              "      <td>5.860038</td>\n",
              "      <td>1.552922</td>\n",
              "      <td>0.393632</td>\n",
              "      <td>-0.278504</td>\n",
              "      <td>5.005061</td>\n",
              "      <td>2.350830</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1647</td>\n",
              "      <td>2014</td>\n",
              "      <td>USA</td>\n",
              "      <td>1.636470</td>\n",
              "      <td>2.728901</td>\n",
              "      <td>-2.005692</td>\n",
              "      <td>1.976285</td>\n",
              "      <td>1.121094</td>\n",
              "      <td>11.805296</td>\n",
              "      <td>3.766884</td>\n",
              "      <td>3.880589</td>\n",
              "      <td>1.633363</td>\n",
              "      <td>1.445847</td>\n",
              "      <td>8.239024</td>\n",
              "      <td>2.540833</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1648</td>\n",
              "      <td>2015</td>\n",
              "      <td>USA</td>\n",
              "      <td>0.115009</td>\n",
              "      <td>3.857580</td>\n",
              "      <td>-2.062812</td>\n",
              "      <td>-2.325581</td>\n",
              "      <td>3.254445</td>\n",
              "      <td>-0.124115</td>\n",
              "      <td>5.476484</td>\n",
              "      <td>7.237568</td>\n",
              "      <td>6.575875</td>\n",
              "      <td>5.619048</td>\n",
              "      <td>9.953044</td>\n",
              "      <td>2.135833</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1649</td>\n",
              "      <td>2016</td>\n",
              "      <td>USA</td>\n",
              "      <td>1.263642</td>\n",
              "      <td>1.497679</td>\n",
              "      <td>-2.333502</td>\n",
              "      <td>4.960317</td>\n",
              "      <td>3.626093</td>\n",
              "      <td>8.009177</td>\n",
              "      <td>4.339013</td>\n",
              "      <td>5.178080</td>\n",
              "      <td>5.581981</td>\n",
              "      <td>4.680563</td>\n",
              "      <td>5.979889</td>\n",
              "      <td>1.841667</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1650 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      year  iso     cpi_g     rgdp_g    ca/gdp  debtgdp_g  tloansgdp_g  \\\n",
              "0     1871  AUS -1.538437   2.914825  2.486658  11.144013    -3.194398   \n",
              "1     1872  AUS -4.687499  12.773495  3.459822 -19.227942    -3.375740   \n",
              "2     1873  AUS  0.000000  17.211961 -4.144906  -7.893106    -0.076511   \n",
              "3     1874  AUS  4.918032   2.836231 -1.934752  36.182827     1.328401   \n",
              "4     1875  AUS  3.124987   1.407157 -2.629759  20.257614     6.963422   \n",
              "...    ...  ...       ...        ...       ...        ...          ...   \n",
              "1645  2012  USA  2.088378   1.977832 -2.751995   4.270833    -0.870406   \n",
              "1646  2013  USA  1.452713   1.839598 -2.553377   1.098901    -0.281498   \n",
              "1647  2014  USA  1.636470   2.728901 -2.005692   1.976285     1.121094   \n",
              "1648  2015  USA  0.115009   3.857580 -2.062812  -2.325581     3.254445   \n",
              "1649  2016  USA  1.263642   1.497679 -2.333502   4.960317     3.626093   \n",
              "\n",
              "          rsp_g      rhp_g  rtloans_g   rtmort_g     rthh_g    rtbus_g  \\\n",
              "0     -6.603148  -3.054001  -0.372684   6.761506   6.761506  -0.598348   \n",
              "1     21.243278   8.248763   8.966555 -12.667323 -12.667323   9.701529   \n",
              "2     15.630000  -3.076923  17.122282  -7.210884  -7.210884  17.780394   \n",
              "3      0.564219  14.980159   4.202308   0.203905   0.203905   4.287503   \n",
              "4      1.566073  -3.030291   8.468565   5.760547   5.760547   8.524006   \n",
              "...         ...        ...        ...        ...        ...        ...   \n",
              "1645  12.054405  -2.106521   1.090211  -1.425487  -1.229252   5.772191   \n",
              "1646  25.283465   5.860038   1.552922   0.393632  -0.278504   5.005061   \n",
              "1647  11.805296   3.766884   3.880589   1.633363   1.445847   8.239024   \n",
              "1648  -0.124115   5.476484   7.237568   6.575875   5.619048   9.953044   \n",
              "1649   8.009177   4.339013   5.178080   5.581981   4.680563   5.979889   \n",
              "\n",
              "        ltrate  stir  crisisJST  cid  precrisis  stfilt  \n",
              "0     4.844633  4.60          0    0          0       0  \n",
              "1     4.737350  4.60          0    0          0       0  \n",
              "2     4.671958  4.40          0    0          0       0  \n",
              "3     4.653317  4.50          0    0          0       0  \n",
              "4     4.507325  4.60          0    0          0       0  \n",
              "...        ...   ...        ...  ...        ...     ...  \n",
              "1645  1.802500  0.14          0   16          0       0  \n",
              "1646  2.350830  0.11          0   16          0       0  \n",
              "1647  2.540833  0.09          0   16          0       0  \n",
              "1648  2.135833  0.13          0   16          0       0  \n",
              "1649  1.841667  0.39          0   16          0       0  \n",
              "\n",
              "[1650 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcTrHUQNtap4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}